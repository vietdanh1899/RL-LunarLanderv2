Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
flatten (Flatten)            (None, 8)                 0
_________________________________________________________________
dense (Dense)                (None, 128)               1152
_________________________________________________________________
activation (Activation)      (None, 128)               0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               16512
_________________________________________________________________
activation_1 (Activation)    (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 516
_________________________________________________________________
activation_2 (Activation)    (None, 4)                 0
=================================================================
Total params: 18,180
Trainable params: 18,180
Non-trainable params: 0
_________________________________________________________________
None
C:\Users\nguye\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  warnings.warn('`Model.state_updates` will be removed in a future version. '
C:\Users\nguye\anaconda3\lib\site-packages\rl\memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!
  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')
Training for 300000 steps ...
    116/300000: episode: 1, duration: 1.062s, episode steps: 116, steps per second: 109, episode reward: -185.076, mean reward: -1.595 [-100.000, 38.204], mean action: 1.509 [0.000, 3.000],  loss: 0.351594, mae: 0.836370, mean_q: 0.183592, mean_eps: 0.999811
    188/300000: episode: 2, duration: 0.447s, episode steps:  72, steps per second: 161, episode reward: -101.336, mean reward: -1.407 [-100.000,  8.306], mean action: 1.139 [0.000, 3.000],  loss: 26.708036, mae: 1.255218, mean_q: -0.100171, mean_eps: 0.999545
    256/300000: episode: 3, duration: 0.409s, episode steps:  68, steps per second: 166, episode reward: -134.081, mean reward: -1.972 [-100.000, 21.979], mean action: 1.676 [0.000, 3.000],  loss: 24.463712, mae: 1.380862, mean_q: 0.935737, mean_eps: 0.999335
    397/300000: episode: 4, duration: 0.862s, episode steps: 141, steps per second: 164, episode reward: -106.182, mean reward: -0.753 [-100.000, 50.658], mean action: 1.504 [0.000, 3.000],  loss: 25.022576, mae: 1.919771, mean_q: 2.680947, mean_eps: 0.999022
    466/300000: episode: 5, duration: 0.426s, episode steps:  69, steps per second: 162, episode reward: -228.195, mean reward: -3.307 [-100.000, 13.719], mean action: 1.812 [0.000, 3.000],  loss: 25.280459, mae: 3.043045, mean_q: 4.849423, mean_eps: 0.998707
    548/300000: episode: 6, duration: 0.523s, episode steps:  82, steps per second: 157, episode reward: -112.658, mean reward: -1.374 [-100.000, 17.122], mean action: 1.573 [0.000, 3.000],  loss: 40.858098, mae: 3.701685, mean_q: 5.680199, mean_eps: 0.998480
    655/300000: episode: 7, duration: 0.713s, episode steps: 107, steps per second: 150, episode reward: -120.438, mean reward: -1.126 [-100.000, 32.767], mean action: 1.551 [0.000, 3.000],  loss: 33.437474, mae: 4.752659, mean_q: 7.817463, mean_eps: 0.998197
    741/300000: episode: 8, duration: 0.589s, episode steps:  86, steps per second: 146, episode reward: -71.597, mean reward: -0.833 [-100.000, 32.765], mean action: 1.570 [0.000, 3.000],  loss: 59.210568, mae: 6.741323, mean_q: 11.340569, mean_eps: 0.997908
    829/300000: episode: 9, duration: 0.580s, episode steps:  88, steps per second: 152, episode reward: -110.467, mean reward: -1.255 [-100.000,  7.913], mean action: 1.545 [0.000, 3.000],  loss: 47.908497, mae: 8.521872, mean_q: 14.353024, mean_eps: 0.997646
    949/300000: episode: 10, duration: 0.905s, episode steps: 120, steps per second: 133, episode reward: -240.566, mean reward: -2.005 [-100.000,  6.094], mean action: 1.358 [0.000, 3.000],  loss: 85.989391, mae: 11.548555, mean_q: 18.670086, mean_eps: 0.997334
   1079/300000: episode: 11, duration: 0.998s, episode steps: 130, steps per second: 130, episode reward: -4.894, mean reward: -0.038 [-100.000, 111.878], mean action: 1.631 [0.000, 3.000],  loss: 111.372553, mae: 13.826548, mean_q: 21.717695, mean_eps: 0.996959
   1184/300000: episode: 12, duration: 0.715s, episode steps: 105, steps per second: 147, episode reward: -393.807, mean reward: -3.751 [-100.000,  1.531], mean action: 1.571 [0.000, 3.000],  loss: 129.345973, mae: 15.794267, mean_q: 24.153894, mean_eps: 0.996607
   1278/300000: episode: 13, duration: 0.798s, episode steps:  94, steps per second: 118, episode reward: -60.007, mean reward: -0.638 [-100.000, 11.697], mean action: 1.383 [0.000, 3.000],  loss: 145.781568, mae: 19.372671, mean_q: 29.119267, mean_eps: 0.996308
   1347/300000: episode: 14, duration: 0.576s, episode steps:  69, steps per second: 120, episode reward: -137.212, mean reward: -1.989 [-100.000,  7.354], mean action: 1.493 [0.000, 3.000],  loss: 185.979725, mae: 21.622695, mean_q: 32.470658, mean_eps: 0.996064
   1486/300000: episode: 15, duration: 0.980s, episode steps: 139, steps per second: 142, episode reward: -129.767, mean reward: -0.934 [-100.000, 11.113], mean action: 1.540 [0.000, 3.000],  loss: 166.250191, mae: 23.579899, mean_q: 34.700713, mean_eps: 0.995752
   1607/300000: episode: 16, duration: 0.987s, episode steps: 121, steps per second: 123, episode reward: -478.531, mean reward: -3.955 [-100.000,  1.340], mean action: 1.521 [0.000, 3.000],  loss: 182.928126, mae: 28.155119, mean_q: 40.923680, mean_eps: 0.995362
   1689/300000: episode: 17, duration: 0.672s, episode steps:  82, steps per second: 122, episode reward: -266.796, mean reward: -3.254 [-100.000,  4.380], mean action: 1.573 [0.000, 3.000],  loss: 141.741553, mae: 31.241199, mean_q: 44.404244, mean_eps: 0.995057
   1789/300000: episode: 18, duration: 0.787s, episode steps: 100, steps per second: 127, episode reward: -218.033, mean reward: -2.180 [-100.000, 71.588], mean action: 1.570 [0.000, 3.000],  loss: 252.011414, mae: 33.217575, mean_q: 47.489373, mean_eps: 0.994785
   1847/300000: episode: 19, duration: 0.509s, episode steps:  58, steps per second: 114, episode reward: -141.082, mean reward: -2.432 [-100.000,  7.425], mean action: 1.569 [0.000, 3.000],  loss: 239.171437, mae: 35.358531, mean_q: 50.248482, mean_eps: 0.994547
   1910/300000: episode: 20, duration: 0.445s, episode steps:  63, steps per second: 142, episode reward: -74.044, mean reward: -1.175 [-100.000,  7.356], mean action: 1.524 [0.000, 3.000],  loss: 285.388829, mae: 36.808500, mean_q: 52.071969, mean_eps: 0.994366
   2002/300000: episode: 21, duration: 0.542s, episode steps:  92, steps per second: 170, episode reward: -362.239, mean reward: -3.937 [-100.000,  4.653], mean action: 1.446 [0.000, 3.000],  loss: 250.102989, mae: 40.163921, mean_q: 56.397430, mean_eps: 0.994133
   2115/300000: episode: 22, duration: 0.764s, episode steps: 113, steps per second: 148, episode reward: -117.584, mean reward: -1.041 [-100.000, 23.979], mean action: 1.389 [0.000, 3.000],  loss: 323.226519, mae: 41.674261, mean_q: 58.347524, mean_eps: 0.993826
   2179/300000: episode: 23, duration: 0.429s, episode steps:  64, steps per second: 149, episode reward: -84.256, mean reward: -1.316 [-100.000,  7.958], mean action: 1.281 [0.000, 3.000],  loss: 241.259270, mae: 43.300786, mean_q: 60.459725, mean_eps: 0.993561
   2284/300000: episode: 24, duration: 0.638s, episode steps: 105, steps per second: 165, episode reward: -262.522, mean reward: -2.500 [-100.000, 26.246], mean action: 1.448 [0.000, 3.000],  loss: 167.795263, mae: 45.733361, mean_q: 63.729302, mean_eps: 0.993307
   2395/300000: episode: 25, duration: 0.778s, episode steps: 111, steps per second: 143, episode reward: -210.145, mean reward: -1.893 [-100.000,  6.660], mean action: 1.730 [0.000, 3.000],  loss: 141.844667, mae: 47.442609, mean_q: 65.671724, mean_eps: 0.992983
   2463/300000: episode: 26, duration: 0.448s, episode steps:  68, steps per second: 152, episode reward: -122.584, mean reward: -1.803 [-100.000,  9.723], mean action: 1.397 [0.000, 3.000],  loss: 169.072333, mae: 50.589415, mean_q: 69.636843, mean_eps: 0.992715
   2569/300000: episode: 27, duration: 0.793s, episode steps: 106, steps per second: 134, episode reward: -314.386, mean reward: -2.966 [-100.000,  0.868], mean action: 1.509 [0.000, 3.000],  loss: 208.081274, mae: 51.763552, mean_q: 71.162774, mean_eps: 0.992454
   2680/300000: episode: 28, duration: 0.708s, episode steps: 111, steps per second: 157, episode reward: -112.249, mean reward: -1.011 [-100.000, 17.255], mean action: 1.568 [0.000, 3.000],  loss: 165.191218, mae: 54.420289, mean_q: 74.878205, mean_eps: 0.992128
   2768/300000: episode: 29, duration: 0.515s, episode steps:  88, steps per second: 171, episode reward: -419.816, mean reward: -4.771 [-100.000, -0.279], mean action: 1.489 [0.000, 3.000],  loss: 153.614254, mae: 55.177409, mean_q: 75.568769, mean_eps: 0.991830
   2861/300000: episode: 30, duration: 0.563s, episode steps:  93, steps per second: 165, episode reward: -122.936, mean reward: -1.322 [-100.000, 12.659], mean action: 1.591 [0.000, 3.000],  loss: 156.835018, mae: 57.051702, mean_q: 77.838147, mean_eps: 0.991558
   2977/300000: episode: 31, duration: 0.691s, episode steps: 116, steps per second: 168, episode reward: -128.851, mean reward: -1.111 [-100.000,  7.241], mean action: 1.362 [0.000, 3.000],  loss: 172.158626, mae: 58.884068, mean_q: 80.172342, mean_eps: 0.991245
   3059/300000: episode: 32, duration: 0.511s, episode steps:  82, steps per second: 160, episode reward: -88.219, mean reward: -1.076 [-100.000, 12.100], mean action: 1.585 [0.000, 3.000],  loss: 165.234287, mae: 61.626585, mean_q: 83.740643, mean_eps: 0.990947
   3158/300000: episode: 33, duration: 0.591s, episode steps:  99, steps per second: 168, episode reward: -468.049, mean reward: -4.728 [-100.000,  0.563], mean action: 1.384 [0.000, 3.000],  loss: 124.802551, mae: 59.984764, mean_q: 81.926450, mean_eps: 0.990676
   3219/300000: episode: 34, duration: 0.378s, episode steps:  61, steps per second: 161, episode reward: -124.553, mean reward: -2.042 [-100.000,  9.442], mean action: 1.361 [0.000, 3.000],  loss: 122.754005, mae: 60.712609, mean_q: 81.846090, mean_eps: 0.990436
   3331/300000: episode: 35, duration: 0.671s, episode steps: 112, steps per second: 167, episode reward: -97.924, mean reward: -0.874 [-100.000, 14.325], mean action: 1.420 [0.000, 3.000],  loss: 151.535198, mae: 63.097084, mean_q: 85.358343, mean_eps: 0.990176
   3420/300000: episode: 36, duration: 0.521s, episode steps:  89, steps per second: 171, episode reward: -115.740, mean reward: -1.300 [-100.000, 15.673], mean action: 1.472 [0.000, 3.000],  loss: 107.459609, mae: 66.023221, mean_q: 89.284116, mean_eps: 0.989875
   3527/300000: episode: 37, duration: 0.635s, episode steps: 107, steps per second: 169, episode reward: -193.370, mean reward: -1.807 [-100.000, 65.670], mean action: 1.607 [0.000, 3.000],  loss: 109.104892, mae: 64.901166, mean_q: 86.770235, mean_eps: 0.989581
   3641/300000: episode: 38, duration: 0.716s, episode steps: 114, steps per second: 159, episode reward: -123.491, mean reward: -1.083 [-100.000,  5.442], mean action: 1.377 [0.000, 3.000],  loss: 121.723855, mae: 66.874832, mean_q: 88.559324, mean_eps: 0.989249
   3753/300000: episode: 39, duration: 0.665s, episode steps: 112, steps per second: 168, episode reward: -201.187, mean reward: -1.796 [-100.000,  5.941], mean action: 1.509 [0.000, 3.000],  loss: 90.931885, mae: 68.549821, mean_q: 90.850911, mean_eps: 0.988911
   3835/300000: episode: 40, duration: 0.483s, episode steps:  82, steps per second: 170, episode reward: -66.811, mean reward: -0.815 [-100.000, 16.314], mean action: 1.610 [0.000, 3.000],  loss: 86.086228, mae: 68.387149, mean_q: 90.521757, mean_eps: 0.988619
   3897/300000: episode: 41, duration: 0.368s, episode steps:  62, steps per second: 168, episode reward: -72.457, mean reward: -1.169 [-100.000, 17.650], mean action: 1.452 [0.000, 3.000],  loss: 94.809570, mae: 73.328239, mean_q: 96.502142, mean_eps: 0.988403
   3979/300000: episode: 42, duration: 0.515s, episode steps:  82, steps per second: 159, episode reward: -98.756, mean reward: -1.204 [-100.000,  6.750], mean action: 1.610 [0.000, 3.000],  loss: 90.131200, mae: 72.063832, mean_q: 94.423118, mean_eps: 0.988187
   4088/300000: episode: 43, duration: 0.685s, episode steps: 109, steps per second: 159, episode reward: -355.912, mean reward: -3.265 [-100.000,  5.585], mean action: 1.486 [0.000, 3.000],  loss: 72.955552, mae: 74.134830, mean_q: 96.979576, mean_eps: 0.987901
   4234/300000: episode: 44, duration: 0.869s, episode steps: 146, steps per second: 168, episode reward: -95.871, mean reward: -0.657 [-100.000, 10.691], mean action: 1.479 [0.000, 3.000],  loss: 74.272013, mae: 75.244594, mean_q: 97.262526, mean_eps: 0.987519
   4305/300000: episode: 45, duration: 0.449s, episode steps:  71, steps per second: 158, episode reward: -101.744, mean reward: -1.433 [-100.000,  7.526], mean action: 1.493 [0.000, 3.000],  loss: 39.809655, mae: 75.138183, mean_q: 97.522283, mean_eps: 0.987193
   4397/300000: episode: 46, duration: 0.596s, episode steps:  92, steps per second: 154, episode reward: -347.112, mean reward: -3.773 [-100.000,  0.358], mean action: 1.543 [0.000, 3.000],  loss: 46.315504, mae: 75.772973, mean_q: 97.170289, mean_eps: 0.986949
   4463/300000: episode: 47, duration: 0.418s, episode steps:  66, steps per second: 158, episode reward: -330.980, mean reward: -5.015 [-100.000,  2.387], mean action: 1.652 [0.000, 3.000],  loss: 39.209099, mae: 76.458533, mean_q: 98.568866, mean_eps: 0.986711
   4560/300000: episode: 48, duration: 0.627s, episode steps:  97, steps per second: 155, episode reward: -400.819, mean reward: -4.132 [-100.000,  0.838], mean action: 1.464 [0.000, 3.000],  loss: 52.802074, mae: 76.749848, mean_q: 98.028996, mean_eps: 0.986467
   4659/300000: episode: 49, duration: 0.651s, episode steps:  99, steps per second: 152, episode reward: -75.085, mean reward: -0.758 [-100.000, 44.758], mean action: 1.354 [0.000, 3.000],  loss: 49.039916, mae: 76.213216, mean_q: 97.130207, mean_eps: 0.986173
   4780/300000: episode: 50, duration: 0.753s, episode steps: 121, steps per second: 161, episode reward: -169.282, mean reward: -1.399 [-100.000, 29.219], mean action: 1.471 [0.000, 3.000],  loss: 48.900441, mae: 77.415215, mean_q: 97.917099, mean_eps: 0.985843
   4870/300000: episode: 51, duration: 0.558s, episode steps:  90, steps per second: 161, episode reward: -152.183, mean reward: -1.691 [-100.000,  7.545], mean action: 1.511 [0.000, 3.000],  loss: 36.516789, mae: 76.455697, mean_q: 96.704930, mean_eps: 0.985526
   4980/300000: episode: 52, duration: 0.756s, episode steps: 110, steps per second: 146, episode reward: -142.602, mean reward: -1.296 [-100.000,  6.192], mean action: 1.564 [0.000, 3.000],  loss: 46.740261, mae: 75.780873, mean_q: 95.324758, mean_eps: 0.985227
   5096/300000: episode: 53, duration: 0.756s, episode steps: 116, steps per second: 153, episode reward: -111.851, mean reward: -0.964 [-100.000,  9.550], mean action: 1.431 [0.000, 3.000],  loss: 53.402489, mae: 77.562445, mean_q: 97.940378, mean_eps: 0.984888
   5163/300000: episode: 54, duration: 0.408s, episode steps:  67, steps per second: 164, episode reward: -101.809, mean reward: -1.520 [-100.000,  9.243], mean action: 1.493 [0.000, 3.000],  loss: 30.438320, mae: 80.860049, mean_q: 99.869068, mean_eps: 0.984613
   5275/300000: episode: 55, duration: 0.693s, episode steps: 112, steps per second: 162, episode reward: -98.580, mean reward: -0.880 [-100.000,  8.264], mean action: 1.491 [0.000, 3.000],  loss: 56.179914, mae: 80.606391, mean_q: 99.728880, mean_eps: 0.984344
   5335/300000: episode: 56, duration: 0.376s, episode steps:  60, steps per second: 160, episode reward: -108.275, mean reward: -1.805 [-100.000,  5.000], mean action: 1.733 [0.000, 3.000],  loss: 62.690593, mae: 81.882786, mean_q: 100.801717, mean_eps: 0.984086
   5446/300000: episode: 57, duration: 0.676s, episode steps: 111, steps per second: 164, episode reward: -116.488, mean reward: -1.049 [-100.000, 12.992], mean action: 1.495 [0.000, 3.000],  loss: 37.871749, mae: 82.593927, mean_q: 103.334434, mean_eps: 0.983830
   5524/300000: episode: 58, duration: 0.469s, episode steps:  78, steps per second: 166, episode reward: -339.441, mean reward: -4.352 [-100.000, 61.577], mean action: 1.577 [0.000, 3.000],  loss: 45.525039, mae: 82.918411, mean_q: 101.958090, mean_eps: 0.983546
   5625/300000: episode: 59, duration: 0.630s, episode steps: 101, steps per second: 160, episode reward: -302.178, mean reward: -2.992 [-100.000,  0.955], mean action: 1.525 [0.000, 3.000],  loss: 54.294228, mae: 83.912897, mean_q: 103.451671, mean_eps: 0.983278
   5750/300000: episode: 60, duration: 0.763s, episode steps: 125, steps per second: 164, episode reward: -436.471, mean reward: -3.492 [-100.000,  5.334], mean action: 1.608 [0.000, 3.000],  loss: 54.054766, mae: 85.531369, mean_q: 105.834937, mean_eps: 0.982939
   5850/300000: episode: 61, duration: 0.595s, episode steps: 100, steps per second: 168, episode reward: -355.438, mean reward: -3.554 [-100.000, -0.039], mean action: 1.440 [0.000, 3.000],  loss: 48.774858, mae: 88.043380, mean_q: 110.687140, mean_eps: 0.982602
   5908/300000: episode: 62, duration: 0.363s, episode steps:  58, steps per second: 160, episode reward: -116.986, mean reward: -2.017 [-100.000,  8.761], mean action: 1.259 [0.000, 3.000],  loss: 44.126981, mae: 86.854620, mean_q: 110.140334, mean_eps: 0.982364
   6046/300000: episode: 63, duration: 0.860s, episode steps: 138, steps per second: 160, episode reward: -141.156, mean reward: -1.023 [-100.000, 18.340], mean action: 1.601 [0.000, 3.000],  loss: 41.927894, mae: 87.988665, mean_q: 108.059842, mean_eps: 0.982071
   6121/300000: episode: 64, duration: 0.473s, episode steps:  75, steps per second: 158, episode reward: -253.138, mean reward: -3.375 [-100.000,  5.945], mean action: 1.333 [0.000, 3.000],  loss: 41.083353, mae: 89.290684, mean_q: 110.823055, mean_eps: 0.981751
   6183/300000: episode: 65, duration: 0.385s, episode steps:  62, steps per second: 161, episode reward: -91.985, mean reward: -1.484 [-100.000,  7.382], mean action: 1.597 [0.000, 3.000],  loss: 55.547267, mae: 90.529093, mean_q: 112.539661, mean_eps: 0.981545
   6248/300000: episode: 66, duration: 0.413s, episode steps:  65, steps per second: 157, episode reward: -285.925, mean reward: -4.399 [-100.000, 38.805], mean action: 1.200 [0.000, 3.000],  loss: 36.200094, mae: 91.952703, mean_q: 114.191036, mean_eps: 0.981355
   6376/300000: episode: 67, duration: 0.929s, episode steps: 128, steps per second: 138, episode reward: -190.146, mean reward: -1.486 [-100.000,  6.335], mean action: 1.680 [0.000, 3.000],  loss: 53.877582, mae: 92.675011, mean_q: 114.561939, mean_eps: 0.981066
   6520/300000: episode: 68, duration: 0.948s, episode steps: 144, steps per second: 152, episode reward: -227.731, mean reward: -1.581 [-100.000,  6.311], mean action: 1.507 [0.000, 3.000],  loss: 46.001220, mae: 92.444679, mean_q: 112.560681, mean_eps: 0.980657
   6625/300000: episode: 69, duration: 0.807s, episode steps: 105, steps per second: 130, episode reward:  8.261, mean reward:  0.079 [-100.000, 103.461], mean action: 1.600 [0.000, 3.000],  loss: 39.679223, mae: 92.298551, mean_q: 112.762407, mean_eps: 0.980284
   6711/300000: episode: 70, duration: 0.778s, episode steps:  86, steps per second: 111, episode reward: -167.730, mean reward: -1.950 [-100.000, 24.471], mean action: 1.419 [0.000, 3.000],  loss: 29.899050, mae: 91.746192, mean_q: 111.775383, mean_eps: 0.979998
   6797/300000: episode: 71, duration: 0.734s, episode steps:  86, steps per second: 117, episode reward: -314.927, mean reward: -3.662 [-100.000,  3.626], mean action: 1.628 [0.000, 3.000],  loss: 46.224141, mae: 92.591217, mean_q: 113.007826, mean_eps: 0.979739
   6882/300000: episode: 72, duration: 0.668s, episode steps:  85, steps per second: 127, episode reward: -117.506, mean reward: -1.382 [-100.000, 12.311], mean action: 1.776 [0.000, 3.000],  loss: 45.693783, mae: 93.957745, mean_q: 114.210759, mean_eps: 0.979483
   6978/300000: episode: 73, duration: 0.691s, episode steps:  96, steps per second: 139, episode reward: -426.527, mean reward: -4.443 [-100.000,  0.007], mean action: 1.490 [0.000, 3.000],  loss: 43.539331, mae: 92.421426, mean_q: 111.070376, mean_eps: 0.979211
   7059/300000: episode: 74, duration: 0.521s, episode steps:  81, steps per second: 155, episode reward: -137.678, mean reward: -1.700 [-100.000,  8.377], mean action: 1.346 [0.000, 3.000],  loss: 45.556289, mae: 93.889554, mean_q: 112.840820, mean_eps: 0.978946
   7121/300000: episode: 75, duration: 0.383s, episode steps:  62, steps per second: 162, episode reward: -95.438, mean reward: -1.539 [-100.000, 12.355], mean action: 1.661 [0.000, 3.000],  loss: 38.288064, mae: 93.961806, mean_q: 111.644089, mean_eps: 0.978731
   7209/300000: episode: 76, duration: 0.612s, episode steps:  88, steps per second: 144, episode reward: -335.596, mean reward: -3.814 [-100.000, -0.374], mean action: 1.523 [0.000, 3.000],  loss: 47.979972, mae: 93.749544, mean_q: 111.992412, mean_eps: 0.978507
   7312/300000: episode: 77, duration: 0.734s, episode steps: 103, steps per second: 140, episode reward: -81.241, mean reward: -0.789 [-100.000,  8.959], mean action: 1.524 [0.000, 3.000],  loss: 47.905365, mae: 93.785094, mean_q: 111.586262, mean_eps: 0.978220
   7417/300000: episode: 78, duration: 0.647s, episode steps: 105, steps per second: 162, episode reward: -187.136, mean reward: -1.782 [-100.000, 11.215], mean action: 1.495 [0.000, 3.000],  loss: 41.623544, mae: 94.312841, mean_q: 111.841733, mean_eps: 0.977908
   7509/300000: episode: 79, duration: 0.593s, episode steps:  92, steps per second: 155, episode reward: -379.031, mean reward: -4.120 [-100.000, 70.211], mean action: 1.576 [0.000, 3.000],  loss: 39.375013, mae: 93.548268, mean_q: 109.624664, mean_eps: 0.977612
   7577/300000: episode: 80, duration: 0.496s, episode steps:  68, steps per second: 137, episode reward: -96.656, mean reward: -1.421 [-100.000, 14.752], mean action: 1.647 [0.000, 3.000],  loss: 24.806430, mae: 93.756511, mean_q: 109.818408, mean_eps: 0.977373
   7663/300000: episode: 81, duration: 0.559s, episode steps:  86, steps per second: 154, episode reward: -81.183, mean reward: -0.944 [-100.000,  7.199], mean action: 1.477 [0.000, 3.000],  loss: 42.346456, mae: 93.947980, mean_q: 110.064909, mean_eps: 0.977141
   7798/300000: episode: 82, duration: 0.844s, episode steps: 135, steps per second: 160, episode reward: -16.073, mean reward: -0.119 [-100.000, 68.279], mean action: 1.474 [0.000, 3.000],  loss: 38.974412, mae: 94.253673, mean_q: 110.497718, mean_eps: 0.976810
   7901/300000: episode: 83, duration: 0.684s, episode steps: 103, steps per second: 150, episode reward: -435.019, mean reward: -4.223 [-100.000, -0.067], mean action: 1.641 [0.000, 3.000],  loss: 46.182394, mae: 91.542767, mean_q: 105.088524, mean_eps: 0.976453
   7974/300000: episode: 84, duration: 0.487s, episode steps:  73, steps per second: 150, episode reward: -86.765, mean reward: -1.189 [-100.000, 12.328], mean action: 1.438 [0.000, 3.000],  loss: 43.035623, mae: 91.259705, mean_q: 104.952162, mean_eps: 0.976189
   8042/300000: episode: 85, duration: 0.436s, episode steps:  68, steps per second: 156, episode reward: -66.623, mean reward: -0.980 [-100.000,  8.468], mean action: 1.588 [0.000, 3.000],  loss: 30.305577, mae: 91.533710, mean_q: 105.580660, mean_eps: 0.975978
   8141/300000: episode: 86, duration: 0.670s, episode steps:  99, steps per second: 148, episode reward: -137.390, mean reward: -1.388 [-100.000,  6.276], mean action: 1.263 [0.000, 3.000],  loss: 34.583740, mae: 91.584804, mean_q: 107.134398, mean_eps: 0.975727
   8206/300000: episode: 87, duration: 0.500s, episode steps:  65, steps per second: 130, episode reward: -96.336, mean reward: -1.482 [-100.000, 35.704], mean action: 1.431 [0.000, 3.000],  loss: 32.644525, mae: 89.902870, mean_q: 103.562750, mean_eps: 0.975481
   8299/300000: episode: 88, duration: 0.641s, episode steps:  93, steps per second: 145, episode reward: -364.922, mean reward: -3.924 [-100.000,  0.570], mean action: 1.409 [0.000, 3.000],  loss: 26.037674, mae: 89.552966, mean_q: 103.031936, mean_eps: 0.975244
   8380/300000: episode: 89, duration: 0.515s, episode steps:  81, steps per second: 157, episode reward: -156.446, mean reward: -1.931 [-100.000,  8.466], mean action: 1.568 [0.000, 3.000],  loss: 34.194526, mae: 87.860085, mean_q: 99.592079, mean_eps: 0.974983
   8514/300000: episode: 90, duration: 0.911s, episode steps: 134, steps per second: 147, episode reward: -187.633, mean reward: -1.400 [-100.000,  9.874], mean action: 1.410 [0.000, 3.000],  loss: 28.390734, mae: 88.343523, mean_q: 100.992418, mean_eps: 0.974661
   8631/300000: episode: 91, duration: 0.758s, episode steps: 117, steps per second: 154, episode reward: -212.740, mean reward: -1.818 [-100.000,  7.965], mean action: 1.752 [0.000, 3.000],  loss: 23.203398, mae: 89.402475, mean_q: 103.592334, mean_eps: 0.974284
   8765/300000: episode: 92, duration: 0.822s, episode steps: 134, steps per second: 163, episode reward: -218.427, mean reward: -1.630 [-100.000, 29.251], mean action: 1.552 [0.000, 3.000],  loss: 31.409530, mae: 88.225734, mean_q: 101.553944, mean_eps: 0.973907
   8884/300000: episode: 93, duration: 0.775s, episode steps: 119, steps per second: 153, episode reward: -65.408, mean reward: -0.550 [-100.000, 13.891], mean action: 1.521 [0.000, 3.000],  loss: 31.178819, mae: 87.109370, mean_q: 100.333406, mean_eps: 0.973528
   8947/300000: episode: 94, duration: 0.443s, episode steps:  63, steps per second: 142, episode reward: -271.719, mean reward: -4.313 [-100.000,  6.327], mean action: 1.794 [0.000, 3.000],  loss: 16.205287, mae: 89.172749, mean_q: 103.761671, mean_eps: 0.973255
   9029/300000: episode: 95, duration: 0.561s, episode steps:  82, steps per second: 146, episode reward: 33.569, mean reward:  0.409 [-100.000, 105.531], mean action: 1.610 [0.000, 3.000],  loss: 27.503204, mae: 88.401487, mean_q: 103.658597, mean_eps: 0.973037
   9137/300000: episode: 96, duration: 0.677s, episode steps: 108, steps per second: 159, episode reward: -195.083, mean reward: -1.806 [-100.000, 19.772], mean action: 1.435 [0.000, 3.000],  loss: 37.720392, mae: 86.127475, mean_q: 99.628916, mean_eps: 0.972753
   9202/300000: episode: 97, duration: 0.495s, episode steps:  65, steps per second: 131, episode reward: -159.961, mean reward: -2.461 [-100.000,  6.530], mean action: 1.569 [0.000, 3.000],  loss: 50.424226, mae: 85.379969, mean_q: 98.797497, mean_eps: 0.972493
   9317/300000: episode: 98, duration: 0.843s, episode steps: 115, steps per second: 136, episode reward: -105.209, mean reward: -0.915 [-100.000, 11.974], mean action: 1.626 [0.000, 3.000],  loss: 41.950869, mae: 84.508419, mean_q: 99.684116, mean_eps: 0.972223
   9417/300000: episode: 99, duration: 0.722s, episode steps: 100, steps per second: 138, episode reward: -121.192, mean reward: -1.212 [-100.000, 48.882], mean action: 1.650 [0.000, 3.000],  loss: 26.534951, mae: 84.176066, mean_q: 98.563149, mean_eps: 0.971900
   9517/300000: episode: 100, duration: 0.724s, episode steps: 100, steps per second: 138, episode reward: -106.141, mean reward: -1.061 [-100.000, 16.494], mean action: 1.530 [0.000, 3.000],  loss: 34.730029, mae: 83.640941, mean_q: 99.781761, mean_eps: 0.971601
   9603/300000: episode: 101, duration: 0.603s, episode steps:  86, steps per second: 143, episode reward: -119.571, mean reward: -1.390 [-100.000,  8.060], mean action: 1.465 [0.000, 3.000],  loss: 40.186662, mae: 82.452134, mean_q: 97.175057, mean_eps: 0.971321
   9675/300000: episode: 102, duration: 0.465s, episode steps:  72, steps per second: 155, episode reward: -71.674, mean reward: -0.995 [-100.000, 21.324], mean action: 1.486 [0.000, 3.000],  loss: 25.509318, mae: 83.253355, mean_q: 98.507371, mean_eps: 0.971085
   9767/300000: episode: 103, duration: 0.576s, episode steps:  92, steps per second: 160, episode reward: -384.927, mean reward: -4.184 [-100.000,  6.541], mean action: 1.207 [0.000, 3.000],  loss: 31.389369, mae: 82.205939, mean_q: 96.581010, mean_eps: 0.970838
   9911/300000: episode: 104, duration: 0.946s, episode steps: 144, steps per second: 152, episode reward: -325.524, mean reward: -2.261 [-100.000, 83.280], mean action: 1.507 [0.000, 3.000],  loss: 27.016838, mae: 82.426941, mean_q: 96.324346, mean_eps: 0.970485
   9996/300000: episode: 105, duration: 0.527s, episode steps:  85, steps per second: 161, episode reward: -144.270, mean reward: -1.697 [-100.000, 38.532], mean action: 1.506 [0.000, 3.000],  loss: 21.678807, mae: 82.317671, mean_q: 95.048000, mean_eps: 0.970141
  10099/300000: episode: 106, duration: 0.642s, episode steps: 103, steps per second: 160, episode reward: -202.210, mean reward: -1.963 [-100.000,  1.028], mean action: 1.670 [0.000, 3.000],  loss: 23.272843, mae: 81.017687, mean_q: 92.937798, mean_eps: 0.969859
  10211/300000: episode: 107, duration: 0.730s, episode steps: 112, steps per second: 153, episode reward: -128.239, mean reward: -1.145 [-100.000, 26.593], mean action: 1.446 [0.000, 3.000],  loss: 23.561610, mae: 80.889893, mean_q: 92.392971, mean_eps: 0.969537
  10310/300000: episode: 108, duration: 0.623s, episode steps:  99, steps per second: 159, episode reward: -226.412, mean reward: -2.287 [-100.000, 78.610], mean action: 1.566 [0.000, 3.000],  loss: 19.290467, mae: 81.962605, mean_q: 94.732939, mean_eps: 0.969220
  10381/300000: episode: 109, duration: 0.441s, episode steps:  71, steps per second: 161, episode reward: -96.366, mean reward: -1.357 [-100.000, 10.596], mean action: 1.507 [0.000, 3.000],  loss: 29.021139, mae: 81.686371, mean_q: 90.437456, mean_eps: 0.968965
  10462/300000: episode: 110, duration: 0.569s, episode steps:  81, steps per second: 142, episode reward: -103.513, mean reward: -1.278 [-100.000,  7.342], mean action: 1.580 [0.000, 3.000],  loss: 18.610413, mae: 80.895751, mean_q: 92.299779, mean_eps: 0.968737
  10582/300000: episode: 111, duration: 0.891s, episode steps: 120, steps per second: 135, episode reward: -355.955, mean reward: -2.966 [-100.000,  3.326], mean action: 1.650 [0.000, 3.000],  loss: 19.017620, mae: 80.468584, mean_q: 91.712568, mean_eps: 0.968435
  10679/300000: episode: 112, duration: 0.693s, episode steps:  97, steps per second: 140, episode reward: -201.387, mean reward: -2.076 [-100.000, 87.586], mean action: 1.485 [0.000, 3.000],  loss: 19.153488, mae: 80.593255, mean_q: 91.655879, mean_eps: 0.968110
  10768/300000: episode: 113, duration: 0.637s, episode steps:  89, steps per second: 140, episode reward: -123.142, mean reward: -1.384 [-100.000, 12.017], mean action: 1.607 [0.000, 3.000],  loss: 33.423956, mae: 78.581762, mean_q: 88.339691, mean_eps: 0.967831
  10866/300000: episode: 114, duration: 0.699s, episode steps:  98, steps per second: 140, episode reward: -128.732, mean reward: -1.314 [-100.000,  7.173], mean action: 1.347 [0.000, 3.000],  loss: 18.892090, mae: 81.264025, mean_q: 92.586890, mean_eps: 0.967550
  10955/300000: episode: 115, duration: 0.623s, episode steps:  89, steps per second: 143, episode reward: -142.584, mean reward: -1.602 [-100.000, 25.519], mean action: 1.539 [0.000, 3.000],  loss: 23.169841, mae: 77.312433, mean_q: 86.399029, mean_eps: 0.967270
  11035/300000: episode: 116, duration: 0.554s, episode steps:  80, steps per second: 144, episode reward: -72.088, mean reward: -0.901 [-100.000, 16.689], mean action: 1.613 [0.000, 3.000],  loss: 26.639761, mae: 77.181531, mean_q: 85.978830, mean_eps: 0.967017
  11114/300000: episode: 117, duration: 0.566s, episode steps:  79, steps per second: 140, episode reward: -110.968, mean reward: -1.405 [-100.000, 10.617], mean action: 1.557 [0.000, 3.000],  loss: 27.936745, mae: 77.576103, mean_q: 87.476969, mean_eps: 0.966778
  11215/300000: episode: 118, duration: 0.693s, episode steps: 101, steps per second: 146, episode reward: -271.991, mean reward: -2.693 [-100.000,  4.829], mean action: 1.594 [0.000, 3.000],  loss: 23.593405, mae: 77.556810, mean_q: 86.394739, mean_eps: 0.966508
  11294/300000: episode: 119, duration: 0.499s, episode steps:  79, steps per second: 158, episode reward: -100.654, mean reward: -1.274 [-100.000, 13.660], mean action: 1.430 [0.000, 3.000],  loss: 26.715170, mae: 76.010197, mean_q: 86.213072, mean_eps: 0.966238
  11389/300000: episode: 120, duration: 0.704s, episode steps:  95, steps per second: 135, episode reward: -98.964, mean reward: -1.042 [-100.000,  6.889], mean action: 1.674 [0.000, 3.000],  loss: 28.467184, mae: 76.704944, mean_q: 86.220237, mean_eps: 0.965977
  11532/300000: episode: 121, duration: 0.919s, episode steps: 143, steps per second: 156, episode reward: -158.467, mean reward: -1.108 [-100.000, 13.756], mean action: 1.469 [0.000, 3.000],  loss: 20.802265, mae: 76.694767, mean_q: 86.642264, mean_eps: 0.965620
  11672/300000: episode: 122, duration: 0.870s, episode steps: 140, steps per second: 161, episode reward: -131.781, mean reward: -0.941 [-100.000,  5.658], mean action: 1.714 [0.000, 3.000],  loss: 19.593871, mae: 76.559516, mean_q: 86.488489, mean_eps: 0.965196
  11735/300000: episode: 123, duration: 0.429s, episode steps:  63, steps per second: 147, episode reward: -63.409, mean reward: -1.006 [-100.000, 11.699], mean action: 1.238 [0.000, 3.000],  loss: 17.770543, mae: 75.951895, mean_q: 85.054867, mean_eps: 0.964891
  11850/300000: episode: 124, duration: 0.734s, episode steps: 115, steps per second: 157, episode reward: -229.007, mean reward: -1.991 [-100.000, 108.556], mean action: 1.478 [0.000, 3.000],  loss: 20.891478, mae: 74.532729, mean_q: 82.578076, mean_eps: 0.964624
  11936/300000: episode: 125, duration: 0.539s, episode steps:  86, steps per second: 160, episode reward: -122.224, mean reward: -1.421 [-100.000,  9.350], mean action: 1.477 [0.000, 3.000],  loss: 38.865132, mae: 76.253650, mean_q: 85.705085, mean_eps: 0.964322
  12059/300000: episode: 126, duration: 0.777s, episode steps: 123, steps per second: 158, episode reward: -121.651, mean reward: -0.989 [-100.000, 19.072], mean action: 1.504 [0.000, 3.000],  loss: 16.215137, mae: 74.625369, mean_q: 83.081439, mean_eps: 0.964009
  12123/300000: episode: 127, duration: 0.458s, episode steps:  64, steps per second: 140, episode reward: -71.520, mean reward: -1.117 [-100.000,  7.214], mean action: 1.656 [0.000, 3.000],  loss: 23.803278, mae: 72.764657, mean_q: 80.439559, mean_eps: 0.963728
  12245/300000: episode: 128, duration: 0.766s, episode steps: 122, steps per second: 159, episode reward: -112.482, mean reward: -0.922 [-100.000, 16.820], mean action: 1.467 [0.000, 3.000],  loss: 19.875287, mae: 73.371862, mean_q: 82.109525, mean_eps: 0.963449
  12334/300000: episode: 129, duration: 0.563s, episode steps:  89, steps per second: 158, episode reward: -151.364, mean reward: -1.701 [-100.000,  4.519], mean action: 1.596 [0.000, 3.000],  loss: 25.585608, mae: 73.761193, mean_q: 84.490304, mean_eps: 0.963133
  12427/300000: episode: 130, duration: 0.635s, episode steps:  93, steps per second: 146, episode reward: -100.686, mean reward: -1.083 [-100.000, 13.837], mean action: 1.484 [0.000, 3.000],  loss: 28.488958, mae: 74.005333, mean_q: 83.961069, mean_eps: 0.962860
  12543/300000: episode: 131, duration: 0.742s, episode steps: 116, steps per second: 156, episode reward: -117.425, mean reward: -1.012 [-100.000, 10.564], mean action: 1.483 [0.000, 3.000],  loss: 21.552922, mae: 73.790747, mean_q: 82.852065, mean_eps: 0.962546
  12620/300000: episode: 132, duration: 0.481s, episode steps:  77, steps per second: 160, episode reward: -138.763, mean reward: -1.802 [-100.000, 101.089], mean action: 1.649 [0.000, 3.000],  loss: 20.050811, mae: 71.882763, mean_q: 79.253505, mean_eps: 0.962257
  12708/300000: episode: 133, duration: 0.537s, episode steps:  88, steps per second: 164, episode reward: -400.282, mean reward: -4.549 [-100.000,  1.326], mean action: 1.341 [0.000, 3.000],  loss: 25.654681, mae: 73.114851, mean_q: 80.075401, mean_eps: 0.962009
  12772/300000: episode: 134, duration: 0.450s, episode steps:  64, steps per second: 142, episode reward: -55.264, mean reward: -0.863 [-100.000, 16.360], mean action: 1.375 [0.000, 3.000],  loss: 23.879896, mae: 72.996362, mean_q: 77.995337, mean_eps: 0.961782
  12863/300000: episode: 135, duration: 0.595s, episode steps:  91, steps per second: 153, episode reward: -431.101, mean reward: -4.737 [-100.000,  7.159], mean action: 1.582 [0.000, 3.000],  loss: 18.208542, mae: 72.818404, mean_q: 76.831405, mean_eps: 0.961549
  12950/300000: episode: 136, duration: 0.541s, episode steps:  87, steps per second: 161, episode reward: -314.422, mean reward: -3.614 [-100.000, 111.230], mean action: 1.471 [0.000, 3.000],  loss: 16.524613, mae: 70.372004, mean_q: 74.462531, mean_eps: 0.961282
  13046/300000: episode: 137, duration: 0.592s, episode steps:  96, steps per second: 162, episode reward: -340.268, mean reward: -3.544 [-100.000,  3.272], mean action: 1.625 [0.000, 3.000],  loss: 19.459431, mae: 70.293516, mean_q: 73.547492, mean_eps: 0.961008
  13137/300000: episode: 138, duration: 0.605s, episode steps:  91, steps per second: 150, episode reward: -158.625, mean reward: -1.743 [-100.000, 11.063], mean action: 1.593 [0.000, 3.000],  loss: 20.999892, mae: 69.359901, mean_q: 72.938423, mean_eps: 0.960727
  13195/300000: episode: 139, duration: 0.370s, episode steps:  58, steps per second: 157, episode reward: -73.158, mean reward: -1.261 [-100.000,  9.321], mean action: 1.466 [0.000, 3.000],  loss: 14.807014, mae: 68.097676, mean_q: 72.952999, mean_eps: 0.960503
  13301/300000: episode: 140, duration: 0.668s, episode steps: 106, steps per second: 159, episode reward: -112.710, mean reward: -1.063 [-100.000, 12.545], mean action: 1.594 [0.000, 3.000],  loss: 22.886832, mae: 68.472470, mean_q: 71.125414, mean_eps: 0.960257
  13398/300000: episode: 141, duration: 0.622s, episode steps:  97, steps per second: 156, episode reward: -221.946, mean reward: -2.288 [-100.000,  6.045], mean action: 1.701 [0.000, 3.000],  loss: 25.489794, mae: 67.922835, mean_q: 71.509522, mean_eps: 0.959953
  13493/300000: episode: 142, duration: 0.633s, episode steps:  95, steps per second: 150, episode reward: -141.038, mean reward: -1.485 [-100.000, 12.673], mean action: 1.695 [0.000, 3.000],  loss: 17.726717, mae: 67.528511, mean_q: 70.833369, mean_eps: 0.959665
  13582/300000: episode: 143, duration: 0.566s, episode steps:  89, steps per second: 157, episode reward: -124.768, mean reward: -1.402 [-100.000, 11.025], mean action: 1.618 [0.000, 3.000],  loss: 20.521581, mae: 66.402672, mean_q: 68.181880, mean_eps: 0.959389
  13682/300000: episode: 144, duration: 0.627s, episode steps: 100, steps per second: 160, episode reward: -244.239, mean reward: -2.442 [-100.000, 19.494], mean action: 1.510 [0.000, 3.000],  loss: 25.834635, mae: 66.587058, mean_q: 68.036037, mean_eps: 0.959106
  13793/300000: episode: 145, duration: 0.739s, episode steps: 111, steps per second: 150, episode reward: -358.349, mean reward: -3.228 [-100.000, 120.424], mean action: 1.541 [0.000, 3.000],  loss: 25.208736, mae: 66.268504, mean_q: 66.057838, mean_eps: 0.958789
  13863/300000: episode: 146, duration: 0.443s, episode steps:  70, steps per second: 158, episode reward: -158.525, mean reward: -2.265 [-100.000,  5.243], mean action: 1.371 [0.000, 3.000],  loss: 21.225140, mae: 65.779108, mean_q: 65.041975, mean_eps: 0.958518
  13956/300000: episode: 147, duration: 0.591s, episode steps:  93, steps per second: 157, episode reward: -151.404, mean reward: -1.628 [-100.000, 12.374], mean action: 1.398 [0.000, 3.000],  loss: 19.630379, mae: 64.800111, mean_q: 63.342338, mean_eps: 0.958273
  14055/300000: episode: 148, duration: 0.623s, episode steps:  99, steps per second: 159, episode reward: -372.143, mean reward: -3.759 [-100.000,  0.210], mean action: 1.596 [0.000, 3.000],  loss: 28.381049, mae: 65.910520, mean_q: 65.521896, mean_eps: 0.957985
  14176/300000: episode: 149, duration: 0.784s, episode steps: 121, steps per second: 154, episode reward: -328.444, mean reward: -2.714 [-100.000,  3.361], mean action: 1.529 [0.000, 3.000],  loss: 19.610614, mae: 64.828678, mean_q: 64.196478, mean_eps: 0.957655
  14282/300000: episode: 150, duration: 0.685s, episode steps: 106, steps per second: 155, episode reward: -197.485, mean reward: -1.863 [-100.000, 10.936], mean action: 1.623 [0.000, 3.000],  loss: 29.491397, mae: 65.237534, mean_q: 64.861499, mean_eps: 0.957314
  14380/300000: episode: 151, duration: 0.698s, episode steps:  98, steps per second: 140, episode reward: -364.963, mean reward: -3.724 [-100.000,  0.827], mean action: 1.459 [0.000, 3.000],  loss: 20.552744, mae: 65.581524, mean_q: 67.037649, mean_eps: 0.957009
  14493/300000: episode: 152, duration: 0.871s, episode steps: 113, steps per second: 130, episode reward: -338.976, mean reward: -3.000 [-100.000, 97.127], mean action: 1.496 [0.000, 3.000],  loss: 16.528068, mae: 64.881617, mean_q: 66.694385, mean_eps: 0.956692
  14621/300000: episode: 153, duration: 0.944s, episode steps: 128, steps per second: 136, episode reward: -123.510, mean reward: -0.965 [-100.000, 17.288], mean action: 1.570 [0.000, 3.000],  loss: 21.155040, mae: 65.422378, mean_q: 66.842776, mean_eps: 0.956330
  14713/300000: episode: 154, duration: 0.738s, episode steps:  92, steps per second: 125, episode reward: -135.984, mean reward: -1.478 [-100.000, 16.382], mean action: 1.511 [0.000, 3.000],  loss: 18.540792, mae: 64.812284, mean_q: 68.027845, mean_eps: 0.956000
  14843/300000: episode: 155, duration: 0.950s, episode steps: 130, steps per second: 137, episode reward: -122.777, mean reward: -0.944 [-100.000, 15.920], mean action: 1.485 [0.000, 3.000],  loss: 16.609460, mae: 64.510826, mean_q: 66.322890, mean_eps: 0.955668
  14941/300000: episode: 156, duration: 0.663s, episode steps:  98, steps per second: 148, episode reward: -109.845, mean reward: -1.121 [-100.000,  7.531], mean action: 1.622 [0.000, 3.000],  loss: 25.405381, mae: 65.231022, mean_q: 67.595849, mean_eps: 0.955325
  15014/300000: episode: 157, duration: 0.545s, episode steps:  73, steps per second: 134, episode reward: -95.539, mean reward: -1.309 [-100.000,  9.481], mean action: 1.479 [0.000, 3.000],  loss: 21.627998, mae: 63.696539, mean_q: 66.113408, mean_eps: 0.955069
  15105/300000: episode: 158, duration: 0.606s, episode steps:  91, steps per second: 150, episode reward: -114.901, mean reward: -1.263 [-100.000, 22.825], mean action: 1.560 [0.000, 3.000],  loss: 14.957715, mae: 63.049432, mean_q: 66.836434, mean_eps: 0.954823
  15208/300000: episode: 159, duration: 0.647s, episode steps: 103, steps per second: 159, episode reward: -207.443, mean reward: -2.014 [-100.000, 19.204], mean action: 1.592 [0.000, 3.000],  loss: 14.330088, mae: 64.162916, mean_q: 67.241571, mean_eps: 0.954532
  15295/300000: episode: 160, duration: 0.559s, episode steps:  87, steps per second: 156, episode reward: -371.822, mean reward: -4.274 [-100.000,  3.219], mean action: 1.253 [0.000, 3.000],  loss: 27.690673, mae: 63.441742, mean_q: 64.776569, mean_eps: 0.954247
  15386/300000: episode: 161, duration: 0.645s, episode steps:  91, steps per second: 141, episode reward: -222.653, mean reward: -2.447 [-100.000, 78.192], mean action: 1.505 [0.000, 3.000],  loss: 26.643118, mae: 64.070402, mean_q: 64.553190, mean_eps: 0.953980
  15466/300000: episode: 162, duration: 0.499s, episode steps:  80, steps per second: 160, episode reward: -76.311, mean reward: -0.954 [-100.000, 12.551], mean action: 1.650 [0.000, 3.000],  loss: 21.530669, mae: 63.103362, mean_q: 61.830883, mean_eps: 0.953723
  15531/300000: episode: 163, duration: 0.409s, episode steps:  65, steps per second: 159, episode reward: -298.508, mean reward: -4.592 [-100.000, 10.851], mean action: 1.292 [0.000, 3.000],  loss: 18.531787, mae: 62.573410, mean_q: 62.155591, mean_eps: 0.953506
  15610/300000: episode: 164, duration: 0.499s, episode steps:  79, steps per second: 158, episode reward: -202.926, mean reward: -2.569 [-100.000,  6.016], mean action: 1.392 [0.000, 3.000],  loss: 24.113646, mae: 63.385144, mean_q: 62.316828, mean_eps: 0.953290
  15717/300000: episode: 165, duration: 0.726s, episode steps: 107, steps per second: 147, episode reward: -345.968, mean reward: -3.233 [-100.000,  3.964], mean action: 1.729 [0.000, 3.000],  loss: 17.923718, mae: 62.078121, mean_q: 61.860472, mean_eps: 0.953011
  15856/300000: episode: 166, duration: 0.853s, episode steps: 139, steps per second: 163, episode reward: -353.861, mean reward: -2.546 [-100.000,  5.261], mean action: 1.353 [0.000, 3.000],  loss: 19.941404, mae: 61.781778, mean_q: 60.595430, mean_eps: 0.952642
  15916/300000: episode: 167, duration: 0.382s, episode steps:  60, steps per second: 157, episode reward: -95.670, mean reward: -1.595 [-100.000, 12.400], mean action: 1.533 [0.000, 3.000],  loss: 16.216782, mae: 63.249661, mean_q: 62.638553, mean_eps: 0.952343
  16008/300000: episode: 168, duration: 0.647s, episode steps:  92, steps per second: 142, episode reward: -259.719, mean reward: -2.823 [-100.000, 40.593], mean action: 1.500 [0.000, 3.000],  loss: 22.073746, mae: 61.993916, mean_q: 60.416004, mean_eps: 0.952115
  16112/300000: episode: 169, duration: 0.677s, episode steps: 104, steps per second: 154, episode reward: -184.461, mean reward: -1.774 [-100.000, 21.289], mean action: 1.346 [0.000, 3.000],  loss: 21.374070, mae: 61.243505, mean_q: 58.905947, mean_eps: 0.951821
  16210/300000: episode: 170, duration: 0.608s, episode steps:  98, steps per second: 161, episode reward: -112.835, mean reward: -1.151 [-100.000,  4.906], mean action: 1.684 [0.000, 3.000],  loss: 19.236414, mae: 61.058010, mean_q: 58.625951, mean_eps: 0.951518
  16320/300000: episode: 171, duration: 0.710s, episode steps: 110, steps per second: 155, episode reward: -251.956, mean reward: -2.291 [-100.000,  1.024], mean action: 1.536 [0.000, 3.000],  loss: 18.636740, mae: 59.666482, mean_q: 55.494379, mean_eps: 0.951207
  16420/300000: episode: 172, duration: 0.647s, episode steps: 100, steps per second: 155, episode reward: -136.686, mean reward: -1.367 [-100.000,  8.139], mean action: 1.590 [0.000, 3.000],  loss: 29.144425, mae: 60.957371, mean_q: 59.210065, mean_eps: 0.950891
  16506/300000: episode: 173, duration: 0.549s, episode steps:  86, steps per second: 157, episode reward: -129.093, mean reward: -1.501 [-100.000,  6.723], mean action: 1.256 [0.000, 3.000],  loss: 15.641797, mae: 60.214175, mean_q: 59.204022, mean_eps: 0.950613
  16589/300000: episode: 174, duration: 0.521s, episode steps:  83, steps per second: 159, episode reward: -100.904, mean reward: -1.216 [-100.000,  5.769], mean action: 1.554 [0.000, 3.000],  loss: 17.777769, mae: 59.741998, mean_q: 59.132888, mean_eps: 0.950359
  16691/300000: episode: 175, duration: 0.684s, episode steps: 102, steps per second: 149, episode reward: -146.743, mean reward: -1.439 [-100.000,  8.120], mean action: 1.510 [0.000, 3.000],  loss: 19.614163, mae: 60.754349, mean_q: 60.060717, mean_eps: 0.950081
  16769/300000: episode: 176, duration: 0.501s, episode steps:  78, steps per second: 156, episode reward: -226.748, mean reward: -2.907 [-100.000,  4.019], mean action: 1.718 [0.000, 3.000],  loss: 13.481935, mae: 60.015042, mean_q: 59.474692, mean_eps: 0.949811
  17769/300000: episode: 177, duration: 6.851s, episode steps: 1000, steps per second: 146, episode reward: 28.952, mean reward:  0.029 [-24.359, 105.165], mean action: 1.500 [0.000, 3.000],  loss: 18.503134, mae: 59.274619, mean_q: 57.486294, mean_eps: 0.948195
  17849/300000: episode: 178, duration: 0.508s, episode steps:  80, steps per second: 158, episode reward: -105.590, mean reward: -1.320 [-100.000, 10.413], mean action: 1.363 [0.000, 3.000],  loss: 12.843513, mae: 57.677034, mean_q: 53.790001, mean_eps: 0.946574
  17910/300000: episode: 179, duration: 0.388s, episode steps:  61, steps per second: 157, episode reward: -74.876, mean reward: -1.227 [-100.000,  8.732], mean action: 1.492 [0.000, 3.000],  loss: 15.834192, mae: 58.111317, mean_q: 54.551989, mean_eps: 0.946363
  18011/300000: episode: 180, duration: 0.672s, episode steps: 101, steps per second: 150, episode reward: -86.862, mean reward: -0.860 [-100.000, 18.463], mean action: 1.505 [0.000, 3.000],  loss: 16.796956, mae: 57.657711, mean_q: 54.080632, mean_eps: 0.946120
  18104/300000: episode: 181, duration: 0.583s, episode steps:  93, steps per second: 160, episode reward: -183.583, mean reward: -1.974 [-100.000,  7.151], mean action: 1.505 [0.000, 3.000],  loss: 16.984744, mae: 57.079349, mean_q: 53.369245, mean_eps: 0.945829
  18203/300000: episode: 182, duration: 0.626s, episode steps:  99, steps per second: 158, episode reward: -244.396, mean reward: -2.469 [-100.000,  6.988], mean action: 1.162 [0.000, 3.000],  loss: 20.173534, mae: 57.933046, mean_q: 53.617584, mean_eps: 0.945541
  18322/300000: episode: 183, duration: 0.941s, episode steps: 119, steps per second: 126, episode reward: -131.160, mean reward: -1.102 [-100.000,  8.462], mean action: 1.395 [0.000, 3.000],  loss: 25.259468, mae: 56.592107, mean_q: 54.179581, mean_eps: 0.945214
  18410/300000: episode: 184, duration: 0.577s, episode steps:  88, steps per second: 153, episode reward: -228.984, mean reward: -2.602 [-100.000,  5.496], mean action: 1.591 [0.000, 3.000],  loss: 18.867223, mae: 56.234811, mean_q: 53.711656, mean_eps: 0.944903
  18483/300000: episode: 185, duration: 0.462s, episode steps:  73, steps per second: 158, episode reward: -159.746, mean reward: -2.188 [-100.000,  5.503], mean action: 1.397 [0.000, 3.000],  loss: 23.203961, mae: 57.692386, mean_q: 54.022450, mean_eps: 0.944662
  18592/300000: episode: 186, duration: 0.731s, episode steps: 109, steps per second: 149, episode reward: -186.666, mean reward: -1.713 [-100.000, 114.149], mean action: 1.606 [0.000, 3.000],  loss: 24.311444, mae: 57.205899, mean_q: 53.866612, mean_eps: 0.944389
  18676/300000: episode: 187, duration: 0.539s, episode steps:  84, steps per second: 156, episode reward: -110.508, mean reward: -1.316 [-100.000, 16.399], mean action: 1.464 [0.000, 3.000],  loss: 20.273439, mae: 57.682320, mean_q: 53.812447, mean_eps: 0.944099
  18742/300000: episode: 188, duration: 0.425s, episode steps:  66, steps per second: 155, episode reward: -174.056, mean reward: -2.637 [-100.000,  4.846], mean action: 1.712 [0.000, 3.000],  loss: 22.074313, mae: 55.715448, mean_q: 50.444778, mean_eps: 0.943874
  18871/300000: episode: 189, duration: 0.805s, episode steps: 129, steps per second: 160, episode reward: -231.972, mean reward: -1.798 [-100.000,  8.622], mean action: 1.473 [0.000, 3.000],  loss: 23.207895, mae: 55.392593, mean_q: 48.622381, mean_eps: 0.943582
  18960/300000: episode: 190, duration: 0.608s, episode steps:  89, steps per second: 146, episode reward: -253.765, mean reward: -2.851 [-100.000,  7.070], mean action: 1.652 [0.000, 3.000],  loss: 21.405541, mae: 53.899675, mean_q: 48.007913, mean_eps: 0.943255
  19052/300000: episode: 191, duration: 0.583s, episode steps:  92, steps per second: 158, episode reward: -97.851, mean reward: -1.064 [-100.000,  8.370], mean action: 1.554 [0.000, 3.000],  loss: 23.519742, mae: 55.349678, mean_q: 48.447759, mean_eps: 0.942983
  19161/300000: episode: 192, duration: 0.684s, episode steps: 109, steps per second: 159, episode reward: -139.017, mean reward: -1.275 [-100.000,  6.790], mean action: 1.569 [0.000, 3.000],  loss: 22.936096, mae: 56.115071, mean_q: 49.861489, mean_eps: 0.942682
  19242/300000: episode: 193, duration: 0.548s, episode steps:  81, steps per second: 148, episode reward: -49.765, mean reward: -0.614 [-100.000, 11.940], mean action: 1.568 [0.000, 3.000],  loss: 23.083145, mae: 55.986874, mean_q: 50.179581, mean_eps: 0.942397
  19358/300000: episode: 194, duration: 0.773s, episode steps: 116, steps per second: 150, episode reward: -50.361, mean reward: -0.434 [-100.000, 20.852], mean action: 1.578 [0.000, 3.000],  loss: 25.166232, mae: 56.701154, mean_q: 51.132881, mean_eps: 0.942101
  19442/300000: episode: 195, duration: 0.536s, episode steps:  84, steps per second: 157, episode reward: -80.883, mean reward: -0.963 [-100.000, 12.765], mean action: 1.619 [0.000, 3.000],  loss: 21.840692, mae: 56.136878, mean_q: 48.649596, mean_eps: 0.941802
  19510/300000: episode: 196, duration: 0.441s, episode steps:  68, steps per second: 154, episode reward: -164.996, mean reward: -2.426 [-100.000,  6.813], mean action: 1.618 [0.000, 3.000],  loss: 14.904650, mae: 55.162220, mean_q: 45.943391, mean_eps: 0.941574
  19630/300000: episode: 197, duration: 0.787s, episode steps: 120, steps per second: 152, episode reward: -90.802, mean reward: -0.757 [-100.000,  8.712], mean action: 1.300 [0.000, 3.000],  loss: 19.713146, mae: 55.959660, mean_q: 47.584019, mean_eps: 0.941292
  19738/300000: episode: 198, duration: 0.690s, episode steps: 108, steps per second: 156, episode reward: -102.498, mean reward: -0.949 [-100.000,  8.127], mean action: 1.472 [0.000, 3.000],  loss: 14.549931, mae: 57.207985, mean_q: 50.400145, mean_eps: 0.940949
  19833/300000: episode: 199, duration: 0.617s, episode steps:  95, steps per second: 154, episode reward: -188.843, mean reward: -1.988 [-100.000,  7.333], mean action: 1.611 [0.000, 3.000],  loss: 21.736155, mae: 55.966769, mean_q: 50.117750, mean_eps: 0.940645
  19901/300000: episode: 200, duration: 0.440s, episode steps:  68, steps per second: 155, episode reward: -144.717, mean reward: -2.128 [-100.000,  6.330], mean action: 1.397 [0.000, 3.000],  loss: 20.627282, mae: 55.332876, mean_q: 48.905232, mean_eps: 0.940400
  19961/300000: episode: 201, duration: 0.412s, episode steps:  60, steps per second: 146, episode reward: -238.279, mean reward: -3.971 [-100.000, 44.679], mean action: 1.683 [0.000, 3.000],  loss: 18.024374, mae: 53.928097, mean_q: 47.391436, mean_eps: 0.940209
  20085/300000: episode: 202, duration: 0.787s, episode steps: 124, steps per second: 158, episode reward: -52.165, mean reward: -0.421 [-100.000, 10.772], mean action: 1.605 [0.000, 3.000],  loss: 20.373786, mae: 54.013382, mean_q: 44.741328, mean_eps: 0.939932
  20166/300000: episode: 203, duration: 0.519s, episode steps:  81, steps per second: 156, episode reward: -79.301, mean reward: -0.979 [-100.000, 10.736], mean action: 1.728 [0.000, 3.000],  loss: 16.629444, mae: 54.024865, mean_q: 44.717600, mean_eps: 0.939625
  20251/300000: episode: 204, duration: 0.571s, episode steps:  85, steps per second: 149, episode reward: -154.649, mean reward: -1.819 [-100.000, 23.318], mean action: 1.576 [0.000, 3.000],  loss: 17.568978, mae: 54.565817, mean_q: 46.263136, mean_eps: 0.939376
  20374/300000: episode: 205, duration: 0.795s, episode steps: 123, steps per second: 155, episode reward: -202.062, mean reward: -1.643 [-100.000,  5.475], mean action: 1.447 [0.000, 3.000],  loss: 23.109757, mae: 55.090933, mean_q: 46.507602, mean_eps: 0.939064
  20456/300000: episode: 206, duration: 0.566s, episode steps:  82, steps per second: 145, episode reward: -166.725, mean reward: -2.033 [-100.000, 11.514], mean action: 1.549 [0.000, 3.000],  loss: 19.541846, mae: 55.851091, mean_q: 47.826578, mean_eps: 0.938757
  20554/300000: episode: 207, duration: 0.907s, episode steps:  98, steps per second: 108, episode reward: -196.870, mean reward: -2.009 [-100.000,  6.067], mean action: 1.571 [0.000, 3.000],  loss: 14.349233, mae: 55.061375, mean_q: 46.698503, mean_eps: 0.938486
  20644/300000: episode: 208, duration: 0.726s, episode steps:  90, steps per second: 124, episode reward: -210.851, mean reward: -2.343 [-100.000, 30.534], mean action: 1.556 [0.000, 3.000],  loss: 14.453769, mae: 55.731424, mean_q: 47.623276, mean_eps: 0.938204
  20776/300000: episode: 209, duration: 0.930s, episode steps: 132, steps per second: 142, episode reward: -96.769, mean reward: -0.733 [-100.000,  7.205], mean action: 1.591 [0.000, 3.000],  loss: 16.391460, mae: 55.472538, mean_q: 47.661088, mean_eps: 0.937871
  20883/300000: episode: 210, duration: 0.771s, episode steps: 107, steps per second: 139, episode reward: -217.279, mean reward: -2.031 [-100.000, 29.966], mean action: 1.439 [0.000, 3.000],  loss: 23.652087, mae: 55.251052, mean_q: 50.221141, mean_eps: 0.937513
  20988/300000: episode: 211, duration: 0.694s, episode steps: 105, steps per second: 151, episode reward: -143.653, mean reward: -1.368 [-100.000, 62.715], mean action: 1.562 [0.000, 3.000],  loss: 19.998502, mae: 54.775576, mean_q: 49.159656, mean_eps: 0.937195
  21044/300000: episode: 212, duration: 0.374s, episode steps:  56, steps per second: 150, episode reward: -162.167, mean reward: -2.896 [-100.000,  6.077], mean action: 1.464 [0.000, 3.000],  loss: 19.477218, mae: 53.945814, mean_q: 48.077028, mean_eps: 0.936954
  21162/300000: episode: 213, duration: 0.796s, episode steps: 118, steps per second: 148, episode reward: -199.459, mean reward: -1.690 [-100.000,  6.225], mean action: 1.517 [0.000, 3.000],  loss: 18.845731, mae: 54.263363, mean_q: 46.537486, mean_eps: 0.936692
  21267/300000: episode: 214, duration: 0.674s, episode steps: 105, steps per second: 156, episode reward: -343.362, mean reward: -3.270 [-100.000,  1.784], mean action: 1.381 [0.000, 3.000],  loss: 19.743039, mae: 54.901576, mean_q: 46.854945, mean_eps: 0.936358
  21366/300000: episode: 215, duration: 0.630s, episode steps:  99, steps per second: 157, episode reward: -184.505, mean reward: -1.864 [-100.000, 33.986], mean action: 1.616 [0.000, 3.000],  loss: 17.339386, mae: 55.350493, mean_q: 48.495182, mean_eps: 0.936052
  21485/300000: episode: 216, duration: 0.792s, episode steps: 119, steps per second: 150, episode reward: -252.320, mean reward: -2.120 [-100.000, 104.810], mean action: 1.521 [0.000, 3.000],  loss: 15.276303, mae: 55.050125, mean_q: 46.888464, mean_eps: 0.935725
  21599/300000: episode: 217, duration: 0.750s, episode steps: 114, steps per second: 152, episode reward: -80.785, mean reward: -0.709 [-100.000, 11.592], mean action: 1.570 [0.000, 3.000],  loss: 16.482078, mae: 57.414267, mean_q: 52.787833, mean_eps: 0.935375
  21665/300000: episode: 218, duration: 0.410s, episode steps:  66, steps per second: 161, episode reward: -84.981, mean reward: -1.288 [-100.000, 13.121], mean action: 1.409 [0.000, 3.000],  loss: 15.144438, mae: 54.909350, mean_q: 48.658132, mean_eps: 0.935106
  21769/300000: episode: 219, duration: 0.672s, episode steps: 104, steps per second: 155, episode reward: -125.337, mean reward: -1.205 [-100.000, 35.592], mean action: 1.538 [0.000, 3.000],  loss: 24.332311, mae: 54.701815, mean_q: 51.757666, mean_eps: 0.934851
  21857/300000: episode: 220, duration: 0.611s, episode steps:  88, steps per second: 144, episode reward: -220.729, mean reward: -2.508 [-100.000, 27.251], mean action: 1.625 [0.000, 3.000],  loss: 14.210556, mae: 55.048247, mean_q: 49.491826, mean_eps: 0.934563
  21936/300000: episode: 221, duration: 0.510s, episode steps:  79, steps per second: 155, episode reward: -207.186, mean reward: -2.623 [-100.000,  4.212], mean action: 1.519 [0.000, 3.000],  loss: 16.619498, mae: 54.957144, mean_q: 52.168623, mean_eps: 0.934312
  22042/300000: episode: 222, duration: 0.679s, episode steps: 106, steps per second: 156, episode reward: -71.720, mean reward: -0.677 [-100.000, 14.152], mean action: 1.453 [0.000, 3.000],  loss: 20.120681, mae: 55.207587, mean_q: 50.395967, mean_eps: 0.934034
  22158/300000: episode: 223, duration: 0.755s, episode steps: 116, steps per second: 154, episode reward: -96.892, mean reward: -0.835 [-100.000, 47.864], mean action: 1.457 [0.000, 3.000],  loss: 18.990792, mae: 55.488623, mean_q: 51.525054, mean_eps: 0.933701
  22281/300000: episode: 224, duration: 0.786s, episode steps: 123, steps per second: 157, episode reward: -428.031, mean reward: -3.480 [-100.000,  5.024], mean action: 1.650 [0.000, 3.000],  loss: 20.511415, mae: 55.743285, mean_q: 51.663395, mean_eps: 0.933343
  22410/300000: episode: 225, duration: 0.831s, episode steps: 129, steps per second: 155, episode reward: -151.123, mean reward: -1.171 [-100.000,  3.887], mean action: 1.682 [0.000, 3.000],  loss: 17.480939, mae: 57.009688, mean_q: 54.727416, mean_eps: 0.932965
  22514/300000: episode: 226, duration: 0.704s, episode steps: 104, steps per second: 148, episode reward: -134.018, mean reward: -1.289 [-100.000, 18.270], mean action: 1.490 [0.000, 3.000],  loss: 18.258354, mae: 56.619938, mean_q: 54.288229, mean_eps: 0.932616
  22607/300000: episode: 227, duration: 0.598s, episode steps:  93, steps per second: 155, episode reward: -104.806, mean reward: -1.127 [-100.000,  6.981], mean action: 1.591 [0.000, 3.000],  loss: 21.757356, mae: 57.356758, mean_q: 56.523063, mean_eps: 0.932320
  22736/300000: episode: 228, duration: 0.800s, episode steps: 129, steps per second: 161, episode reward: -122.622, mean reward: -0.951 [-100.000,  9.299], mean action: 1.512 [0.000, 3.000],  loss: 16.581259, mae: 57.554068, mean_q: 56.698122, mean_eps: 0.931987
  22829/300000: episode: 229, duration: 0.616s, episode steps:  93, steps per second: 151, episode reward: -347.398, mean reward: -3.735 [-100.000,  0.645], mean action: 1.624 [0.000, 3.000],  loss: 19.466948, mae: 58.045814, mean_q: 56.265850, mean_eps: 0.931654
  22911/300000: episode: 230, duration: 0.550s, episode steps:  82, steps per second: 149, episode reward: -116.309, mean reward: -1.418 [-100.000, 18.359], mean action: 1.683 [0.000, 3.000],  loss: 25.004138, mae: 58.556775, mean_q: 55.271822, mean_eps: 0.931392
  23026/300000: episode: 231, duration: 0.736s, episode steps: 115, steps per second: 156, episode reward: -105.946, mean reward: -0.921 [-100.000, 12.113], mean action: 1.513 [0.000, 3.000],  loss: 22.140808, mae: 58.467492, mean_q: 54.815333, mean_eps: 0.931096
  23107/300000: episode: 232, duration: 0.504s, episode steps:  81, steps per second: 161, episode reward: -93.841, mean reward: -1.159 [-100.000, 49.295], mean action: 1.296 [0.000, 3.000],  loss: 30.236536, mae: 58.280614, mean_q: 55.892858, mean_eps: 0.930802
  23182/300000: episode: 233, duration: 0.497s, episode steps:  75, steps per second: 151, episode reward: -79.029, mean reward: -1.054 [-100.000, 16.901], mean action: 1.400 [0.000, 3.000],  loss: 22.229545, mae: 58.492991, mean_q: 57.828504, mean_eps: 0.930568
  23251/300000: episode: 234, duration: 0.454s, episode steps:  69, steps per second: 152, episode reward: -112.680, mean reward: -1.633 [-100.000,  7.637], mean action: 1.319 [0.000, 3.000],  loss: 20.312329, mae: 59.299242, mean_q: 58.650608, mean_eps: 0.930352
  23366/300000: episode: 235, duration: 0.737s, episode steps: 115, steps per second: 156, episode reward: -206.507, mean reward: -1.796 [-100.000, 15.985], mean action: 1.574 [0.000, 3.000],  loss: 18.580033, mae: 58.983005, mean_q: 55.457596, mean_eps: 0.930076
  23486/300000: episode: 236, duration: 0.780s, episode steps: 120, steps per second: 154, episode reward: -123.128, mean reward: -1.026 [-100.000,  4.448], mean action: 1.567 [0.000, 3.000],  loss: 20.493164, mae: 59.877722, mean_q: 59.213069, mean_eps: 0.929724
  23593/300000: episode: 237, duration: 0.691s, episode steps: 107, steps per second: 155, episode reward: -269.913, mean reward: -2.523 [-100.000,  3.823], mean action: 1.514 [0.000, 3.000],  loss: 26.168385, mae: 59.017249, mean_q: 57.921489, mean_eps: 0.929383
  23669/300000: episode: 238, duration: 0.486s, episode steps:  76, steps per second: 157, episode reward: -10.133, mean reward: -0.133 [-100.000, 60.783], mean action: 1.526 [0.000, 3.000],  loss: 23.824716, mae: 59.549904, mean_q: 58.385456, mean_eps: 0.929109
  23797/300000: episode: 239, duration: 0.812s, episode steps: 128, steps per second: 158, episode reward: -289.015, mean reward: -2.258 [-100.000,  1.457], mean action: 1.492 [0.000, 3.000],  loss: 22.811992, mae: 59.069873, mean_q: 58.064980, mean_eps: 0.928802
  23885/300000: episode: 240, duration: 0.617s, episode steps:  88, steps per second: 143, episode reward: -108.614, mean reward: -1.234 [-100.000, 16.276], mean action: 1.432 [0.000, 3.000],  loss: 18.424152, mae: 59.346288, mean_q: 59.358201, mean_eps: 0.928478
  24007/300000: episode: 241, duration: 0.776s, episode steps: 122, steps per second: 157, episode reward:  0.030, mean reward:  0.000 [-100.000, 109.638], mean action: 1.484 [0.000, 3.000],  loss: 20.692521, mae: 59.487380, mean_q: 59.067939, mean_eps: 0.928163
  24096/300000: episode: 242, duration: 0.548s, episode steps:  89, steps per second: 162, episode reward: -475.762, mean reward: -5.346 [-100.000, 44.351], mean action: 1.360 [0.000, 3.000],  loss: 25.273516, mae: 58.943011, mean_q: 59.640320, mean_eps: 0.927847
  24165/300000: episode: 243, duration: 0.485s, episode steps:  69, steps per second: 142, episode reward: -87.462, mean reward: -1.268 [-100.000, 12.741], mean action: 1.435 [0.000, 3.000],  loss: 23.731894, mae: 59.231217, mean_q: 59.697929, mean_eps: 0.927610
  24268/300000: episode: 244, duration: 0.766s, episode steps: 103, steps per second: 134, episode reward: -80.911, mean reward: -0.786 [-100.000, 14.959], mean action: 1.534 [0.000, 3.000],  loss: 26.013130, mae: 59.577612, mean_q: 60.642483, mean_eps: 0.927352
  24360/300000: episode: 245, duration: 0.701s, episode steps:  92, steps per second: 131, episode reward: -56.798, mean reward: -0.617 [-100.000,  6.448], mean action: 1.543 [0.000, 3.000],  loss: 22.890170, mae: 58.431107, mean_q: 60.654612, mean_eps: 0.927059
  24427/300000: episode: 246, duration: 0.552s, episode steps:  67, steps per second: 121, episode reward: -50.963, mean reward: -0.761 [-100.000,  8.188], mean action: 1.687 [0.000, 3.000],  loss: 29.182238, mae: 60.462588, mean_q: 63.896200, mean_eps: 0.926821
  24504/300000: episode: 247, duration: 0.572s, episode steps:  77, steps per second: 135, episode reward: -88.667, mean reward: -1.152 [-100.000,  8.864], mean action: 1.494 [0.000, 3.000],  loss: 34.809178, mae: 59.765553, mean_q: 63.379311, mean_eps: 0.926605
  24592/300000: episode: 248, duration: 0.633s, episode steps:  88, steps per second: 139, episode reward: -311.069, mean reward: -3.535 [-100.000, -0.331], mean action: 1.409 [0.000, 3.000],  loss: 23.632441, mae: 58.990890, mean_q: 62.742812, mean_eps: 0.926358
  24685/300000: episode: 249, duration: 0.662s, episode steps:  93, steps per second: 141, episode reward: -238.829, mean reward: -2.568 [-100.000, 23.898], mean action: 1.462 [0.000, 3.000],  loss: 23.549704, mae: 59.512227, mean_q: 62.824815, mean_eps: 0.926086
  24777/300000: episode: 250, duration: 0.696s, episode steps:  92, steps per second: 132, episode reward: -111.761, mean reward: -1.215 [-100.000, 10.642], mean action: 1.576 [0.000, 3.000],  loss: 25.521644, mae: 58.759560, mean_q: 60.871711, mean_eps: 0.925809
  24870/300000: episode: 251, duration: 0.644s, episode steps:  93, steps per second: 144, episode reward: -171.207, mean reward: -1.841 [-100.000, 39.357], mean action: 1.624 [0.000, 3.000],  loss: 25.529310, mae: 57.906222, mean_q: 58.358677, mean_eps: 0.925531
  24933/300000: episode: 252, duration: 0.406s, episode steps:  63, steps per second: 155, episode reward: -67.286, mean reward: -1.068 [-100.000, 11.105], mean action: 1.365 [0.000, 3.000],  loss: 19.957566, mae: 57.140531, mean_q: 56.473131, mean_eps: 0.925297
  25026/300000: episode: 253, duration: 0.624s, episode steps:  93, steps per second: 149, episode reward: -158.399, mean reward: -1.703 [-100.000,  6.163], mean action: 1.516 [0.000, 3.000],  loss: 15.713575, mae: 57.114553, mean_q: 57.428274, mean_eps: 0.925063
  25146/300000: episode: 254, duration: 0.809s, episode steps: 120, steps per second: 148, episode reward: -95.307, mean reward: -0.794 [-100.000,  6.986], mean action: 1.475 [0.000, 3.000],  loss: 20.508633, mae: 56.933632, mean_q: 55.708124, mean_eps: 0.924744
  25243/300000: episode: 255, duration: 0.615s, episode steps:  97, steps per second: 158, episode reward: -262.049, mean reward: -2.702 [-100.000,  6.752], mean action: 1.557 [0.000, 3.000],  loss: 27.476325, mae: 56.446134, mean_q: 54.784260, mean_eps: 0.924418
  25309/300000: episode: 256, duration: 0.426s, episode steps:  66, steps per second: 155, episode reward: -150.750, mean reward: -2.284 [-100.000, 57.572], mean action: 1.712 [0.000, 3.000],  loss: 19.893701, mae: 57.206889, mean_q: 55.986980, mean_eps: 0.924173
  25416/300000: episode: 257, duration: 0.714s, episode steps: 107, steps per second: 150, episode reward: -86.914, mean reward: -0.812 [-100.000, 14.476], mean action: 1.533 [0.000, 3.000],  loss: 20.564214, mae: 56.471416, mean_q: 55.109490, mean_eps: 0.923914
  25550/300000: episode: 258, duration: 0.847s, episode steps: 134, steps per second: 158, episode reward: -173.427, mean reward: -1.294 [-100.000, 15.481], mean action: 1.575 [0.000, 3.000],  loss: 23.860129, mae: 56.068850, mean_q: 55.965132, mean_eps: 0.923552
  25643/300000: episode: 259, duration: 0.587s, episode steps:  93, steps per second: 158, episode reward: -276.399, mean reward: -2.972 [-100.000, 12.814], mean action: 1.538 [0.000, 3.000],  loss: 22.896409, mae: 55.480480, mean_q: 53.667339, mean_eps: 0.923212
  25745/300000: episode: 260, duration: 0.694s, episode steps: 102, steps per second: 147, episode reward: -124.786, mean reward: -1.223 [-100.000,  8.024], mean action: 1.578 [0.000, 3.000],  loss: 22.805934, mae: 54.476178, mean_q: 51.678053, mean_eps: 0.922920
  25864/300000: episode: 261, duration: 0.758s, episode steps: 119, steps per second: 157, episode reward: -200.213, mean reward: -1.682 [-100.000,  8.608], mean action: 1.588 [0.000, 3.000],  loss: 27.980721, mae: 55.437639, mean_q: 55.597175, mean_eps: 0.922588
  25940/300000: episode: 262, duration: 0.477s, episode steps:  76, steps per second: 159, episode reward: -59.687, mean reward: -0.785 [-100.000, 18.313], mean action: 1.553 [0.000, 3.000],  loss: 20.851525, mae: 55.413770, mean_q: 54.597773, mean_eps: 0.922296
  26054/300000: episode: 263, duration: 0.784s, episode steps: 114, steps per second: 145, episode reward: -107.557, mean reward: -0.943 [-100.000, 15.234], mean action: 1.684 [0.000, 3.000],  loss: 17.884332, mae: 56.376503, mean_q: 55.773035, mean_eps: 0.922010
  26145/300000: episode: 264, duration: 0.598s, episode steps:  91, steps per second: 152, episode reward: -78.431, mean reward: -0.862 [-100.000, 10.477], mean action: 1.637 [0.000, 3.000],  loss: 19.963496, mae: 57.103308, mean_q: 58.257723, mean_eps: 0.921703
  26283/300000: episode: 265, duration: 0.852s, episode steps: 138, steps per second: 162, episode reward: -114.717, mean reward: -0.831 [-100.000,  9.592], mean action: 1.435 [0.000, 3.000],  loss: 19.751511, mae: 57.497764, mean_q: 57.976366, mean_eps: 0.921359
  26352/300000: episode: 266, duration: 0.436s, episode steps:  69, steps per second: 158, episode reward: -87.804, mean reward: -1.273 [-100.000,  7.597], mean action: 1.348 [0.000, 3.000],  loss: 21.796711, mae: 58.678024, mean_q: 59.919717, mean_eps: 0.921049
  26473/300000: episode: 267, duration: 0.822s, episode steps: 121, steps per second: 147, episode reward: -113.848, mean reward: -0.941 [-100.000, 13.422], mean action: 1.645 [0.000, 3.000],  loss: 21.364818, mae: 57.035214, mean_q: 56.995617, mean_eps: 0.920764
  26549/300000: episode: 268, duration: 0.484s, episode steps:  76, steps per second: 157, episode reward: -132.143, mean reward: -1.739 [-100.000,  9.092], mean action: 1.618 [0.000, 3.000],  loss: 22.472502, mae: 57.229126, mean_q: 57.255046, mean_eps: 0.920469
  26618/300000: episode: 269, duration: 0.429s, episode steps:  69, steps per second: 161, episode reward: -74.477, mean reward: -1.079 [-100.000,  9.491], mean action: 1.623 [0.000, 3.000],  loss: 24.813896, mae: 56.877765, mean_q: 57.340040, mean_eps: 0.920251
  26716/300000: episode: 270, duration: 0.642s, episode steps:  98, steps per second: 153, episode reward: -159.368, mean reward: -1.626 [-100.000, 14.801], mean action: 1.592 [0.000, 3.000],  loss: 23.870831, mae: 56.236601, mean_q: 57.840128, mean_eps: 0.920000
  26830/300000: episode: 271, duration: 0.746s, episode steps: 114, steps per second: 153, episode reward: -311.466, mean reward: -2.732 [-100.000, 28.316], mean action: 1.377 [0.000, 3.000],  loss: 24.388957, mae: 55.953193, mean_q: 56.638583, mean_eps: 0.919682
  26956/300000: episode: 272, duration: 0.786s, episode steps: 126, steps per second: 160, episode reward: -225.317, mean reward: -1.788 [-100.000, 38.784], mean action: 1.603 [0.000, 3.000],  loss: 32.636551, mae: 55.864274, mean_q: 55.660678, mean_eps: 0.919323
  27042/300000: episode: 273, duration: 0.570s, episode steps:  86, steps per second: 151, episode reward: -120.353, mean reward: -1.399 [-100.000, 18.827], mean action: 1.581 [0.000, 3.000],  loss: 13.854354, mae: 56.129218, mean_q: 55.675754, mean_eps: 0.919004
  27164/300000: episode: 274, duration: 0.812s, episode steps: 122, steps per second: 150, episode reward: -118.323, mean reward: -0.970 [-100.000,  9.200], mean action: 1.574 [0.000, 3.000],  loss: 15.934085, mae: 55.714462, mean_q: 55.706030, mean_eps: 0.918692
  27279/300000: episode: 275, duration: 0.713s, episode steps: 115, steps per second: 161, episode reward: -297.662, mean reward: -2.588 [-100.000, 103.423], mean action: 1.513 [0.000, 3.000],  loss: 20.233336, mae: 56.183037, mean_q: 55.793514, mean_eps: 0.918337
  27387/300000: episode: 276, duration: 0.690s, episode steps: 108, steps per second: 157, episode reward: -153.269, mean reward: -1.419 [-100.000,  9.362], mean action: 1.509 [0.000, 3.000],  loss: 26.420220, mae: 57.009755, mean_q: 56.948934, mean_eps: 0.918003
  27512/300000: episode: 277, duration: 0.845s, episode steps: 125, steps per second: 148, episode reward: -110.237, mean reward: -0.882 [-100.000, 12.598], mean action: 1.536 [0.000, 3.000],  loss: 23.405491, mae: 56.874174, mean_q: 58.743452, mean_eps: 0.917653
  27612/300000: episode: 278, duration: 0.624s, episode steps: 100, steps per second: 160, episode reward: -97.890, mean reward: -0.979 [-100.000, 12.466], mean action: 1.630 [0.000, 3.000],  loss: 21.886112, mae: 56.609264, mean_q: 57.379269, mean_eps: 0.917315
  27720/300000: episode: 279, duration: 0.700s, episode steps: 108, steps per second: 154, episode reward: -77.170, mean reward: -0.715 [-100.000, 16.515], mean action: 1.722 [0.000, 3.000],  loss: 22.008463, mae: 56.976873, mean_q: 59.253756, mean_eps: 0.917004
  27802/300000: episode: 280, duration: 0.547s, episode steps:  82, steps per second: 150, episode reward: -90.178, mean reward: -1.100 [-100.000,  9.938], mean action: 1.500 [0.000, 3.000],  loss: 21.013533, mae: 57.483425, mean_q: 59.096959, mean_eps: 0.916718
  27881/300000: episode: 281, duration: 0.503s, episode steps:  79, steps per second: 157, episode reward: -104.839, mean reward: -1.327 [-100.000,  8.073], mean action: 1.696 [0.000, 3.000],  loss: 21.615795, mae: 57.276576, mean_q: 59.596994, mean_eps: 0.916477
  27980/300000: episode: 282, duration: 0.641s, episode steps:  99, steps per second: 154, episode reward: -136.345, mean reward: -1.377 [-100.000,  6.304], mean action: 1.354 [0.000, 3.000],  loss: 23.396683, mae: 57.569520, mean_q: 59.828989, mean_eps: 0.916210
  28108/300000: episode: 283, duration: 0.855s, episode steps: 128, steps per second: 150, episode reward: -141.701, mean reward: -1.107 [-100.000,  4.875], mean action: 1.531 [0.000, 3.000],  loss: 23.504751, mae: 56.798916, mean_q: 58.148860, mean_eps: 0.915870
  28208/300000: episode: 284, duration: 0.653s, episode steps: 100, steps per second: 153, episode reward: -261.715, mean reward: -2.617 [-100.000, 13.753], mean action: 1.420 [0.000, 3.000],  loss: 26.243998, mae: 56.663020, mean_q: 58.334359, mean_eps: 0.915527
  28342/300000: episode: 285, duration: 0.838s, episode steps: 134, steps per second: 160, episode reward: -333.698, mean reward: -2.490 [-100.000, 112.202], mean action: 1.470 [0.000, 3.000],  loss: 23.598246, mae: 57.844529, mean_q: 58.885190, mean_eps: 0.915176
  28450/300000: episode: 286, duration: 0.737s, episode steps: 108, steps per second: 147, episode reward: -105.993, mean reward: -0.981 [-100.000,  6.897], mean action: 1.611 [0.000, 3.000],  loss: 19.930338, mae: 57.649136, mean_q: 58.683461, mean_eps: 0.914814
  28556/300000: episode: 287, duration: 0.715s, episode steps: 106, steps per second: 148, episode reward: -295.684, mean reward: -2.789 [-100.000,  6.473], mean action: 1.679 [0.000, 3.000],  loss: 27.020797, mae: 58.375682, mean_q: 58.553958, mean_eps: 0.914493
  28652/300000: episode: 288, duration: 0.606s, episode steps:  96, steps per second: 158, episode reward: -110.544, mean reward: -1.151 [-100.000,  9.961], mean action: 1.594 [0.000, 3.000],  loss: 22.993330, mae: 58.835268, mean_q: 60.620353, mean_eps: 0.914189
  28724/300000: episode: 289, duration: 0.488s, episode steps:  72, steps per second: 148, episode reward: -85.723, mean reward: -1.191 [-100.000,  7.951], mean action: 1.472 [0.000, 3.000],  loss: 27.865540, mae: 59.266271, mean_q: 62.242378, mean_eps: 0.913937
  28855/300000: episode: 290, duration: 0.856s, episode steps: 131, steps per second: 153, episode reward: -122.380, mean reward: -0.934 [-100.000,  7.143], mean action: 1.489 [0.000, 3.000],  loss: 19.053576, mae: 58.818201, mean_q: 60.457803, mean_eps: 0.913633
  28999/300000: episode: 291, duration: 0.913s, episode steps: 144, steps per second: 158, episode reward: -102.799, mean reward: -0.714 [-100.000, 19.876], mean action: 1.514 [0.000, 3.000],  loss: 23.763852, mae: 58.805236, mean_q: 60.123818, mean_eps: 0.913221
  29076/300000: episode: 292, duration: 0.527s, episode steps:  77, steps per second: 146, episode reward: -113.327, mean reward: -1.472 [-100.000,  7.183], mean action: 1.325 [0.000, 3.000],  loss: 20.997051, mae: 59.057035, mean_q: 59.724906, mean_eps: 0.912889
  29151/300000: episode: 293, duration: 0.477s, episode steps:  75, steps per second: 157, episode reward: -34.474, mean reward: -0.460 [-100.000, 56.580], mean action: 1.467 [0.000, 3.000],  loss: 23.028503, mae: 58.790348, mean_q: 59.578577, mean_eps: 0.912661
  29249/300000: episode: 294, duration: 0.643s, episode steps:  98, steps per second: 152, episode reward: -114.054, mean reward: -1.164 [-100.000, 21.083], mean action: 1.388 [0.000, 3.000],  loss: 21.348296, mae: 58.682138, mean_q: 58.719866, mean_eps: 0.912402
  29350/300000: episode: 295, duration: 0.641s, episode steps: 101, steps per second: 158, episode reward: -153.076, mean reward: -1.516 [-100.000, 14.918], mean action: 1.287 [0.000, 3.000],  loss: 19.357193, mae: 58.334553, mean_q: 58.885517, mean_eps: 0.912103
  29433/300000: episode: 296, duration: 0.557s, episode steps:  83, steps per second: 149, episode reward: -108.743, mean reward: -1.310 [-100.000, 11.807], mean action: 1.410 [0.000, 3.000],  loss: 30.267133, mae: 58.646095, mean_q: 58.489889, mean_eps: 0.911827
  29544/300000: episode: 297, duration: 0.706s, episode steps: 111, steps per second: 157, episode reward: -239.367, mean reward: -2.156 [-100.000,  0.955], mean action: 1.550 [0.000, 3.000],  loss: 26.703167, mae: 58.265500, mean_q: 60.191387, mean_eps: 0.911536
  29650/300000: episode: 298, duration: 0.673s, episode steps: 106, steps per second: 157, episode reward: -179.100, mean reward: -1.690 [-100.000, 11.606], mean action: 1.491 [0.000, 3.000],  loss: 21.602973, mae: 57.915743, mean_q: 58.522627, mean_eps: 0.911211
  29763/300000: episode: 299, duration: 0.747s, episode steps: 113, steps per second: 151, episode reward: -96.993, mean reward: -0.858 [-100.000, 51.960], mean action: 1.637 [0.000, 3.000],  loss: 18.599333, mae: 58.676541, mean_q: 60.525784, mean_eps: 0.910882
  29855/300000: episode: 300, duration: 0.590s, episode steps:  92, steps per second: 156, episode reward: -0.402, mean reward: -0.004 [-100.000, 72.148], mean action: 1.576 [0.000, 3.000],  loss: 22.168215, mae: 57.916863, mean_q: 60.393798, mean_eps: 0.910575
  29979/300000: episode: 301, duration: 0.813s, episode steps: 124, steps per second: 153, episode reward: -94.065, mean reward: -0.759 [-100.000, 10.862], mean action: 1.556 [0.000, 3.000],  loss: 28.258762, mae: 58.485907, mean_q: 60.712472, mean_eps: 0.910251
  30060/300000: episode: 302, duration: 0.549s, episode steps:  81, steps per second: 148, episode reward: -190.714, mean reward: -2.354 [-100.000, 28.577], mean action: 1.506 [0.000, 3.000],  loss: 31.918729, mae: 59.299077, mean_q: 63.048491, mean_eps: 0.909943
  30169/300000: episode: 303, duration: 0.695s, episode steps: 109, steps per second: 157, episode reward: -141.962, mean reward: -1.302 [-100.000, 15.931], mean action: 1.505 [0.000, 3.000],  loss: 30.580628, mae: 60.740537, mean_q: 64.669192, mean_eps: 0.909658
  30256/300000: episode: 304, duration: 0.562s, episode steps:  87, steps per second: 155, episode reward: -184.541, mean reward: -2.121 [-100.000,  7.065], mean action: 1.575 [0.000, 3.000],  loss: 34.973371, mae: 61.861220, mean_q: 66.059830, mean_eps: 0.909364
  30344/300000: episode: 305, duration: 0.597s, episode steps:  88, steps per second: 147, episode reward: -126.761, mean reward: -1.440 [-100.000,  7.674], mean action: 1.466 [0.000, 3.000],  loss: 39.880051, mae: 62.072915, mean_q: 67.250463, mean_eps: 0.909102
  30436/300000: episode: 306, duration: 0.678s, episode steps:  92, steps per second: 136, episode reward: -90.958, mean reward: -0.989 [-100.000,  7.018], mean action: 1.576 [0.000, 3.000],  loss: 39.840014, mae: 62.225896, mean_q: 69.116912, mean_eps: 0.908831
  30532/300000: episode: 307, duration: 0.677s, episode steps:  96, steps per second: 142, episode reward: -134.392, mean reward: -1.400 [-100.000, 19.162], mean action: 1.562 [0.000, 3.000],  loss: 20.084488, mae: 61.897079, mean_q: 67.114077, mean_eps: 0.908550
  30625/300000: episode: 308, duration: 0.644s, episode steps:  93, steps per second: 144, episode reward: -108.750, mean reward: -1.169 [-100.000, 12.078], mean action: 1.591 [0.000, 3.000],  loss: 29.629041, mae: 62.691945, mean_q: 67.943344, mean_eps: 0.908266
  30711/300000: episode: 309, duration: 0.616s, episode steps:  86, steps per second: 140, episode reward: -83.530, mean reward: -0.971 [-100.000, 13.698], mean action: 1.512 [0.000, 3.000],  loss: 24.773724, mae: 62.146700, mean_q: 67.592759, mean_eps: 0.907998
  30846/300000: episode: 310, duration: 0.897s, episode steps: 135, steps per second: 150, episode reward: -134.282, mean reward: -0.995 [-100.000,  9.242], mean action: 1.541 [0.000, 3.000],  loss: 20.401022, mae: 63.910037, mean_q: 69.092733, mean_eps: 0.907666
  30920/300000: episode: 311, duration: 0.477s, episode steps:  74, steps per second: 155, episode reward: -107.678, mean reward: -1.455 [-100.000,  6.744], mean action: 1.257 [0.000, 3.000],  loss: 22.801636, mae: 64.346127, mean_q: 70.190588, mean_eps: 0.907352
  30976/300000: episode: 312, duration: 0.394s, episode steps:  56, steps per second: 142, episode reward: -143.949, mean reward: -2.571 [-100.000,  8.093], mean action: 1.571 [0.000, 3.000],  loss: 18.730552, mae: 64.471018, mean_q: 70.049851, mean_eps: 0.907158
  31074/300000: episode: 313, duration: 0.672s, episode steps:  98, steps per second: 146, episode reward: -332.773, mean reward: -3.396 [-100.000, 31.976], mean action: 1.439 [0.000, 3.000],  loss: 44.711619, mae: 65.038954, mean_q: 71.308730, mean_eps: 0.906926
  31181/300000: episode: 314, duration: 0.673s, episode steps: 107, steps per second: 159, episode reward: -78.361, mean reward: -0.732 [-100.000, 77.146], mean action: 1.467 [0.000, 3.000],  loss: 34.268950, mae: 65.348315, mean_q: 72.580757, mean_eps: 0.906619
  31272/300000: episode: 315, duration: 0.566s, episode steps:  91, steps per second: 161, episode reward: -77.339, mean reward: -0.850 [-100.000, 10.104], mean action: 1.560 [0.000, 3.000],  loss: 22.590497, mae: 65.418750, mean_q: 71.973028, mean_eps: 0.906322
  31340/300000: episode: 316, duration: 0.471s, episode steps:  68, steps per second: 144, episode reward: -120.436, mean reward: -1.771 [-100.000,  5.560], mean action: 1.250 [0.000, 3.000],  loss: 22.119340, mae: 64.897778, mean_q: 71.691714, mean_eps: 0.906083
  31415/300000: episode: 317, duration: 0.486s, episode steps:  75, steps per second: 154, episode reward: -204.673, mean reward: -2.729 [-100.000, 29.060], mean action: 1.400 [0.000, 3.000],  loss: 22.381128, mae: 66.830128, mean_q: 73.430463, mean_eps: 0.905869
  31526/300000: episode: 318, duration: 0.719s, episode steps: 111, steps per second: 154, episode reward: -284.642, mean reward: -2.564 [-100.000,  3.971], mean action: 1.541 [0.000, 3.000],  loss: 41.319733, mae: 67.431645, mean_q: 74.380141, mean_eps: 0.905590
  31618/300000: episode: 319, duration: 0.586s, episode steps:  92, steps per second: 157, episode reward: -63.793, mean reward: -0.693 [-100.000, 12.952], mean action: 1.587 [0.000, 3.000],  loss: 22.389673, mae: 68.195279, mean_q: 76.201915, mean_eps: 0.905285
  31684/300000: episode: 320, duration: 0.471s, episode steps:  66, steps per second: 140, episode reward: -85.946, mean reward: -1.302 [-100.000,  8.453], mean action: 1.485 [0.000, 3.000],  loss: 31.181635, mae: 68.106389, mean_q: 77.205437, mean_eps: 0.905048
  31785/300000: episode: 321, duration: 0.656s, episode steps: 101, steps per second: 154, episode reward: -159.782, mean reward: -1.582 [-100.000, 23.293], mean action: 1.465 [0.000, 3.000],  loss: 25.700448, mae: 68.668372, mean_q: 75.612774, mean_eps: 0.904798
  31860/300000: episode: 322, duration: 0.477s, episode steps:  75, steps per second: 157, episode reward: -91.499, mean reward: -1.220 [-100.000, 10.453], mean action: 1.373 [0.000, 3.000],  loss: 17.576002, mae: 67.638176, mean_q: 74.991791, mean_eps: 0.904534
  31930/300000: episode: 323, duration: 0.441s, episode steps:  70, steps per second: 159, episode reward: -73.487, mean reward: -1.050 [-100.000,  7.387], mean action: 1.414 [0.000, 3.000],  loss: 25.588772, mae: 67.924991, mean_q: 74.943708, mean_eps: 0.904316
  32010/300000: episode: 324, duration: 0.569s, episode steps:  80, steps per second: 141, episode reward: -66.366, mean reward: -0.830 [-100.000,  9.576], mean action: 1.625 [0.000, 3.000],  loss: 23.748641, mae: 68.632551, mean_q: 76.693814, mean_eps: 0.904092
  32087/300000: episode: 325, duration: 0.521s, episode steps:  77, steps per second: 148, episode reward: -144.664, mean reward: -1.879 [-100.000, 26.165], mean action: 1.442 [0.000, 3.000],  loss: 21.427760, mae: 68.184238, mean_q: 75.922715, mean_eps: 0.903856
  32196/300000: episode: 326, duration: 0.708s, episode steps: 109, steps per second: 154, episode reward: -234.903, mean reward: -2.155 [-100.000,  7.670], mean action: 1.505 [0.000, 3.000],  loss: 25.879386, mae: 68.063456, mean_q: 75.294485, mean_eps: 0.903577
  32256/300000: episode: 327, duration: 0.379s, episode steps:  60, steps per second: 158, episode reward: -105.459, mean reward: -1.758 [-100.000,  9.337], mean action: 1.300 [0.000, 3.000],  loss: 18.472067, mae: 68.488425, mean_q: 76.281862, mean_eps: 0.903324
  32351/300000: episode: 328, duration: 0.652s, episode steps:  95, steps per second: 146, episode reward: -193.834, mean reward: -2.040 [-100.000,  6.353], mean action: 1.642 [0.000, 3.000],  loss: 22.163725, mae: 68.429354, mean_q: 74.975221, mean_eps: 0.903091
  32427/300000: episode: 329, duration: 0.500s, episode steps:  76, steps per second: 152, episode reward: -113.341, mean reward: -1.491 [-100.000,  5.452], mean action: 1.395 [0.000, 3.000],  loss: 38.412592, mae: 68.202842, mean_q: 74.984401, mean_eps: 0.902835
  32527/300000: episode: 330, duration: 0.643s, episode steps: 100, steps per second: 156, episode reward: -136.974, mean reward: -1.370 [-100.000, 10.771], mean action: 1.490 [0.000, 3.000],  loss: 14.822358, mae: 68.134560, mean_q: 75.037808, mean_eps: 0.902571
  32597/300000: episode: 331, duration: 0.434s, episode steps:  70, steps per second: 161, episode reward: -95.825, mean reward: -1.369 [-100.000, 12.966], mean action: 1.600 [0.000, 3.000],  loss: 24.520736, mae: 68.179223, mean_q: 72.962640, mean_eps: 0.902315
  32668/300000: episode: 332, duration: 0.501s, episode steps:  71, steps per second: 142, episode reward: -120.640, mean reward: -1.699 [-100.000,  9.996], mean action: 1.268 [0.000, 3.000],  loss: 27.496692, mae: 67.989132, mean_q: 73.582596, mean_eps: 0.902104
  32770/300000: episode: 333, duration: 0.664s, episode steps: 102, steps per second: 154, episode reward: -183.093, mean reward: -1.795 [-100.000, 86.812], mean action: 1.392 [0.000, 3.000],  loss: 19.872462, mae: 68.032599, mean_q: 74.489714, mean_eps: 0.901844
  32905/300000: episode: 334, duration: 0.855s, episode steps: 135, steps per second: 158, episode reward: -67.192, mean reward: -0.498 [-100.000, 10.314], mean action: 1.637 [0.000, 3.000],  loss: 38.215690, mae: 67.132031, mean_q: 73.517734, mean_eps: 0.901489
  32975/300000: episode: 335, duration: 0.486s, episode steps:  70, steps per second: 144, episode reward: -120.350, mean reward: -1.719 [-100.000, 45.066], mean action: 1.657 [0.000, 3.000],  loss: 43.169560, mae: 67.596512, mean_q: 73.100562, mean_eps: 0.901181
  33069/300000: episode: 336, duration: 0.614s, episode steps:  94, steps per second: 153, episode reward: -63.024, mean reward: -0.670 [-100.000,  8.211], mean action: 1.585 [0.000, 3.000],  loss: 31.770314, mae: 68.475291, mean_q: 74.934083, mean_eps: 0.900936
  33159/300000: episode: 337, duration: 0.584s, episode steps:  90, steps per second: 154, episode reward: -95.053, mean reward: -1.056 [-100.000, 24.323], mean action: 1.556 [0.000, 3.000],  loss: 18.352703, mae: 69.005160, mean_q: 75.068000, mean_eps: 0.900659
  33256/300000: episode: 338, duration: 0.613s, episode steps:  97, steps per second: 158, episode reward: -208.190, mean reward: -2.146 [-100.000,  9.604], mean action: 1.577 [0.000, 3.000],  loss: 22.742843, mae: 69.222482, mean_q: 75.338753, mean_eps: 0.900379
  33347/300000: episode: 339, duration: 0.598s, episode steps:  91, steps per second: 152, episode reward: -240.635, mean reward: -2.644 [-100.000,  4.571], mean action: 1.549 [0.000, 3.000],  loss: 32.772515, mae: 68.674239, mean_q: 75.790093, mean_eps: 0.900097
  33431/300000: episode: 340, duration: 0.553s, episode steps:  84, steps per second: 152, episode reward: -127.720, mean reward: -1.520 [-100.000, 16.694], mean action: 1.488 [0.000, 3.000],  loss: 37.075054, mae: 68.512381, mean_q: 74.229149, mean_eps: 0.899835
  33548/300000: episode: 341, duration: 0.766s, episode steps: 117, steps per second: 153, episode reward: -115.493, mean reward: -0.987 [-100.000,  6.668], mean action: 1.709 [0.000, 3.000],  loss: 29.911850, mae: 69.323829, mean_q: 75.001717, mean_eps: 0.899533
  33620/300000: episode: 342, duration: 0.479s, episode steps:  72, steps per second: 150, episode reward: -100.898, mean reward: -1.401 [-100.000,  7.656], mean action: 1.486 [0.000, 3.000],  loss: 28.358985, mae: 69.249572, mean_q: 74.533900, mean_eps: 0.899250
  33721/300000: episode: 343, duration: 0.651s, episode steps: 101, steps per second: 155, episode reward: -110.016, mean reward: -1.089 [-100.000, 10.954], mean action: 1.337 [0.000, 3.000],  loss: 40.508487, mae: 69.654441, mean_q: 76.733781, mean_eps: 0.898990
  33819/300000: episode: 344, duration: 0.625s, episode steps:  98, steps per second: 157, episode reward: -133.564, mean reward: -1.363 [-100.000, 15.777], mean action: 1.439 [0.000, 3.000],  loss: 29.791978, mae: 70.481265, mean_q: 77.198116, mean_eps: 0.898692
  33887/300000: episode: 345, duration: 0.439s, episode steps:  68, steps per second: 155, episode reward: -79.991, mean reward: -1.176 [-100.000, 44.898], mean action: 1.721 [0.000, 3.000],  loss: 20.979730, mae: 71.637122, mean_q: 78.884710, mean_eps: 0.898442
  33977/300000: episode: 346, duration: 0.614s, episode steps:  90, steps per second: 147, episode reward: -186.168, mean reward: -2.069 [-100.000, 10.539], mean action: 1.489 [0.000, 3.000],  loss: 41.571972, mae: 72.194782, mean_q: 79.336437, mean_eps: 0.898206
  34041/300000: episode: 347, duration: 0.414s, episode steps:  64, steps per second: 155, episode reward: -278.390, mean reward: -4.350 [-100.000,  3.236], mean action: 1.656 [0.000, 3.000],  loss: 25.866720, mae: 72.123751, mean_q: 79.480803, mean_eps: 0.897975
  34117/300000: episode: 348, duration: 0.486s, episode steps:  76, steps per second: 157, episode reward: -207.340, mean reward: -2.728 [-100.000, 80.670], mean action: 1.553 [0.000, 3.000],  loss: 24.665543, mae: 71.159976, mean_q: 78.199181, mean_eps: 0.897765
  34196/300000: episode: 349, duration: 0.628s, episode steps:  79, steps per second: 126, episode reward: -58.444, mean reward: -0.740 [-100.000, 68.384], mean action: 1.570 [0.000, 3.000],  loss: 32.409325, mae: 70.156809, mean_q: 77.301221, mean_eps: 0.897532
  34276/300000: episode: 350, duration: 0.653s, episode steps:  80, steps per second: 122, episode reward: -136.385, mean reward: -1.705 [-100.000, 10.081], mean action: 1.663 [0.000, 3.000],  loss: 37.511231, mae: 71.400753, mean_q: 78.021845, mean_eps: 0.897293
  34379/300000: episode: 351, duration: 0.743s, episode steps: 103, steps per second: 139, episode reward: -121.612, mean reward: -1.181 [-100.000, 22.115], mean action: 1.437 [0.000, 3.000],  loss: 42.026535, mae: 72.605292, mean_q: 81.322631, mean_eps: 0.897019
  34474/300000: episode: 352, duration: 0.666s, episode steps:  95, steps per second: 143, episode reward: -370.957, mean reward: -3.905 [-100.000, -0.405], mean action: 1.705 [0.000, 3.000],  loss: 32.206723, mae: 71.105536, mean_q: 78.193210, mean_eps: 0.896722
  34550/300000: episode: 353, duration: 0.548s, episode steps:  76, steps per second: 139, episode reward: -73.003, mean reward: -0.961 [-100.000, 11.332], mean action: 1.724 [0.000, 3.000],  loss: 23.625914, mae: 72.688160, mean_q: 80.420089, mean_eps: 0.896466
  34633/300000: episode: 354, duration: 0.609s, episode steps:  83, steps per second: 136, episode reward: -192.950, mean reward: -2.325 [-100.000,  4.468], mean action: 1.337 [0.000, 3.000],  loss: 23.743866, mae: 72.438662, mean_q: 78.653240, mean_eps: 0.896227
  34742/300000: episode: 355, duration: 0.761s, episode steps: 109, steps per second: 143, episode reward: -104.211, mean reward: -0.956 [-100.000, 10.218], mean action: 1.679 [0.000, 3.000],  loss: 38.555445, mae: 72.202164, mean_q: 79.400436, mean_eps: 0.895939
  34824/300000: episode: 356, duration: 0.571s, episode steps:  82, steps per second: 144, episode reward: -117.028, mean reward: -1.427 [-100.000,  7.608], mean action: 1.768 [0.000, 3.000],  loss: 26.431383, mae: 72.061531, mean_q: 77.523421, mean_eps: 0.895653
  34917/300000: episode: 357, duration: 0.655s, episode steps:  93, steps per second: 142, episode reward: -55.520, mean reward: -0.597 [-100.000, 14.794], mean action: 1.710 [0.000, 3.000],  loss: 22.007279, mae: 73.118881, mean_q: 78.869862, mean_eps: 0.895390
  35014/300000: episode: 358, duration: 0.627s, episode steps:  97, steps per second: 155, episode reward: -130.230, mean reward: -1.343 [-100.000, 10.332], mean action: 1.567 [0.000, 3.000],  loss: 38.713400, mae: 73.846827, mean_q: 79.975746, mean_eps: 0.895105
  35107/300000: episode: 359, duration: 0.588s, episode steps:  93, steps per second: 158, episode reward: -117.706, mean reward: -1.266 [-100.000,  5.988], mean action: 1.527 [0.000, 3.000],  loss: 48.562880, mae: 74.114061, mean_q: 80.737934, mean_eps: 0.894820
  35174/300000: episode: 360, duration: 0.436s, episode steps:  67, steps per second: 154, episode reward: -102.536, mean reward: -1.530 [-100.000,  6.793], mean action: 1.597 [0.000, 3.000],  loss: 64.143845, mae: 75.360507, mean_q: 81.750837, mean_eps: 0.894580
  35264/300000: episode: 361, duration: 0.605s, episode steps:  90, steps per second: 149, episode reward: -340.896, mean reward: -3.788 [-100.000,  0.559], mean action: 1.511 [0.000, 3.000],  loss: 54.229812, mae: 74.587583, mean_q: 82.592195, mean_eps: 0.894344
  35341/300000: episode: 362, duration: 0.490s, episode steps:  77, steps per second: 157, episode reward: -190.286, mean reward: -2.471 [-100.000, 18.789], mean action: 1.390 [0.000, 3.000],  loss: 29.291317, mae: 75.360084, mean_q: 83.376610, mean_eps: 0.894094
  35417/300000: episode: 363, duration: 0.474s, episode steps:  76, steps per second: 160, episode reward: -36.422, mean reward: -0.479 [-100.000, 11.536], mean action: 1.526 [0.000, 3.000],  loss: 52.007432, mae: 76.322994, mean_q: 86.236423, mean_eps: 0.893865
  35491/300000: episode: 364, duration: 0.467s, episode steps:  74, steps per second: 158, episode reward: -52.550, mean reward: -0.710 [-100.000, 10.634], mean action: 1.514 [0.000, 3.000],  loss: 63.379765, mae: 75.090502, mean_q: 84.448042, mean_eps: 0.893640
  35584/300000: episode: 365, duration: 0.646s, episode steps:  93, steps per second: 144, episode reward: -125.621, mean reward: -1.351 [-100.000, 10.339], mean action: 1.462 [0.000, 3.000],  loss: 24.858643, mae: 76.038511, mean_q: 87.021721, mean_eps: 0.893389
  35703/300000: episode: 366, duration: 0.757s, episode steps: 119, steps per second: 157, episode reward: -280.211, mean reward: -2.355 [-100.000,  4.191], mean action: 1.303 [0.000, 3.000],  loss: 33.456781, mae: 74.912192, mean_q: 84.981541, mean_eps: 0.893071
  35786/300000: episode: 367, duration: 0.527s, episode steps:  83, steps per second: 157, episode reward: -109.379, mean reward: -1.318 [-100.000,  6.476], mean action: 1.590 [0.000, 3.000],  loss: 53.774351, mae: 76.747052, mean_q: 88.015316, mean_eps: 0.892768
  35873/300000: episode: 368, duration: 0.595s, episode steps:  87, steps per second: 146, episode reward: -124.025, mean reward: -1.426 [-100.000, 10.009], mean action: 1.586 [0.000, 3.000],  loss: 32.685606, mae: 76.368220, mean_q: 88.305915, mean_eps: 0.892513
  35946/300000: episode: 369, duration: 0.480s, episode steps:  73, steps per second: 152, episode reward: -76.266, mean reward: -1.045 [-100.000,  6.586], mean action: 1.397 [0.000, 3.000],  loss: 44.688041, mae: 75.951000, mean_q: 87.073365, mean_eps: 0.892273
  36057/300000: episode: 370, duration: 0.698s, episode steps: 111, steps per second: 159, episode reward: -58.009, mean reward: -0.523 [-100.000, 11.821], mean action: 1.414 [0.000, 3.000],  loss: 38.652022, mae: 75.786258, mean_q: 88.233894, mean_eps: 0.891997
  36155/300000: episode: 371, duration: 0.619s, episode steps:  98, steps per second: 158, episode reward: -92.166, mean reward: -0.940 [-100.000, 14.134], mean action: 1.459 [0.000, 3.000],  loss: 43.764536, mae: 77.321865, mean_q: 89.911174, mean_eps: 0.891683
  36243/300000: episode: 372, duration: 0.608s, episode steps:  88, steps per second: 145, episode reward: -157.091, mean reward: -1.785 [-100.000, 25.308], mean action: 1.682 [0.000, 3.000],  loss: 78.888912, mae: 75.329727, mean_q: 87.666260, mean_eps: 0.891405
  36338/300000: episode: 373, duration: 0.617s, episode steps:  95, steps per second: 154, episode reward: -132.505, mean reward: -1.395 [-100.000, 14.928], mean action: 1.463 [0.000, 3.000],  loss: 39.430577, mae: 76.265926, mean_q: 89.780650, mean_eps: 0.891130
  36455/300000: episode: 374, duration: 0.726s, episode steps: 117, steps per second: 161, episode reward: -125.830, mean reward: -1.075 [-100.000,  5.978], mean action: 1.453 [0.000, 3.000],  loss: 53.198840, mae: 76.427475, mean_q: 88.437302, mean_eps: 0.890812
  36540/300000: episode: 375, duration: 0.576s, episode steps:  85, steps per second: 148, episode reward: -32.481, mean reward: -0.382 [-100.000, 45.192], mean action: 1.447 [0.000, 3.000],  loss: 28.381508, mae: 75.171789, mean_q: 86.992403, mean_eps: 0.890509
  36617/300000: episode: 376, duration: 0.515s, episode steps:  77, steps per second: 149, episode reward: -93.575, mean reward: -1.215 [-100.000, 22.796], mean action: 1.636 [0.000, 3.000],  loss: 45.697360, mae: 76.642932, mean_q: 89.159041, mean_eps: 0.890266
  36695/300000: episode: 377, duration: 0.492s, episode steps:  78, steps per second: 159, episode reward: -65.225, mean reward: -0.836 [-100.000,  6.518], mean action: 1.603 [0.000, 3.000],  loss: 41.161276, mae: 77.580709, mean_q: 89.746652, mean_eps: 0.890034
  36815/300000: episode: 378, duration: 0.746s, episode steps: 120, steps per second: 161, episode reward: -315.646, mean reward: -2.630 [-100.000,  3.898], mean action: 1.375 [0.000, 3.000],  loss: 33.132169, mae: 76.439403, mean_q: 88.329826, mean_eps: 0.889737
  36890/300000: episode: 379, duration: 0.496s, episode steps:  75, steps per second: 151, episode reward: -104.580, mean reward: -1.394 [-100.000, 12.487], mean action: 1.467 [0.000, 3.000],  loss: 25.516957, mae: 73.643868, mean_q: 83.457734, mean_eps: 0.889444
  36983/300000: episode: 380, duration: 0.615s, episode steps:  93, steps per second: 151, episode reward: -106.532, mean reward: -1.146 [-100.000, 11.146], mean action: 1.538 [0.000, 3.000],  loss: 28.769108, mae: 73.778241, mean_q: 85.435251, mean_eps: 0.889192
  37091/300000: episode: 381, duration: 0.679s, episode steps: 108, steps per second: 159, episode reward: -105.730, mean reward: -0.979 [-100.000, 22.626], mean action: 1.630 [0.000, 3.000],  loss: 42.230319, mae: 73.098414, mean_q: 84.498892, mean_eps: 0.888890
  37250/300000: episode: 382, duration: 1.033s, episode steps: 159, steps per second: 154, episode reward: -127.518, mean reward: -0.802 [-100.000, 30.381], mean action: 1.428 [0.000, 3.000],  loss: 37.217614, mae: 69.641651, mean_q: 80.769448, mean_eps: 0.888490
  37384/300000: episode: 383, duration: 0.879s, episode steps: 134, steps per second: 152, episode reward: -90.527, mean reward: -0.676 [-100.000, 16.587], mean action: 1.336 [0.000, 3.000],  loss: 46.268358, mae: 67.714515, mean_q: 77.596131, mean_eps: 0.888050
  37446/300000: episode: 384, duration: 0.398s, episode steps:  62, steps per second: 156, episode reward: -70.817, mean reward: -1.142 [-100.000,  6.504], mean action: 1.774 [0.000, 3.000],  loss: 39.422802, mae: 67.124531, mean_q: 76.811811, mean_eps: 0.887756
  37535/300000: episode: 385, duration: 0.595s, episode steps:  89, steps per second: 150, episode reward: -70.081, mean reward: -0.787 [-100.000, 17.135], mean action: 1.449 [0.000, 3.000],  loss: 26.672468, mae: 66.874057, mean_q: 74.562136, mean_eps: 0.887530
  37648/300000: episode: 386, duration: 0.739s, episode steps: 113, steps per second: 153, episode reward: -119.736, mean reward: -1.060 [-100.000, 15.810], mean action: 1.327 [0.000, 3.000],  loss: 22.598046, mae: 66.167672, mean_q: 73.368739, mean_eps: 0.887227
  37732/300000: episode: 387, duration: 0.535s, episode steps:  84, steps per second: 157, episode reward: -124.475, mean reward: -1.482 [-100.000, 13.460], mean action: 1.524 [0.000, 3.000],  loss: 17.662459, mae: 65.680268, mean_q: 73.856527, mean_eps: 0.886931
  37848/300000: episode: 388, duration: 0.758s, episode steps: 116, steps per second: 153, episode reward: -111.120, mean reward: -0.958 [-100.000, 10.384], mean action: 1.500 [0.000, 3.000],  loss: 21.992269, mae: 65.998007, mean_q: 73.603816, mean_eps: 0.886631
  37925/300000: episode: 389, duration: 0.516s, episode steps:  77, steps per second: 149, episode reward: -107.226, mean reward: -1.393 [-100.000, 10.735], mean action: 1.545 [0.000, 3.000],  loss: 14.353179, mae: 64.421000, mean_q: 68.718987, mean_eps: 0.886342
  38039/300000: episode: 390, duration: 0.749s, episode steps: 114, steps per second: 152, episode reward: -136.252, mean reward: -1.195 [-100.000, 35.222], mean action: 1.518 [0.000, 3.000],  loss: 20.458203, mae: 65.671166, mean_q: 71.354806, mean_eps: 0.886055
  38113/300000: episode: 391, duration: 0.481s, episode steps:  74, steps per second: 154, episode reward: -81.454, mean reward: -1.101 [-100.000,  5.964], mean action: 1.392 [0.000, 3.000],  loss: 29.054228, mae: 65.549876, mean_q: 69.498609, mean_eps: 0.885774
  38226/300000: episode: 392, duration: 0.905s, episode steps: 113, steps per second: 125, episode reward: -336.070, mean reward: -2.974 [-100.000,  0.599], mean action: 1.363 [0.000, 3.000],  loss: 22.405103, mae: 66.617414, mean_q: 73.859305, mean_eps: 0.885493
  38294/300000: episode: 393, duration: 0.461s, episode steps:  68, steps per second: 147, episode reward: -74.080, mean reward: -1.089 [-100.000,  7.192], mean action: 1.559 [0.000, 3.000],  loss: 24.942272, mae: 66.531220, mean_q: 71.246627, mean_eps: 0.885221
  38400/300000: episode: 394, duration: 0.694s, episode steps: 106, steps per second: 153, episode reward: -140.224, mean reward: -1.323 [-100.000,  9.843], mean action: 1.528 [0.000, 3.000],  loss: 24.506635, mae: 66.941925, mean_q: 73.404969, mean_eps: 0.884961
  38528/300000: episode: 395, duration: 0.845s, episode steps: 128, steps per second: 151, episode reward: -166.439, mean reward: -1.300 [-100.000,  5.309], mean action: 1.398 [0.000, 3.000],  loss: 17.536220, mae: 66.183801, mean_q: 72.656461, mean_eps: 0.884610
  38601/300000: episode: 396, duration: 0.466s, episode steps:  73, steps per second: 157, episode reward: -107.070, mean reward: -1.467 [-100.000,  8.867], mean action: 1.548 [0.000, 3.000],  loss: 31.252020, mae: 65.949215, mean_q: 70.589260, mean_eps: 0.884308
  38684/300000: episode: 397, duration: 0.538s, episode steps:  83, steps per second: 154, episode reward: -78.072, mean reward: -0.941 [-100.000, 10.109], mean action: 1.506 [0.000, 3.000],  loss: 24.622825, mae: 66.164935, mean_q: 72.443743, mean_eps: 0.884074
  38763/300000: episode: 398, duration: 0.521s, episode steps:  79, steps per second: 152, episode reward: -79.813, mean reward: -1.010 [-100.000,  7.142], mean action: 1.671 [0.000, 3.000],  loss: 25.999445, mae: 67.254414, mean_q: 74.357027, mean_eps: 0.883831
  38831/300000: episode: 399, duration: 0.473s, episode steps:  68, steps per second: 144, episode reward: -91.161, mean reward: -1.341 [-100.000,  7.535], mean action: 1.471 [0.000, 3.000],  loss: 22.515006, mae: 66.419008, mean_q: 71.582814, mean_eps: 0.883611
  38905/300000: episode: 400, duration: 0.490s, episode steps:  74, steps per second: 151, episode reward: -169.181, mean reward: -2.286 [-100.000,  5.933], mean action: 1.716 [0.000, 3.000],  loss: 13.190410, mae: 67.019391, mean_q: 73.728587, mean_eps: 0.883397
  39026/300000: episode: 401, duration: 0.764s, episode steps: 121, steps per second: 158, episode reward: -49.882, mean reward: -0.412 [-100.000, 12.681], mean action: 1.570 [0.000, 3.000],  loss: 15.760659, mae: 67.122273, mean_q: 72.286146, mean_eps: 0.883105
  39117/300000: episode: 402, duration: 0.581s, episode steps:  91, steps per second: 157, episode reward: -123.867, mean reward: -1.361 [-100.000, 10.428], mean action: 1.363 [0.000, 3.000],  loss: 15.700727, mae: 66.220449, mean_q: 71.507473, mean_eps: 0.882787
  39253/300000: episode: 403, duration: 0.891s, episode steps: 136, steps per second: 153, episode reward: -139.383, mean reward: -1.025 [-100.000,  5.649], mean action: 1.669 [0.000, 3.000],  loss: 19.798214, mae: 67.370440, mean_q: 71.982252, mean_eps: 0.882446
  39332/300000: episode: 404, duration: 0.509s, episode steps:  79, steps per second: 155, episode reward: -193.520, mean reward: -2.450 [-100.000,  8.021], mean action: 1.544 [0.000, 3.000],  loss: 15.646692, mae: 67.241977, mean_q: 71.605354, mean_eps: 0.882124
  39407/300000: episode: 405, duration: 0.485s, episode steps:  75, steps per second: 155, episode reward: -120.704, mean reward: -1.609 [-100.000,  8.029], mean action: 1.453 [0.000, 3.000],  loss: 11.212974, mae: 67.207528, mean_q: 71.862495, mean_eps: 0.881893
  39491/300000: episode: 406, duration: 0.545s, episode steps:  84, steps per second: 154, episode reward: -57.205, mean reward: -0.681 [-100.000, 17.234], mean action: 1.726 [0.000, 3.000],  loss: 17.956135, mae: 68.185554, mean_q: 72.853440, mean_eps: 0.881655
  39565/300000: episode: 407, duration: 0.502s, episode steps:  74, steps per second: 147, episode reward: -97.968, mean reward: -1.324 [-100.000,  7.521], mean action: 1.419 [0.000, 3.000],  loss: 18.006067, mae: 67.848309, mean_q: 74.185814, mean_eps: 0.881418
  39637/300000: episode: 408, duration: 0.460s, episode steps:  72, steps per second: 157, episode reward: -75.976, mean reward: -1.055 [-100.000, 16.372], mean action: 1.722 [0.000, 3.000],  loss: 16.315117, mae: 67.826381, mean_q: 72.822197, mean_eps: 0.881198
  39710/300000: episode: 409, duration: 0.473s, episode steps:  73, steps per second: 154, episode reward: -59.800, mean reward: -0.819 [-100.000,  6.795], mean action: 1.699 [0.000, 3.000],  loss: 10.381319, mae: 68.666842, mean_q: 75.231750, mean_eps: 0.880981
  39775/300000: episode: 410, duration: 0.418s, episode steps:  65, steps per second: 155, episode reward: -276.538, mean reward: -4.254 [-100.000, 10.475], mean action: 1.431 [0.000, 3.000],  loss: 14.504451, mae: 67.158136, mean_q: 73.462795, mean_eps: 0.880774
  39850/300000: episode: 411, duration: 0.502s, episode steps:  75, steps per second: 149, episode reward: -74.256, mean reward: -0.990 [-100.000, 16.899], mean action: 1.507 [0.000, 3.000],  loss: 13.680573, mae: 68.004551, mean_q: 73.742149, mean_eps: 0.880564
  39955/300000: episode: 412, duration: 0.676s, episode steps: 105, steps per second: 155, episode reward: -114.906, mean reward: -1.094 [-100.000, 19.229], mean action: 1.476 [0.000, 3.000],  loss: 10.148180, mae: 68.870961, mean_q: 76.058852, mean_eps: 0.880294
  40018/300000: episode: 413, duration: 0.402s, episode steps:  63, steps per second: 157, episode reward: -130.247, mean reward: -2.067 [-100.000, 24.509], mean action: 1.508 [0.000, 3.000],  loss: 16.868274, mae: 67.979521, mean_q: 73.276534, mean_eps: 0.880042
  40130/300000: episode: 414, duration: 0.723s, episode steps: 112, steps per second: 155, episode reward: -80.709, mean reward: -0.721 [-100.000,  7.312], mean action: 1.527 [0.000, 3.000],  loss: 10.818725, mae: 68.727935, mean_q: 75.881655, mean_eps: 0.879779
  40244/300000: episode: 415, duration: 0.770s, episode steps: 114, steps per second: 148, episode reward: -195.171, mean reward: -1.712 [-100.000, 15.312], mean action: 1.421 [0.000, 3.000],  loss: 13.325466, mae: 69.176299, mean_q: 76.427992, mean_eps: 0.879441
  40345/300000: episode: 416, duration: 0.686s, episode steps: 101, steps per second: 147, episode reward: -169.465, mean reward: -1.678 [-100.000,  7.119], mean action: 1.703 [0.000, 3.000],  loss: 13.527002, mae: 69.131906, mean_q: 76.417253, mean_eps: 0.879118
  40422/300000: episode: 417, duration: 0.549s, episode steps:  77, steps per second: 140, episode reward: -75.379, mean reward: -0.979 [-100.000, 16.675], mean action: 1.610 [0.000, 3.000],  loss: 11.856965, mae: 68.684937, mean_q: 74.887179, mean_eps: 0.878851
  40539/300000: episode: 418, duration: 0.858s, episode steps: 117, steps per second: 136, episode reward: -94.556, mean reward: -0.808 [-100.000, 14.103], mean action: 1.530 [0.000, 3.000],  loss: 11.245876, mae: 68.990335, mean_q: 76.922800, mean_eps: 0.878560
  40651/300000: episode: 419, duration: 0.751s, episode steps: 112, steps per second: 149, episode reward: -134.793, mean reward: -1.204 [-100.000,  9.424], mean action: 1.562 [0.000, 3.000],  loss: 9.961319, mae: 69.698269, mean_q: 78.238354, mean_eps: 0.878216
  40756/300000: episode: 420, duration: 0.725s, episode steps: 105, steps per second: 145, episode reward: -88.630, mean reward: -0.844 [-100.000, 12.789], mean action: 1.590 [0.000, 3.000],  loss: 9.454700, mae: 68.466106, mean_q: 76.702351, mean_eps: 0.877891
  40862/300000: episode: 421, duration: 0.747s, episode steps: 106, steps per second: 142, episode reward: -133.147, mean reward: -1.256 [-100.000,  6.559], mean action: 1.623 [0.000, 3.000],  loss: 10.727445, mae: 69.439222, mean_q: 76.956446, mean_eps: 0.877575
  40939/300000: episode: 422, duration: 0.525s, episode steps:  77, steps per second: 147, episode reward: -137.986, mean reward: -1.792 [-100.000,  7.135], mean action: 1.195 [0.000, 3.000],  loss: 11.059570, mae: 68.729396, mean_q: 76.648095, mean_eps: 0.877300
  41029/300000: episode: 423, duration: 0.690s, episode steps:  90, steps per second: 130, episode reward: -71.957, mean reward: -0.800 [-100.000, 16.240], mean action: 1.600 [0.000, 3.000],  loss: 11.093687, mae: 68.670414, mean_q: 76.929667, mean_eps: 0.877050
  41161/300000: episode: 424, duration: 0.929s, episode steps: 132, steps per second: 142, episode reward: -315.540, mean reward: -2.390 [-100.000, 129.363], mean action: 1.621 [0.000, 3.000],  loss: 16.015578, mae: 69.450743, mean_q: 77.064015, mean_eps: 0.876716
  41234/300000: episode: 425, duration: 0.495s, episode steps:  73, steps per second: 147, episode reward: -81.353, mean reward: -1.114 [-100.000, 14.013], mean action: 1.425 [0.000, 3.000],  loss: 20.905388, mae: 70.019290, mean_q: 77.821183, mean_eps: 0.876409
  41365/300000: episode: 426, duration: 0.837s, episode steps: 131, steps per second: 156, episode reward: -158.520, mean reward: -1.210 [-100.000, 53.105], mean action: 1.656 [0.000, 3.000],  loss: 7.525550, mae: 70.478673, mean_q: 77.839468, mean_eps: 0.876103
  41460/300000: episode: 427, duration: 0.652s, episode steps:  95, steps per second: 146, episode reward: -69.213, mean reward: -0.729 [-100.000, 29.625], mean action: 1.484 [0.000, 3.000],  loss: 10.686970, mae: 70.794681, mean_q: 77.697723, mean_eps: 0.875764
  41538/300000: episode: 428, duration: 0.497s, episode steps:  78, steps per second: 157, episode reward: -200.551, mean reward: -2.571 [-100.000,  7.483], mean action: 1.487 [0.000, 3.000],  loss: 10.262880, mae: 70.423260, mean_q: 76.660663, mean_eps: 0.875505
  41668/300000: episode: 429, duration: 0.834s, episode steps: 130, steps per second: 156, episode reward: -99.033, mean reward: -0.762 [-100.000,  7.285], mean action: 1.677 [0.000, 3.000],  loss: 16.424394, mae: 71.298047, mean_q: 78.317604, mean_eps: 0.875193
  41747/300000: episode: 430, duration: 0.542s, episode steps:  79, steps per second: 146, episode reward: -185.706, mean reward: -2.351 [-100.000,  6.831], mean action: 1.620 [0.000, 3.000],  loss: 10.000990, mae: 71.761718, mean_q: 79.453735, mean_eps: 0.874879
  41842/300000: episode: 431, duration: 0.625s, episode steps:  95, steps per second: 152, episode reward: -92.912, mean reward: -0.978 [-100.000, 12.772], mean action: 1.453 [0.000, 3.000],  loss: 12.554350, mae: 71.200651, mean_q: 78.616285, mean_eps: 0.874618
  41942/300000: episode: 432, duration: 0.658s, episode steps: 100, steps per second: 152, episode reward: -88.783, mean reward: -0.888 [-100.000,  8.019], mean action: 1.300 [0.000, 3.000],  loss: 12.268311, mae: 70.769194, mean_q: 76.215410, mean_eps: 0.874325
  42054/300000: episode: 433, duration: 0.722s, episode steps: 112, steps per second: 155, episode reward: -403.495, mean reward: -3.603 [-100.000,  1.964], mean action: 1.536 [0.000, 3.000],  loss: 12.454046, mae: 71.080172, mean_q: 76.850915, mean_eps: 0.874008
  42177/300000: episode: 434, duration: 0.808s, episode steps: 123, steps per second: 152, episode reward: -138.447, mean reward: -1.126 [-100.000,  9.818], mean action: 1.496 [0.000, 3.000],  loss: 13.217041, mae: 70.846696, mean_q: 76.594011, mean_eps: 0.873655
  42270/300000: episode: 435, duration: 0.597s, episode steps:  93, steps per second: 156, episode reward: -93.482, mean reward: -1.005 [-100.000,  7.721], mean action: 1.430 [0.000, 3.000],  loss: 13.301269, mae: 70.263871, mean_q: 74.438818, mean_eps: 0.873331
  42369/300000: episode: 436, duration: 0.668s, episode steps:  99, steps per second: 148, episode reward: -84.435, mean reward: -0.853 [-100.000, 11.572], mean action: 1.495 [0.000, 3.000],  loss: 9.710721, mae: 71.304431, mean_q: 77.043549, mean_eps: 0.873043
  42452/300000: episode: 437, duration: 0.580s, episode steps:  83, steps per second: 143, episode reward: -54.991, mean reward: -0.663 [-100.000, 10.737], mean action: 1.627 [0.000, 3.000],  loss: 13.326213, mae: 70.074830, mean_q: 72.626901, mean_eps: 0.872770
  42581/300000: episode: 438, duration: 0.849s, episode steps: 129, steps per second: 152, episode reward: -75.865, mean reward: -0.588 [-100.000, 29.546], mean action: 1.233 [0.000, 3.000],  loss: 12.898065, mae: 70.506603, mean_q: 73.932715, mean_eps: 0.872452
  42645/300000: episode: 439, duration: 0.409s, episode steps:  64, steps per second: 156, episode reward: -86.668, mean reward: -1.354 [-100.000, 21.267], mean action: 1.609 [0.000, 3.000],  loss: 8.998292, mae: 69.593390, mean_q: 73.655006, mean_eps: 0.872162
  42779/300000: episode: 440, duration: 0.868s, episode steps: 134, steps per second: 154, episode reward: -52.986, mean reward: -0.395 [-100.000,  9.889], mean action: 1.567 [0.000, 3.000],  loss: 8.004591, mae: 70.743409, mean_q: 75.256283, mean_eps: 0.871865
  42908/300000: episode: 441, duration: 0.830s, episode steps: 129, steps per second: 155, episode reward: -223.333, mean reward: -1.731 [-100.000,  5.822], mean action: 1.605 [0.000, 3.000],  loss: 9.184727, mae: 70.623770, mean_q: 75.158245, mean_eps: 0.871471
  42993/300000: episode: 442, duration: 0.538s, episode steps:  85, steps per second: 158, episode reward: -77.113, mean reward: -0.907 [-100.000,  6.248], mean action: 1.671 [0.000, 3.000],  loss: 10.436966, mae: 70.701822, mean_q: 74.785575, mean_eps: 0.871150
  43111/300000: episode: 443, duration: 0.783s, episode steps: 118, steps per second: 151, episode reward: -125.216, mean reward: -1.061 [-100.000, 27.898], mean action: 1.627 [0.000, 3.000],  loss: 11.330945, mae: 71.095923, mean_q: 76.374587, mean_eps: 0.870846
  43217/300000: episode: 444, duration: 0.685s, episode steps: 106, steps per second: 155, episode reward: -72.084, mean reward: -0.680 [-100.000, 22.177], mean action: 1.434 [0.000, 3.000],  loss: 11.666570, mae: 71.667321, mean_q: 76.469531, mean_eps: 0.870509
  43344/300000: episode: 445, duration: 0.843s, episode steps: 127, steps per second: 151, episode reward: -180.130, mean reward: -1.418 [-100.000, 14.239], mean action: 1.598 [0.000, 3.000],  loss: 12.494985, mae: 71.537763, mean_q: 76.404462, mean_eps: 0.870160
  43439/300000: episode: 446, duration: 0.654s, episode steps:  95, steps per second: 145, episode reward: -117.186, mean reward: -1.234 [-100.000,  6.792], mean action: 1.453 [0.000, 3.000],  loss: 12.959192, mae: 70.694894, mean_q: 74.977335, mean_eps: 0.869827
  43573/300000: episode: 447, duration: 0.866s, episode steps: 134, steps per second: 155, episode reward: -330.296, mean reward: -2.465 [-100.000, 36.159], mean action: 1.530 [0.000, 3.000],  loss: 13.046455, mae: 70.597878, mean_q: 75.098350, mean_eps: 0.869483
  43692/300000: episode: 448, duration: 0.760s, episode steps: 119, steps per second: 157, episode reward: -135.246, mean reward: -1.137 [-100.000,  8.531], mean action: 1.613 [0.000, 3.000],  loss: 13.526100, mae: 70.671083, mean_q: 75.322665, mean_eps: 0.869104
  43768/300000: episode: 449, duration: 0.525s, episode steps:  76, steps per second: 145, episode reward: -108.462, mean reward: -1.427 [-100.000,  6.140], mean action: 1.526 [0.000, 3.000],  loss: 9.957966, mae: 69.802267, mean_q: 74.382524, mean_eps: 0.868811
  43877/300000: episode: 450, duration: 0.696s, episode steps: 109, steps per second: 157, episode reward: -101.870, mean reward: -0.935 [-100.000, 13.874], mean action: 1.486 [0.000, 3.000],  loss: 13.023632, mae: 69.635325, mean_q: 73.714541, mean_eps: 0.868534
  44021/300000: episode: 451, duration: 0.911s, episode steps: 144, steps per second: 158, episode reward: -28.558, mean reward: -0.198 [-100.000, 17.986], mean action: 1.569 [0.000, 3.000],  loss: 9.955395, mae: 69.604880, mean_q: 73.436183, mean_eps: 0.868154
  44109/300000: episode: 452, duration: 0.634s, episode steps:  88, steps per second: 139, episode reward: -183.731, mean reward: -2.088 [-100.000, 18.176], mean action: 1.739 [0.000, 3.000],  loss: 10.631703, mae: 68.908691, mean_q: 71.380363, mean_eps: 0.867807
  44203/300000: episode: 453, duration: 0.708s, episode steps:  94, steps per second: 133, episode reward: -146.444, mean reward: -1.558 [-100.000, 20.179], mean action: 1.564 [0.000, 3.000],  loss: 8.101212, mae: 67.874453, mean_q: 69.828299, mean_eps: 0.867533
  44279/300000: episode: 454, duration: 0.555s, episode steps:  76, steps per second: 137, episode reward: -71.671, mean reward: -0.943 [-100.000,  7.776], mean action: 1.645 [0.000, 3.000],  loss: 12.364441, mae: 68.300999, mean_q: 71.544874, mean_eps: 0.867279
  44355/300000: episode: 455, duration: 0.592s, episode steps:  76, steps per second: 128, episode reward: -80.021, mean reward: -1.053 [-100.000, 11.030], mean action: 1.355 [0.000, 3.000],  loss: 9.473963, mae: 68.390518, mean_q: 72.149982, mean_eps: 0.867050
  44440/300000: episode: 456, duration: 0.601s, episode steps:  85, steps per second: 141, episode reward: -85.062, mean reward: -1.001 [-100.000, 13.586], mean action: 1.471 [0.000, 3.000],  loss: 16.790164, mae: 68.797415, mean_q: 71.792393, mean_eps: 0.866809
  44606/300000: episode: 457, duration: 1.175s, episode steps: 166, steps per second: 141, episode reward: -20.862, mean reward: -0.126 [-100.000, 54.292], mean action: 1.657 [0.000, 3.000],  loss: 11.829362, mae: 67.296044, mean_q: 71.136170, mean_eps: 0.866432
  44685/300000: episode: 458, duration: 0.603s, episode steps:  79, steps per second: 131, episode reward: -123.739, mean reward: -1.566 [-100.000, 12.159], mean action: 1.544 [0.000, 3.000],  loss: 10.964951, mae: 68.000253, mean_q: 71.434636, mean_eps: 0.866065
  44756/300000: episode: 459, duration: 0.548s, episode steps:  71, steps per second: 129, episode reward: -74.063, mean reward: -1.043 [-100.000, 12.801], mean action: 1.704 [0.000, 3.000],  loss: 7.420969, mae: 67.483573, mean_q: 71.583938, mean_eps: 0.865840
  44832/300000: episode: 460, duration: 0.496s, episode steps:  76, steps per second: 153, episode reward: -138.443, mean reward: -1.822 [-100.000, 23.547], mean action: 1.632 [0.000, 3.000],  loss: 8.985850, mae: 66.555118, mean_q: 68.920314, mean_eps: 0.865619
  44923/300000: episode: 461, duration: 0.594s, episode steps:  91, steps per second: 153, episode reward: -66.794, mean reward: -0.734 [-100.000, 17.735], mean action: 1.725 [0.000, 3.000],  loss: 11.678482, mae: 67.616357, mean_q: 69.918212, mean_eps: 0.865369
  45025/300000: episode: 462, duration: 0.679s, episode steps: 102, steps per second: 150, episode reward: -145.744, mean reward: -1.429 [-100.000,  6.883], mean action: 1.539 [0.000, 3.000],  loss: 12.849756, mae: 67.344140, mean_q: 70.048861, mean_eps: 0.865080
  45109/300000: episode: 463, duration: 0.526s, episode steps:  84, steps per second: 160, episode reward: -208.476, mean reward: -2.482 [-100.000,  9.797], mean action: 1.548 [0.000, 3.000],  loss: 9.461794, mae: 67.759655, mean_q: 71.617825, mean_eps: 0.864800
  45222/300000: episode: 464, duration: 0.713s, episode steps: 113, steps per second: 158, episode reward: -69.909, mean reward: -0.619 [-100.000, 12.569], mean action: 1.504 [0.000, 3.000],  loss: 21.252863, mae: 67.287153, mean_q: 72.675244, mean_eps: 0.864505
  45320/300000: episode: 465, duration: 0.658s, episode steps:  98, steps per second: 149, episode reward: -133.630, mean reward: -1.364 [-100.000,  9.597], mean action: 1.561 [0.000, 3.000],  loss: 15.721542, mae: 66.963452, mean_q: 71.918302, mean_eps: 0.864189
  45433/300000: episode: 466, duration: 0.716s, episode steps: 113, steps per second: 158, episode reward: -146.340, mean reward: -1.295 [-100.000, 11.850], mean action: 1.593 [0.000, 3.000],  loss: 9.788649, mae: 67.529601, mean_q: 73.095456, mean_eps: 0.863872
  45521/300000: episode: 467, duration: 0.558s, episode steps:  88, steps per second: 158, episode reward: -123.066, mean reward: -1.398 [-100.000,  8.551], mean action: 1.682 [0.000, 3.000],  loss: 17.556888, mae: 66.217385, mean_q: 72.533185, mean_eps: 0.863570
  45626/300000: episode: 468, duration: 0.723s, episode steps: 105, steps per second: 145, episode reward: -193.026, mean reward: -1.838 [-100.000,  7.697], mean action: 1.476 [0.000, 3.000],  loss: 14.762279, mae: 67.366178, mean_q: 73.424372, mean_eps: 0.863281
  45700/300000: episode: 469, duration: 0.532s, episode steps:  74, steps per second: 139, episode reward: 36.058, mean reward:  0.487 [-100.000, 84.041], mean action: 1.432 [0.000, 3.000],  loss: 9.419410, mae: 67.283589, mean_q: 72.496304, mean_eps: 0.863013
  45809/300000: episode: 470, duration: 0.717s, episode steps: 109, steps per second: 152, episode reward: -106.725, mean reward: -0.979 [-100.000,  9.961], mean action: 1.752 [0.000, 3.000],  loss: 12.364953, mae: 67.342357, mean_q: 73.271822, mean_eps: 0.862738
  45899/300000: episode: 471, duration: 0.563s, episode steps:  90, steps per second: 160, episode reward: -83.519, mean reward: -0.928 [-100.000,  7.478], mean action: 1.589 [0.000, 3.000],  loss: 10.990555, mae: 66.215109, mean_q: 70.538070, mean_eps: 0.862439
  46026/300000: episode: 472, duration: 0.866s, episode steps: 127, steps per second: 147, episode reward: -122.521, mean reward: -0.965 [-100.000, 10.570], mean action: 1.669 [0.000, 3.000],  loss: 10.872699, mae: 67.087453, mean_q: 70.578559, mean_eps: 0.862114
  46124/300000: episode: 473, duration: 0.630s, episode steps:  98, steps per second: 156, episode reward: -125.840, mean reward: -1.284 [-100.000, 13.947], mean action: 1.398 [0.000, 3.000],  loss: 8.466915, mae: 67.077043, mean_q: 70.328942, mean_eps: 0.861776
  46195/300000: episode: 474, duration: 0.446s, episode steps:  71, steps per second: 159, episode reward: -67.588, mean reward: -0.952 [-100.000, 13.733], mean action: 1.507 [0.000, 3.000],  loss: 12.082950, mae: 67.489439, mean_q: 71.952574, mean_eps: 0.861523
  46313/300000: episode: 475, duration: 0.790s, episode steps: 118, steps per second: 149, episode reward: -242.843, mean reward: -2.058 [-100.000,  8.827], mean action: 1.500 [0.000, 3.000],  loss: 14.395566, mae: 66.844437, mean_q: 70.476186, mean_eps: 0.861240
  46388/300000: episode: 476, duration: 0.496s, episode steps:  75, steps per second: 151, episode reward: -66.376, mean reward: -0.885 [-100.000,  8.405], mean action: 1.693 [0.000, 3.000],  loss: 14.393447, mae: 68.307081, mean_q: 71.236247, mean_eps: 0.860950
  46499/300000: episode: 477, duration: 0.700s, episode steps: 111, steps per second: 159, episode reward: -128.116, mean reward: -1.154 [-100.000,  5.773], mean action: 1.685 [0.000, 3.000],  loss: 10.708397, mae: 68.137612, mean_q: 71.529161, mean_eps: 0.860671
  46572/300000: episode: 478, duration: 0.483s, episode steps:  73, steps per second: 151, episode reward: -85.664, mean reward: -1.173 [-100.000,  8.497], mean action: 1.521 [0.000, 3.000],  loss: 11.438833, mae: 66.635292, mean_q: 69.319897, mean_eps: 0.860395
  46669/300000: episode: 479, duration: 0.668s, episode steps:  97, steps per second: 145, episode reward: -461.934, mean reward: -4.762 [-100.000, -0.778], mean action: 1.567 [0.000, 3.000],  loss: 13.110012, mae: 66.833530, mean_q: 70.100271, mean_eps: 0.860140
  46739/300000: episode: 480, duration: 0.489s, episode steps:  70, steps per second: 143, episode reward: -95.121, mean reward: -1.359 [-100.000,  5.799], mean action: 1.571 [0.000, 3.000],  loss: 16.240478, mae: 67.110846, mean_q: 70.928353, mean_eps: 0.859889
  46853/300000: episode: 481, duration: 0.728s, episode steps: 114, steps per second: 157, episode reward: -110.438, mean reward: -0.969 [-100.000,  4.314], mean action: 1.605 [0.000, 3.000],  loss: 9.717073, mae: 65.967791, mean_q: 69.319555, mean_eps: 0.859613
  46951/300000: episode: 482, duration: 0.665s, episode steps:  98, steps per second: 147, episode reward: -154.352, mean reward: -1.575 [-100.000, 44.814], mean action: 1.684 [0.000, 3.000],  loss: 9.620014, mae: 66.501968, mean_q: 70.460476, mean_eps: 0.859295
  47031/300000: episode: 483, duration: 0.538s, episode steps:  80, steps per second: 149, episode reward: -211.201, mean reward: -2.640 [-100.000,  5.775], mean action: 1.538 [0.000, 3.000],  loss: 15.895783, mae: 65.826005, mean_q: 69.636668, mean_eps: 0.859028
  47115/300000: episode: 484, duration: 0.547s, episode steps:  84, steps per second: 153, episode reward: -95.971, mean reward: -1.143 [-100.000,  6.326], mean action: 1.548 [0.000, 3.000],  loss: 11.435023, mae: 65.738471, mean_q: 68.974491, mean_eps: 0.858783
  47228/300000: episode: 485, duration: 0.744s, episode steps: 113, steps per second: 152, episode reward: -131.784, mean reward: -1.166 [-100.000, 16.315], mean action: 1.522 [0.000, 3.000],  loss: 9.897893, mae: 66.299703, mean_q: 70.110498, mean_eps: 0.858487
  47332/300000: episode: 486, duration: 0.688s, episode steps: 104, steps per second: 151, episode reward: -145.051, mean reward: -1.395 [-100.000, 40.387], mean action: 1.462 [0.000, 3.000],  loss: 8.314360, mae: 65.972036, mean_q: 69.332613, mean_eps: 0.858162
  47423/300000: episode: 487, duration: 0.593s, episode steps:  91, steps per second: 153, episode reward: -118.834, mean reward: -1.306 [-100.000, 10.207], mean action: 1.352 [0.000, 3.000],  loss: 10.163016, mae: 66.365163, mean_q: 70.132681, mean_eps: 0.857869
  47506/300000: episode: 488, duration: 0.535s, episode steps:  83, steps per second: 155, episode reward: -207.262, mean reward: -2.497 [-100.000,  7.527], mean action: 1.494 [0.000, 3.000],  loss: 7.082912, mae: 66.532571, mean_q: 71.227603, mean_eps: 0.857608
  47644/300000: episode: 489, duration: 0.940s, episode steps: 138, steps per second: 147, episode reward: -64.777, mean reward: -0.469 [-100.000, 13.080], mean action: 1.558 [0.000, 3.000],  loss: 8.011873, mae: 66.786952, mean_q: 70.189831, mean_eps: 0.857276
  47716/300000: episode: 490, duration: 0.465s, episode steps:  72, steps per second: 155, episode reward: -141.157, mean reward: -1.961 [-100.000, 17.043], mean action: 1.444 [0.000, 3.000],  loss: 9.194072, mae: 66.786039, mean_q: 70.882346, mean_eps: 0.856962
  47826/300000: episode: 491, duration: 0.728s, episode steps: 110, steps per second: 151, episode reward: -90.284, mean reward: -0.821 [-100.000,  6.775], mean action: 1.564 [0.000, 3.000],  loss: 11.361797, mae: 65.980855, mean_q: 67.270787, mean_eps: 0.856688
  47943/300000: episode: 492, duration: 0.779s, episode steps: 117, steps per second: 150, episode reward: -121.147, mean reward: -1.035 [-100.000, 11.531], mean action: 1.607 [0.000, 3.000],  loss: 16.781809, mae: 66.204259, mean_q: 69.059844, mean_eps: 0.856348
  48026/300000: episode: 493, duration: 0.531s, episode steps:  83, steps per second: 156, episode reward: -333.160, mean reward: -4.014 [-100.000, -0.230], mean action: 1.627 [0.000, 3.000],  loss: 10.416064, mae: 65.754428, mean_q: 68.125626, mean_eps: 0.856048
  48131/300000: episode: 494, duration: 0.662s, episode steps: 105, steps per second: 159, episode reward: -186.477, mean reward: -1.776 [-100.000, 20.952], mean action: 1.448 [0.000, 3.000],  loss: 10.808065, mae: 65.585544, mean_q: 67.933390, mean_eps: 0.855766
  48222/300000: episode: 495, duration: 0.588s, episode steps:  91, steps per second: 155, episode reward: -93.578, mean reward: -1.028 [-100.000, 16.090], mean action: 1.615 [0.000, 3.000],  loss: 10.704090, mae: 65.813857, mean_q: 68.509705, mean_eps: 0.855472
  48363/300000: episode: 496, duration: 0.920s, episode steps: 141, steps per second: 153, episode reward: -54.563, mean reward: -0.387 [-100.000, 61.828], mean action: 1.539 [0.000, 3.000],  loss: 8.113191, mae: 65.623244, mean_q: 69.155178, mean_eps: 0.855124
  48460/300000: episode: 497, duration: 0.633s, episode steps:  97, steps per second: 153, episode reward:  8.912, mean reward:  0.092 [-100.000, 64.324], mean action: 1.701 [0.000, 3.000],  loss: 10.486541, mae: 65.509999, mean_q: 68.658152, mean_eps: 0.854767
  48562/300000: episode: 498, duration: 0.678s, episode steps: 102, steps per second: 151, episode reward: -158.028, mean reward: -1.549 [-100.000, 63.221], mean action: 1.598 [0.000, 3.000],  loss: 12.159216, mae: 66.812351, mean_q: 69.941837, mean_eps: 0.854468
  48665/300000: episode: 499, duration: 0.679s, episode steps: 103, steps per second: 152, episode reward: -149.153, mean reward: -1.448 [-100.000, 20.171], mean action: 1.757 [0.000, 3.000],  loss: 13.432496, mae: 65.729130, mean_q: 68.088759, mean_eps: 0.854161
  48754/300000: episode: 500, duration: 0.572s, episode steps:  89, steps per second: 156, episode reward: -155.670, mean reward: -1.749 [-100.000,  6.211], mean action: 1.539 [0.000, 3.000],  loss: 11.292182, mae: 65.270888, mean_q: 67.243190, mean_eps: 0.853873
  48858/300000: episode: 501, duration: 0.667s, episode steps: 104, steps per second: 156, episode reward: -97.178, mean reward: -0.934 [-100.000,  6.099], mean action: 1.692 [0.000, 3.000],  loss: 8.970498, mae: 65.592626, mean_q: 69.494510, mean_eps: 0.853583
  48938/300000: episode: 502, duration: 0.550s, episode steps:  80, steps per second: 146, episode reward: -122.645, mean reward: -1.533 [-100.000,  5.723], mean action: 1.413 [0.000, 3.000],  loss: 8.417982, mae: 66.060939, mean_q: 69.767635, mean_eps: 0.853307
  49039/300000: episode: 503, duration: 0.640s, episode steps: 101, steps per second: 158, episode reward: -114.262, mean reward: -1.131 [-100.000, 14.841], mean action: 1.564 [0.000, 3.000],  loss: 11.888903, mae: 65.868928, mean_q: 70.530707, mean_eps: 0.853036
  49126/300000: episode: 504, duration: 0.555s, episode steps:  87, steps per second: 157, episode reward: -71.227, mean reward: -0.819 [-100.000, 12.559], mean action: 1.655 [0.000, 3.000],  loss: 11.533648, mae: 64.969748, mean_q: 66.998050, mean_eps: 0.852754
  49205/300000: episode: 505, duration: 0.507s, episode steps:  79, steps per second: 156, episode reward: -73.325, mean reward: -0.928 [-100.000, 16.547], mean action: 1.380 [0.000, 3.000],  loss: 9.984004, mae: 65.520771, mean_q: 68.752435, mean_eps: 0.852505
  49330/300000: episode: 506, duration: 0.847s, episode steps: 125, steps per second: 148, episode reward: -125.611, mean reward: -1.005 [-100.000, 18.717], mean action: 1.704 [0.000, 3.000],  loss: 16.036189, mae: 65.926930, mean_q: 68.996646, mean_eps: 0.852199
  49449/300000: episode: 507, duration: 0.760s, episode steps: 119, steps per second: 157, episode reward: -118.390, mean reward: -0.995 [-100.000, 15.106], mean action: 1.697 [0.000, 3.000],  loss: 10.207371, mae: 66.051184, mean_q: 70.173739, mean_eps: 0.851833
  49545/300000: episode: 508, duration: 0.625s, episode steps:  96, steps per second: 154, episode reward: -122.831, mean reward: -1.279 [-100.000, 27.992], mean action: 1.823 [0.000, 3.000],  loss: 9.006672, mae: 66.168406, mean_q: 69.808983, mean_eps: 0.851510
  49620/300000: episode: 509, duration: 0.497s, episode steps:  75, steps per second: 151, episode reward: -73.805, mean reward: -0.984 [-100.000,  7.806], mean action: 1.520 [0.000, 3.000],  loss: 9.991705, mae: 64.814077, mean_q: 67.725434, mean_eps: 0.851254
  49721/300000: episode: 510, duration: 0.638s, episode steps: 101, steps per second: 158, episode reward: -76.540, mean reward: -0.758 [-100.000,  5.993], mean action: 1.624 [0.000, 3.000],  loss: 15.291789, mae: 63.636938, mean_q: 66.796989, mean_eps: 0.850990
  49818/300000: episode: 511, duration: 0.614s, episode steps:  97, steps per second: 158, episode reward: -67.862, mean reward: -0.700 [-100.000, 11.803], mean action: 1.423 [0.000, 3.000],  loss: 13.166702, mae: 64.045306, mean_q: 66.850845, mean_eps: 0.850693
  49903/300000: episode: 512, duration: 0.561s, episode steps:  85, steps per second: 152, episode reward: -45.278, mean reward: -0.533 [-100.000, 17.011], mean action: 1.635 [0.000, 3.000],  loss: 11.981162, mae: 63.160309, mean_q: 66.415778, mean_eps: 0.850420
  49968/300000: episode: 513, duration: 0.433s, episode steps:  65, steps per second: 150, episode reward: -153.508, mean reward: -2.362 [-100.000,  5.208], mean action: 1.523 [0.000, 3.000],  loss: 7.724937, mae: 62.567432, mean_q: 67.113435, mean_eps: 0.850195
  50084/300000: episode: 514, duration: 0.744s, episode steps: 116, steps per second: 156, episode reward: -113.767, mean reward: -0.981 [-100.000,  7.595], mean action: 1.655 [0.000, 3.000],  loss: 10.072184, mae: 63.360979, mean_q: 68.975381, mean_eps: 0.849924
  50170/300000: episode: 515, duration: 0.543s, episode steps:  86, steps per second: 158, episode reward: -74.024, mean reward: -0.861 [-100.000, 10.023], mean action: 1.570 [0.000, 3.000],  loss: 10.861282, mae: 62.054482, mean_q: 67.553606, mean_eps: 0.849620
  50246/300000: episode: 516, duration: 0.519s, episode steps:  76, steps per second: 147, episode reward: -34.568, mean reward: -0.455 [-100.000, 53.402], mean action: 1.750 [0.000, 3.000],  loss: 19.733916, mae: 62.825917, mean_q: 68.818236, mean_eps: 0.849378
  50351/300000: episode: 517, duration: 0.740s, episode steps: 105, steps per second: 142, episode reward: -137.457, mean reward: -1.309 [-100.000, 10.408], mean action: 1.419 [0.000, 3.000],  loss: 13.748039, mae: 62.974275, mean_q: 68.036856, mean_eps: 0.849106
  50447/300000: episode: 518, duration: 0.683s, episode steps:  96, steps per second: 141, episode reward: -103.226, mean reward: -1.075 [-100.000, 13.351], mean action: 1.740 [0.000, 3.000],  loss: 12.831798, mae: 63.854483, mean_q: 69.444727, mean_eps: 0.848804
  50555/300000: episode: 519, duration: 0.798s, episode steps: 108, steps per second: 135, episode reward: -172.717, mean reward: -1.599 [-100.000,  6.814], mean action: 1.574 [0.000, 3.000],  loss: 18.137324, mae: 62.471469, mean_q: 67.231823, mean_eps: 0.848499
  50654/300000: episode: 520, duration: 0.685s, episode steps:  99, steps per second: 144, episode reward: -57.682, mean reward: -0.583 [-100.000,  8.707], mean action: 1.444 [0.000, 3.000],  loss: 14.092478, mae: 62.475243, mean_q: 66.752126, mean_eps: 0.848188
  50752/300000: episode: 521, duration: 0.662s, episode steps:  98, steps per second: 148, episode reward: -212.898, mean reward: -2.172 [-100.000,  1.006], mean action: 1.449 [0.000, 3.000],  loss: 14.387693, mae: 62.252323, mean_q: 66.696068, mean_eps: 0.847892
  50842/300000: episode: 522, duration: 0.633s, episode steps:  90, steps per second: 142, episode reward: -95.592, mean reward: -1.062 [-100.000,  5.447], mean action: 1.589 [0.000, 3.000],  loss: 13.074469, mae: 61.704012, mean_q: 65.586724, mean_eps: 0.847610
  50964/300000: episode: 523, duration: 0.832s, episode steps: 122, steps per second: 147, episode reward: -174.511, mean reward: -1.430 [-100.000,  8.904], mean action: 1.516 [0.000, 3.000],  loss: 7.989194, mae: 61.265288, mean_q: 64.622185, mean_eps: 0.847292
  51074/300000: episode: 524, duration: 0.693s, episode steps: 110, steps per second: 159, episode reward: -126.465, mean reward: -1.150 [-100.000,  7.338], mean action: 1.291 [0.000, 3.000],  loss: 16.472152, mae: 61.082221, mean_q: 63.180975, mean_eps: 0.846945
  51170/300000: episode: 525, duration: 0.628s, episode steps:  96, steps per second: 153, episode reward: -217.453, mean reward: -2.265 [-100.000,  7.675], mean action: 1.375 [0.000, 3.000],  loss: 8.955712, mae: 61.531679, mean_q: 63.737939, mean_eps: 0.846635
  51319/300000: episode: 526, duration: 0.982s, episode steps: 149, steps per second: 152, episode reward: -95.995, mean reward: -0.644 [-100.000, 19.414], mean action: 1.409 [0.000, 3.000],  loss: 14.850718, mae: 61.454021, mean_q: 63.868445, mean_eps: 0.846268
  51450/300000: episode: 527, duration: 0.826s, episode steps: 131, steps per second: 159, episode reward: -191.913, mean reward: -1.465 [-100.000, 22.286], mean action: 1.382 [0.000, 3.000],  loss: 12.983490, mae: 61.728084, mean_q: 64.603914, mean_eps: 0.845848
  51541/300000: episode: 528, duration: 0.634s, episode steps:  91, steps per second: 144, episode reward: -83.335, mean reward: -0.916 [-100.000, 10.180], mean action: 1.703 [0.000, 3.000],  loss: 12.657800, mae: 62.229655, mean_q: 64.108496, mean_eps: 0.845515
  51653/300000: episode: 529, duration: 0.772s, episode steps: 112, steps per second: 145, episode reward: -99.142, mean reward: -0.885 [-100.000,  8.687], mean action: 1.438 [0.000, 3.000],  loss: 15.986935, mae: 62.266132, mean_q: 63.894095, mean_eps: 0.845211
  51747/300000: episode: 530, duration: 0.592s, episode steps:  94, steps per second: 159, episode reward: -93.880, mean reward: -0.999 [-100.000, 12.476], mean action: 1.298 [0.000, 3.000],  loss: 12.725017, mae: 62.070067, mean_q: 63.790484, mean_eps: 0.844901
  51847/300000: episode: 531, duration: 0.655s, episode steps: 100, steps per second: 153, episode reward: -149.031, mean reward: -1.490 [-100.000, 29.630], mean action: 1.360 [0.000, 3.000],  loss: 7.285033, mae: 62.188601, mean_q: 63.927705, mean_eps: 0.844611
  51954/300000: episode: 532, duration: 0.698s, episode steps: 107, steps per second: 153, episode reward: -216.292, mean reward: -2.021 [-100.000,  6.339], mean action: 1.523 [0.000, 3.000],  loss: 12.805790, mae: 62.233481, mean_q: 64.570280, mean_eps: 0.844300
  52069/300000: episode: 533, duration: 0.739s, episode steps: 115, steps per second: 156, episode reward: -93.121, mean reward: -0.810 [-100.000, 13.498], mean action: 1.713 [0.000, 3.000],  loss: 16.723821, mae: 62.390217, mean_q: 64.213276, mean_eps: 0.843967
  52179/300000: episode: 534, duration: 0.752s, episode steps: 110, steps per second: 146, episode reward: -65.885, mean reward: -0.599 [-100.000,  9.328], mean action: 1.655 [0.000, 3.000],  loss: 8.126983, mae: 62.839220, mean_q: 66.160574, mean_eps: 0.843630
  52296/300000: episode: 535, duration: 0.767s, episode steps: 117, steps per second: 153, episode reward: -50.311, mean reward: -0.430 [-100.000, 11.535], mean action: 1.504 [0.000, 3.000],  loss: 11.477050, mae: 62.361014, mean_q: 63.077581, mean_eps: 0.843289
  52390/300000: episode: 536, duration: 0.599s, episode steps:  94, steps per second: 157, episode reward: -23.184, mean reward: -0.247 [-100.000, 97.396], mean action: 1.436 [0.000, 3.000],  loss: 19.542632, mae: 61.481367, mean_q: 63.930871, mean_eps: 0.842973
  52469/300000: episode: 537, duration: 0.501s, episode steps:  79, steps per second: 158, episode reward: -83.620, mean reward: -1.058 [-100.000, 14.007], mean action: 1.570 [0.000, 3.000],  loss: 16.427059, mae: 61.946701, mean_q: 63.365906, mean_eps: 0.842713
  52569/300000: episode: 538, duration: 0.682s, episode steps: 100, steps per second: 147, episode reward: -146.115, mean reward: -1.461 [-100.000, 29.587], mean action: 1.460 [0.000, 3.000],  loss: 17.263969, mae: 61.086722, mean_q: 62.893457, mean_eps: 0.842445
  52648/300000: episode: 539, duration: 0.499s, episode steps:  79, steps per second: 158, episode reward: -55.506, mean reward: -0.703 [-100.000, 12.231], mean action: 1.570 [0.000, 3.000],  loss: 12.646640, mae: 61.431403, mean_q: 63.071884, mean_eps: 0.842176
  52732/300000: episode: 540, duration: 0.529s, episode steps:  84, steps per second: 159, episode reward: -147.191, mean reward: -1.752 [-100.000, 11.467], mean action: 1.548 [0.000, 3.000],  loss: 12.283325, mae: 61.569818, mean_q: 64.380923, mean_eps: 0.841931
  52849/300000: episode: 541, duration: 0.759s, episode steps: 117, steps per second: 154, episode reward: -144.873, mean reward: -1.238 [-100.000,  3.027], mean action: 1.581 [0.000, 3.000],  loss: 15.746689, mae: 61.440689, mean_q: 63.569858, mean_eps: 0.841630
  52937/300000: episode: 542, duration: 0.580s, episode steps:  88, steps per second: 152, episode reward: -93.488, mean reward: -1.062 [-100.000, 27.189], mean action: 1.602 [0.000, 3.000],  loss: 13.921731, mae: 61.221442, mean_q: 61.500391, mean_eps: 0.841322
  53008/300000: episode: 543, duration: 0.457s, episode steps:  71, steps per second: 155, episode reward: -99.665, mean reward: -1.404 [-100.000,  6.524], mean action: 1.352 [0.000, 3.000],  loss: 10.573013, mae: 61.330398, mean_q: 62.858271, mean_eps: 0.841084
  53089/300000: episode: 544, duration: 0.514s, episode steps:  81, steps per second: 157, episode reward: -47.075, mean reward: -0.581 [-100.000, 21.679], mean action: 1.346 [0.000, 3.000],  loss: 11.776698, mae: 60.305852, mean_q: 61.283300, mean_eps: 0.840856
  53197/300000: episode: 545, duration: 0.728s, episode steps: 108, steps per second: 148, episode reward: -43.134, mean reward: -0.399 [-100.000, 11.974], mean action: 1.676 [0.000, 3.000],  loss: 10.387139, mae: 61.332595, mean_q: 62.614111, mean_eps: 0.840572
  53271/300000: episode: 546, duration: 0.484s, episode steps:  74, steps per second: 153, episode reward: -129.820, mean reward: -1.754 [-100.000, 32.598], mean action: 1.527 [0.000, 3.000],  loss: 11.075525, mae: 63.092327, mean_q: 64.264119, mean_eps: 0.840299
  53343/300000: episode: 547, duration: 0.463s, episode steps:  72, steps per second: 156, episode reward: -53.147, mean reward: -0.738 [-100.000,  7.925], mean action: 1.639 [0.000, 3.000],  loss: 18.194035, mae: 61.598954, mean_q: 62.319440, mean_eps: 0.840080
  53418/300000: episode: 548, duration: 0.480s, episode steps:  75, steps per second: 156, episode reward: -109.156, mean reward: -1.455 [-100.000,  6.173], mean action: 1.587 [0.000, 3.000],  loss: 13.154647, mae: 61.456723, mean_q: 63.830964, mean_eps: 0.839860
  53517/300000: episode: 549, duration: 0.692s, episode steps:  99, steps per second: 143, episode reward: -137.443, mean reward: -1.388 [-100.000,  7.517], mean action: 1.535 [0.000, 3.000],  loss: 14.832875, mae: 60.793876, mean_q: 61.652651, mean_eps: 0.839599
  53579/300000: episode: 550, duration: 0.393s, episode steps:  62, steps per second: 158, episode reward: -125.551, mean reward: -2.025 [-100.000,  8.118], mean action: 1.484 [0.000, 3.000],  loss: 11.578613, mae: 60.577140, mean_q: 62.043816, mean_eps: 0.839358
  53668/300000: episode: 551, duration: 0.571s, episode steps:  89, steps per second: 156, episode reward: -95.231, mean reward: -1.070 [-100.000, 13.609], mean action: 1.539 [0.000, 3.000],  loss: 15.653792, mae: 61.755470, mean_q: 64.813347, mean_eps: 0.839131
  53776/300000: episode: 552, duration: 0.677s, episode steps: 108, steps per second: 160, episode reward: -65.358, mean reward: -0.605 [-100.000, 15.681], mean action: 1.546 [0.000, 3.000],  loss: 12.056605, mae: 60.221004, mean_q: 60.914960, mean_eps: 0.838835
  53867/300000: episode: 553, duration: 0.636s, episode steps:  91, steps per second: 143, episode reward: -68.369, mean reward: -0.751 [-100.000, 11.884], mean action: 1.824 [0.000, 3.000],  loss: 9.270051, mae: 60.958150, mean_q: 62.911818, mean_eps: 0.838537
  53937/300000: episode: 554, duration: 0.464s, episode steps:  70, steps per second: 151, episode reward: -48.619, mean reward: -0.695 [-100.000, 13.622], mean action: 1.429 [0.000, 3.000],  loss: 12.811865, mae: 60.438250, mean_q: 62.224408, mean_eps: 0.838295
  54034/300000: episode: 555, duration: 0.697s, episode steps:  97, steps per second: 139, episode reward: -110.697, mean reward: -1.141 [-100.000,  6.740], mean action: 1.577 [0.000, 3.000],  loss: 10.091693, mae: 61.147024, mean_q: 63.000341, mean_eps: 0.838045
  54128/300000: episode: 556, duration: 0.735s, episode steps:  94, steps per second: 128, episode reward: -55.986, mean reward: -0.596 [-100.000, 18.178], mean action: 1.574 [0.000, 3.000],  loss: 11.703442, mae: 60.774109, mean_q: 62.956084, mean_eps: 0.837759
  54230/300000: episode: 557, duration: 0.773s, episode steps: 102, steps per second: 132, episode reward: -67.387, mean reward: -0.661 [-100.000, 13.336], mean action: 1.578 [0.000, 3.000],  loss: 10.869574, mae: 60.277287, mean_q: 61.695506, mean_eps: 0.837465
  54300/300000: episode: 558, duration: 0.484s, episode steps:  70, steps per second: 145, episode reward: -117.939, mean reward: -1.685 [-100.000, 16.465], mean action: 1.500 [0.000, 3.000],  loss: 6.169647, mae: 59.770188, mean_q: 61.870333, mean_eps: 0.837206
  54449/300000: episode: 559, duration: 1.069s, episode steps: 149, steps per second: 139, episode reward: -156.430, mean reward: -1.050 [-100.000,  9.144], mean action: 1.510 [0.000, 3.000],  loss: 13.687958, mae: 60.953087, mean_q: 62.387092, mean_eps: 0.836878
  54530/300000: episode: 560, duration: 0.577s, episode steps:  81, steps per second: 140, episode reward: -72.996, mean reward: -0.901 [-100.000, 21.574], mean action: 1.753 [0.000, 3.000],  loss: 8.751763, mae: 60.524738, mean_q: 62.077418, mean_eps: 0.836533
  54647/300000: episode: 561, duration: 0.809s, episode steps: 117, steps per second: 145, episode reward: -88.507, mean reward: -0.756 [-100.000, 13.410], mean action: 1.504 [0.000, 3.000],  loss: 11.336677, mae: 60.948795, mean_q: 62.228707, mean_eps: 0.836236
  54720/300000: episode: 562, duration: 0.481s, episode steps:  73, steps per second: 152, episode reward: -69.067, mean reward: -0.946 [-100.000, 10.063], mean action: 1.699 [0.000, 3.000],  loss: 9.932469, mae: 61.111661, mean_q: 62.839034, mean_eps: 0.835951
  54819/300000: episode: 563, duration: 0.680s, episode steps:  99, steps per second: 146, episode reward: -39.141, mean reward: -0.395 [-100.000, 21.692], mean action: 1.566 [0.000, 3.000],  loss: 10.345645, mae: 60.487683, mean_q: 61.047294, mean_eps: 0.835693
  54898/300000: episode: 564, duration: 0.502s, episode steps:  79, steps per second: 157, episode reward: -88.075, mean reward: -1.115 [-100.000, 35.797], mean action: 1.405 [0.000, 3.000],  loss: 18.407909, mae: 61.167060, mean_q: 61.393304, mean_eps: 0.835426
  54984/300000: episode: 565, duration: 0.553s, episode steps:  86, steps per second: 155, episode reward: -15.825, mean reward: -0.184 [-100.000, 53.539], mean action: 1.477 [0.000, 3.000],  loss: 13.548681, mae: 61.166771, mean_q: 62.275707, mean_eps: 0.835179
  55107/300000: episode: 566, duration: 0.863s, episode steps: 123, steps per second: 143, episode reward: -114.778, mean reward: -0.933 [-100.000,  9.334], mean action: 1.659 [0.000, 3.000],  loss: 17.503117, mae: 61.436738, mean_q: 64.313572, mean_eps: 0.834865
  55217/300000: episode: 567, duration: 0.757s, episode steps: 110, steps per second: 145, episode reward: -69.662, mean reward: -0.633 [-100.000,  7.469], mean action: 1.573 [0.000, 3.000],  loss: 10.895353, mae: 60.560288, mean_q: 62.371601, mean_eps: 0.834515
  55307/300000: episode: 568, duration: 0.627s, episode steps:  90, steps per second: 144, episode reward: -118.945, mean reward: -1.322 [-100.000,  5.955], mean action: 1.667 [0.000, 3.000],  loss: 13.385513, mae: 60.252716, mean_q: 63.044600, mean_eps: 0.834215
  55410/300000: episode: 569, duration: 0.837s, episode steps: 103, steps per second: 123, episode reward: -73.193, mean reward: -0.711 [-100.000,  8.758], mean action: 1.621 [0.000, 3.000],  loss: 13.725569, mae: 62.232413, mean_q: 65.676319, mean_eps: 0.833926
  55530/300000: episode: 570, duration: 0.808s, episode steps: 120, steps per second: 149, episode reward: -143.550, mean reward: -1.196 [-100.000,  9.981], mean action: 1.608 [0.000, 3.000],  loss: 12.702363, mae: 61.299046, mean_q: 64.015199, mean_eps: 0.833592
  55646/300000: episode: 571, duration: 0.743s, episode steps: 116, steps per second: 156, episode reward: -42.134, mean reward: -0.363 [-100.000, 16.789], mean action: 1.500 [0.000, 3.000],  loss: 13.269588, mae: 61.171761, mean_q: 62.901984, mean_eps: 0.833238
  55738/300000: episode: 572, duration: 0.656s, episode steps:  92, steps per second: 140, episode reward: -195.393, mean reward: -2.124 [-100.000, 44.817], mean action: 1.630 [0.000, 3.000],  loss: 15.633796, mae: 61.525111, mean_q: 64.781567, mean_eps: 0.832926
  55886/300000: episode: 573, duration: 1.082s, episode steps: 148, steps per second: 137, episode reward: -59.926, mean reward: -0.405 [-100.000, 12.040], mean action: 1.669 [0.000, 3.000],  loss: 11.748267, mae: 60.772625, mean_q: 63.440780, mean_eps: 0.832566
  55985/300000: episode: 574, duration: 0.676s, episode steps:  99, steps per second: 146, episode reward: -98.909, mean reward: -0.999 [-100.000,  7.604], mean action: 1.566 [0.000, 3.000],  loss: 12.105840, mae: 61.157354, mean_q: 64.936559, mean_eps: 0.832195
  56108/300000: episode: 575, duration: 0.851s, episode steps: 123, steps per second: 145, episode reward: -94.349, mean reward: -0.767 [-100.000, 11.426], mean action: 1.659 [0.000, 3.000],  loss: 15.044285, mae: 61.342515, mean_q: 64.460047, mean_eps: 0.831862
  56167/300000: episode: 576, duration: 0.388s, episode steps:  59, steps per second: 152, episode reward: -87.391, mean reward: -1.481 [-100.000,  8.056], mean action: 1.542 [0.000, 3.000],  loss: 14.030779, mae: 60.548998, mean_q: 62.609629, mean_eps: 0.831589
  56251/300000: episode: 577, duration: 0.545s, episode steps:  84, steps per second: 154, episode reward: -77.434, mean reward: -0.922 [-100.000,  9.080], mean action: 1.643 [0.000, 3.000],  loss: 15.365123, mae: 61.065081, mean_q: 64.159184, mean_eps: 0.831375
  56372/300000: episode: 578, duration: 0.822s, episode steps: 121, steps per second: 147, episode reward: -69.738, mean reward: -0.576 [-100.000,  7.863], mean action: 1.421 [0.000, 3.000],  loss: 13.071828, mae: 60.262459, mean_q: 64.256255, mean_eps: 0.831067
  56489/300000: episode: 579, duration: 0.744s, episode steps: 117, steps per second: 157, episode reward: -76.736, mean reward: -0.656 [-100.000, 14.274], mean action: 1.641 [0.000, 3.000],  loss: 22.946311, mae: 60.338365, mean_q: 63.792593, mean_eps: 0.830710
  56597/300000: episode: 580, duration: 0.685s, episode steps: 108, steps per second: 158, episode reward: -120.027, mean reward: -1.111 [-100.000,  7.572], mean action: 1.417 [0.000, 3.000],  loss: 12.889531, mae: 61.444424, mean_q: 65.576852, mean_eps: 0.830372
  56665/300000: episode: 581, duration: 0.488s, episode steps:  68, steps per second: 139, episode reward: -103.090, mean reward: -1.516 [-100.000, 24.606], mean action: 1.382 [0.000, 3.000],  loss: 13.051688, mae: 60.506453, mean_q: 64.234833, mean_eps: 0.830108
  56755/300000: episode: 582, duration: 0.623s, episode steps:  90, steps per second: 144, episode reward: -79.279, mean reward: -0.881 [-100.000, 12.003], mean action: 1.711 [0.000, 3.000],  loss: 9.222830, mae: 60.923600, mean_q: 65.694632, mean_eps: 0.829871
  56855/300000: episode: 583, duration: 0.642s, episode steps: 100, steps per second: 156, episode reward: -26.137, mean reward: -0.261 [-100.000, 12.593], mean action: 1.590 [0.000, 3.000],  loss: 11.304276, mae: 60.666037, mean_q: 64.825403, mean_eps: 0.829586
  56957/300000: episode: 584, duration: 0.670s, episode steps: 102, steps per second: 152, episode reward: -103.770, mean reward: -1.017 [-100.000, 13.047], mean action: 1.647 [0.000, 3.000],  loss: 17.403416, mae: 60.442024, mean_q: 64.097207, mean_eps: 0.829283
  57056/300000: episode: 585, duration: 0.665s, episode steps:  99, steps per second: 149, episode reward: -98.019, mean reward: -0.990 [-100.000,  9.325], mean action: 1.707 [0.000, 3.000],  loss: 18.136355, mae: 61.002089, mean_q: 66.578938, mean_eps: 0.828982
  57204/300000: episode: 586, duration: 0.949s, episode steps: 148, steps per second: 156, episode reward: -240.105, mean reward: -1.622 [-100.000, 11.135], mean action: 1.676 [0.000, 3.000],  loss: 13.342547, mae: 60.872911, mean_q: 65.516896, mean_eps: 0.828611
  57309/300000: episode: 587, duration: 0.684s, episode steps: 105, steps per second: 153, episode reward: -96.960, mean reward: -0.923 [-100.000, 11.233], mean action: 1.629 [0.000, 3.000],  loss: 13.887450, mae: 61.224001, mean_q: 66.504778, mean_eps: 0.828232
  57389/300000: episode: 588, duration: 0.529s, episode steps:  80, steps per second: 151, episode reward: -71.733, mean reward: -0.897 [-100.000, 17.430], mean action: 1.337 [0.000, 3.000],  loss: 14.745308, mae: 62.631421, mean_q: 68.378048, mean_eps: 0.827955
  57518/300000: episode: 589, duration: 0.821s, episode steps: 129, steps per second: 157, episode reward: -215.175, mean reward: -1.668 [-100.000, 41.179], mean action: 1.473 [0.000, 3.000],  loss: 15.051401, mae: 61.705159, mean_q: 66.433127, mean_eps: 0.827641
  57588/300000: episode: 590, duration: 0.456s, episode steps:  70, steps per second: 153, episode reward: -150.871, mean reward: -2.155 [-100.000, 17.905], mean action: 1.614 [0.000, 3.000],  loss: 11.790503, mae: 62.243079, mean_q: 67.966833, mean_eps: 0.827342
  57702/300000: episode: 591, duration: 0.764s, episode steps: 114, steps per second: 149, episode reward: -49.378, mean reward: -0.433 [-100.000, 11.685], mean action: 1.553 [0.000, 3.000],  loss: 16.979228, mae: 61.742139, mean_q: 68.018603, mean_eps: 0.827067
  57800/300000: episode: 592, duration: 0.620s, episode steps:  98, steps per second: 158, episode reward: -95.870, mean reward: -0.978 [-100.000,  7.174], mean action: 1.673 [0.000, 3.000],  loss: 12.138398, mae: 60.846419, mean_q: 65.774651, mean_eps: 0.826748
  57897/300000: episode: 593, duration: 0.613s, episode steps:  97, steps per second: 158, episode reward: -75.066, mean reward: -0.774 [-100.000, 12.410], mean action: 1.546 [0.000, 3.000],  loss: 9.084639, mae: 60.267283, mean_q: 64.725835, mean_eps: 0.826456
  58014/300000: episode: 594, duration: 0.801s, episode steps: 117, steps per second: 146, episode reward: -71.129, mean reward: -0.608 [-100.000, 13.301], mean action: 1.479 [0.000, 3.000],  loss: 10.900761, mae: 60.476660, mean_q: 64.634760, mean_eps: 0.826135
  58088/300000: episode: 595, duration: 0.484s, episode steps:  74, steps per second: 153, episode reward: -97.166, mean reward: -1.313 [-100.000,  4.813], mean action: 1.392 [0.000, 3.000],  loss: 14.424897, mae: 61.447848, mean_q: 66.532337, mean_eps: 0.825848
  58154/300000: episode: 596, duration: 0.419s, episode steps:  66, steps per second: 158, episode reward: -126.223, mean reward: -1.912 [-100.000, 34.651], mean action: 1.394 [0.000, 3.000],  loss: 15.147032, mae: 60.777434, mean_q: 65.282899, mean_eps: 0.825638
  58249/300000: episode: 597, duration: 0.598s, episode steps:  95, steps per second: 159, episode reward: -135.069, mean reward: -1.422 [-100.000,  6.855], mean action: 1.495 [0.000, 3.000],  loss: 17.969395, mae: 60.547799, mean_q: 64.297580, mean_eps: 0.825397
  58359/300000: episode: 598, duration: 0.746s, episode steps: 110, steps per second: 148, episode reward: -79.634, mean reward: -0.724 [-100.000,  9.334], mean action: 1.600 [0.000, 3.000],  loss: 15.390042, mae: 61.175518, mean_q: 65.712087, mean_eps: 0.825090
  58479/300000: episode: 599, duration: 0.777s, episode steps: 120, steps per second: 155, episode reward: -69.072, mean reward: -0.576 [-100.000, 14.587], mean action: 1.608 [0.000, 3.000],  loss: 11.075571, mae: 61.801827, mean_q: 65.735111, mean_eps: 0.824744
  58603/300000: episode: 600, duration: 0.802s, episode steps: 124, steps per second: 155, episode reward: -255.084, mean reward: -2.057 [-100.000, 63.498], mean action: 1.605 [0.000, 3.000],  loss: 13.861253, mae: 62.376382, mean_q: 66.278064, mean_eps: 0.824379
  58680/300000: episode: 601, duration: 0.516s, episode steps:  77, steps per second: 149, episode reward: -88.103, mean reward: -1.144 [-100.000, 26.110], mean action: 1.519 [0.000, 3.000],  loss: 17.186844, mae: 62.260134, mean_q: 66.062871, mean_eps: 0.824077
  58740/300000: episode: 602, duration: 0.387s, episode steps:  60, steps per second: 155, episode reward: -80.512, mean reward: -1.342 [-100.000, 12.065], mean action: 1.567 [0.000, 3.000],  loss: 9.787458, mae: 61.589684, mean_q: 64.138410, mean_eps: 0.823871
  58809/300000: episode: 603, duration: 0.447s, episode steps:  69, steps per second: 155, episode reward: -81.239, mean reward: -1.177 [-100.000, 12.735], mean action: 1.594 [0.000, 3.000],  loss: 12.951217, mae: 61.295371, mean_q: 62.844850, mean_eps: 0.823678
  58880/300000: episode: 604, duration: 0.457s, episode steps:  71, steps per second: 155, episode reward: -81.647, mean reward: -1.150 [-100.000, 12.145], mean action: 1.704 [0.000, 3.000],  loss: 13.249290, mae: 61.615045, mean_q: 63.446645, mean_eps: 0.823468
  58947/300000: episode: 605, duration: 0.458s, episode steps:  67, steps per second: 146, episode reward: -105.479, mean reward: -1.574 [-100.000, 18.167], mean action: 1.657 [0.000, 3.000],  loss: 8.568284, mae: 61.901045, mean_q: 64.216993, mean_eps: 0.823261
  59016/300000: episode: 606, duration: 0.461s, episode steps:  69, steps per second: 150, episode reward: -64.321, mean reward: -0.932 [-100.000, 22.551], mean action: 1.609 [0.000, 3.000],  loss: 10.732513, mae: 61.635849, mean_q: 62.968738, mean_eps: 0.823057
  59075/300000: episode: 607, duration: 0.386s, episode steps:  59, steps per second: 153, episode reward: -69.417, mean reward: -1.177 [-100.000,  9.884], mean action: 1.458 [0.000, 3.000],  loss: 16.366427, mae: 61.913799, mean_q: 64.053088, mean_eps: 0.822865
  59215/300000: episode: 608, duration: 0.885s, episode steps: 140, steps per second: 158, episode reward:  9.074, mean reward:  0.065 [-100.000, 70.482], mean action: 1.629 [0.000, 3.000],  loss: 11.000683, mae: 62.900996, mean_q: 65.833575, mean_eps: 0.822567
  59287/300000: episode: 609, duration: 0.487s, episode steps:  72, steps per second: 148, episode reward: -69.002, mean reward: -0.958 [-100.000, 10.458], mean action: 1.472 [0.000, 3.000],  loss: 13.280025, mae: 62.208787, mean_q: 64.457076, mean_eps: 0.822249
  59400/300000: episode: 610, duration: 0.743s, episode steps: 113, steps per second: 152, episode reward: -133.395, mean reward: -1.180 [-100.000,  5.173], mean action: 1.566 [0.000, 3.000],  loss: 10.453525, mae: 62.402842, mean_q: 65.375550, mean_eps: 0.821971
  59489/300000: episode: 611, duration: 0.562s, episode steps:  89, steps per second: 158, episode reward: -87.901, mean reward: -0.988 [-100.000,  9.963], mean action: 1.461 [0.000, 3.000],  loss: 13.941087, mae: 62.965335, mean_q: 67.125064, mean_eps: 0.821668
  59622/300000: episode: 612, duration: 0.873s, episode steps: 133, steps per second: 152, episode reward: -307.435, mean reward: -2.312 [-100.000, 99.332], mean action: 1.331 [0.000, 3.000],  loss: 14.811056, mae: 62.176698, mean_q: 66.550978, mean_eps: 0.821335
  59705/300000: episode: 613, duration: 0.544s, episode steps:  83, steps per second: 153, episode reward: -79.133, mean reward: -0.953 [-100.000,  9.084], mean action: 1.711 [0.000, 3.000],  loss: 11.604572, mae: 61.343175, mean_q: 63.687035, mean_eps: 0.821011
  59830/300000: episode: 614, duration: 0.800s, episode steps: 125, steps per second: 156, episode reward: -147.352, mean reward: -1.179 [-100.000, 26.692], mean action: 1.584 [0.000, 3.000],  loss: 15.970468, mae: 61.288428, mean_q: 64.621066, mean_eps: 0.820699
  59903/300000: episode: 615, duration: 0.465s, episode steps:  73, steps per second: 157, episode reward: -118.957, mean reward: -1.630 [-100.000,  5.391], mean action: 1.740 [0.000, 3.000],  loss: 28.886082, mae: 61.595114, mean_q: 65.869145, mean_eps: 0.820402
  60015/300000: episode: 616, duration: 0.755s, episode steps: 112, steps per second: 148, episode reward: -188.889, mean reward: -1.687 [-100.000,  8.148], mean action: 1.491 [0.000, 3.000],  loss: 20.604091, mae: 61.130374, mean_q: 65.508786, mean_eps: 0.820125
  60110/300000: episode: 617, duration: 0.604s, episode steps:  95, steps per second: 157, episode reward: -78.374, mean reward: -0.825 [-100.000,  9.554], mean action: 1.526 [0.000, 3.000],  loss: 14.981297, mae: 62.231860, mean_q: 68.095899, mean_eps: 0.819814
  60236/300000: episode: 618, duration: 0.862s, episode steps: 126, steps per second: 146, episode reward: -77.965, mean reward: -0.619 [-100.000, 10.359], mean action: 1.627 [0.000, 3.000],  loss: 20.725076, mae: 62.403926, mean_q: 67.211089, mean_eps: 0.819482
  60320/300000: episode: 619, duration: 0.665s, episode steps:  84, steps per second: 126, episode reward: -111.174, mean reward: -1.324 [-100.000,  5.747], mean action: 1.536 [0.000, 3.000],  loss: 20.788098, mae: 62.710352, mean_q: 68.435541, mean_eps: 0.819167
  60381/300000: episode: 620, duration: 0.432s, episode steps:  61, steps per second: 141, episode reward: -126.210, mean reward: -2.069 [-100.000,  9.023], mean action: 1.557 [0.000, 3.000],  loss: 13.044471, mae: 64.163519, mean_q: 69.574248, mean_eps: 0.818950
  60462/300000: episode: 621, duration: 0.590s, episode steps:  81, steps per second: 137, episode reward: -39.117, mean reward: -0.483 [-100.000, 16.584], mean action: 1.543 [0.000, 3.000],  loss: 17.652029, mae: 64.052722, mean_q: 69.741377, mean_eps: 0.818737
  60547/300000: episode: 622, duration: 0.628s, episode steps:  85, steps per second: 135, episode reward: -76.430, mean reward: -0.899 [-100.000, 17.528], mean action: 1.659 [0.000, 3.000],  loss: 19.417063, mae: 63.889991, mean_q: 68.980663, mean_eps: 0.818488
  60651/300000: episode: 623, duration: 0.761s, episode steps: 104, steps per second: 137, episode reward: -173.022, mean reward: -1.664 [-100.000, 14.525], mean action: 1.635 [0.000, 3.000],  loss: 15.417385, mae: 64.002835, mean_q: 69.075663, mean_eps: 0.818205
  60729/300000: episode: 624, duration: 0.533s, episode steps:  78, steps per second: 146, episode reward: -144.727, mean reward: -1.855 [-100.000,  6.678], mean action: 1.718 [0.000, 3.000],  loss: 9.889145, mae: 63.580276, mean_q: 68.258262, mean_eps: 0.817932
  60865/300000: episode: 625, duration: 0.902s, episode steps: 136, steps per second: 151, episode reward: -58.298, mean reward: -0.429 [-100.000,  9.924], mean action: 1.559 [0.000, 3.000],  loss: 21.501390, mae: 65.247814, mean_q: 70.748744, mean_eps: 0.817610
  60984/300000: episode: 626, duration: 0.767s, episode steps: 119, steps per second: 155, episode reward: -29.821, mean reward: -0.251 [-100.000, 14.260], mean action: 1.639 [0.000, 3.000],  loss: 17.137709, mae: 65.600399, mean_q: 70.027435, mean_eps: 0.817228
  61106/300000: episode: 627, duration: 0.821s, episode steps: 122, steps per second: 149, episode reward: -98.475, mean reward: -0.807 [-100.000,  7.266], mean action: 1.279 [0.000, 3.000],  loss: 14.033669, mae: 66.153844, mean_q: 70.896208, mean_eps: 0.816867
  61212/300000: episode: 628, duration: 0.722s, episode steps: 106, steps per second: 147, episode reward: -133.291, mean reward: -1.257 [-100.000, 13.681], mean action: 1.481 [0.000, 3.000],  loss: 14.338469, mae: 65.422779, mean_q: 69.008290, mean_eps: 0.816524
  61320/300000: episode: 629, duration: 0.697s, episode steps: 108, steps per second: 155, episode reward: -83.233, mean reward: -0.771 [-100.000,  5.504], mean action: 1.620 [0.000, 3.000],  loss: 12.228607, mae: 66.689055, mean_q: 70.979666, mean_eps: 0.816204
  61398/300000: episode: 630, duration: 0.495s, episode steps:  78, steps per second: 158, episode reward: -42.977, mean reward: -0.551 [-100.000, 16.190], mean action: 1.500 [0.000, 3.000],  loss: 13.712262, mae: 66.613941, mean_q: 70.897913, mean_eps: 0.815925
  61488/300000: episode: 631, duration: 0.575s, episode steps:  90, steps per second: 157, episode reward: -75.123, mean reward: -0.835 [-100.000, 12.456], mean action: 1.600 [0.000, 3.000],  loss: 19.359395, mae: 66.534336, mean_q: 71.178878, mean_eps: 0.815672
  61582/300000: episode: 632, duration: 0.644s, episode steps:  94, steps per second: 146, episode reward: -27.263, mean reward: -0.290 [-100.000,  8.632], mean action: 1.691 [0.000, 3.000],  loss: 14.433478, mae: 66.590106, mean_q: 71.923871, mean_eps: 0.815396
  61668/300000: episode: 633, duration: 0.552s, episode steps:  86, steps per second: 156, episode reward: -70.310, mean reward: -0.818 [-100.000, 18.650], mean action: 1.512 [0.000, 3.000],  loss: 12.697354, mae: 66.461709, mean_q: 72.135647, mean_eps: 0.815127
  61761/300000: episode: 634, duration: 0.596s, episode steps:  93, steps per second: 156, episode reward: -98.274, mean reward: -1.057 [-100.000,  5.030], mean action: 1.602 [0.000, 3.000],  loss: 13.713444, mae: 66.269955, mean_q: 71.704195, mean_eps: 0.814858
  61839/300000: episode: 635, duration: 0.522s, episode steps:  78, steps per second: 149, episode reward: -108.082, mean reward: -1.386 [-100.000,  9.761], mean action: 1.436 [0.000, 3.000],  loss: 16.681279, mae: 67.219771, mean_q: 73.618190, mean_eps: 0.814602
  61932/300000: episode: 636, duration: 0.618s, episode steps:  93, steps per second: 150, episode reward: -61.841, mean reward: -0.665 [-100.000, 31.376], mean action: 1.645 [0.000, 3.000],  loss: 12.542473, mae: 66.433758, mean_q: 71.547179, mean_eps: 0.814345
  62062/300000: episode: 637, duration: 0.859s, episode steps: 130, steps per second: 151, episode reward: -129.887, mean reward: -0.999 [-100.000,  6.547], mean action: 1.646 [0.000, 3.000],  loss: 12.283879, mae: 65.998549, mean_q: 70.550811, mean_eps: 0.814010
  62162/300000: episode: 638, duration: 0.639s, episode steps: 100, steps per second: 156, episode reward: -41.281, mean reward: -0.413 [-100.000, 11.449], mean action: 1.680 [0.000, 3.000],  loss: 15.082673, mae: 65.559177, mean_q: 70.376994, mean_eps: 0.813665
  62257/300000: episode: 639, duration: 0.637s, episode steps:  95, steps per second: 149, episode reward: -96.902, mean reward: -1.020 [-100.000, 14.012], mean action: 1.737 [0.000, 3.000],  loss: 15.057602, mae: 64.901305, mean_q: 69.500119, mean_eps: 0.813373
  62377/300000: episode: 640, duration: 0.752s, episode steps: 120, steps per second: 160, episode reward: -179.106, mean reward: -1.493 [-100.000, 55.341], mean action: 1.408 [0.000, 3.000],  loss: 16.939528, mae: 65.120323, mean_q: 68.745561, mean_eps: 0.813050
  62443/300000: episode: 641, duration: 0.436s, episode steps:  66, steps per second: 151, episode reward: -0.702, mean reward: -0.011 [-100.000, 73.212], mean action: 1.697 [0.000, 3.000],  loss: 11.262022, mae: 66.569370, mean_q: 71.646865, mean_eps: 0.812771
  62539/300000: episode: 642, duration: 0.680s, episode steps:  96, steps per second: 141, episode reward: -238.054, mean reward: -2.480 [-100.000, 42.446], mean action: 1.708 [0.000, 3.000],  loss: 14.663386, mae: 67.457440, mean_q: 72.654224, mean_eps: 0.812528
  62610/300000: episode: 643, duration: 0.467s, episode steps:  71, steps per second: 152, episode reward: -58.234, mean reward: -0.820 [-100.000, 11.081], mean action: 1.535 [0.000, 3.000],  loss: 19.585140, mae: 68.353355, mean_q: 74.660863, mean_eps: 0.812278
  62704/300000: episode: 644, duration: 0.594s, episode steps:  94, steps per second: 158, episode reward: -67.056, mean reward: -0.713 [-100.000, 14.386], mean action: 1.638 [0.000, 3.000],  loss: 17.106086, mae: 67.521508, mean_q: 71.546024, mean_eps: 0.812030
  62837/300000: episode: 645, duration: 0.897s, episode steps: 133, steps per second: 148, episode reward: -78.897, mean reward: -0.593 [-100.000,  9.559], mean action: 1.707 [0.000, 3.000],  loss: 15.112873, mae: 68.042420, mean_q: 74.429934, mean_eps: 0.811690
  62932/300000: episode: 646, duration: 0.647s, episode steps:  95, steps per second: 147, episode reward: -117.613, mean reward: -1.238 [-100.000, 19.791], mean action: 1.568 [0.000, 3.000],  loss: 17.210180, mae: 68.119456, mean_q: 74.438457, mean_eps: 0.811348
  62993/300000: episode: 647, duration: 0.389s, episode steps:  61, steps per second: 157, episode reward: -21.855, mean reward: -0.358 [-100.000, 75.922], mean action: 1.492 [0.000, 3.000],  loss: 18.898485, mae: 67.013800, mean_q: 72.226829, mean_eps: 0.811114
  63063/300000: episode: 648, duration: 0.438s, episode steps:  70, steps per second: 160, episode reward: -30.574, mean reward: -0.437 [-100.000, 13.481], mean action: 1.514 [0.000, 3.000],  loss: 31.627128, mae: 68.236094, mean_q: 73.101265, mean_eps: 0.810917
  63132/300000: episode: 649, duration: 0.443s, episode steps:  69, steps per second: 156, episode reward: -88.320, mean reward: -1.280 [-100.000,  8.330], mean action: 1.478 [0.000, 3.000],  loss: 26.359073, mae: 68.300749, mean_q: 72.972113, mean_eps: 0.810709
  63203/300000: episode: 650, duration: 0.517s, episode steps:  71, steps per second: 137, episode reward: 11.760, mean reward:  0.166 [-100.000, 86.355], mean action: 1.408 [0.000, 3.000],  loss: 24.835091, mae: 68.216654, mean_q: 74.601610, mean_eps: 0.810499
  63333/300000: episode: 651, duration: 0.831s, episode steps: 130, steps per second: 156, episode reward: -227.269, mean reward: -1.748 [-100.000, 38.045], mean action: 1.623 [0.000, 3.000],  loss: 21.957850, mae: 68.836277, mean_q: 74.654538, mean_eps: 0.810197
  63438/300000: episode: 652, duration: 0.759s, episode steps: 105, steps per second: 138, episode reward: -64.688, mean reward: -0.616 [-100.000, 13.349], mean action: 1.657 [0.000, 3.000],  loss: 23.415213, mae: 70.227435, mean_q: 77.014430, mean_eps: 0.809845
  63526/300000: episode: 653, duration: 0.641s, episode steps:  88, steps per second: 137, episode reward: -132.895, mean reward: -1.510 [-100.000,  7.375], mean action: 1.534 [0.000, 3.000],  loss: 10.825905, mae: 69.616860, mean_q: 73.342626, mean_eps: 0.809555
  63639/300000: episode: 654, duration: 0.736s, episode steps: 113, steps per second: 153, episode reward: -77.486, mean reward: -0.686 [-100.000,  6.798], mean action: 1.513 [0.000, 3.000],  loss: 36.888361, mae: 70.156378, mean_q: 75.837523, mean_eps: 0.809254
  63762/300000: episode: 655, duration: 0.758s, episode steps: 123, steps per second: 162, episode reward: -102.816, mean reward: -0.836 [-100.000,  9.647], mean action: 1.504 [0.000, 3.000],  loss: 21.427087, mae: 67.930018, mean_q: 71.623747, mean_eps: 0.808900
  63870/300000: episode: 656, duration: 0.871s, episode steps: 108, steps per second: 124, episode reward: -163.657, mean reward: -1.515 [-100.000,  4.049], mean action: 1.639 [0.000, 3.000],  loss: 21.442997, mae: 70.479440, mean_q: 75.828670, mean_eps: 0.808553
  63967/300000: episode: 657, duration: 0.694s, episode steps:  97, steps per second: 140, episode reward: -16.501, mean reward: -0.170 [-100.000, 61.984], mean action: 1.567 [0.000, 3.000],  loss: 19.384066, mae: 69.281847, mean_q: 74.901446, mean_eps: 0.808246
  64063/300000: episode: 658, duration: 0.689s, episode steps:  96, steps per second: 139, episode reward: -58.458, mean reward: -0.609 [-100.000, 12.496], mean action: 1.490 [0.000, 3.000],  loss: 23.124758, mae: 69.335929, mean_q: 75.682915, mean_eps: 0.807956
  64143/300000: episode: 659, duration: 0.607s, episode steps:  80, steps per second: 132, episode reward: -110.656, mean reward: -1.383 [-100.000, 12.785], mean action: 1.750 [0.000, 3.000],  loss: 16.347123, mae: 69.381341, mean_q: 75.672177, mean_eps: 0.807693
  64212/300000: episode: 660, duration: 0.479s, episode steps:  69, steps per second: 144, episode reward: -89.618, mean reward: -1.299 [-100.000, 24.113], mean action: 1.783 [0.000, 3.000],  loss: 17.653523, mae: 70.406184, mean_q: 77.410572, mean_eps: 0.807469
  64295/300000: episode: 661, duration: 0.587s, episode steps:  83, steps per second: 141, episode reward: -82.933, mean reward: -0.999 [-100.000, 10.239], mean action: 1.566 [0.000, 3.000],  loss: 13.274334, mae: 71.237076, mean_q: 78.406551, mean_eps: 0.807241
  64414/300000: episode: 662, duration: 0.840s, episode steps: 119, steps per second: 142, episode reward: -63.691, mean reward: -0.535 [-100.000, 21.853], mean action: 1.496 [0.000, 3.000],  loss: 35.871298, mae: 70.255303, mean_q: 75.145460, mean_eps: 0.806938
  64487/300000: episode: 663, duration: 0.549s, episode steps:  73, steps per second: 133, episode reward: -20.511, mean reward: -0.281 [-100.000, 12.714], mean action: 1.685 [0.000, 3.000],  loss: 20.092441, mae: 68.491207, mean_q: 73.981072, mean_eps: 0.806650
  64611/300000: episode: 664, duration: 0.805s, episode steps: 124, steps per second: 154, episode reward: -24.837, mean reward: -0.200 [-100.000, 59.476], mean action: 1.613 [0.000, 3.000],  loss: 12.761472, mae: 70.273276, mean_q: 76.859685, mean_eps: 0.806354
  64687/300000: episode: 665, duration: 0.472s, episode steps:  76, steps per second: 161, episode reward: -80.720, mean reward: -1.062 [-100.000,  6.742], mean action: 1.500 [0.000, 3.000],  loss: 23.870881, mae: 70.081422, mean_q: 74.766110, mean_eps: 0.806055
  64836/300000: episode: 666, duration: 1.016s, episode steps: 149, steps per second: 147, episode reward: -69.279, mean reward: -0.465 [-100.000,  7.167], mean action: 1.685 [0.000, 3.000],  loss: 24.162672, mae: 70.938182, mean_q: 77.265716, mean_eps: 0.805717
  64953/300000: episode: 667, duration: 0.752s, episode steps: 117, steps per second: 156, episode reward: -211.771, mean reward: -1.810 [-100.000, 74.905], mean action: 1.624 [0.000, 3.000],  loss: 18.114477, mae: 71.632640, mean_q: 79.137122, mean_eps: 0.805318
  65043/300000: episode: 668, duration: 0.585s, episode steps:  90, steps per second: 154, episode reward: -32.706, mean reward: -0.363 [-100.000, 16.228], mean action: 1.622 [0.000, 3.000],  loss: 17.254788, mae: 71.331461, mean_q: 79.420378, mean_eps: 0.805008
  65134/300000: episode: 669, duration: 0.610s, episode steps:  91, steps per second: 149, episode reward: -193.603, mean reward: -2.128 [-100.000, 50.323], mean action: 1.802 [0.000, 3.000],  loss: 18.507353, mae: 72.694363, mean_q: 81.702979, mean_eps: 0.804736
  65224/300000: episode: 670, duration: 0.596s, episode steps:  90, steps per second: 151, episode reward: -230.061, mean reward: -2.556 [-100.000, 27.397], mean action: 1.633 [0.000, 3.000],  loss: 18.913988, mae: 74.458494, mean_q: 83.698438, mean_eps: 0.804464
  65303/300000: episode: 671, duration: 0.504s, episode steps:  79, steps per second: 157, episode reward: -41.423, mean reward: -0.524 [-100.000, 17.369], mean action: 1.671 [0.000, 3.000],  loss: 20.743772, mae: 73.290388, mean_q: 82.495151, mean_eps: 0.804211
  65429/300000: episode: 672, duration: 0.900s, episode steps: 126, steps per second: 140, episode reward: -98.856, mean reward: -0.785 [-100.000, 19.800], mean action: 1.579 [0.000, 3.000],  loss: 15.802973, mae: 74.133807, mean_q: 83.570373, mean_eps: 0.803903
  65545/300000: episode: 673, duration: 0.768s, episode steps: 116, steps per second: 151, episode reward: -66.675, mean reward: -0.575 [-100.000, 79.751], mean action: 1.698 [0.000, 3.000],  loss: 17.537991, mae: 73.755117, mean_q: 83.745211, mean_eps: 0.803541
  65692/300000: episode: 674, duration: 0.961s, episode steps: 147, steps per second: 153, episode reward: -36.384, mean reward: -0.248 [-100.000, 12.973], mean action: 1.626 [0.000, 3.000],  loss: 15.955181, mae: 73.365437, mean_q: 83.801813, mean_eps: 0.803146
  65751/300000: episode: 675, duration: 0.401s, episode steps:  59, steps per second: 147, episode reward: -92.998, mean reward: -1.576 [-100.000, 12.387], mean action: 1.542 [0.000, 3.000],  loss: 25.430710, mae: 74.477615, mean_q: 85.510244, mean_eps: 0.802837
  65837/300000: episode: 676, duration: 0.559s, episode steps:  86, steps per second: 154, episode reward: -54.398, mean reward: -0.633 [-100.000,  7.465], mean action: 1.628 [0.000, 3.000],  loss: 18.200162, mae: 73.915486, mean_q: 84.887680, mean_eps: 0.802620
  65917/300000: episode: 677, duration: 0.515s, episode steps:  80, steps per second: 155, episode reward: -98.315, mean reward: -1.229 [-100.000,  8.370], mean action: 1.613 [0.000, 3.000],  loss: 21.034015, mae: 75.108824, mean_q: 86.088247, mean_eps: 0.802370
  66027/300000: episode: 678, duration: 0.718s, episode steps: 110, steps per second: 153, episode reward: -49.274, mean reward: -0.448 [-100.000, 16.014], mean action: 1.609 [0.000, 3.000],  loss: 20.050090, mae: 76.094048, mean_q: 87.356885, mean_eps: 0.802086
  66109/300000: episode: 679, duration: 0.558s, episode steps:  82, steps per second: 147, episode reward: -80.430, mean reward: -0.981 [-100.000,  7.440], mean action: 1.378 [0.000, 3.000],  loss: 21.525027, mae: 78.581388, mean_q: 91.645537, mean_eps: 0.801797
  66210/300000: episode: 680, duration: 0.635s, episode steps: 101, steps per second: 159, episode reward: -133.075, mean reward: -1.318 [-100.000,  7.427], mean action: 1.574 [0.000, 3.000],  loss: 19.986975, mae: 76.839890, mean_q: 88.492680, mean_eps: 0.801523
  66294/300000: episode: 681, duration: 0.540s, episode steps:  84, steps per second: 156, episode reward: -70.919, mean reward: -0.844 [-100.000, 17.884], mean action: 1.643 [0.000, 3.000],  loss: 17.166671, mae: 76.374441, mean_q: 87.076609, mean_eps: 0.801245
  66383/300000: episode: 682, duration: 0.598s, episode steps:  89, steps per second: 149, episode reward: -50.326, mean reward: -0.565 [-100.000, 11.961], mean action: 1.652 [0.000, 3.000],  loss: 17.391158, mae: 77.245536, mean_q: 89.101268, mean_eps: 0.800986
  66465/300000: episode: 683, duration: 0.546s, episode steps:  82, steps per second: 150, episode reward: -131.352, mean reward: -1.602 [-100.000, 15.869], mean action: 1.488 [0.000, 3.000],  loss: 19.261758, mae: 76.930679, mean_q: 88.434172, mean_eps: 0.800729
  66535/300000: episode: 684, duration: 0.452s, episode steps:  70, steps per second: 155, episode reward: -64.470, mean reward: -0.921 [-100.000,  8.282], mean action: 1.243 [0.000, 3.000],  loss: 23.123977, mae: 76.099324, mean_q: 87.328101, mean_eps: 0.800501
  66652/300000: episode: 685, duration: 0.754s, episode steps: 117, steps per second: 155, episode reward: -102.415, mean reward: -0.875 [-100.000,  6.980], mean action: 1.684 [0.000, 3.000],  loss: 16.627923, mae: 77.224889, mean_q: 88.671230, mean_eps: 0.800221
  66748/300000: episode: 686, duration: 0.642s, episode steps:  96, steps per second: 150, episode reward: -101.801, mean reward: -1.060 [-100.000, 18.991], mean action: 1.521 [0.000, 3.000],  loss: 12.348391, mae: 78.147571, mean_q: 91.066339, mean_eps: 0.799901
  66819/300000: episode: 687, duration: 0.457s, episode steps:  71, steps per second: 155, episode reward: -39.906, mean reward: -0.562 [-100.000, 24.760], mean action: 1.746 [0.000, 3.000],  loss: 13.270947, mae: 77.677924, mean_q: 89.181085, mean_eps: 0.799651
  66915/300000: episode: 688, duration: 0.610s, episode steps:  96, steps per second: 157, episode reward: -103.125, mean reward: -1.074 [-100.000, 33.940], mean action: 1.615 [0.000, 3.000],  loss: 12.254519, mae: 78.750077, mean_q: 92.033185, mean_eps: 0.799400
  67017/300000: episode: 689, duration: 0.670s, episode steps: 102, steps per second: 152, episode reward: -150.743, mean reward: -1.478 [-100.000,  8.536], mean action: 1.412 [0.000, 3.000],  loss: 17.431509, mae: 79.372269, mean_q: 91.565815, mean_eps: 0.799104
  67126/300000: episode: 690, duration: 0.716s, episode steps: 109, steps per second: 152, episode reward: -76.932, mean reward: -0.706 [-100.000, 10.270], mean action: 1.431 [0.000, 3.000],  loss: 20.568254, mae: 78.329242, mean_q: 90.498712, mean_eps: 0.798787
  67236/300000: episode: 691, duration: 0.700s, episode steps: 110, steps per second: 157, episode reward: -36.444, mean reward: -0.331 [-100.000, 19.712], mean action: 1.500 [0.000, 3.000],  loss: 17.771619, mae: 78.772629, mean_q: 92.236875, mean_eps: 0.798458
  67303/300000: episode: 692, duration: 0.423s, episode steps:  67, steps per second: 159, episode reward: -100.385, mean reward: -1.498 [-100.000,  6.195], mean action: 1.687 [0.000, 3.000],  loss: 13.161555, mae: 79.013792, mean_q: 93.341539, mean_eps: 0.798193
  67409/300000: episode: 693, duration: 0.716s, episode steps: 106, steps per second: 148, episode reward: -105.690, mean reward: -0.997 [-100.000, 15.581], mean action: 1.585 [0.000, 3.000],  loss: 11.095509, mae: 76.143006, mean_q: 88.113604, mean_eps: 0.797933
  67503/300000: episode: 694, duration: 0.610s, episode steps:  94, steps per second: 154, episode reward: -53.498, mean reward: -0.569 [-100.000, 12.850], mean action: 1.660 [0.000, 3.000],  loss: 20.463215, mae: 78.944657, mean_q: 92.109022, mean_eps: 0.797634
  67603/300000: episode: 695, duration: 0.634s, episode steps: 100, steps per second: 158, episode reward: -91.219, mean reward: -0.912 [-100.000,  6.834], mean action: 1.550 [0.000, 3.000],  loss: 16.724508, mae: 78.930115, mean_q: 90.644684, mean_eps: 0.797343
  67735/300000: episode: 696, duration: 0.881s, episode steps: 132, steps per second: 150, episode reward:  4.374, mean reward:  0.033 [-100.000, 13.608], mean action: 1.492 [0.000, 3.000],  loss: 18.013286, mae: 79.747396, mean_q: 92.043097, mean_eps: 0.796995
  67858/300000: episode: 697, duration: 0.786s, episode steps: 123, steps per second: 156, episode reward: -69.609, mean reward: -0.566 [-100.000, 10.832], mean action: 1.577 [0.000, 3.000],  loss: 13.198081, mae: 79.794524, mean_q: 93.334386, mean_eps: 0.796612
  67980/300000: episode: 698, duration: 0.783s, episode steps: 122, steps per second: 156, episode reward: -85.510, mean reward: -0.701 [-100.000, 22.760], mean action: 1.590 [0.000, 3.000],  loss: 15.245748, mae: 80.153090, mean_q: 93.306457, mean_eps: 0.796245
  68097/300000: episode: 699, duration: 0.848s, episode steps: 117, steps per second: 138, episode reward: -112.644, mean reward: -0.963 [-100.000, 11.444], mean action: 1.658 [0.000, 3.000],  loss: 15.679748, mae: 79.055649, mean_q: 92.553479, mean_eps: 0.795886
  68204/300000: episode: 700, duration: 0.697s, episode steps: 107, steps per second: 154, episode reward: -159.340, mean reward: -1.489 [-100.000,  5.283], mean action: 1.776 [0.000, 3.000],  loss: 12.703012, mae: 81.645412, mean_q: 95.114541, mean_eps: 0.795550
  68295/300000: episode: 701, duration: 0.589s, episode steps:  91, steps per second: 155, episode reward: -60.071, mean reward: -0.660 [-100.000, 21.495], mean action: 1.637 [0.000, 3.000],  loss: 15.104283, mae: 80.627772, mean_q: 94.061494, mean_eps: 0.795253
  68417/300000: episode: 702, duration: 0.822s, episode steps: 122, steps per second: 148, episode reward: -70.592, mean reward: -0.579 [-100.000,  8.004], mean action: 1.566 [0.000, 3.000],  loss: 17.410618, mae: 83.616919, mean_q: 97.286571, mean_eps: 0.794933
  68491/300000: episode: 703, duration: 0.473s, episode steps:  74, steps per second: 156, episode reward: -62.147, mean reward: -0.840 [-100.000,  7.518], mean action: 1.514 [0.000, 3.000],  loss: 12.388560, mae: 82.637037, mean_q: 96.247233, mean_eps: 0.794639
  68630/300000: episode: 704, duration: 0.872s, episode steps: 139, steps per second: 159, episode reward: -20.180, mean reward: -0.145 [-100.000, 27.829], mean action: 1.655 [0.000, 3.000],  loss: 12.418243, mae: 84.180497, mean_q: 98.950660, mean_eps: 0.794320
  68747/300000: episode: 705, duration: 0.794s, episode steps: 117, steps per second: 147, episode reward: -11.281, mean reward: -0.096 [-100.000, 78.092], mean action: 1.504 [0.000, 3.000],  loss: 15.258758, mae: 84.458519, mean_q: 98.217233, mean_eps: 0.793936
  68856/300000: episode: 706, duration: 0.694s, episode steps: 109, steps per second: 157, episode reward: -122.314, mean reward: -1.122 [-100.000, 24.794], mean action: 1.679 [0.000, 3.000],  loss: 14.034081, mae: 85.208905, mean_q: 99.810729, mean_eps: 0.793597
  68956/300000: episode: 707, duration: 0.632s, episode steps: 100, steps per second: 158, episode reward: -235.323, mean reward: -2.353 [-100.000,  0.721], mean action: 1.430 [0.000, 3.000],  loss: 13.427777, mae: 86.390163, mean_q: 101.838145, mean_eps: 0.793284
  69078/300000: episode: 708, duration: 0.801s, episode steps: 122, steps per second: 152, episode reward: -75.220, mean reward: -0.617 [-100.000,  8.326], mean action: 1.631 [0.000, 3.000],  loss: 14.216049, mae: 87.477697, mean_q: 104.586812, mean_eps: 0.792951
  69174/300000: episode: 709, duration: 0.622s, episode steps:  96, steps per second: 154, episode reward: -46.003, mean reward: -0.479 [-100.000, 18.638], mean action: 1.417 [0.000, 3.000],  loss: 11.684116, mae: 88.115872, mean_q: 104.206350, mean_eps: 0.792624
  69244/300000: episode: 710, duration: 0.445s, episode steps:  70, steps per second: 157, episode reward: -86.675, mean reward: -1.238 [-100.000, 20.588], mean action: 1.614 [0.000, 3.000],  loss: 11.277798, mae: 88.686584, mean_q: 105.695293, mean_eps: 0.792374
  69342/300000: episode: 711, duration: 0.634s, episode steps:  98, steps per second: 155, episode reward: -248.714, mean reward: -2.538 [-100.000, 31.283], mean action: 1.541 [0.000, 3.000],  loss: 14.087090, mae: 85.695027, mean_q: 101.478287, mean_eps: 0.792123
  69457/300000: episode: 712, duration: 0.750s, episode steps: 115, steps per second: 153, episode reward: -172.773, mean reward: -1.502 [-100.000,  2.787], mean action: 1.487 [0.000, 3.000],  loss: 12.392921, mae: 87.287922, mean_q: 102.427120, mean_eps: 0.791803
  69565/300000: episode: 713, duration: 0.691s, episode steps: 108, steps per second: 156, episode reward: -160.287, mean reward: -1.484 [-100.000,  8.542], mean action: 1.500 [0.000, 3.000],  loss: 15.775806, mae: 87.980697, mean_q: 102.719061, mean_eps: 0.791468
  69634/300000: episode: 714, duration: 0.449s, episode steps:  69, steps per second: 154, episode reward: -74.851, mean reward: -1.085 [-100.000,  5.619], mean action: 1.377 [0.000, 3.000],  loss: 15.582817, mae: 86.259683, mean_q: 101.082604, mean_eps: 0.791203
  69736/300000: episode: 715, duration: 0.694s, episode steps: 102, steps per second: 147, episode reward: -122.535, mean reward: -1.201 [-100.000, 12.359], mean action: 1.608 [0.000, 3.000],  loss: 18.657842, mae: 86.138826, mean_q: 101.880148, mean_eps: 0.790946
  69854/300000: episode: 716, duration: 0.757s, episode steps: 118, steps per second: 156, episode reward: -126.023, mean reward: -1.068 [-100.000,  8.683], mean action: 1.669 [0.000, 3.000],  loss: 14.758224, mae: 85.185344, mean_q: 99.833410, mean_eps: 0.790617
  69977/300000: episode: 717, duration: 0.781s, episode steps: 123, steps per second: 157, episode reward: -95.447, mean reward: -0.776 [-100.000, 17.057], mean action: 1.642 [0.000, 3.000],  loss: 13.942604, mae: 85.537054, mean_q: 100.409694, mean_eps: 0.790255
  70076/300000: episode: 718, duration: 0.685s, episode steps:  99, steps per second: 145, episode reward: -140.188, mean reward: -1.416 [-100.000,  8.611], mean action: 1.485 [0.000, 3.000],  loss: 10.801943, mae: 86.648211, mean_q: 103.161179, mean_eps: 0.789922
  70159/300000: episode: 719, duration: 0.602s, episode steps:  83, steps per second: 138, episode reward: -67.556, mean reward: -0.814 [-100.000, 52.587], mean action: 1.373 [0.000, 3.000],  loss: 12.079025, mae: 83.606114, mean_q: 96.677459, mean_eps: 0.789649
  70280/300000: episode: 720, duration: 0.881s, episode steps: 121, steps per second: 137, episode reward: -176.954, mean reward: -1.462 [-100.000, 17.202], mean action: 1.686 [0.000, 3.000],  loss: 11.463972, mae: 84.732983, mean_q: 97.647866, mean_eps: 0.789343
  70349/300000: episode: 721, duration: 0.515s, episode steps:  69, steps per second: 134, episode reward: -66.179, mean reward: -0.959 [-100.000,  9.526], mean action: 1.739 [0.000, 3.000],  loss: 11.226975, mae: 85.492302, mean_q: 97.446493, mean_eps: 0.789058
  70495/300000: episode: 722, duration: 0.989s, episode steps: 146, steps per second: 148, episode reward: -180.493, mean reward: -1.236 [-100.000, 39.533], mean action: 1.671 [0.000, 3.000],  loss: 15.409906, mae: 86.704888, mean_q: 99.848968, mean_eps: 0.788736
  70614/300000: episode: 723, duration: 0.815s, episode steps: 119, steps per second: 146, episode reward: -73.056, mean reward: -0.614 [-100.000, 12.914], mean action: 1.756 [0.000, 3.000],  loss: 16.232448, mae: 84.971067, mean_q: 97.022587, mean_eps: 0.788338
  70726/300000: episode: 724, duration: 0.762s, episode steps: 112, steps per second: 147, episode reward: -181.036, mean reward: -1.616 [-100.000,  9.446], mean action: 1.607 [0.000, 3.000],  loss: 19.239543, mae: 84.925188, mean_q: 96.826307, mean_eps: 0.787992
  70860/300000: episode: 725, duration: 0.862s, episode steps: 134, steps per second: 155, episode reward: -113.456, mean reward: -0.847 [-100.000, 14.095], mean action: 1.664 [0.000, 3.000],  loss: 15.046845, mae: 84.571118, mean_q: 96.052812, mean_eps: 0.787623
  70980/300000: episode: 726, duration: 0.817s, episode steps: 120, steps per second: 147, episode reward: -170.295, mean reward: -1.419 [-100.000,  4.824], mean action: 1.442 [0.000, 3.000],  loss: 13.702572, mae: 83.866556, mean_q: 98.173233, mean_eps: 0.787242
  71088/300000: episode: 727, duration: 0.694s, episode steps: 108, steps per second: 156, episode reward: -143.382, mean reward: -1.328 [-100.000,  5.350], mean action: 1.602 [0.000, 3.000],  loss: 18.184901, mae: 83.713847, mean_q: 98.444108, mean_eps: 0.786899
  71196/300000: episode: 728, duration: 0.684s, episode steps: 108, steps per second: 158, episode reward: -128.503, mean reward: -1.190 [-100.000, 19.859], mean action: 1.574 [0.000, 3.000],  loss: 10.005971, mae: 84.252940, mean_q: 99.126384, mean_eps: 0.786575
  71286/300000: episode: 729, duration: 0.625s, episode steps:  90, steps per second: 144, episode reward: -70.023, mean reward: -0.778 [-100.000,  5.204], mean action: 1.578 [0.000, 3.000],  loss: 14.905329, mae: 84.143062, mean_q: 100.129122, mean_eps: 0.786278
  71385/300000: episode: 730, duration: 0.645s, episode steps:  99, steps per second: 154, episode reward: -106.621, mean reward: -1.077 [-100.000,  5.120], mean action: 1.485 [0.000, 3.000],  loss: 13.844815, mae: 82.651540, mean_q: 97.643632, mean_eps: 0.785995
  71499/300000: episode: 731, duration: 0.714s, episode steps: 114, steps per second: 160, episode reward: -227.359, mean reward: -1.994 [-100.000,  1.178], mean action: 1.518 [0.000, 3.000],  loss: 14.719950, mae: 84.469876, mean_q: 99.245808, mean_eps: 0.785676
  71625/300000: episode: 732, duration: 0.860s, episode steps: 126, steps per second: 146, episode reward: -53.009, mean reward: -0.421 [-100.000, 37.976], mean action: 1.722 [0.000, 3.000],  loss: 14.326024, mae: 87.067062, mean_q: 102.363830, mean_eps: 0.785316
  71742/300000: episode: 733, duration: 0.776s, episode steps: 117, steps per second: 151, episode reward: -128.695, mean reward: -1.100 [-100.000,  9.461], mean action: 1.590 [0.000, 3.000],  loss: 18.605900, mae: 86.315564, mean_q: 102.311852, mean_eps: 0.784951
  71840/300000: episode: 734, duration: 0.621s, episode steps:  98, steps per second: 158, episode reward: -1.444, mean reward: -0.015 [-100.000, 105.058], mean action: 1.531 [0.000, 3.000],  loss: 12.585089, mae: 86.916603, mean_q: 103.110050, mean_eps: 0.784628
  71951/300000: episode: 735, duration: 0.730s, episode steps: 111, steps per second: 152, episode reward: -114.616, mean reward: -1.033 [-100.000, 15.181], mean action: 1.703 [0.000, 3.000],  loss: 12.198136, mae: 87.964805, mean_q: 104.351259, mean_eps: 0.784315
  72063/300000: episode: 736, duration: 0.731s, episode steps: 112, steps per second: 153, episode reward: -73.286, mean reward: -0.654 [-100.000,  8.277], mean action: 1.634 [0.000, 3.000],  loss: 18.359411, mae: 88.233347, mean_q: 104.561284, mean_eps: 0.783981
  72176/300000: episode: 737, duration: 0.703s, episode steps: 113, steps per second: 161, episode reward: -115.983, mean reward: -1.026 [-100.000, 14.944], mean action: 1.593 [0.000, 3.000],  loss: 13.750958, mae: 89.900504, mean_q: 107.346007, mean_eps: 0.783643
  72255/300000: episode: 738, duration: 0.506s, episode steps:  79, steps per second: 156, episode reward: -77.570, mean reward: -0.982 [-100.000, 13.997], mean action: 1.557 [0.000, 3.000],  loss: 17.782339, mae: 90.437267, mean_q: 108.420550, mean_eps: 0.783355
  72335/300000: episode: 739, duration: 0.555s, episode steps:  80, steps per second: 144, episode reward: -81.146, mean reward: -1.014 [-100.000,  5.109], mean action: 1.450 [0.000, 3.000],  loss: 13.435202, mae: 91.386107, mean_q: 110.279753, mean_eps: 0.783116
  72405/300000: episode: 740, duration: 0.456s, episode steps:  70, steps per second: 154, episode reward: -102.913, mean reward: -1.470 [-100.000,  4.771], mean action: 1.400 [0.000, 3.000],  loss: 21.955228, mae: 90.019818, mean_q: 107.351341, mean_eps: 0.782892
  72496/300000: episode: 741, duration: 0.590s, episode steps:  91, steps per second: 154, episode reward: -65.788, mean reward: -0.723 [-100.000, 17.326], mean action: 1.505 [0.000, 3.000],  loss: 18.286540, mae: 91.045025, mean_q: 109.353486, mean_eps: 0.782650
  72639/300000: episode: 742, duration: 0.967s, episode steps: 143, steps per second: 148, episode reward: -292.544, mean reward: -2.046 [-100.000, 71.668], mean action: 1.573 [0.000, 3.000],  loss: 18.745517, mae: 90.901929, mean_q: 107.893821, mean_eps: 0.782299
  72774/300000: episode: 743, duration: 0.867s, episode steps: 135, steps per second: 156, episode reward: -151.464, mean reward: -1.122 [-100.000,  3.583], mean action: 1.704 [0.000, 3.000],  loss: 20.785484, mae: 89.898635, mean_q: 106.037027, mean_eps: 0.781882
  72854/300000: episode: 744, duration: 0.509s, episode steps:  80, steps per second: 157, episode reward: -90.281, mean reward: -1.129 [-100.000,  8.306], mean action: 1.675 [0.000, 3.000],  loss: 16.702570, mae: 91.557735, mean_q: 108.481890, mean_eps: 0.781559
  72950/300000: episode: 745, duration: 0.642s, episode steps:  96, steps per second: 150, episode reward: -100.642, mean reward: -1.048 [-100.000, 11.248], mean action: 1.573 [0.000, 3.000],  loss: 22.399001, mae: 89.836727, mean_q: 105.649857, mean_eps: 0.781296
  73031/300000: episode: 746, duration: 0.540s, episode steps:  81, steps per second: 150, episode reward: -99.439, mean reward: -1.228 [-100.000,  6.153], mean action: 1.593 [0.000, 3.000],  loss: 20.164438, mae: 91.960664, mean_q: 108.897785, mean_eps: 0.781030
  73122/300000: episode: 747, duration: 0.586s, episode steps:  91, steps per second: 155, episode reward: -23.488, mean reward: -0.258 [-100.000, 66.079], mean action: 1.604 [0.000, 3.000],  loss: 24.886011, mae: 91.843109, mean_q: 108.312397, mean_eps: 0.780772
  73209/300000: episode: 748, duration: 0.541s, episode steps:  87, steps per second: 161, episode reward: -128.650, mean reward: -1.479 [-100.000, 13.779], mean action: 1.690 [0.000, 3.000],  loss: 23.357541, mae: 93.155750, mean_q: 110.666968, mean_eps: 0.780505
  73294/300000: episode: 749, duration: 0.587s, episode steps:  85, steps per second: 145, episode reward: -145.368, mean reward: -1.710 [-100.000,  7.886], mean action: 1.494 [0.000, 3.000],  loss: 22.474907, mae: 92.703827, mean_q: 110.910254, mean_eps: 0.780247
  73390/300000: episode: 750, duration: 0.644s, episode steps:  96, steps per second: 149, episode reward: -83.113, mean reward: -0.866 [-100.000, 90.753], mean action: 1.448 [0.000, 3.000],  loss: 19.472635, mae: 91.736122, mean_q: 109.055283, mean_eps: 0.779975
  73507/300000: episode: 751, duration: 0.748s, episode steps: 117, steps per second: 156, episode reward: -108.630, mean reward: -0.928 [-100.000, 11.387], mean action: 1.590 [0.000, 3.000],  loss: 20.630072, mae: 93.587178, mean_q: 111.589552, mean_eps: 0.779656
  73636/300000: episode: 752, duration: 0.859s, episode steps: 129, steps per second: 150, episode reward: -123.414, mean reward: -0.957 [-100.000,  7.949], mean action: 1.527 [0.000, 3.000],  loss: 18.290300, mae: 95.846811, mean_q: 115.716515, mean_eps: 0.779287
  73746/300000: episode: 753, duration: 0.759s, episode steps: 110, steps per second: 145, episode reward: -86.906, mean reward: -0.790 [-100.000, 24.343], mean action: 1.536 [0.000, 3.000],  loss: 16.010523, mae: 93.971297, mean_q: 112.887168, mean_eps: 0.778929
  73874/300000: episode: 754, duration: 0.983s, episode steps: 128, steps per second: 130, episode reward: -154.964, mean reward: -1.211 [-100.000,  3.434], mean action: 1.750 [0.000, 3.000],  loss: 23.790693, mae: 96.072342, mean_q: 116.596392, mean_eps: 0.778571
  73972/300000: episode: 755, duration: 0.803s, episode steps:  98, steps per second: 122, episode reward: -104.709, mean reward: -1.068 [-100.000, 12.585], mean action: 1.643 [0.000, 3.000],  loss: 32.867799, mae: 96.621416, mean_q: 117.325472, mean_eps: 0.778233
  74050/300000: episode: 756, duration: 0.583s, episode steps:  78, steps per second: 134, episode reward: -63.798, mean reward: -0.818 [-100.000,  9.658], mean action: 1.615 [0.000, 3.000],  loss: 22.263795, mae: 96.460873, mean_q: 119.114604, mean_eps: 0.777968
  74180/300000: episode: 757, duration: 0.972s, episode steps: 130, steps per second: 134, episode reward: -94.562, mean reward: -0.727 [-100.000, 19.303], mean action: 1.592 [0.000, 3.000],  loss: 19.578169, mae: 99.284243, mean_q: 122.237981, mean_eps: 0.777657
  74297/300000: episode: 758, duration: 0.901s, episode steps: 117, steps per second: 130, episode reward: -97.431, mean reward: -0.833 [-100.000, 27.988], mean action: 1.547 [0.000, 3.000],  loss: 32.728797, mae: 98.015626, mean_q: 120.490734, mean_eps: 0.777286
  74412/300000: episode: 759, duration: 0.929s, episode steps: 115, steps per second: 124, episode reward: -215.309, mean reward: -1.872 [-100.000, 23.663], mean action: 1.365 [0.000, 3.000],  loss: 40.090350, mae: 99.925502, mean_q: 123.974651, mean_eps: 0.776938
  74530/300000: episode: 760, duration: 0.899s, episode steps: 118, steps per second: 131, episode reward: 10.339, mean reward:  0.088 [-100.000, 62.920], mean action: 1.534 [0.000, 3.000],  loss: 37.068224, mae: 100.674830, mean_q: 125.334028, mean_eps: 0.776589
  74638/300000: episode: 761, duration: 0.795s, episode steps: 108, steps per second: 136, episode reward: -97.397, mean reward: -0.902 [-100.000, 10.451], mean action: 1.593 [0.000, 3.000],  loss: 25.288263, mae: 103.036454, mean_q: 129.715650, mean_eps: 0.776250
  74744/300000: episode: 762, duration: 0.755s, episode steps: 106, steps per second: 140, episode reward: -162.810, mean reward: -1.536 [-100.000,  4.952], mean action: 1.660 [0.000, 3.000],  loss: 40.537100, mae: 104.175751, mean_q: 132.053877, mean_eps: 0.775928
  74878/300000: episode: 763, duration: 0.872s, episode steps: 134, steps per second: 154, episode reward: -41.033, mean reward: -0.306 [-100.000, 13.356], mean action: 1.746 [0.000, 3.000],  loss: 29.549435, mae: 105.291926, mean_q: 133.216152, mean_eps: 0.775568
  74945/300000: episode: 764, duration: 0.433s, episode steps:  67, steps per second: 155, episode reward: -86.095, mean reward: -1.285 [-100.000,  6.474], mean action: 1.612 [0.000, 3.000],  loss: 19.972469, mae: 105.484673, mean_q: 133.574684, mean_eps: 0.775267
  75043/300000: episode: 765, duration: 0.622s, episode steps:  98, steps per second: 157, episode reward: -28.909, mean reward: -0.295 [-100.000, 75.791], mean action: 1.622 [0.000, 3.000],  loss: 25.991231, mae: 106.304974, mean_q: 133.765969, mean_eps: 0.775019
  75135/300000: episode: 766, duration: 0.633s, episode steps:  92, steps per second: 145, episode reward: -111.484, mean reward: -1.212 [-100.000, 11.531], mean action: 1.565 [0.000, 3.000],  loss: 26.699005, mae: 105.589331, mean_q: 131.878918, mean_eps: 0.774735
  75243/300000: episode: 767, duration: 0.695s, episode steps: 108, steps per second: 155, episode reward: -39.666, mean reward: -0.367 [-100.000,  6.501], mean action: 1.759 [0.000, 3.000],  loss: 22.833493, mae: 105.364200, mean_q: 131.358176, mean_eps: 0.774435
  75326/300000: episode: 768, duration: 0.539s, episode steps:  83, steps per second: 154, episode reward: -206.442, mean reward: -2.487 [-100.000,  3.487], mean action: 1.711 [0.000, 3.000],  loss: 26.868349, mae: 104.265603, mean_q: 128.807354, mean_eps: 0.774148
  75446/300000: episode: 769, duration: 0.818s, episode steps: 120, steps per second: 147, episode reward: -113.153, mean reward: -0.943 [-100.000,  8.033], mean action: 1.600 [0.000, 3.000],  loss: 23.022301, mae: 102.466684, mean_q: 127.778458, mean_eps: 0.773844
  75521/300000: episode: 770, duration: 0.487s, episode steps:  75, steps per second: 154, episode reward: -80.504, mean reward: -1.073 [-100.000,  9.933], mean action: 1.520 [0.000, 3.000],  loss: 15.653681, mae: 103.855143, mean_q: 130.267422, mean_eps: 0.773551
  75633/300000: episode: 771, duration: 0.718s, episode steps: 112, steps per second: 156, episode reward: -182.672, mean reward: -1.631 [-100.000,  3.082], mean action: 1.759 [0.000, 3.000],  loss: 22.810814, mae: 104.040182, mean_q: 130.550740, mean_eps: 0.773270
  75754/300000: episode: 772, duration: 0.810s, episode steps: 121, steps per second: 149, episode reward: 18.779, mean reward:  0.155 [-100.000, 107.875], mean action: 1.537 [0.000, 3.000],  loss: 23.053979, mae: 104.375020, mean_q: 129.549264, mean_eps: 0.772921
  75832/300000: episode: 773, duration: 0.520s, episode steps:  78, steps per second: 150, episode reward: -96.768, mean reward: -1.241 [-100.000,  6.567], mean action: 1.615 [0.000, 3.000],  loss: 20.275578, mae: 105.167535, mean_q: 129.727296, mean_eps: 0.772623
  75950/300000: episode: 774, duration: 0.744s, episode steps: 118, steps per second: 159, episode reward: -93.372, mean reward: -0.791 [-100.000, 13.284], mean action: 1.627 [0.000, 3.000],  loss: 26.057818, mae: 103.239492, mean_q: 128.063614, mean_eps: 0.772328
  76034/300000: episode: 775, duration: 0.528s, episode steps:  84, steps per second: 159, episode reward: -66.451, mean reward: -0.791 [-100.000,  9.600], mean action: 1.607 [0.000, 3.000],  loss: 14.681876, mae: 104.920731, mean_q: 131.073362, mean_eps: 0.772025
  76112/300000: episode: 776, duration: 0.562s, episode steps:  78, steps per second: 139, episode reward: -85.919, mean reward: -1.102 [-100.000,  7.498], mean action: 1.551 [0.000, 3.000],  loss: 40.067450, mae: 104.914175, mean_q: 129.600025, mean_eps: 0.771782
  76213/300000: episode: 777, duration: 0.669s, episode steps: 101, steps per second: 151, episode reward: -234.656, mean reward: -2.323 [-100.000, 59.414], mean action: 1.475 [0.000, 3.000],  loss: 34.591721, mae: 103.751549, mean_q: 127.297099, mean_eps: 0.771514
  76309/300000: episode: 778, duration: 0.608s, episode steps:  96, steps per second: 158, episode reward: -137.409, mean reward: -1.431 [-100.000, 10.957], mean action: 1.594 [0.000, 3.000],  loss: 30.693557, mae: 105.052222, mean_q: 129.631794, mean_eps: 0.771218
  76390/300000: episode: 779, duration: 0.538s, episode steps:  81, steps per second: 151, episode reward: -111.472, mean reward: -1.376 [-100.000,  7.599], mean action: 1.543 [0.000, 3.000],  loss: 25.857614, mae: 105.876376, mean_q: 131.128670, mean_eps: 0.770953
  76471/300000: episode: 780, duration: 0.541s, episode steps:  81, steps per second: 150, episode reward: -76.222, mean reward: -0.941 [-100.000,  7.800], mean action: 1.617 [0.000, 3.000],  loss: 53.931191, mae: 104.846903, mean_q: 126.824727, mean_eps: 0.770710
  76569/300000: episode: 781, duration: 0.627s, episode steps:  98, steps per second: 156, episode reward: -249.223, mean reward: -2.543 [-100.000, 14.809], mean action: 1.510 [0.000, 3.000],  loss: 20.150226, mae: 105.027385, mean_q: 128.231059, mean_eps: 0.770441
  76699/300000: episode: 782, duration: 0.823s, episode steps: 130, steps per second: 158, episode reward: -320.669, mean reward: -2.467 [-100.000, 18.530], mean action: 1.592 [0.000, 3.000],  loss: 24.184866, mae: 105.702555, mean_q: 128.823461, mean_eps: 0.770099
  76829/300000: episode: 783, duration: 0.904s, episode steps: 130, steps per second: 144, episode reward: -88.450, mean reward: -0.680 [-100.000, 12.579], mean action: 1.523 [0.000, 3.000],  loss: 29.260640, mae: 108.849993, mean_q: 134.352713, mean_eps: 0.769710
  76944/300000: episode: 784, duration: 0.737s, episode steps: 115, steps per second: 156, episode reward: -127.610, mean reward: -1.110 [-100.000, 10.529], mean action: 1.861 [0.000, 3.000],  loss: 30.693802, mae: 107.370390, mean_q: 130.720201, mean_eps: 0.769342
  77043/300000: episode: 785, duration: 0.667s, episode steps:  99, steps per second: 148, episode reward: -148.592, mean reward: -1.501 [-100.000,  7.502], mean action: 1.727 [0.000, 3.000],  loss: 24.363363, mae: 108.275760, mean_q: 129.944391, mean_eps: 0.769021
  77163/300000: episode: 786, duration: 0.794s, episode steps: 120, steps per second: 151, episode reward: -120.539, mean reward: -1.004 [-100.000, 26.696], mean action: 1.625 [0.000, 3.000],  loss: 26.748777, mae: 107.034796, mean_q: 128.311714, mean_eps: 0.768693
  77264/300000: episode: 787, duration: 0.637s, episode steps: 101, steps per second: 159, episode reward: -124.971, mean reward: -1.237 [-100.000,  8.650], mean action: 1.703 [0.000, 3.000],  loss: 50.440482, mae: 109.392135, mean_q: 133.811106, mean_eps: 0.768361
  77352/300000: episode: 788, duration: 0.553s, episode steps:  88, steps per second: 159, episode reward: -159.584, mean reward: -1.813 [-100.000, 18.197], mean action: 1.500 [0.000, 3.000],  loss: 36.734636, mae: 109.305040, mean_q: 133.623491, mean_eps: 0.768078
  77456/300000: episode: 789, duration: 0.724s, episode steps: 104, steps per second: 144, episode reward: -81.717, mean reward: -0.786 [-100.000, 100.514], mean action: 1.587 [0.000, 3.000],  loss: 27.694492, mae: 111.199318, mean_q: 136.085784, mean_eps: 0.767790
  77587/300000: episode: 790, duration: 0.848s, episode steps: 131, steps per second: 154, episode reward: -84.073, mean reward: -0.642 [-100.000,  6.956], mean action: 1.664 [0.000, 3.000],  loss: 20.741508, mae: 110.892502, mean_q: 135.529872, mean_eps: 0.767437
  77679/300000: episode: 791, duration: 0.585s, episode steps:  92, steps per second: 157, episode reward: -118.416, mean reward: -1.287 [-100.000, 25.639], mean action: 1.717 [0.000, 3.000],  loss: 34.491038, mae: 108.949837, mean_q: 133.180392, mean_eps: 0.767103
  77762/300000: episode: 792, duration: 0.581s, episode steps:  83, steps per second: 143, episode reward: -97.542, mean reward: -1.175 [-100.000, 46.200], mean action: 1.578 [0.000, 3.000],  loss: 52.481831, mae: 112.107189, mean_q: 138.237827, mean_eps: 0.766840
  77859/300000: episode: 793, duration: 0.627s, episode steps:  97, steps per second: 155, episode reward: -105.752, mean reward: -1.090 [-100.000,  6.432], mean action: 1.443 [0.000, 3.000],  loss: 28.614740, mae: 111.378665, mean_q: 136.865991, mean_eps: 0.766570
  77971/300000: episode: 794, duration: 0.722s, episode steps: 112, steps per second: 155, episode reward: -135.077, mean reward: -1.206 [-100.000,  4.120], mean action: 1.500 [0.000, 3.000],  loss: 38.248770, mae: 112.689098, mean_q: 138.840278, mean_eps: 0.766257
  78070/300000: episode: 795, duration: 0.643s, episode steps:  99, steps per second: 154, episode reward: -68.277, mean reward: -0.690 [-100.000, 14.476], mean action: 1.636 [0.000, 3.000],  loss: 37.300229, mae: 110.457076, mean_q: 133.723353, mean_eps: 0.765940
  78188/300000: episode: 796, duration: 0.768s, episode steps: 118, steps per second: 154, episode reward: -131.427, mean reward: -1.114 [-100.000, 28.926], mean action: 1.703 [0.000, 3.000],  loss: 26.381747, mae: 114.643788, mean_q: 139.930369, mean_eps: 0.765614
  78290/300000: episode: 797, duration: 0.650s, episode steps: 102, steps per second: 157, episode reward: -91.150, mean reward: -0.894 [-100.000,  9.699], mean action: 1.784 [0.000, 3.000],  loss: 35.788454, mae: 114.891331, mean_q: 142.097159, mean_eps: 0.765285
  78390/300000: episode: 798, duration: 0.682s, episode steps: 100, steps per second: 147, episode reward: -185.533, mean reward: -1.855 [-100.000,  8.230], mean action: 1.510 [0.000, 3.000],  loss: 31.784461, mae: 114.841924, mean_q: 141.839088, mean_eps: 0.764981
  78521/300000: episode: 799, duration: 0.857s, episode steps: 131, steps per second: 153, episode reward: -21.387, mean reward: -0.163 [-100.000, 88.640], mean action: 1.565 [0.000, 3.000],  loss: 29.373105, mae: 114.420623, mean_q: 141.193567, mean_eps: 0.764635
  78611/300000: episode: 800, duration: 0.579s, episode steps:  90, steps per second: 156, episode reward: -118.292, mean reward: -1.314 [-100.000, 10.882], mean action: 1.544 [0.000, 3.000],  loss: 40.382082, mae: 117.529542, mean_q: 146.940369, mean_eps: 0.764304
  78714/300000: episode: 801, duration: 0.685s, episode steps: 103, steps per second: 150, episode reward: -26.778, mean reward: -0.260 [-100.000, 21.350], mean action: 1.602 [0.000, 3.000],  loss: 43.387553, mae: 119.767064, mean_q: 148.895059, mean_eps: 0.764014
  78813/300000: episode: 802, duration: 0.753s, episode steps:  99, steps per second: 131, episode reward: -102.367, mean reward: -1.034 [-100.000,  6.827], mean action: 1.737 [0.000, 3.000],  loss: 47.132072, mae: 118.956492, mean_q: 149.505823, mean_eps: 0.763711
  78908/300000: episode: 803, duration: 0.731s, episode steps:  95, steps per second: 130, episode reward: -265.821, mean reward: -2.798 [-100.000,  7.168], mean action: 1.442 [0.000, 3.000],  loss: 68.187910, mae: 119.682594, mean_q: 152.013989, mean_eps: 0.763420
  78990/300000: episode: 804, duration: 0.621s, episode steps:  82, steps per second: 132, episode reward: -92.995, mean reward: -1.134 [-100.000,  7.950], mean action: 1.585 [0.000, 3.000],  loss: 40.620712, mae: 118.561563, mean_q: 150.485298, mean_eps: 0.763154
  79110/300000: episode: 805, duration: 0.797s, episode steps: 120, steps per second: 150, episode reward: -12.343, mean reward: -0.103 [-100.000, 47.922], mean action: 1.542 [0.000, 3.000],  loss: 41.143631, mae: 119.098967, mean_q: 150.976023, mean_eps: 0.762852
  79199/300000: episode: 806, duration: 0.603s, episode steps:  89, steps per second: 148, episode reward: -104.125, mean reward: -1.170 [-100.000, 17.137], mean action: 1.640 [0.000, 3.000],  loss: 60.243316, mae: 118.712894, mean_q: 148.999336, mean_eps: 0.762538
  79342/300000: episode: 807, duration: 0.951s, episode steps: 143, steps per second: 150, episode reward: -64.041, mean reward: -0.448 [-100.000, 17.364], mean action: 1.643 [0.000, 3.000],  loss: 33.725981, mae: 122.987238, mean_q: 155.979106, mean_eps: 0.762190
  79409/300000: episode: 808, duration: 0.430s, episode steps:  67, steps per second: 156, episode reward: -54.460, mean reward: -0.813 [-100.000, 12.211], mean action: 1.552 [0.000, 3.000],  loss: 35.145820, mae: 121.857852, mean_q: 153.769177, mean_eps: 0.761875
  79493/300000: episode: 809, duration: 0.534s, episode steps:  84, steps per second: 157, episode reward: -101.552, mean reward: -1.209 [-100.000, 17.298], mean action: 1.690 [0.000, 3.000],  loss: 37.818830, mae: 120.583873, mean_q: 152.212727, mean_eps: 0.761649
  79600/300000: episode: 810, duration: 0.694s, episode steps: 107, steps per second: 154, episode reward: -109.403, mean reward: -1.022 [-100.000,  7.774], mean action: 1.701 [0.000, 3.000],  loss: 29.156052, mae: 123.717012, mean_q: 157.937044, mean_eps: 0.761362
  79701/300000: episode: 811, duration: 0.677s, episode steps: 101, steps per second: 149, episode reward: -104.390, mean reward: -1.034 [-100.000,  6.245], mean action: 1.713 [0.000, 3.000],  loss: 38.168592, mae: 121.927480, mean_q: 155.018873, mean_eps: 0.761050
  79814/300000: episode: 812, duration: 0.719s, episode steps: 113, steps per second: 157, episode reward: -251.237, mean reward: -2.223 [-100.000,  0.800], mean action: 1.646 [0.000, 3.000],  loss: 43.518462, mae: 124.662645, mean_q: 158.941349, mean_eps: 0.760729
  79924/300000: episode: 813, duration: 0.805s, episode steps: 110, steps per second: 137, episode reward: -204.589, mean reward: -1.860 [-100.000,  1.392], mean action: 1.618 [0.000, 3.000],  loss: 63.202827, mae: 122.632982, mean_q: 156.348420, mean_eps: 0.760394
  80043/300000: episode: 814, duration: 0.866s, episode steps: 119, steps per second: 137, episode reward: -109.552, mean reward: -0.921 [-100.000, 15.544], mean action: 1.630 [0.000, 3.000],  loss: 30.686013, mae: 125.446111, mean_q: 161.002169, mean_eps: 0.760051
  80106/300000: episode: 815, duration: 0.435s, episode steps:  63, steps per second: 145, episode reward: -73.284, mean reward: -1.163 [-100.000,  9.307], mean action: 1.683 [0.000, 3.000],  loss: 43.709642, mae: 125.041986, mean_q: 160.949385, mean_eps: 0.759778
  80224/300000: episode: 816, duration: 0.802s, episode steps: 118, steps per second: 147, episode reward: -182.254, mean reward: -1.545 [-100.000, 24.042], mean action: 1.551 [0.000, 3.000],  loss: 58.268331, mae: 122.968917, mean_q: 157.368837, mean_eps: 0.759506
  80307/300000: episode: 817, duration: 0.615s, episode steps:  83, steps per second: 135, episode reward: -81.673, mean reward: -0.984 [-100.000, 11.721], mean action: 1.663 [0.000, 3.000],  loss: 35.889532, mae: 126.978665, mean_q: 164.360501, mean_eps: 0.759205
  80377/300000: episode: 818, duration: 0.457s, episode steps:  70, steps per second: 153, episode reward: -91.225, mean reward: -1.303 [-100.000,  8.822], mean action: 1.700 [0.000, 3.000],  loss: 38.931905, mae: 129.101759, mean_q: 166.441620, mean_eps: 0.758976
  80465/300000: episode: 819, duration: 0.581s, episode steps:  88, steps per second: 151, episode reward: -97.292, mean reward: -1.106 [-100.000,  7.458], mean action: 1.557 [0.000, 3.000],  loss: 50.720891, mae: 130.293224, mean_q: 167.515861, mean_eps: 0.758739
  80554/300000: episode: 820, duration: 0.587s, episode steps:  89, steps per second: 152, episode reward: -316.125, mean reward: -3.552 [-100.000, 64.724], mean action: 1.584 [0.000, 3.000],  loss: 43.112469, mae: 129.156350, mean_q: 165.525183, mean_eps: 0.758473
  80636/300000: episode: 821, duration: 0.588s, episode steps:  82, steps per second: 139, episode reward: -51.573, mean reward: -0.629 [-100.000,  7.678], mean action: 1.622 [0.000, 3.000],  loss: 71.863068, mae: 125.464366, mean_q: 160.711319, mean_eps: 0.758216
  80729/300000: episode: 822, duration: 0.600s, episode steps:  93, steps per second: 155, episode reward: -113.767, mean reward: -1.223 [-100.000, 22.421], mean action: 1.667 [0.000, 3.000],  loss: 49.905062, mae: 127.664068, mean_q: 164.461721, mean_eps: 0.757954
  80820/300000: episode: 823, duration: 0.582s, episode steps:  91, steps per second: 156, episode reward: -221.761, mean reward: -2.437 [-100.000, 12.367], mean action: 1.747 [0.000, 3.000],  loss: 49.716296, mae: 126.216393, mean_q: 162.810078, mean_eps: 0.757678
  80911/300000: episode: 824, duration: 0.598s, episode steps:  91, steps per second: 152, episode reward: -71.194, mean reward: -0.782 [-100.000, 12.304], mean action: 1.582 [0.000, 3.000],  loss: 39.067447, mae: 126.843386, mean_q: 164.191810, mean_eps: 0.757405
  81032/300000: episode: 825, duration: 0.780s, episode steps: 121, steps per second: 155, episode reward: -63.623, mean reward: -0.526 [-100.000, 13.251], mean action: 1.603 [0.000, 3.000],  loss: 48.175135, mae: 128.634828, mean_q: 166.849053, mean_eps: 0.757087
  81122/300000: episode: 826, duration: 0.571s, episode steps:  90, steps per second: 158, episode reward: -62.218, mean reward: -0.691 [-100.000, 16.926], mean action: 1.778 [0.000, 3.000],  loss: 63.312542, mae: 127.885988, mean_q: 165.021912, mean_eps: 0.756771
  81268/300000: episode: 827, duration: 0.944s, episode steps: 146, steps per second: 155, episode reward: -175.051, mean reward: -1.199 [-100.000,  5.870], mean action: 1.699 [0.000, 3.000],  loss: 63.571452, mae: 129.145549, mean_q: 166.865617, mean_eps: 0.756417
  81400/300000: episode: 828, duration: 0.862s, episode steps: 132, steps per second: 153, episode reward: -16.038, mean reward: -0.121 [-100.000, 21.164], mean action: 1.644 [0.000, 3.000],  loss: 55.953891, mae: 130.501645, mean_q: 168.020843, mean_eps: 0.755999
  81508/300000: episode: 829, duration: 0.711s, episode steps: 108, steps per second: 152, episode reward: -112.948, mean reward: -1.046 [-100.000, 11.753], mean action: 1.602 [0.000, 3.000],  loss: 82.225404, mae: 134.064783, mean_q: 173.140570, mean_eps: 0.755639
  81596/300000: episode: 830, duration: 0.611s, episode steps:  88, steps per second: 144, episode reward: -365.717, mean reward: -4.156 [-100.000,  0.190], mean action: 1.750 [0.000, 3.000],  loss: 53.020326, mae: 131.724252, mean_q: 171.467243, mean_eps: 0.755346
  81671/300000: episode: 831, duration: 0.509s, episode steps:  75, steps per second: 147, episode reward: -115.410, mean reward: -1.539 [-100.000,  4.713], mean action: 1.573 [0.000, 3.000],  loss: 45.020229, mae: 132.390161, mean_q: 170.694521, mean_eps: 0.755101
  81819/300000: episode: 832, duration: 0.940s, episode steps: 148, steps per second: 157, episode reward: -174.915, mean reward: -1.182 [-100.000,  3.393], mean action: 1.466 [0.000, 3.000],  loss: 52.843063, mae: 135.480197, mean_q: 175.376975, mean_eps: 0.754767
  81972/300000: episode: 833, duration: 1.008s, episode steps: 153, steps per second: 152, episode reward: -81.824, mean reward: -0.535 [-100.000,  9.404], mean action: 1.654 [0.000, 3.000],  loss: 63.767175, mae: 136.158766, mean_q: 177.054751, mean_eps: 0.754315
  82059/300000: episode: 834, duration: 0.571s, episode steps:  87, steps per second: 152, episode reward: -134.628, mean reward: -1.547 [-100.000, 14.576], mean action: 1.506 [0.000, 3.000],  loss: 45.881661, mae: 135.299557, mean_q: 174.700863, mean_eps: 0.753955
  82142/300000: episode: 835, duration: 0.538s, episode steps:  83, steps per second: 154, episode reward: -92.848, mean reward: -1.119 [-100.000,  7.588], mean action: 1.494 [0.000, 3.000],  loss: 62.325792, mae: 136.483991, mean_q: 176.071446, mean_eps: 0.753700
  82265/300000: episode: 836, duration: 0.823s, episode steps: 123, steps per second: 150, episode reward: -143.744, mean reward: -1.169 [-100.000, 10.021], mean action: 1.715 [0.000, 3.000],  loss: 65.254603, mae: 135.736345, mean_q: 175.926152, mean_eps: 0.753391
  82398/300000: episode: 837, duration: 0.871s, episode steps: 133, steps per second: 153, episode reward: -320.005, mean reward: -2.406 [-100.000, 59.268], mean action: 1.624 [0.000, 3.000],  loss: 86.736878, mae: 140.085058, mean_q: 181.800848, mean_eps: 0.753007
  82527/300000: episode: 838, duration: 0.836s, episode steps: 129, steps per second: 154, episode reward: -33.686, mean reward: -0.261 [-100.000, 57.571], mean action: 1.519 [0.000, 3.000],  loss: 71.973097, mae: 140.383684, mean_q: 180.134955, mean_eps: 0.752614
  82599/300000: episode: 839, duration: 0.506s, episode steps:  72, steps per second: 142, episode reward: -49.263, mean reward: -0.684 [-100.000, 19.398], mean action: 1.583 [0.000, 3.000],  loss: 91.426292, mae: 142.747443, mean_q: 183.827257, mean_eps: 0.752312
  82731/300000: episode: 840, duration: 0.859s, episode steps: 132, steps per second: 154, episode reward: -77.538, mean reward: -0.587 [-100.000, 16.776], mean action: 1.576 [0.000, 3.000],  loss: 71.534735, mae: 143.950434, mean_q: 185.522727, mean_eps: 0.752007
  82844/300000: episode: 841, duration: 0.738s, episode steps: 113, steps per second: 153, episode reward: -104.783, mean reward: -0.927 [-100.000, 14.387], mean action: 1.442 [0.000, 3.000],  loss: 72.973129, mae: 143.567918, mean_q: 184.498738, mean_eps: 0.751639
  82985/300000: episode: 842, duration: 0.955s, episode steps: 141, steps per second: 148, episode reward: -120.189, mean reward: -0.852 [-100.000,  6.999], mean action: 1.631 [0.000, 3.000],  loss: 56.341013, mae: 143.321207, mean_q: 185.137891, mean_eps: 0.751258
  83049/300000: episode: 843, duration: 0.431s, episode steps:  64, steps per second: 149, episode reward: -70.150, mean reward: -1.096 [-100.000, 13.144], mean action: 1.688 [0.000, 3.000],  loss: 97.469148, mae: 150.947472, mean_q: 196.435427, mean_eps: 0.750951
  83166/300000: episode: 844, duration: 0.749s, episode steps: 117, steps per second: 156, episode reward: -376.133, mean reward: -3.215 [-100.000, 58.848], mean action: 1.538 [0.000, 3.000],  loss: 60.379116, mae: 146.865646, mean_q: 190.083097, mean_eps: 0.750679
  83278/300000: episode: 845, duration: 0.763s, episode steps: 112, steps per second: 147, episode reward: -113.395, mean reward: -1.012 [-100.000,  7.347], mean action: 1.589 [0.000, 3.000],  loss: 62.612154, mae: 148.706830, mean_q: 193.509166, mean_eps: 0.750336
  83398/300000: episode: 846, duration: 0.787s, episode steps: 120, steps per second: 152, episode reward: -130.626, mean reward: -1.089 [-100.000,  9.309], mean action: 1.592 [0.000, 3.000],  loss: 59.350814, mae: 151.012804, mean_q: 196.543443, mean_eps: 0.749988
  83468/300000: episode: 847, duration: 0.516s, episode steps:  70, steps per second: 136, episode reward: -138.878, mean reward: -1.984 [-100.000,  7.969], mean action: 1.529 [0.000, 3.000],  loss: 89.514450, mae: 151.480908, mean_q: 196.444536, mean_eps: 0.749703
  83563/300000: episode: 848, duration: 0.760s, episode steps:  95, steps per second: 125, episode reward: -142.728, mean reward: -1.502 [-100.000,  8.640], mean action: 1.558 [0.000, 3.000],  loss: 60.588808, mae: 151.939395, mean_q: 196.994399, mean_eps: 0.749455
  83645/300000: episode: 849, duration: 0.633s, episode steps:  82, steps per second: 129, episode reward: -68.226, mean reward: -0.832 [-100.000,  7.511], mean action: 1.646 [0.000, 3.000],  loss: 50.587977, mae: 151.532938, mean_q: 196.059477, mean_eps: 0.749190
  83715/300000: episode: 850, duration: 0.508s, episode steps:  70, steps per second: 138, episode reward: -134.188, mean reward: -1.917 [-100.000,  8.880], mean action: 1.371 [0.000, 3.000],  loss: 35.708554, mae: 154.346287, mean_q: 199.424297, mean_eps: 0.748961
  83833/300000: episode: 851, duration: 0.892s, episode steps: 118, steps per second: 132, episode reward: -76.686, mean reward: -0.650 [-100.000, 100.768], mean action: 1.771 [0.000, 3.000],  loss: 75.192010, mae: 153.870862, mean_q: 198.975826, mean_eps: 0.748680
  83907/300000: episode: 852, duration: 0.524s, episode steps:  74, steps per second: 141, episode reward: -75.236, mean reward: -1.017 [-100.000, 11.079], mean action: 1.676 [0.000, 3.000],  loss: 114.318317, mae: 155.018117, mean_q: 200.426040, mean_eps: 0.748392
  84062/300000: episode: 853, duration: 1.083s, episode steps: 155, steps per second: 143, episode reward: -164.492, mean reward: -1.061 [-100.000,  5.404], mean action: 1.735 [0.000, 3.000],  loss: 56.167719, mae: 152.124962, mean_q: 198.191718, mean_eps: 0.748048
  84136/300000: episode: 854, duration: 0.504s, episode steps:  74, steps per second: 147, episode reward: -47.814, mean reward: -0.646 [-100.000, 10.039], mean action: 1.743 [0.000, 3.000],  loss: 37.235775, mae: 154.214849, mean_q: 199.736430, mean_eps: 0.747704
  84315/300000: episode: 855, duration: 1.173s, episode steps: 179, steps per second: 153, episode reward: -91.125, mean reward: -0.509 [-100.000,  9.674], mean action: 1.676 [0.000, 3.000],  loss: 46.375245, mae: 155.847626, mean_q: 202.517786, mean_eps: 0.747325
  84443/300000: episode: 856, duration: 0.880s, episode steps: 128, steps per second: 145, episode reward: -6.123, mean reward: -0.048 [-100.000, 49.897], mean action: 1.508 [0.000, 3.000],  loss: 107.329063, mae: 158.526450, mean_q: 206.873839, mean_eps: 0.746865
  84579/300000: episode: 857, duration: 0.918s, episode steps: 136, steps per second: 148, episode reward: -3.011, mean reward: -0.022 [-100.000, 46.648], mean action: 1.581 [0.000, 3.000],  loss: 52.789681, mae: 159.017516, mean_q: 207.321490, mean_eps: 0.746468
  84693/300000: episode: 858, duration: 0.762s, episode steps: 114, steps per second: 150, episode reward: -157.795, mean reward: -1.384 [-100.000,  8.472], mean action: 1.772 [0.000, 3.000],  loss: 58.595942, mae: 159.091996, mean_q: 207.113949, mean_eps: 0.746093
  84786/300000: episode: 859, duration: 0.666s, episode steps:  93, steps per second: 140, episode reward: -69.375, mean reward: -0.746 [-100.000, 10.928], mean action: 1.871 [0.000, 3.000],  loss: 54.378613, mae: 159.558638, mean_q: 207.385396, mean_eps: 0.745783
  84890/300000: episode: 860, duration: 0.793s, episode steps: 104, steps per second: 131, episode reward: -123.579, mean reward: -1.188 [-100.000,  5.852], mean action: 1.577 [0.000, 3.000],  loss: 57.675771, mae: 161.295627, mean_q: 210.869128, mean_eps: 0.745487
  85028/300000: episode: 861, duration: 0.863s, episode steps: 138, steps per second: 160, episode reward: -82.560, mean reward: -0.598 [-100.000,  8.751], mean action: 1.790 [0.000, 3.000],  loss: 41.928943, mae: 160.980609, mean_q: 209.916796, mean_eps: 0.745124
  85113/300000: episode: 862, duration: 0.593s, episode steps:  85, steps per second: 143, episode reward: -167.356, mean reward: -1.969 [-100.000,  8.209], mean action: 1.694 [0.000, 3.000],  loss: 32.562624, mae: 162.534759, mean_q: 213.313845, mean_eps: 0.744790
  85218/300000: episode: 863, duration: 0.680s, episode steps: 105, steps per second: 155, episode reward: -116.044, mean reward: -1.105 [-100.000, 18.492], mean action: 1.552 [0.000, 3.000],  loss: 68.028207, mae: 161.438614, mean_q: 212.056970, mean_eps: 0.744505
  85338/300000: episode: 864, duration: 0.768s, episode steps: 120, steps per second: 156, episode reward: -88.050, mean reward: -0.734 [-100.000, 29.612], mean action: 1.800 [0.000, 3.000],  loss: 48.953330, mae: 161.514918, mean_q: 212.723654, mean_eps: 0.744167
  85432/300000: episode: 865, duration: 0.659s, episode steps:  94, steps per second: 143, episode reward: -123.973, mean reward: -1.319 [-100.000, 10.334], mean action: 1.723 [0.000, 3.000],  loss: 45.173769, mae: 166.006987, mean_q: 218.540956, mean_eps: 0.743846
  85527/300000: episode: 866, duration: 0.619s, episode steps:  95, steps per second: 153, episode reward: -15.730, mean reward: -0.166 [-100.000, 19.158], mean action: 1.611 [0.000, 3.000],  loss: 50.646409, mae: 161.238186, mean_q: 210.669284, mean_eps: 0.743563
  85623/300000: episode: 867, duration: 0.601s, episode steps:  96, steps per second: 160, episode reward: -197.399, mean reward: -2.056 [-100.000,  7.041], mean action: 1.490 [0.000, 3.000],  loss: 65.411974, mae: 161.521109, mean_q: 212.938969, mean_eps: 0.743277
  85709/300000: episode: 868, duration: 0.550s, episode steps:  86, steps per second: 156, episode reward: -79.495, mean reward: -0.924 [-100.000,  5.407], mean action: 1.477 [0.000, 3.000],  loss: 48.212184, mae: 165.027863, mean_q: 218.138130, mean_eps: 0.743004
  85799/300000: episode: 869, duration: 0.627s, episode steps:  90, steps per second: 144, episode reward: -66.320, mean reward: -0.737 [-100.000,  8.659], mean action: 1.378 [0.000, 3.000],  loss: 45.560267, mae: 161.908682, mean_q: 212.790844, mean_eps: 0.742740
  85873/300000: episode: 870, duration: 0.488s, episode steps:  74, steps per second: 152, episode reward: -26.968, mean reward: -0.364 [-100.000, 10.479], mean action: 1.662 [0.000, 3.000],  loss: 51.999568, mae: 165.897365, mean_q: 218.603231, mean_eps: 0.742494
  85994/300000: episode: 871, duration: 0.773s, episode steps: 121, steps per second: 156, episode reward: -166.867, mean reward: -1.379 [-100.000, 41.764], mean action: 1.612 [0.000, 3.000],  loss: 74.664485, mae: 167.520433, mean_q: 220.854147, mean_eps: 0.742201
  86058/300000: episode: 872, duration: 0.444s, episode steps:  64, steps per second: 144, episode reward: 47.474, mean reward:  0.742 [-100.000, 108.518], mean action: 1.453 [0.000, 3.000],  loss: 34.849347, mae: 167.925006, mean_q: 221.635571, mean_eps: 0.741923
  86130/300000: episode: 873, duration: 0.487s, episode steps:  72, steps per second: 148, episode reward: -105.950, mean reward: -1.472 [-100.000,  5.869], mean action: 1.667 [0.000, 3.000],  loss: 52.327538, mae: 168.006968, mean_q: 221.715819, mean_eps: 0.741719
  86232/300000: episode: 874, duration: 0.650s, episode steps: 102, steps per second: 157, episode reward: -139.471, mean reward: -1.367 [-100.000, 10.523], mean action: 1.676 [0.000, 3.000],  loss: 58.382851, mae: 168.637321, mean_q: 222.311562, mean_eps: 0.741459
  86762/300000: episode: 875, duration: 3.605s, episode steps: 530, steps per second: 147, episode reward: -235.756, mean reward: -0.445 [-100.000, 88.977], mean action: 1.668 [0.000, 3.000],  loss: 72.880729, mae: 169.435014, mean_q: 223.149353, mean_eps: 0.740510
  86865/300000: episode: 876, duration: 0.656s, episode steps: 103, steps per second: 157, episode reward: -371.853, mean reward: -3.610 [-100.000, 82.906], mean action: 1.621 [0.000, 3.000],  loss: 99.520143, mae: 168.871263, mean_q: 222.981089, mean_eps: 0.739561
  86985/300000: episode: 877, duration: 0.749s, episode steps: 120, steps per second: 160, episode reward:  4.464, mean reward:  0.037 [-100.000, 88.721], mean action: 1.475 [0.000, 3.000],  loss: 93.160337, mae: 169.126963, mean_q: 223.303845, mean_eps: 0.739226
  87090/300000: episode: 878, duration: 0.707s, episode steps: 105, steps per second: 149, episode reward: -231.326, mean reward: -2.203 [-100.000,  9.422], mean action: 1.514 [0.000, 3.000],  loss: 88.380766, mae: 167.426641, mean_q: 222.187647, mean_eps: 0.738889
  87157/300000: episode: 879, duration: 0.461s, episode steps:  67, steps per second: 145, episode reward: -97.466, mean reward: -1.455 [-100.000,  6.179], mean action: 1.478 [0.000, 3.000],  loss: 62.153505, mae: 171.350602, mean_q: 226.456330, mean_eps: 0.738631
  87256/300000: episode: 880, duration: 0.641s, episode steps:  99, steps per second: 155, episode reward: -33.312, mean reward: -0.336 [-100.000,  7.680], mean action: 1.606 [0.000, 3.000],  loss: 127.361680, mae: 166.092782, mean_q: 219.431971, mean_eps: 0.738382
  87398/300000: episode: 881, duration: 0.951s, episode steps: 142, steps per second: 149, episode reward: -63.303, mean reward: -0.446 [-100.000, 17.561], mean action: 1.556 [0.000, 3.000],  loss: 90.909054, mae: 166.310692, mean_q: 219.290621, mean_eps: 0.738020
  87483/300000: episode: 882, duration: 0.569s, episode steps:  85, steps per second: 149, episode reward: -10.223, mean reward: -0.120 [-100.000, 17.521], mean action: 1.635 [0.000, 3.000],  loss: 83.076225, mae: 165.499786, mean_q: 219.405160, mean_eps: 0.737680
  87609/300000: episode: 883, duration: 0.802s, episode steps: 126, steps per second: 157, episode reward: -165.131, mean reward: -1.311 [-100.000,  7.938], mean action: 1.516 [0.000, 3.000],  loss: 62.084140, mae: 167.342159, mean_q: 222.058757, mean_eps: 0.737364
  87704/300000: episode: 884, duration: 0.601s, episode steps:  95, steps per second: 158, episode reward: -80.036, mean reward: -0.842 [-100.000, 53.435], mean action: 1.537 [0.000, 3.000],  loss: 118.457024, mae: 165.550832, mean_q: 219.046280, mean_eps: 0.737032
  87791/300000: episode: 885, duration: 0.574s, episode steps:  87, steps per second: 152, episode reward: -288.174, mean reward: -3.312 [-100.000, 104.588], mean action: 1.690 [0.000, 3.000],  loss: 97.312690, mae: 169.990032, mean_q: 225.866229, mean_eps: 0.736759
  87894/300000: episode: 886, duration: 0.654s, episode steps: 103, steps per second: 157, episode reward: -130.325, mean reward: -1.265 [-100.000, 41.153], mean action: 1.650 [0.000, 3.000],  loss: 70.729143, mae: 170.984940, mean_q: 226.502681, mean_eps: 0.736474
  88029/300000: episode: 887, duration: 0.883s, episode steps: 135, steps per second: 153, episode reward: -199.635, mean reward: -1.479 [-100.000,  2.484], mean action: 1.674 [0.000, 3.000],  loss: 126.291711, mae: 174.284996, mean_q: 231.477326, mean_eps: 0.736117
  88153/300000: episode: 888, duration: 0.873s, episode steps: 124, steps per second: 142, episode reward: -43.960, mean reward: -0.355 [-100.000, 13.499], mean action: 1.750 [0.000, 3.000],  loss: 100.125145, mae: 174.712215, mean_q: 232.771905, mean_eps: 0.735729
  88271/300000: episode: 889, duration: 0.765s, episode steps: 118, steps per second: 154, episode reward: -107.359, mean reward: -0.910 [-100.000,  7.164], mean action: 1.568 [0.000, 3.000],  loss: 113.316366, mae: 175.676789, mean_q: 233.913314, mean_eps: 0.735365
  88353/300000: episode: 890, duration: 0.555s, episode steps:  82, steps per second: 148, episode reward: -156.867, mean reward: -1.913 [-100.000, 10.015], mean action: 1.598 [0.000, 3.000],  loss: 85.911324, mae: 177.500591, mean_q: 236.055517, mean_eps: 0.735066
  88429/300000: episode: 891, duration: 0.503s, episode steps:  76, steps per second: 151, episode reward: -57.839, mean reward: -0.761 [-100.000, 11.389], mean action: 1.566 [0.000, 3.000],  loss: 87.681982, mae: 171.832182, mean_q: 228.868556, mean_eps: 0.734828
  88546/300000: episode: 892, duration: 0.747s, episode steps: 117, steps per second: 157, episode reward: -141.628, mean reward: -1.210 [-100.000,  6.001], mean action: 1.607 [0.000, 3.000],  loss: 83.738343, mae: 172.443721, mean_q: 230.127399, mean_eps: 0.734539
  88675/300000: episode: 893, duration: 0.826s, episode steps: 129, steps per second: 156, episode reward: -116.569, mean reward: -0.904 [-100.000,  5.989], mean action: 1.566 [0.000, 3.000],  loss: 66.033397, mae: 174.431801, mean_q: 232.255852, mean_eps: 0.734170
  88779/300000: episode: 894, duration: 0.684s, episode steps: 104, steps per second: 152, episode reward: -210.084, mean reward: -2.020 [-100.000,  7.400], mean action: 1.635 [0.000, 3.000],  loss: 83.062800, mae: 177.055063, mean_q: 237.097989, mean_eps: 0.733821
  88909/300000: episode: 895, duration: 0.832s, episode steps: 130, steps per second: 156, episode reward: -388.060, mean reward: -2.985 [-100.000, 78.087], mean action: 1.592 [0.000, 3.000],  loss: 86.641268, mae: 177.668954, mean_q: 236.725904, mean_eps: 0.733470
  88998/300000: episode: 896, duration: 0.581s, episode steps:  89, steps per second: 153, episode reward: -78.176, mean reward: -0.878 [-100.000, 48.746], mean action: 1.685 [0.000, 3.000],  loss: 114.345358, mae: 174.063955, mean_q: 232.585206, mean_eps: 0.733141
  89083/300000: episode: 897, duration: 0.569s, episode steps:  85, steps per second: 149, episode reward: -34.559, mean reward: -0.407 [-100.000, 10.718], mean action: 1.612 [0.000, 3.000],  loss: 72.928283, mae: 180.475505, mean_q: 241.718326, mean_eps: 0.732880
  89231/300000: episode: 898, duration: 0.936s, episode steps: 148, steps per second: 158, episode reward: -122.527, mean reward: -0.828 [-100.000, 28.255], mean action: 1.649 [0.000, 3.000],  loss: 99.586317, mae: 175.466216, mean_q: 233.626684, mean_eps: 0.732530
  89351/300000: episode: 899, duration: 0.794s, episode steps: 120, steps per second: 151, episode reward: -335.233, mean reward: -2.794 [-100.000, 74.908], mean action: 1.583 [0.000, 3.000],  loss: 74.205754, mae: 175.792960, mean_q: 235.136654, mean_eps: 0.732129
  89468/300000: episode: 900, duration: 0.769s, episode steps: 117, steps per second: 152, episode reward: -167.738, mean reward: -1.434 [-100.000,  7.735], mean action: 1.701 [0.000, 3.000],  loss: 80.696199, mae: 176.694893, mean_q: 237.060642, mean_eps: 0.731773
  89561/300000: episode: 901, duration: 0.583s, episode steps:  93, steps per second: 159, episode reward: -56.536, mean reward: -0.608 [-100.000, 10.939], mean action: 1.667 [0.000, 3.000],  loss: 101.990035, mae: 175.932026, mean_q: 235.957604, mean_eps: 0.731458
  89762/300000: episode: 902, duration: 1.482s, episode steps: 201, steps per second: 136, episode reward: -60.415, mean reward: -0.301 [-100.000, 48.536], mean action: 1.542 [0.000, 3.000],  loss: 89.758171, mae: 176.525428, mean_q: 235.344375, mean_eps: 0.731017
  89905/300000: episode: 903, duration: 1.019s, episode steps: 143, steps per second: 140, episode reward: -57.630, mean reward: -0.403 [-100.000, 12.927], mean action: 1.706 [0.000, 3.000],  loss: 113.020868, mae: 177.919230, mean_q: 237.961832, mean_eps: 0.730501
  90002/300000: episode: 904, duration: 0.715s, episode steps:  97, steps per second: 136, episode reward: -186.955, mean reward: -1.927 [-100.000,  8.996], mean action: 1.639 [0.000, 3.000],  loss: 108.137578, mae: 172.882799, mean_q: 229.781694, mean_eps: 0.730141
  90092/300000: episode: 905, duration: 0.599s, episode steps:  90, steps per second: 150, episode reward: -152.035, mean reward: -1.689 [-100.000,  8.976], mean action: 1.722 [0.000, 3.000],  loss: 63.377829, mae: 173.445180, mean_q: 232.058262, mean_eps: 0.729860
  90230/300000: episode: 906, duration: 0.913s, episode steps: 138, steps per second: 151, episode reward: -50.162, mean reward: -0.363 [-100.000, 24.914], mean action: 1.703 [0.000, 3.000],  loss: 84.472686, mae: 173.186035, mean_q: 230.009522, mean_eps: 0.729518
  90374/300000: episode: 907, duration: 0.991s, episode steps: 144, steps per second: 145, episode reward: -182.870, mean reward: -1.270 [-100.000, 10.333], mean action: 1.674 [0.000, 3.000],  loss: 103.089827, mae: 174.967102, mean_q: 233.602210, mean_eps: 0.729096
  90476/300000: episode: 908, duration: 0.679s, episode steps: 102, steps per second: 150, episode reward: -213.531, mean reward: -2.093 [-100.000,  7.261], mean action: 1.696 [0.000, 3.000],  loss: 124.208213, mae: 170.392887, mean_q: 227.384748, mean_eps: 0.728727
  90571/300000: episode: 909, duration: 0.614s, episode steps:  95, steps per second: 155, episode reward: -70.287, mean reward: -0.740 [-100.000,  8.624], mean action: 1.547 [0.000, 3.000],  loss: 72.913170, mae: 173.879098, mean_q: 232.237822, mean_eps: 0.728431
  90666/300000: episode: 910, duration: 0.661s, episode steps:  95, steps per second: 144, episode reward: -63.720, mean reward: -0.671 [-100.000, 25.677], mean action: 1.537 [0.000, 3.000],  loss: 71.590011, mae: 176.774373, mean_q: 235.670775, mean_eps: 0.728146
  90780/300000: episode: 911, duration: 0.738s, episode steps: 114, steps per second: 155, episode reward: -232.432, mean reward: -2.039 [-100.000,  7.420], mean action: 1.632 [0.000, 3.000],  loss: 87.301522, mae: 175.931476, mean_q: 235.672840, mean_eps: 0.727833
  90901/300000: episode: 912, duration: 0.761s, episode steps: 121, steps per second: 159, episode reward: -94.821, mean reward: -0.784 [-100.000, 10.027], mean action: 1.686 [0.000, 3.000],  loss: 117.962074, mae: 176.689635, mean_q: 236.118230, mean_eps: 0.727480
  91030/300000: episode: 913, duration: 0.861s, episode steps: 129, steps per second: 150, episode reward: -76.103, mean reward: -0.590 [-100.000, 12.478], mean action: 1.504 [0.000, 3.000],  loss: 105.180502, mae: 177.460134, mean_q: 237.502205, mean_eps: 0.727105
  91135/300000: episode: 914, duration: 0.676s, episode steps: 105, steps per second: 155, episode reward: -72.933, mean reward: -0.695 [-100.000, 29.147], mean action: 1.867 [0.000, 3.000],  loss: 90.825742, mae: 176.564305, mean_q: 236.673999, mean_eps: 0.726754
  91233/300000: episode: 915, duration: 0.627s, episode steps:  98, steps per second: 156, episode reward: -86.934, mean reward: -0.887 [-100.000, 29.641], mean action: 1.551 [0.000, 3.000],  loss: 129.272072, mae: 176.518576, mean_q: 236.715638, mean_eps: 0.726450
  91322/300000: episode: 916, duration: 0.612s, episode steps:  89, steps per second: 145, episode reward: 10.407, mean reward:  0.117 [-100.000, 13.616], mean action: 1.652 [0.000, 3.000],  loss: 143.848597, mae: 177.894933, mean_q: 239.652410, mean_eps: 0.726169
  91405/300000: episode: 917, duration: 0.554s, episode steps:  83, steps per second: 150, episode reward: -86.686, mean reward: -1.044 [-100.000,  7.951], mean action: 1.542 [0.000, 3.000],  loss: 121.112287, mae: 179.501134, mean_q: 241.650297, mean_eps: 0.725911
  91537/300000: episode: 918, duration: 0.882s, episode steps: 132, steps per second: 150, episode reward: -326.353, mean reward: -2.472 [-100.000, 112.351], mean action: 1.583 [0.000, 3.000],  loss: 108.207038, mae: 179.992291, mean_q: 242.723697, mean_eps: 0.725588
  91651/300000: episode: 919, duration: 0.771s, episode steps: 114, steps per second: 148, episode reward: -152.077, mean reward: -1.334 [-100.000, 19.010], mean action: 1.649 [0.000, 3.000],  loss: 122.175813, mae: 182.820552, mean_q: 245.786394, mean_eps: 0.725220
  91758/300000: episode: 920, duration: 0.699s, episode steps: 107, steps per second: 153, episode reward: -131.735, mean reward: -1.231 [-100.000,  8.756], mean action: 1.654 [0.000, 3.000],  loss: 130.736208, mae: 180.599411, mean_q: 242.937953, mean_eps: 0.724888
  91881/300000: episode: 921, duration: 0.779s, episode steps: 123, steps per second: 158, episode reward: -195.365, mean reward: -1.588 [-100.000,  1.764], mean action: 1.667 [0.000, 3.000],  loss: 119.777775, mae: 182.099469, mean_q: 244.418507, mean_eps: 0.724543
  91978/300000: episode: 922, duration: 0.660s, episode steps:  97, steps per second: 147, episode reward: -349.289, mean reward: -3.601 [-100.000,  1.154], mean action: 1.722 [0.000, 3.000],  loss: 124.667917, mae: 183.492206, mean_q: 245.514450, mean_eps: 0.724213
  92053/300000: episode: 923, duration: 0.503s, episode steps:  75, steps per second: 149, episode reward: -13.073, mean reward: -0.174 [-100.000, 22.517], mean action: 1.720 [0.000, 3.000],  loss: 78.067873, mae: 185.483879, mean_q: 248.410120, mean_eps: 0.723955
  92174/300000: episode: 924, duration: 0.785s, episode steps: 121, steps per second: 154, episode reward: -116.425, mean reward: -0.962 [-100.000,  6.832], mean action: 1.488 [0.000, 3.000],  loss: 75.371702, mae: 185.133152, mean_q: 249.103166, mean_eps: 0.723661
  92336/300000: episode: 925, duration: 1.089s, episode steps: 162, steps per second: 149, episode reward: -70.463, mean reward: -0.435 [-100.000, 20.831], mean action: 1.753 [0.000, 3.000],  loss: 57.401202, mae: 185.236893, mean_q: 248.294609, mean_eps: 0.723236
  92441/300000: episode: 926, duration: 0.689s, episode steps: 105, steps per second: 152, episode reward: -92.267, mean reward: -0.879 [-100.000,  8.374], mean action: 1.562 [0.000, 3.000],  loss: 82.769948, mae: 186.966236, mean_q: 251.443253, mean_eps: 0.722836
  92583/300000: episode: 927, duration: 0.973s, episode steps: 142, steps per second: 146, episode reward: -84.282, mean reward: -0.594 [-100.000,  7.014], mean action: 1.507 [0.000, 3.000],  loss: 110.209886, mae: 186.043988, mean_q: 249.073195, mean_eps: 0.722465
  92687/300000: episode: 928, duration: 0.693s, episode steps: 104, steps per second: 150, episode reward: -146.020, mean reward: -1.404 [-100.000,  9.669], mean action: 1.471 [0.000, 3.000],  loss: 177.873172, mae: 190.716998, mean_q: 255.240978, mean_eps: 0.722097
  92801/300000: episode: 929, duration: 0.720s, episode steps: 114, steps per second: 158, episode reward: -210.818, mean reward: -1.849 [-100.000,  1.063], mean action: 1.684 [0.000, 3.000],  loss: 115.473490, mae: 189.749897, mean_q: 254.036575, mean_eps: 0.721769
  92890/300000: episode: 930, duration: 0.578s, episode steps:  89, steps per second: 154, episode reward: -113.472, mean reward: -1.275 [-100.000, 38.476], mean action: 1.551 [0.000, 3.000],  loss: 125.262435, mae: 190.169046, mean_q: 254.575892, mean_eps: 0.721465
  93022/300000: episode: 931, duration: 0.895s, episode steps: 132, steps per second: 147, episode reward: -61.019, mean reward: -0.462 [-100.000, 10.375], mean action: 1.795 [0.000, 3.000],  loss: 139.276930, mae: 189.708982, mean_q: 253.585549, mean_eps: 0.721133
  93124/300000: episode: 932, duration: 0.641s, episode steps: 102, steps per second: 159, episode reward: -312.232, mean reward: -3.061 [-100.000,  0.901], mean action: 1.667 [0.000, 3.000],  loss: 92.277683, mae: 190.899152, mean_q: 255.516546, mean_eps: 0.720783
  93251/300000: episode: 933, duration: 0.832s, episode steps: 127, steps per second: 153, episode reward: -284.067, mean reward: -2.237 [-100.000, 47.982], mean action: 1.575 [0.000, 3.000],  loss: 82.293917, mae: 194.686248, mean_q: 260.730525, mean_eps: 0.720439
  93351/300000: episode: 934, duration: 0.813s, episode steps: 100, steps per second: 123, episode reward: -57.212, mean reward: -0.572 [-100.000, 19.161], mean action: 1.720 [0.000, 3.000],  loss: 224.079489, mae: 193.098725, mean_q: 258.191331, mean_eps: 0.720098
  93464/300000: episode: 935, duration: 0.847s, episode steps: 113, steps per second: 133, episode reward: -241.417, mean reward: -2.136 [-100.000,  4.529], mean action: 1.611 [0.000, 3.000],  loss: 134.118972, mae: 199.784716, mean_q: 268.033873, mean_eps: 0.719779
  93582/300000: episode: 936, duration: 0.855s, episode steps: 118, steps per second: 138, episode reward: -172.042, mean reward: -1.458 [-100.000,  8.876], mean action: 1.534 [0.000, 3.000],  loss: 116.464895, mae: 195.617728, mean_q: 262.596389, mean_eps: 0.719433
  93735/300000: episode: 937, duration: 1.181s, episode steps: 153, steps per second: 130, episode reward: -185.582, mean reward: -1.213 [-100.000,  9.185], mean action: 1.614 [0.000, 3.000],  loss: 96.511880, mae: 196.732073, mean_q: 264.015313, mean_eps: 0.719026
  93851/300000: episode: 938, duration: 0.879s, episode steps: 116, steps per second: 132, episode reward: -207.006, mean reward: -1.785 [-100.000,  9.136], mean action: 1.612 [0.000, 3.000],  loss: 122.234569, mae: 195.932542, mean_q: 262.130878, mean_eps: 0.718622
  93912/300000: episode: 939, duration: 0.421s, episode steps:  61, steps per second: 145, episode reward: -50.947, mean reward: -0.835 [-100.000, 10.543], mean action: 1.475 [0.000, 3.000],  loss: 127.346307, mae: 198.235045, mean_q: 265.365441, mean_eps: 0.718357
  94019/300000: episode: 940, duration: 0.754s, episode steps: 107, steps per second: 142, episode reward: -168.327, mean reward: -1.573 [-100.000,  7.461], mean action: 1.505 [0.000, 3.000],  loss: 167.609553, mae: 197.589078, mean_q: 262.944034, mean_eps: 0.718105
  94141/300000: episode: 941, duration: 0.817s, episode steps: 122, steps per second: 149, episode reward: -130.526, mean reward: -1.070 [-100.000, 21.213], mean action: 1.664 [0.000, 3.000],  loss: 113.496396, mae: 199.661828, mean_q: 267.150426, mean_eps: 0.717762
  94251/300000: episode: 942, duration: 0.716s, episode steps: 110, steps per second: 154, episode reward: -178.496, mean reward: -1.623 [-100.000,  1.323], mean action: 1.782 [0.000, 3.000],  loss: 144.825474, mae: 200.867112, mean_q: 268.494343, mean_eps: 0.717414
  94362/300000: episode: 943, duration: 0.710s, episode steps: 111, steps per second: 156, episode reward: -178.780, mean reward: -1.611 [-100.000, 10.851], mean action: 1.631 [0.000, 3.000],  loss: 66.323862, mae: 199.415951, mean_q: 267.308100, mean_eps: 0.717082
  94423/300000: episode: 944, duration: 0.405s, episode steps:  61, steps per second: 151, episode reward: -81.983, mean reward: -1.344 [-100.000,  7.310], mean action: 1.590 [0.000, 3.000],  loss: 88.892187, mae: 199.058631, mean_q: 265.236374, mean_eps: 0.716824
  94537/300000: episode: 945, duration: 0.757s, episode steps: 114, steps per second: 151, episode reward: -97.694, mean reward: -0.857 [-100.000,  5.953], mean action: 1.842 [0.000, 3.000],  loss: 135.947516, mae: 198.926429, mean_q: 264.645547, mean_eps: 0.716562
  94631/300000: episode: 946, duration: 0.614s, episode steps:  94, steps per second: 153, episode reward: -147.798, mean reward: -1.572 [-100.000, 35.296], mean action: 1.723 [0.000, 3.000],  loss: 179.733251, mae: 201.549846, mean_q: 269.711328, mean_eps: 0.716250
  94728/300000: episode: 947, duration: 0.624s, episode steps:  97, steps per second: 155, episode reward: -198.030, mean reward: -2.042 [-100.000,  7.552], mean action: 1.814 [0.000, 3.000],  loss: 129.461963, mae: 202.420742, mean_q: 271.733552, mean_eps: 0.715963
  94810/300000: episode: 948, duration: 0.563s, episode steps:  82, steps per second: 146, episode reward: -175.542, mean reward: -2.141 [-100.000,  8.191], mean action: 1.695 [0.000, 3.000],  loss: 151.531806, mae: 199.481988, mean_q: 266.611109, mean_eps: 0.715695
  94913/300000: episode: 949, duration: 0.713s, episode steps: 103, steps per second: 144, episode reward: -50.592, mean reward: -0.491 [-100.000, 23.690], mean action: 1.777 [0.000, 3.000],  loss: 131.646556, mae: 198.742597, mean_q: 266.779480, mean_eps: 0.715417
  95011/300000: episode: 950, duration: 0.621s, episode steps:  98, steps per second: 158, episode reward: -239.884, mean reward: -2.448 [-100.000, 15.432], mean action: 1.551 [0.000, 3.000],  loss: 105.245635, mae: 198.198376, mean_q: 264.305673, mean_eps: 0.715115
  95107/300000: episode: 951, duration: 0.676s, episode steps:  96, steps per second: 142, episode reward: -226.349, mean reward: -2.358 [-100.000,  1.255], mean action: 1.646 [0.000, 3.000],  loss: 72.616906, mae: 198.764124, mean_q: 265.227974, mean_eps: 0.714825
  95217/300000: episode: 952, duration: 0.773s, episode steps: 110, steps per second: 142, episode reward: -69.531, mean reward: -0.632 [-100.000, 10.086], mean action: 1.436 [0.000, 3.000],  loss: 96.820492, mae: 200.484643, mean_q: 266.855488, mean_eps: 0.714516
  95325/300000: episode: 953, duration: 0.770s, episode steps: 108, steps per second: 140, episode reward: -43.315, mean reward: -0.401 [-100.000, 33.725], mean action: 1.528 [0.000, 3.000],  loss: 81.911126, mae: 198.907089, mean_q: 265.051066, mean_eps: 0.714189
  95440/300000: episode: 954, duration: 0.895s, episode steps: 115, steps per second: 128, episode reward: -302.603, mean reward: -2.631 [-100.000, 100.639], mean action: 1.800 [0.000, 3.000],  loss: 221.845652, mae: 200.803571, mean_q: 268.696666, mean_eps: 0.713854
  95554/300000: episode: 955, duration: 0.865s, episode steps: 114, steps per second: 132, episode reward: -313.813, mean reward: -2.753 [-100.000, 94.789], mean action: 1.430 [0.000, 3.000],  loss: 143.970192, mae: 205.245460, mean_q: 275.049691, mean_eps: 0.713511
  95674/300000: episode: 956, duration: 0.882s, episode steps: 120, steps per second: 136, episode reward:  0.250, mean reward:  0.002 [-100.000, 53.403], mean action: 1.517 [0.000, 3.000],  loss: 88.298187, mae: 204.508891, mean_q: 273.314424, mean_eps: 0.713159
  95780/300000: episode: 957, duration: 0.717s, episode steps: 106, steps per second: 148, episode reward: -209.138, mean reward: -1.973 [-100.000,  0.947], mean action: 1.443 [0.000, 3.000],  loss: 137.567307, mae: 203.247596, mean_q: 271.423851, mean_eps: 0.712820
  95884/300000: episode: 958, duration: 0.697s, episode steps: 104, steps per second: 149, episode reward: -57.997, mean reward: -0.558 [-100.000,  8.804], mean action: 1.606 [0.000, 3.000],  loss: 112.905293, mae: 206.984325, mean_q: 275.519980, mean_eps: 0.712506
  95993/300000: episode: 959, duration: 0.798s, episode steps: 109, steps per second: 137, episode reward: -162.024, mean reward: -1.486 [-100.000,  6.640], mean action: 1.651 [0.000, 3.000],  loss: 142.739698, mae: 207.964513, mean_q: 276.860720, mean_eps: 0.712186
  96102/300000: episode: 960, duration: 0.833s, episode steps: 109, steps per second: 131, episode reward: -118.800, mean reward: -1.090 [-100.000,  3.909], mean action: 1.780 [0.000, 3.000],  loss: 122.808828, mae: 213.337009, mean_q: 284.674995, mean_eps: 0.711859
  96179/300000: episode: 961, duration: 0.531s, episode steps:  77, steps per second: 145, episode reward: -50.855, mean reward: -0.660 [-100.000,  7.213], mean action: 1.701 [0.000, 3.000],  loss: 121.532695, mae: 216.163009, mean_q: 289.163090, mean_eps: 0.711580
  96307/300000: episode: 962, duration: 0.946s, episode steps: 128, steps per second: 135, episode reward: -147.617, mean reward: -1.153 [-100.000, 12.514], mean action: 1.656 [0.000, 3.000],  loss: 141.326459, mae: 216.546974, mean_q: 289.537261, mean_eps: 0.711272
  96391/300000: episode: 963, duration: 0.646s, episode steps:  84, steps per second: 130, episode reward: -67.135, mean reward: -0.799 [-100.000,  8.769], mean action: 1.452 [0.000, 3.000],  loss: 96.945494, mae: 217.040399, mean_q: 290.249214, mean_eps: 0.710955
  96518/300000: episode: 964, duration: 0.945s, episode steps: 127, steps per second: 134, episode reward: -69.872, mean reward: -0.550 [-100.000, 11.426], mean action: 1.559 [0.000, 3.000],  loss: 162.746003, mae: 219.088952, mean_q: 293.717454, mean_eps: 0.710638
  96622/300000: episode: 965, duration: 0.828s, episode steps: 104, steps per second: 126, episode reward: -110.671, mean reward: -1.064 [-100.000, 12.522], mean action: 1.750 [0.000, 3.000],  loss: 181.544808, mae: 223.257641, mean_q: 299.418920, mean_eps: 0.710292
  96712/300000: episode: 966, duration: 0.654s, episode steps:  90, steps per second: 138, episode reward: -87.243, mean reward: -0.969 [-100.000,  7.852], mean action: 1.733 [0.000, 3.000],  loss: 184.633358, mae: 222.938187, mean_q: 298.800215, mean_eps: 0.710001
  96831/300000: episode: 967, duration: 0.841s, episode steps: 119, steps per second: 141, episode reward: -60.980, mean reward: -0.512 [-100.000, 22.253], mean action: 1.681 [0.000, 3.000],  loss: 141.494231, mae: 220.787094, mean_q: 295.915774, mean_eps: 0.709687
  96934/300000: episode: 968, duration: 0.713s, episode steps: 103, steps per second: 144, episode reward: -99.862, mean reward: -0.970 [-100.000,  9.757], mean action: 1.641 [0.000, 3.000],  loss: 129.037830, mae: 223.225975, mean_q: 298.083339, mean_eps: 0.709354
  97048/300000: episode: 969, duration: 0.743s, episode steps: 114, steps per second: 153, episode reward: -131.689, mean reward: -1.155 [-100.000,  6.880], mean action: 1.789 [0.000, 3.000],  loss: 179.535092, mae: 225.815358, mean_q: 302.218067, mean_eps: 0.709029
  97163/300000: episode: 970, duration: 0.729s, episode steps: 115, steps per second: 158, episode reward: -88.954, mean reward: -0.774 [-100.000,  5.551], mean action: 1.609 [0.000, 3.000],  loss: 184.856609, mae: 225.988073, mean_q: 303.149442, mean_eps: 0.708685
  97297/300000: episode: 971, duration: 0.905s, episode steps: 134, steps per second: 148, episode reward: -150.768, mean reward: -1.125 [-100.000, 44.452], mean action: 1.843 [0.000, 3.000],  loss: 136.601401, mae: 225.440731, mean_q: 302.250669, mean_eps: 0.708311
  97408/300000: episode: 972, duration: 0.700s, episode steps: 111, steps per second: 159, episode reward: -158.579, mean reward: -1.429 [-100.000, 17.939], mean action: 1.901 [0.000, 3.000],  loss: 205.144820, mae: 230.268996, mean_q: 309.026106, mean_eps: 0.707944
  97502/300000: episode: 973, duration: 0.602s, episode steps:  94, steps per second: 156, episode reward: -33.821, mean reward: -0.360 [-100.000, 13.640], mean action: 1.649 [0.000, 3.000],  loss: 104.676740, mae: 229.642659, mean_q: 307.651951, mean_eps: 0.707637
  97620/300000: episode: 974, duration: 0.805s, episode steps: 118, steps per second: 147, episode reward: -91.521, mean reward: -0.776 [-100.000, 10.242], mean action: 1.678 [0.000, 3.000],  loss: 154.060509, mae: 233.373697, mean_q: 315.135390, mean_eps: 0.707318
  97701/300000: episode: 975, duration: 0.532s, episode steps:  81, steps per second: 152, episode reward: -49.486, mean reward: -0.611 [-100.000, 11.175], mean action: 1.543 [0.000, 3.000],  loss: 192.951379, mae: 236.123650, mean_q: 317.475728, mean_eps: 0.707020
  97790/300000: episode: 976, duration: 0.564s, episode steps:  89, steps per second: 158, episode reward: -106.954, mean reward: -1.202 [-100.000,  9.563], mean action: 1.820 [0.000, 3.000],  loss: 153.616843, mae: 235.796722, mean_q: 318.605405, mean_eps: 0.706765
  97909/300000: episode: 977, duration: 0.802s, episode steps: 119, steps per second: 148, episode reward: -21.627, mean reward: -0.182 [-100.000, 77.736], mean action: 1.689 [0.000, 3.000],  loss: 160.316560, mae: 235.216059, mean_q: 316.527432, mean_eps: 0.706453
  98052/300000: episode: 978, duration: 0.911s, episode steps: 143, steps per second: 157, episode reward: -174.076, mean reward: -1.217 [-100.000, 11.870], mean action: 1.692 [0.000, 3.000],  loss: 283.715594, mae: 241.748047, mean_q: 326.518165, mean_eps: 0.706060
  98145/300000: episode: 979, duration: 0.595s, episode steps:  93, steps per second: 156, episode reward: -179.798, mean reward: -1.933 [-100.000, 11.262], mean action: 1.634 [0.000, 3.000],  loss: 226.796962, mae: 246.975025, mean_q: 332.630324, mean_eps: 0.705706
  98249/300000: episode: 980, duration: 0.702s, episode steps: 104, steps per second: 148, episode reward: -70.902, mean reward: -0.682 [-100.000,  7.044], mean action: 1.558 [0.000, 3.000],  loss: 209.102650, mae: 246.354784, mean_q: 333.877022, mean_eps: 0.705410
  98329/300000: episode: 981, duration: 0.512s, episode steps:  80, steps per second: 156, episode reward: -104.513, mean reward: -1.306 [-100.000,  6.315], mean action: 1.450 [0.000, 3.000],  loss: 237.022039, mae: 252.490571, mean_q: 342.156067, mean_eps: 0.705134
  98427/300000: episode: 982, duration: 0.630s, episode steps:  98, steps per second: 156, episode reward: -70.313, mean reward: -0.717 [-100.000, 15.630], mean action: 1.714 [0.000, 3.000],  loss: 269.946590, mae: 251.644837, mean_q: 339.449332, mean_eps: 0.704867
  98517/300000: episode: 983, duration: 0.592s, episode steps:  90, steps per second: 152, episode reward: -55.447, mean reward: -0.616 [-100.000, 15.835], mean action: 1.589 [0.000, 3.000],  loss: 240.221934, mae: 251.507013, mean_q: 340.951069, mean_eps: 0.704586
  98617/300000: episode: 984, duration: 0.665s, episode steps: 100, steps per second: 150, episode reward: -114.218, mean reward: -1.142 [-100.000, 11.008], mean action: 1.750 [0.000, 3.000],  loss: 220.726523, mae: 249.619639, mean_q: 336.925498, mean_eps: 0.704300
  98691/300000: episode: 985, duration: 0.474s, episode steps:  74, steps per second: 156, episode reward: -72.700, mean reward: -0.982 [-100.000,  5.988], mean action: 1.892 [0.000, 3.000],  loss: 293.796408, mae: 248.205672, mean_q: 333.743213, mean_eps: 0.704039
  98805/300000: episode: 986, duration: 0.720s, episode steps: 114, steps per second: 158, episode reward: -117.867, mean reward: -1.034 [-100.000,  7.829], mean action: 1.842 [0.000, 3.000],  loss: 213.241672, mae: 252.509513, mean_q: 340.961924, mean_eps: 0.703758
  98910/300000: episode: 987, duration: 0.713s, episode steps: 105, steps per second: 147, episode reward: -112.322, mean reward: -1.070 [-100.000,  8.205], mean action: 1.657 [0.000, 3.000],  loss: 184.688065, mae: 258.791531, mean_q: 349.407646, mean_eps: 0.703429
  99036/300000: episode: 988, duration: 0.809s, episode steps: 126, steps per second: 156, episode reward: -208.455, mean reward: -1.654 [-100.000,  8.394], mean action: 1.698 [0.000, 3.000],  loss: 265.325799, mae: 253.672596, mean_q: 342.163883, mean_eps: 0.703083
  99160/300000: episode: 989, duration: 0.892s, episode steps: 124, steps per second: 139, episode reward: -176.887, mean reward: -1.427 [-100.000,  8.306], mean action: 1.710 [0.000, 3.000],  loss: 299.827155, mae: 255.031493, mean_q: 343.608439, mean_eps: 0.702708
  99269/300000: episode: 990, duration: 0.790s, episode steps: 109, steps per second: 138, episode reward: -134.335, mean reward: -1.232 [-100.000,  6.410], mean action: 1.550 [0.000, 3.000],  loss: 273.936459, mae: 253.408630, mean_q: 341.158181, mean_eps: 0.702358
  99350/300000: episode: 991, duration: 0.554s, episode steps:  81, steps per second: 146, episode reward: -105.047, mean reward: -1.297 [-100.000,  8.674], mean action: 1.580 [0.000, 3.000],  loss: 147.952573, mae: 254.680401, mean_q: 343.430264, mean_eps: 0.702073
  99444/300000: episode: 992, duration: 0.655s, episode steps:  94, steps per second: 144, episode reward: -29.050, mean reward: -0.309 [-100.000, 13.537], mean action: 1.617 [0.000, 3.000],  loss: 174.709824, mae: 257.648127, mean_q: 348.415065, mean_eps: 0.701811
  99548/300000: episode: 993, duration: 0.748s, episode steps: 104, steps per second: 139, episode reward: -140.325, mean reward: -1.349 [-100.000,  6.024], mean action: 1.519 [0.000, 3.000],  loss: 205.929497, mae: 253.139085, mean_q: 340.607219, mean_eps: 0.701514
  99632/300000: episode: 994, duration: 0.569s, episode steps:  84, steps per second: 148, episode reward: -119.585, mean reward: -1.424 [-100.000,  9.968], mean action: 1.524 [0.000, 3.000],  loss: 254.828844, mae: 255.000435, mean_q: 342.469599, mean_eps: 0.701231
  99703/300000: episode: 995, duration: 0.474s, episode steps:  71, steps per second: 150, episode reward: -60.243, mean reward: -0.848 [-100.000, 11.312], mean action: 1.634 [0.000, 3.000],  loss: 213.048068, mae: 254.716617, mean_q: 341.738981, mean_eps: 0.700999
  99847/300000: episode: 996, duration: 1.047s, episode steps: 144, steps per second: 138, episode reward: -94.167, mean reward: -0.654 [-100.000, 38.487], mean action: 1.743 [0.000, 3.000],  loss: 227.478874, mae: 257.553098, mean_q: 345.743268, mean_eps: 0.700677
  99937/300000: episode: 997, duration: 0.588s, episode steps:  90, steps per second: 153, episode reward: -124.448, mean reward: -1.383 [-100.000, 15.398], mean action: 1.544 [0.000, 3.000],  loss: 169.105775, mae: 258.585562, mean_q: 346.935587, mean_eps: 0.700326
 100007/300000: episode: 998, duration: 0.453s, episode steps:  70, steps per second: 155, episode reward: -114.490, mean reward: -1.636 [-100.000,  9.273], mean action: 1.886 [0.000, 3.000],  loss: 221.430052, mae: 259.515608, mean_q: 348.849653, mean_eps: 0.700085
 100128/300000: episode: 999, duration: 0.809s, episode steps: 121, steps per second: 149, episode reward: -74.642, mean reward: -0.617 [-100.000,  9.868], mean action: 1.835 [0.000, 3.000],  loss: 184.249049, mae: 258.746557, mean_q: 347.837679, mean_eps: 0.699799
 100224/300000: episode: 1000, duration: 0.640s, episode steps:  96, steps per second: 150, episode reward: -242.281, mean reward: -2.524 [-100.000,  2.355], mean action: 1.521 [0.000, 3.000],  loss: 222.574792, mae: 260.235824, mean_q: 349.574417, mean_eps: 0.699473
 100293/300000: episode: 1001, duration: 0.448s, episode steps:  69, steps per second: 154, episode reward: -35.498, mean reward: -0.514 [-100.000, 45.630], mean action: 1.696 [0.000, 3.000],  loss: 175.975104, mae: 259.000109, mean_q: 347.023595, mean_eps: 0.699226
 100373/300000: episode: 1002, duration: 0.519s, episode steps:  80, steps per second: 154, episode reward: -101.190, mean reward: -1.265 [-100.000,  7.738], mean action: 1.587 [0.000, 3.000],  loss: 181.444819, mae: 260.165129, mean_q: 349.071516, mean_eps: 0.699003
 100452/300000: episode: 1003, duration: 0.547s, episode steps:  79, steps per second: 144, episode reward: -95.652, mean reward: -1.211 [-100.000, 10.260], mean action: 1.570 [0.000, 3.000],  loss: 117.617940, mae: 260.206285, mean_q: 350.211693, mean_eps: 0.698764
 100577/300000: episode: 1004, duration: 0.842s, episode steps: 125, steps per second: 148, episode reward: -184.017, mean reward: -1.472 [-100.000,  1.980], mean action: 1.656 [0.000, 3.000],  loss: 261.767768, mae: 257.315194, mean_q: 344.997751, mean_eps: 0.698458
 100689/300000: episode: 1005, duration: 0.716s, episode steps: 112, steps per second: 156, episode reward: -195.188, mean reward: -1.743 [-100.000,  8.208], mean action: 1.643 [0.000, 3.000],  loss: 215.667034, mae: 259.476749, mean_q: 347.948003, mean_eps: 0.698102
 100753/300000: episode: 1006, duration: 0.436s, episode steps:  64, steps per second: 147, episode reward: -148.672, mean reward: -2.323 [-100.000,  6.975], mean action: 1.500 [0.000, 3.000],  loss: 246.750509, mae: 259.602299, mean_q: 348.211337, mean_eps: 0.697839
 100843/300000: episode: 1007, duration: 0.622s, episode steps:  90, steps per second: 145, episode reward: -128.942, mean reward: -1.433 [-100.000, 12.540], mean action: 1.800 [0.000, 3.000],  loss: 214.257305, mae: 259.289184, mean_q: 347.053623, mean_eps: 0.697608
 100947/300000: episode: 1008, duration: 0.699s, episode steps: 104, steps per second: 149, episode reward: -109.739, mean reward: -1.055 [-100.000, 15.389], mean action: 1.587 [0.000, 3.000],  loss: 276.048646, mae: 260.990501, mean_q: 348.872096, mean_eps: 0.697317
 101052/300000: episode: 1009, duration: 0.664s, episode steps: 105, steps per second: 158, episode reward: -64.105, mean reward: -0.611 [-100.000, 12.182], mean action: 1.638 [0.000, 3.000],  loss: 226.798387, mae: 256.606391, mean_q: 341.858286, mean_eps: 0.697003
 101152/300000: episode: 1010, duration: 0.669s, episode steps: 100, steps per second: 150, episode reward: -213.690, mean reward: -2.137 [-100.000,  1.816], mean action: 1.760 [0.000, 3.000],  loss: 159.527756, mae: 258.892609, mean_q: 347.082379, mean_eps: 0.696695
 101244/300000: episode: 1011, duration: 0.603s, episode steps:  92, steps per second: 153, episode reward: -89.208, mean reward: -0.970 [-100.000, 17.957], mean action: 1.630 [0.000, 3.000],  loss: 166.178381, mae: 258.513823, mean_q: 347.600739, mean_eps: 0.696408
 101376/300000: episode: 1012, duration: 0.844s, episode steps: 132, steps per second: 156, episode reward: -102.936, mean reward: -0.780 [-100.000, 17.536], mean action: 1.780 [0.000, 3.000],  loss: 165.672949, mae: 259.468593, mean_q: 348.629814, mean_eps: 0.696072
 101488/300000: episode: 1013, duration: 0.801s, episode steps: 112, steps per second: 140, episode reward: -126.582, mean reward: -1.130 [-100.000,  7.447], mean action: 1.625 [0.000, 3.000],  loss: 140.996597, mae: 261.005814, mean_q: 350.427116, mean_eps: 0.695705
 101654/300000: episode: 1014, duration: 1.092s, episode steps: 166, steps per second: 152, episode reward: -119.426, mean reward: -0.719 [-100.000, 11.339], mean action: 1.711 [0.000, 3.000],  loss: 257.347617, mae: 263.823072, mean_q: 354.144804, mean_eps: 0.695288
 101733/300000: episode: 1015, duration: 0.534s, episode steps:  79, steps per second: 148, episode reward: -63.797, mean reward: -0.808 [-100.000,  6.990], mean action: 1.557 [0.000, 3.000],  loss: 206.441081, mae: 267.216540, mean_q: 358.702674, mean_eps: 0.694921
 101830/300000: episode: 1016, duration: 0.657s, episode steps:  97, steps per second: 148, episode reward: 32.005, mean reward:  0.330 [-100.000, 71.845], mean action: 1.629 [0.000, 3.000],  loss: 347.043579, mae: 265.026371, mean_q: 355.906848, mean_eps: 0.694657
 101908/300000: episode: 1017, duration: 0.506s, episode steps:  78, steps per second: 154, episode reward: -213.268, mean reward: -2.734 [-100.000, 21.657], mean action: 1.346 [0.000, 3.000],  loss: 259.034416, mae: 267.381583, mean_q: 357.486927, mean_eps: 0.694395
 101985/300000: episode: 1018, duration: 0.489s, episode steps:  77, steps per second: 157, episode reward: -117.254, mean reward: -1.523 [-100.000, 15.366], mean action: 1.766 [0.000, 3.000],  loss: 358.702189, mae: 266.318375, mean_q: 357.198584, mean_eps: 0.694162
 102100/300000: episode: 1019, duration: 0.759s, episode steps: 115, steps per second: 152, episode reward: -145.450, mean reward: -1.265 [-100.000, 17.864], mean action: 1.713 [0.000, 3.000],  loss: 274.651781, mae: 261.747505, mean_q: 350.348939, mean_eps: 0.693874
 102191/300000: episode: 1020, duration: 0.614s, episode steps:  91, steps per second: 148, episode reward: -80.365, mean reward: -0.883 [-100.000,  8.815], mean action: 1.626 [0.000, 3.000],  loss: 190.122077, mae: 263.636126, mean_q: 353.636473, mean_eps: 0.693565
 102298/300000: episode: 1021, duration: 0.697s, episode steps: 107, steps per second: 153, episode reward: -168.308, mean reward: -1.573 [-100.000,  2.202], mean action: 1.776 [0.000, 3.000],  loss: 201.418033, mae: 259.922710, mean_q: 348.589794, mean_eps: 0.693268
 102396/300000: episode: 1022, duration: 0.629s, episode steps:  98, steps per second: 156, episode reward: -72.862, mean reward: -0.743 [-100.000,  6.325], mean action: 1.653 [0.000, 3.000],  loss: 256.243703, mae: 269.179667, mean_q: 360.903634, mean_eps: 0.692960
 102471/300000: episode: 1023, duration: 0.503s, episode steps:  75, steps per second: 149, episode reward: -99.484, mean reward: -1.326 [-100.000, 11.132], mean action: 1.813 [0.000, 3.000],  loss: 333.985077, mae: 262.445345, mean_q: 352.129430, mean_eps: 0.692701
 102558/300000: episode: 1024, duration: 0.565s, episode steps:  87, steps per second: 154, episode reward: -49.635, mean reward: -0.571 [-100.000, 12.517], mean action: 1.644 [0.000, 3.000],  loss: 176.988360, mae: 264.923921, mean_q: 355.744806, mean_eps: 0.692458
 102634/300000: episode: 1025, duration: 0.503s, episode steps:  76, steps per second: 151, episode reward: -47.556, mean reward: -0.626 [-100.000,  8.656], mean action: 1.566 [0.000, 3.000],  loss: 232.362338, mae: 265.392561, mean_q: 356.445750, mean_eps: 0.692214
 102750/300000: episode: 1026, duration: 0.771s, episode steps: 116, steps per second: 151, episode reward: -155.931, mean reward: -1.344 [-100.000, 14.610], mean action: 1.871 [0.000, 3.000],  loss: 232.660512, mae: 265.648205, mean_q: 355.814601, mean_eps: 0.691926
 102896/300000: episode: 1027, duration: 1.031s, episode steps: 146, steps per second: 142, episode reward: -298.048, mean reward: -2.041 [-100.000, 25.609], mean action: 1.630 [0.000, 3.000],  loss: 244.497286, mae: 270.426924, mean_q: 362.244137, mean_eps: 0.691533
 102959/300000: episode: 1028, duration: 0.480s, episode steps:  63, steps per second: 131, episode reward: -74.349, mean reward: -1.180 [-100.000, 10.296], mean action: 1.540 [0.000, 3.000],  loss: 280.932282, mae: 269.578311, mean_q: 361.697530, mean_eps: 0.691219
 103062/300000: episode: 1029, duration: 0.808s, episode steps: 103, steps per second: 128, episode reward: -33.092, mean reward: -0.321 [-100.000,  7.061], mean action: 1.699 [0.000, 3.000],  loss: 270.012798, mae: 269.513093, mean_q: 362.608073, mean_eps: 0.690970
 103153/300000: episode: 1030, duration: 0.651s, episode steps:  91, steps per second: 140, episode reward: -63.180, mean reward: -0.694 [-100.000, 15.605], mean action: 1.681 [0.000, 3.000],  loss: 371.853206, mae: 266.224018, mean_q: 358.778374, mean_eps: 0.690679
 103250/300000: episode: 1031, duration: 0.683s, episode steps:  97, steps per second: 142, episode reward: -254.187, mean reward: -2.620 [-100.000,  5.056], mean action: 1.495 [0.000, 3.000],  loss: 253.176861, mae: 264.621220, mean_q: 356.324717, mean_eps: 0.690397
 103313/300000: episode: 1032, duration: 0.442s, episode steps:  63, steps per second: 142, episode reward: -74.428, mean reward: -1.181 [-100.000, 11.464], mean action: 1.730 [0.000, 3.000],  loss: 280.411870, mae: 260.805674, mean_q: 350.203793, mean_eps: 0.690157
 103395/300000: episode: 1033, duration: 0.586s, episode steps:  82, steps per second: 140, episode reward: -53.676, mean reward: -0.655 [-100.000, 57.891], mean action: 1.695 [0.000, 3.000],  loss: 352.977222, mae: 269.159124, mean_q: 362.301290, mean_eps: 0.689940
 103497/300000: episode: 1034, duration: 0.703s, episode steps: 102, steps per second: 145, episode reward: -66.300, mean reward: -0.650 [-100.000, 12.304], mean action: 1.520 [0.000, 3.000],  loss: 276.500432, mae: 269.625187, mean_q: 362.996140, mean_eps: 0.689664
 103600/300000: episode: 1035, duration: 0.700s, episode steps: 103, steps per second: 147, episode reward: -168.290, mean reward: -1.634 [-100.000,  2.633], mean action: 1.786 [0.000, 3.000],  loss: 498.471664, mae: 262.102221, mean_q: 351.550785, mean_eps: 0.689356
 103699/300000: episode: 1036, duration: 0.678s, episode steps:  99, steps per second: 146, episode reward: -72.148, mean reward: -0.729 [-100.000, 19.518], mean action: 1.636 [0.000, 3.000],  loss: 306.452707, mae: 262.299952, mean_q: 352.559309, mean_eps: 0.689053
 103820/300000: episode: 1037, duration: 0.765s, episode steps: 121, steps per second: 158, episode reward: -143.630, mean reward: -1.187 [-100.000,  7.623], mean action: 1.686 [0.000, 3.000],  loss: 391.035358, mae: 263.264691, mean_q: 354.115754, mean_eps: 0.688723
 103927/300000: episode: 1038, duration: 0.690s, episode steps: 107, steps per second: 155, episode reward: -115.899, mean reward: -1.083 [-100.000, 11.229], mean action: 1.654 [0.000, 3.000],  loss: 397.153668, mae: 261.009064, mean_q: 349.790827, mean_eps: 0.688381
 104102/300000: episode: 1039, duration: 1.156s, episode steps: 175, steps per second: 151, episode reward: -229.862, mean reward: -1.313 [-100.000, 69.783], mean action: 1.714 [0.000, 3.000],  loss: 379.994563, mae: 265.213756, mean_q: 355.738527, mean_eps: 0.687958
 104209/300000: episode: 1040, duration: 0.682s, episode steps: 107, steps per second: 157, episode reward: -181.570, mean reward: -1.697 [-100.000,  7.435], mean action: 1.664 [0.000, 3.000],  loss: 279.138386, mae: 260.016061, mean_q: 348.588128, mean_eps: 0.687535
 104283/300000: episode: 1041, duration: 0.475s, episode steps:  74, steps per second: 156, episode reward: -72.212, mean reward: -0.976 [-100.000, 10.092], mean action: 1.743 [0.000, 3.000],  loss: 230.714845, mae: 263.002325, mean_q: 352.239282, mean_eps: 0.687263
 104386/300000: episode: 1042, duration: 0.697s, episode steps: 103, steps per second: 148, episode reward: 16.605, mean reward:  0.161 [-100.000, 67.850], mean action: 1.602 [0.000, 3.000],  loss: 348.663603, mae: 259.971353, mean_q: 348.404926, mean_eps: 0.686998
 104515/300000: episode: 1043, duration: 0.820s, episode steps: 129, steps per second: 157, episode reward: -223.473, mean reward: -1.732 [-100.000, 10.929], mean action: 1.612 [0.000, 3.000],  loss: 335.003272, mae: 266.596754, mean_q: 357.760067, mean_eps: 0.686650
 104611/300000: episode: 1044, duration: 0.614s, episode steps:  96, steps per second: 156, episode reward: -113.327, mean reward: -1.180 [-100.000, 45.469], mean action: 1.760 [0.000, 3.000],  loss: 308.115801, mae: 266.721541, mean_q: 356.652489, mean_eps: 0.686312
 104703/300000: episode: 1045, duration: 0.615s, episode steps:  92, steps per second: 150, episode reward: -58.193, mean reward: -0.633 [-100.000, 14.573], mean action: 1.652 [0.000, 3.000],  loss: 373.040682, mae: 261.450976, mean_q: 349.613206, mean_eps: 0.686030
 104833/300000: episode: 1046, duration: 0.831s, episode steps: 130, steps per second: 156, episode reward: -70.375, mean reward: -0.541 [-100.000,  7.245], mean action: 1.462 [0.000, 3.000],  loss: 318.925579, mae: 259.311292, mean_q: 346.718744, mean_eps: 0.685697
 104928/300000: episode: 1047, duration: 0.611s, episode steps:  95, steps per second: 155, episode reward: -82.865, mean reward: -0.872 [-100.000, 21.789], mean action: 1.611 [0.000, 3.000],  loss: 238.651634, mae: 259.705443, mean_q: 349.288669, mean_eps: 0.685360
 105058/300000: episode: 1048, duration: 0.887s, episode steps: 130, steps per second: 147, episode reward: -66.017, mean reward: -0.508 [-100.000,  8.848], mean action: 1.638 [0.000, 3.000],  loss: 433.326719, mae: 259.474059, mean_q: 349.524635, mean_eps: 0.685022
 105128/300000: episode: 1049, duration: 0.461s, episode steps:  70, steps per second: 152, episode reward: -11.465, mean reward: -0.164 [-100.000, 38.149], mean action: 1.771 [0.000, 3.000],  loss: 458.482777, mae: 262.977457, mean_q: 354.109666, mean_eps: 0.684723
 105201/300000: episode: 1050, duration: 0.470s, episode steps:  73, steps per second: 155, episode reward: -18.250, mean reward: -0.250 [-100.000, 13.248], mean action: 1.836 [0.000, 3.000],  loss: 411.496998, mae: 265.963137, mean_q: 359.195641, mean_eps: 0.684508
 105272/300000: episode: 1051, duration: 0.451s, episode steps:  71, steps per second: 157, episode reward: -93.878, mean reward: -1.322 [-100.000, 10.055], mean action: 1.732 [0.000, 3.000],  loss: 397.094061, mae: 261.134700, mean_q: 352.259344, mean_eps: 0.684292
 105396/300000: episode: 1052, duration: 0.837s, episode steps: 124, steps per second: 148, episode reward: -254.887, mean reward: -2.056 [-100.000, 14.529], mean action: 1.750 [0.000, 3.000],  loss: 311.300743, mae: 262.882311, mean_q: 353.636318, mean_eps: 0.683999
 105529/300000: episode: 1053, duration: 0.849s, episode steps: 133, steps per second: 157, episode reward: -207.078, mean reward: -1.557 [-100.000,  7.200], mean action: 1.579 [0.000, 3.000],  loss: 334.804630, mae: 264.391767, mean_q: 355.395124, mean_eps: 0.683614
 105624/300000: episode: 1054, duration: 0.613s, episode steps:  95, steps per second: 155, episode reward: -21.751, mean reward: -0.229 [-100.000, 11.184], mean action: 1.821 [0.000, 3.000],  loss: 253.598234, mae: 263.000884, mean_q: 354.325510, mean_eps: 0.683272
 105699/300000: episode: 1055, duration: 0.513s, episode steps:  75, steps per second: 146, episode reward: -75.427, mean reward: -1.006 [-100.000, 15.883], mean action: 1.347 [0.000, 3.000],  loss: 252.627448, mae: 267.538393, mean_q: 360.534576, mean_eps: 0.683017
 105788/300000: episode: 1056, duration: 0.576s, episode steps:  89, steps per second: 154, episode reward: -51.714, mean reward: -0.581 [-100.000,  8.051], mean action: 1.764 [0.000, 3.000],  loss: 429.377867, mae: 265.541626, mean_q: 358.654455, mean_eps: 0.682771
 105895/300000: episode: 1057, duration: 0.722s, episode steps: 107, steps per second: 148, episode reward: -78.711, mean reward: -0.736 [-100.000, 18.349], mean action: 1.888 [0.000, 3.000],  loss: 449.573968, mae: 270.883704, mean_q: 365.194687, mean_eps: 0.682477
 106034/300000: episode: 1058, duration: 0.932s, episode steps: 139, steps per second: 149, episode reward: -127.921, mean reward: -0.920 [-100.000, 12.986], mean action: 1.676 [0.000, 3.000],  loss: 342.993371, mae: 266.267069, mean_q: 358.935145, mean_eps: 0.682108
 106117/300000: episode: 1059, duration: 0.534s, episode steps:  83, steps per second: 156, episode reward: -28.193, mean reward: -0.340 [-100.000,  7.197], mean action: 1.602 [0.000, 3.000],  loss: 465.844039, mae: 266.229396, mean_q: 358.147409, mean_eps: 0.681775
 106230/300000: episode: 1060, duration: 0.701s, episode steps: 113, steps per second: 161, episode reward: -90.749, mean reward: -0.803 [-100.000, 12.432], mean action: 1.283 [0.000, 3.000],  loss: 362.549125, mae: 259.739798, mean_q: 349.292023, mean_eps: 0.681481
 106336/300000: episode: 1061, duration: 0.704s, episode steps: 106, steps per second: 151, episode reward: -81.208, mean reward: -0.766 [-100.000, 18.102], mean action: 1.415 [0.000, 3.000],  loss: 218.704216, mae: 257.002922, mean_q: 345.390381, mean_eps: 0.681152
 106455/300000: episode: 1062, duration: 0.772s, episode steps: 119, steps per second: 154, episode reward: -116.887, mean reward: -0.982 [-100.000,  6.109], mean action: 1.622 [0.000, 3.000],  loss: 280.850296, mae: 251.679718, mean_q: 338.672488, mean_eps: 0.680815
 106569/300000: episode: 1063, duration: 0.722s, episode steps: 114, steps per second: 158, episode reward: -108.569, mean reward: -0.952 [-100.000, 11.871], mean action: 1.675 [0.000, 3.000],  loss: 236.205547, mae: 247.655309, mean_q: 333.374462, mean_eps: 0.680465
 106659/300000: episode: 1064, duration: 0.635s, episode steps:  90, steps per second: 142, episode reward: -113.117, mean reward: -1.257 [-100.000, 23.471], mean action: 1.444 [0.000, 3.000],  loss: 241.631759, mae: 246.586707, mean_q: 331.013270, mean_eps: 0.680159
 106759/300000: episode: 1065, duration: 0.658s, episode steps: 100, steps per second: 152, episode reward: -135.797, mean reward: -1.358 [-100.000,  7.841], mean action: 1.590 [0.000, 3.000],  loss: 145.122394, mae: 251.106440, mean_q: 338.814721, mean_eps: 0.679874
 106860/300000: episode: 1066, duration: 0.649s, episode steps: 101, steps per second: 156, episode reward: -98.118, mean reward: -0.971 [-100.000,  7.397], mean action: 1.574 [0.000, 3.000],  loss: 215.917013, mae: 248.167137, mean_q: 334.318927, mean_eps: 0.679573
 106953/300000: episode: 1067, duration: 0.621s, episode steps:  93, steps per second: 150, episode reward: -298.328, mean reward: -3.208 [-100.000, 53.460], mean action: 1.720 [0.000, 3.000],  loss: 258.336946, mae: 249.865763, mean_q: 337.037129, mean_eps: 0.679282
 107032/300000: episode: 1068, duration: 0.526s, episode steps:  79, steps per second: 150, episode reward: -81.938, mean reward: -1.037 [-100.000, 19.778], mean action: 1.468 [0.000, 3.000],  loss: 160.734911, mae: 250.581260, mean_q: 337.120243, mean_eps: 0.679024
 107111/300000: episode: 1069, duration: 0.514s, episode steps:  79, steps per second: 154, episode reward: -56.504, mean reward: -0.715 [-100.000, 10.781], mean action: 1.557 [0.000, 3.000],  loss: 181.758362, mae: 248.810801, mean_q: 333.438346, mean_eps: 0.678787
 107228/300000: episode: 1070, duration: 0.746s, episode steps: 117, steps per second: 157, episode reward: -81.932, mean reward: -0.700 [-100.000,  7.534], mean action: 1.547 [0.000, 3.000],  loss: 142.220718, mae: 249.983347, mean_q: 336.652458, mean_eps: 0.678493
 107324/300000: episode: 1071, duration: 0.652s, episode steps:  96, steps per second: 147, episode reward: -50.235, mean reward: -0.523 [-100.000, 18.382], mean action: 1.510 [0.000, 3.000],  loss: 213.879189, mae: 252.187356, mean_q: 339.205002, mean_eps: 0.678174
 107418/300000: episode: 1072, duration: 0.611s, episode steps:  94, steps per second: 154, episode reward: -203.918, mean reward: -2.169 [-100.000,  6.203], mean action: 1.436 [0.000, 3.000],  loss: 216.431580, mae: 247.978079, mean_q: 332.339820, mean_eps: 0.677888
 107528/300000: episode: 1073, duration: 0.704s, episode steps: 110, steps per second: 156, episode reward: -99.501, mean reward: -0.905 [-100.000,  8.656], mean action: 1.855 [0.000, 3.000],  loss: 254.286988, mae: 249.949232, mean_q: 335.253055, mean_eps: 0.677583
 107672/300000: episode: 1074, duration: 0.964s, episode steps: 144, steps per second: 149, episode reward: -26.387, mean reward: -0.183 [-100.000, 130.889], mean action: 1.542 [0.000, 3.000],  loss: 245.707499, mae: 248.218867, mean_q: 332.301108, mean_eps: 0.677202
 107771/300000: episode: 1075, duration: 0.631s, episode steps:  99, steps per second: 157, episode reward: -105.001, mean reward: -1.061 [-100.000,  9.662], mean action: 1.576 [0.000, 3.000],  loss: 265.095542, mae: 247.555033, mean_q: 331.727321, mean_eps: 0.676837
 107857/300000: episode: 1076, duration: 0.546s, episode steps:  86, steps per second: 158, episode reward: -86.333, mean reward: -1.004 [-100.000,  6.792], mean action: 1.512 [0.000, 3.000],  loss: 236.411058, mae: 244.806025, mean_q: 328.338947, mean_eps: 0.676559
 107981/300000: episode: 1077, duration: 0.835s, episode steps: 124, steps per second: 149, episode reward: -60.623, mean reward: -0.489 [-100.000, 22.511], mean action: 1.718 [0.000, 3.000],  loss: 317.614758, mae: 253.555550, mean_q: 339.948838, mean_eps: 0.676245
 108074/300000: episode: 1078, duration: 0.635s, episode steps:  93, steps per second: 146, episode reward: -110.657, mean reward: -1.190 [-100.000,  9.131], mean action: 1.731 [0.000, 3.000],  loss: 314.277602, mae: 252.152636, mean_q: 336.821203, mean_eps: 0.675919
 108178/300000: episode: 1079, duration: 0.696s, episode steps: 104, steps per second: 149, episode reward: -238.811, mean reward: -2.296 [-100.000,  0.890], mean action: 1.288 [0.000, 3.000],  loss: 326.764124, mae: 254.168877, mean_q: 340.121623, mean_eps: 0.675623
 108270/300000: episode: 1080, duration: 0.626s, episode steps:  92, steps per second: 147, episode reward: -86.996, mean reward: -0.946 [-100.000,  7.293], mean action: 1.772 [0.000, 3.000],  loss: 312.443036, mae: 257.647307, mean_q: 346.035033, mean_eps: 0.675330
 108387/300000: episode: 1081, duration: 0.752s, episode steps: 117, steps per second: 156, episode reward: -108.455, mean reward: -0.927 [-100.000,  6.590], mean action: 1.632 [0.000, 3.000],  loss: 266.482135, mae: 256.709346, mean_q: 345.073096, mean_eps: 0.675016
 108459/300000: episode: 1082, duration: 0.450s, episode steps:  72, steps per second: 160, episode reward: -76.664, mean reward: -1.065 [-100.000,  8.720], mean action: 1.681 [0.000, 3.000],  loss: 227.446879, mae: 255.213939, mean_q: 341.883699, mean_eps: 0.674733
 108563/300000: episode: 1083, duration: 0.657s, episode steps: 104, steps per second: 158, episode reward: -48.903, mean reward: -0.470 [-100.000, 12.177], mean action: 1.769 [0.000, 3.000],  loss: 316.685873, mae: 253.779249, mean_q: 340.330060, mean_eps: 0.674468
 108650/300000: episode: 1084, duration: 0.590s, episode steps:  87, steps per second: 147, episode reward: -97.363, mean reward: -1.119 [-100.000,  9.871], mean action: 1.552 [0.000, 3.000],  loss: 272.226714, mae: 252.214253, mean_q: 339.238944, mean_eps: 0.674182
 108756/300000: episode: 1085, duration: 0.675s, episode steps: 106, steps per second: 157, episode reward: -57.862, mean reward: -0.546 [-100.000, 14.919], mean action: 1.575 [0.000, 3.000],  loss: 290.492973, mae: 254.232475, mean_q: 340.520967, mean_eps: 0.673893
 108861/300000: episode: 1086, duration: 0.675s, episode steps: 105, steps per second: 156, episode reward: -193.820, mean reward: -1.846 [-100.000,  6.674], mean action: 1.486 [0.000, 3.000],  loss: 280.805122, mae: 250.350158, mean_q: 335.687286, mean_eps: 0.673576
 108938/300000: episode: 1087, duration: 0.546s, episode steps:  77, steps per second: 141, episode reward: -96.937, mean reward: -1.259 [-100.000,  8.184], mean action: 1.688 [0.000, 3.000],  loss: 198.746443, mae: 251.960228, mean_q: 338.384533, mean_eps: 0.673303
 109060/300000: episode: 1088, duration: 0.986s, episode steps: 122, steps per second: 124, episode reward: -78.413, mean reward: -0.643 [-100.000, 12.958], mean action: 1.508 [0.000, 3.000],  loss: 259.490791, mae: 250.859182, mean_q: 335.496374, mean_eps: 0.673004
 109162/300000: episode: 1089, duration: 0.786s, episode steps: 102, steps per second: 130, episode reward: -256.470, mean reward: -2.514 [-100.000,  7.211], mean action: 1.245 [0.000, 3.000],  loss: 151.986138, mae: 249.276199, mean_q: 332.883391, mean_eps: 0.672669
 109283/300000: episode: 1090, duration: 0.922s, episode steps: 121, steps per second: 131, episode reward: -79.437, mean reward: -0.657 [-100.000, 17.019], mean action: 1.612 [0.000, 3.000],  loss: 220.836779, mae: 249.655086, mean_q: 334.013133, mean_eps: 0.672334
 109351/300000: episode: 1091, duration: 0.547s, episode steps:  68, steps per second: 124, episode reward: -34.251, mean reward: -0.504 [-100.000,  6.692], mean action: 1.882 [0.000, 3.000],  loss: 245.656860, mae: 252.370141, mean_q: 337.324266, mean_eps: 0.672051
 109435/300000: episode: 1092, duration: 0.606s, episode steps:  84, steps per second: 139, episode reward: -57.552, mean reward: -0.685 [-100.000, 12.955], mean action: 1.774 [0.000, 3.000],  loss: 248.312344, mae: 250.391699, mean_q: 335.368180, mean_eps: 0.671822
 109523/300000: episode: 1093, duration: 0.678s, episode steps:  88, steps per second: 130, episode reward: -20.337, mean reward: -0.231 [-100.000, 11.301], mean action: 1.545 [0.000, 3.000],  loss: 166.338801, mae: 248.718650, mean_q: 332.562721, mean_eps: 0.671565
 109902/300000: episode: 1094, duration: 2.654s, episode steps: 379, steps per second: 143, episode reward: -266.272, mean reward: -0.703 [-100.000, 51.289], mean action: 1.588 [0.000, 3.000],  loss: 223.661622, mae: 247.757221, mean_q: 330.709495, mean_eps: 0.670864
 110029/300000: episode: 1095, duration: 0.797s, episode steps: 127, steps per second: 159, episode reward: -84.639, mean reward: -0.666 [-100.000, 24.229], mean action: 1.606 [0.000, 3.000],  loss: 286.877985, mae: 252.329987, mean_q: 336.966372, mean_eps: 0.670105
 110094/300000: episode: 1096, duration: 0.428s, episode steps:  65, steps per second: 152, episode reward: -85.783, mean reward: -1.320 [-100.000, 10.305], mean action: 1.338 [0.000, 3.000],  loss: 307.787516, mae: 250.762571, mean_q: 335.118075, mean_eps: 0.669817
 110222/300000: episode: 1097, duration: 0.923s, episode steps: 128, steps per second: 139, episode reward: -53.123, mean reward: -0.415 [-100.000, 13.814], mean action: 1.633 [0.000, 3.000],  loss: 358.444880, mae: 251.415801, mean_q: 336.871207, mean_eps: 0.669528
 110309/300000: episode: 1098, duration: 0.569s, episode steps:  87, steps per second: 153, episode reward: -17.022, mean reward: -0.196 [-100.000, 28.317], mean action: 1.839 [0.000, 3.000],  loss: 196.187925, mae: 255.470714, mean_q: 343.170884, mean_eps: 0.669205
 110414/300000: episode: 1099, duration: 0.675s, episode steps: 105, steps per second: 156, episode reward: -117.923, mean reward: -1.123 [-100.000, 10.897], mean action: 1.533 [0.000, 3.000],  loss: 370.609301, mae: 252.064169, mean_q: 337.429245, mean_eps: 0.668917
 110550/300000: episode: 1100, duration: 0.918s, episode steps: 136, steps per second: 148, episode reward: -40.435, mean reward: -0.297 [-100.000, 48.235], mean action: 1.507 [0.000, 3.000],  loss: 515.301014, mae: 250.756997, mean_q: 334.998654, mean_eps: 0.668556
 110681/300000: episode: 1101, duration: 0.831s, episode steps: 131, steps per second: 158, episode reward: -152.026, mean reward: -1.161 [-100.000,  4.409], mean action: 1.702 [0.000, 3.000],  loss: 318.760848, mae: 248.931552, mean_q: 333.827060, mean_eps: 0.668155
 110779/300000: episode: 1102, duration: 0.659s, episode steps:  98, steps per second: 149, episode reward: -126.176, mean reward: -1.288 [-100.000,  8.949], mean action: 1.663 [0.000, 3.000],  loss: 231.726282, mae: 250.676727, mean_q: 336.052579, mean_eps: 0.667812
 110878/300000: episode: 1103, duration: 0.677s, episode steps:  99, steps per second: 146, episode reward: -31.193, mean reward: -0.315 [-100.000, 19.332], mean action: 1.707 [0.000, 3.000],  loss: 263.793805, mae: 250.595262, mean_q: 334.800298, mean_eps: 0.667516
 111001/300000: episode: 1104, duration: 0.783s, episode steps: 123, steps per second: 157, episode reward: -188.043, mean reward: -1.529 [-100.000,  4.275], mean action: 1.732 [0.000, 3.000],  loss: 237.577997, mae: 248.658216, mean_q: 332.708524, mean_eps: 0.667183
 111106/300000: episode: 1105, duration: 0.710s, episode steps: 105, steps per second: 148, episode reward: -101.385, mean reward: -0.966 [-100.000, 10.371], mean action: 1.629 [0.000, 3.000],  loss: 353.463407, mae: 250.768040, mean_q: 336.033058, mean_eps: 0.666841
 111194/300000: episode: 1106, duration: 0.581s, episode steps:  88, steps per second: 151, episode reward: -76.771, mean reward: -0.872 [-100.000,  7.421], mean action: 1.591 [0.000, 3.000],  loss: 263.697156, mae: 247.850877, mean_q: 331.155763, mean_eps: 0.666551
 111279/300000: episode: 1107, duration: 0.546s, episode steps:  85, steps per second: 156, episode reward: -47.168, mean reward: -0.555 [-100.000, 17.045], mean action: 1.741 [0.000, 3.000],  loss: 219.967640, mae: 249.206190, mean_q: 333.085813, mean_eps: 0.666292
 111365/300000: episode: 1108, duration: 0.547s, episode steps:  86, steps per second: 157, episode reward: -78.276, mean reward: -0.910 [-100.000,  8.892], mean action: 1.558 [0.000, 3.000],  loss: 243.825276, mae: 245.217387, mean_q: 327.587717, mean_eps: 0.666036
 111480/300000: episode: 1109, duration: 0.802s, episode steps: 115, steps per second: 143, episode reward: -3.236, mean reward: -0.028 [-100.000, 37.109], mean action: 1.774 [0.000, 3.000],  loss: 285.362860, mae: 251.825308, mean_q: 336.856155, mean_eps: 0.665734
 111567/300000: episode: 1110, duration: 0.576s, episode steps:  87, steps per second: 151, episode reward: -113.116, mean reward: -1.300 [-100.000, 54.257], mean action: 1.609 [0.000, 3.000],  loss: 184.530286, mae: 250.138519, mean_q: 335.853410, mean_eps: 0.665431
 111672/300000: episode: 1111, duration: 0.671s, episode steps: 105, steps per second: 157, episode reward: -61.382, mean reward: -0.585 [-100.000, 10.346], mean action: 1.505 [0.000, 3.000],  loss: 202.853774, mae: 255.141743, mean_q: 342.258502, mean_eps: 0.665143
 111788/300000: episode: 1112, duration: 0.763s, episode steps: 116, steps per second: 152, episode reward: -100.424, mean reward: -0.866 [-100.000, 11.441], mean action: 1.724 [0.000, 3.000],  loss: 261.663178, mae: 250.521873, mean_q: 336.495846, mean_eps: 0.664811
 111894/300000: episode: 1113, duration: 0.696s, episode steps: 106, steps per second: 152, episode reward: -335.985, mean reward: -3.170 [-100.000,  4.641], mean action: 1.821 [0.000, 3.000],  loss: 258.817320, mae: 249.647380, mean_q: 333.730713, mean_eps: 0.664478
 111971/300000: episode: 1114, duration: 0.491s, episode steps:  77, steps per second: 157, episode reward: -49.241, mean reward: -0.639 [-100.000,  8.685], mean action: 1.766 [0.000, 3.000],  loss: 273.568025, mae: 251.313488, mean_q: 336.754700, mean_eps: 0.664204
 112039/300000: episode: 1115, duration: 0.423s, episode steps:  68, steps per second: 161, episode reward: -50.264, mean reward: -0.739 [-100.000,  5.996], mean action: 1.500 [0.000, 3.000],  loss: 363.186779, mae: 252.930172, mean_q: 338.329249, mean_eps: 0.663986
 112129/300000: episode: 1116, duration: 0.633s, episode steps:  90, steps per second: 142, episode reward: -92.177, mean reward: -1.024 [-100.000,  8.341], mean action: 1.756 [0.000, 3.000],  loss: 170.719463, mae: 253.634235, mean_q: 340.553337, mean_eps: 0.663749
 112244/300000: episode: 1117, duration: 0.750s, episode steps: 115, steps per second: 153, episode reward: -91.828, mean reward: -0.799 [-100.000, 12.479], mean action: 1.835 [0.000, 3.000],  loss: 295.023150, mae: 255.989520, mean_q: 343.482901, mean_eps: 0.663442
 112337/300000: episode: 1118, duration: 0.584s, episode steps:  93, steps per second: 159, episode reward: -90.453, mean reward: -0.973 [-100.000, 15.216], mean action: 1.613 [0.000, 3.000],  loss: 256.219267, mae: 254.130567, mean_q: 342.311382, mean_eps: 0.663130
 112451/300000: episode: 1119, duration: 0.742s, episode steps: 114, steps per second: 154, episode reward: -67.985, mean reward: -0.596 [-100.000,  8.043], mean action: 1.588 [0.000, 3.000],  loss: 221.656116, mae: 251.874741, mean_q: 339.017795, mean_eps: 0.662820
 112595/300000: episode: 1120, duration: 0.937s, episode steps: 144, steps per second: 154, episode reward: -82.982, mean reward: -0.576 [-100.000,  9.512], mean action: 1.639 [0.000, 3.000],  loss: 276.582367, mae: 250.811516, mean_q: 337.510458, mean_eps: 0.662432
 112700/300000: episode: 1121, duration: 0.783s, episode steps: 105, steps per second: 134, episode reward: -168.265, mean reward: -1.603 [-100.000,  3.666], mean action: 1.695 [0.000, 3.000],  loss: 347.874002, mae: 257.648185, mean_q: 348.177664, mean_eps: 0.662059
 112831/300000: episode: 1122, duration: 1.000s, episode steps: 131, steps per second: 131, episode reward: -117.358, mean reward: -0.896 [-100.000,  7.082], mean action: 1.695 [0.000, 3.000],  loss: 287.194910, mae: 250.098294, mean_q: 337.803422, mean_eps: 0.661705
 112906/300000: episode: 1123, duration: 0.532s, episode steps:  75, steps per second: 141, episode reward: -71.299, mean reward: -0.951 [-100.000,  8.662], mean action: 1.653 [0.000, 3.000],  loss: 346.106282, mae: 250.390097, mean_q: 337.246437, mean_eps: 0.661396
 112989/300000: episode: 1124, duration: 0.581s, episode steps:  83, steps per second: 143, episode reward: -76.997, mean reward: -0.928 [-100.000, 13.057], mean action: 1.639 [0.000, 3.000],  loss: 292.711780, mae: 258.198478, mean_q: 348.156628, mean_eps: 0.661159
 113060/300000: episode: 1125, duration: 0.560s, episode steps:  71, steps per second: 127, episode reward: -75.640, mean reward: -1.065 [-100.000, 12.300], mean action: 1.465 [0.000, 3.000],  loss: 389.850326, mae: 255.198991, mean_q: 342.570148, mean_eps: 0.660928
 113132/300000: episode: 1126, duration: 0.521s, episode steps:  72, steps per second: 138, episode reward: -38.827, mean reward: -0.539 [-100.000, 13.052], mean action: 1.625 [0.000, 3.000],  loss: 371.429729, mae: 252.049923, mean_q: 339.693611, mean_eps: 0.660713
 113236/300000: episode: 1127, duration: 0.722s, episode steps: 104, steps per second: 144, episode reward: -44.788, mean reward: -0.431 [-100.000, 11.274], mean action: 1.596 [0.000, 3.000],  loss: 240.908168, mae: 253.446423, mean_q: 341.746792, mean_eps: 0.660449
 113311/300000: episode: 1128, duration: 0.523s, episode steps:  75, steps per second: 143, episode reward: -116.691, mean reward: -1.556 [-100.000,  7.634], mean action: 1.680 [0.000, 3.000],  loss: 368.261564, mae: 253.349147, mean_q: 340.672830, mean_eps: 0.660181
 113459/300000: episode: 1129, duration: 0.984s, episode steps: 148, steps per second: 150, episode reward: -75.158, mean reward: -0.508 [-100.000,  8.625], mean action: 1.635 [0.000, 3.000],  loss: 300.466059, mae: 253.579095, mean_q: 340.782286, mean_eps: 0.659847
 113571/300000: episode: 1130, duration: 0.731s, episode steps: 112, steps per second: 153, episode reward: -336.009, mean reward: -3.000 [-100.000, 16.311], mean action: 1.652 [0.000, 3.000],  loss: 249.147022, mae: 255.046798, mean_q: 342.887784, mean_eps: 0.659457
 113703/300000: episode: 1131, duration: 0.881s, episode steps: 132, steps per second: 150, episode reward: -68.581, mean reward: -0.520 [-100.000,  6.739], mean action: 1.606 [0.000, 3.000],  loss: 260.328087, mae: 260.214874, mean_q: 348.900561, mean_eps: 0.659090
 113782/300000: episode: 1132, duration: 0.496s, episode steps:  79, steps per second: 159, episode reward: -124.827, mean reward: -1.580 [-100.000, 11.357], mean action: 1.532 [0.000, 3.000],  loss: 351.641254, mae: 257.483564, mean_q: 344.922699, mean_eps: 0.658774
 113935/300000: episode: 1133, duration: 0.986s, episode steps: 153, steps per second: 155, episode reward: -79.064, mean reward: -0.517 [-100.000, 68.650], mean action: 1.471 [0.000, 3.000],  loss: 272.409973, mae: 261.547641, mean_q: 350.950906, mean_eps: 0.658426
 114011/300000: episode: 1134, duration: 0.520s, episode steps:  76, steps per second: 146, episode reward: -83.621, mean reward: -1.100 [-100.000,  5.764], mean action: 1.908 [0.000, 3.000],  loss: 270.632661, mae: 261.852963, mean_q: 352.402885, mean_eps: 0.658082
 114100/300000: episode: 1135, duration: 0.593s, episode steps:  89, steps per second: 150, episode reward: -56.641, mean reward: -0.636 [-100.000,  9.593], mean action: 1.652 [0.000, 3.000],  loss: 234.366296, mae: 260.393265, mean_q: 348.255161, mean_eps: 0.657835
 114192/300000: episode: 1136, duration: 0.580s, episode steps:  92, steps per second: 159, episode reward: -88.092, mean reward: -0.958 [-100.000,  5.559], mean action: 1.587 [0.000, 3.000],  loss: 282.176490, mae: 264.802869, mean_q: 355.742918, mean_eps: 0.657563
 114288/300000: episode: 1137, duration: 0.611s, episode steps:  96, steps per second: 157, episode reward: -109.452, mean reward: -1.140 [-100.000, 10.242], mean action: 1.417 [0.000, 3.000],  loss: 372.818030, mae: 261.076686, mean_q: 350.170232, mean_eps: 0.657281
 114373/300000: episode: 1138, duration: 0.594s, episode steps:  85, steps per second: 143, episode reward: -68.196, mean reward: -0.802 [-100.000, 11.292], mean action: 1.600 [0.000, 3.000],  loss: 296.766839, mae: 262.850261, mean_q: 352.858226, mean_eps: 0.657010
 114450/300000: episode: 1139, duration: 0.500s, episode steps:  77, steps per second: 154, episode reward: -75.339, mean reward: -0.978 [-100.000,  5.669], mean action: 1.351 [0.000, 3.000],  loss: 352.526200, mae: 261.201044, mean_q: 350.312069, mean_eps: 0.656767
 114582/300000: episode: 1140, duration: 0.821s, episode steps: 132, steps per second: 161, episode reward: -333.890, mean reward: -2.529 [-100.000, 110.586], mean action: 1.561 [0.000, 3.000],  loss: 275.343511, mae: 261.154810, mean_q: 350.871761, mean_eps: 0.656453
 114710/300000: episode: 1141, duration: 0.895s, episode steps: 128, steps per second: 143, episode reward: -71.714, mean reward: -0.560 [-100.000, 16.345], mean action: 1.672 [0.000, 3.000],  loss: 206.924068, mae: 259.321903, mean_q: 345.984466, mean_eps: 0.656064
 114812/300000: episode: 1142, duration: 0.672s, episode steps: 102, steps per second: 152, episode reward: -127.433, mean reward: -1.249 [-100.000,  8.741], mean action: 1.598 [0.000, 3.000],  loss: 171.824339, mae: 262.592708, mean_q: 352.258274, mean_eps: 0.655719
 114888/300000: episode: 1143, duration: 0.494s, episode steps:  76, steps per second: 154, episode reward: -45.907, mean reward: -0.604 [-100.000, 12.858], mean action: 1.868 [0.000, 3.000],  loss: 227.789628, mae: 261.903437, mean_q: 351.039247, mean_eps: 0.655451
 115001/300000: episode: 1144, duration: 0.747s, episode steps: 113, steps per second: 151, episode reward: -152.658, mean reward: -1.351 [-100.000, 100.474], mean action: 1.602 [0.000, 3.000],  loss: 235.121566, mae: 265.991397, mean_q: 356.171001, mean_eps: 0.655168
 115121/300000: episode: 1145, duration: 0.779s, episode steps: 120, steps per second: 154, episode reward: -2.735, mean reward: -0.023 [-100.000, 16.261], mean action: 1.700 [0.000, 3.000],  loss: 324.389912, mae: 266.157166, mean_q: 357.424952, mean_eps: 0.654818
 115222/300000: episode: 1146, duration: 0.644s, episode steps: 101, steps per second: 157, episode reward: -131.770, mean reward: -1.305 [-100.000, 13.403], mean action: 1.634 [0.000, 3.000],  loss: 244.078997, mae: 266.910651, mean_q: 360.225765, mean_eps: 0.654487
 115324/300000: episode: 1147, duration: 0.669s, episode steps: 102, steps per second: 152, episode reward: -79.680, mean reward: -0.781 [-100.000, 10.843], mean action: 1.500 [0.000, 3.000],  loss: 275.514148, mae: 266.713451, mean_q: 360.321776, mean_eps: 0.654183
 115419/300000: episode: 1148, duration: 0.642s, episode steps:  95, steps per second: 148, episode reward: -144.155, mean reward: -1.517 [-100.000, 12.970], mean action: 1.705 [0.000, 3.000],  loss: 249.259156, mae: 270.489275, mean_q: 364.846924, mean_eps: 0.653887
 115500/300000: episode: 1149, duration: 0.522s, episode steps:  81, steps per second: 155, episode reward: -47.658, mean reward: -0.588 [-100.000, 20.249], mean action: 1.753 [0.000, 3.000],  loss: 211.591533, mae: 267.026059, mean_q: 360.143233, mean_eps: 0.653623
 115596/300000: episode: 1150, duration: 0.622s, episode steps:  96, steps per second: 154, episode reward: -52.235, mean reward: -0.544 [-100.000, 13.673], mean action: 1.667 [0.000, 3.000],  loss: 251.824613, mae: 267.660446, mean_q: 360.642918, mean_eps: 0.653357
 115687/300000: episode: 1151, duration: 0.625s, episode steps:  91, steps per second: 146, episode reward: -38.408, mean reward: -0.422 [-100.000,  9.798], mean action: 1.626 [0.000, 3.000],  loss: 306.600190, mae: 272.054030, mean_q: 366.642354, mean_eps: 0.653077
 115812/300000: episode: 1152, duration: 0.810s, episode steps: 125, steps per second: 154, episode reward: -134.810, mean reward: -1.078 [-100.000,  5.583], mean action: 1.744 [0.000, 3.000],  loss: 278.818420, mae: 271.450087, mean_q: 366.606845, mean_eps: 0.652753
 115949/300000: episode: 1153, duration: 0.873s, episode steps: 137, steps per second: 157, episode reward: -52.178, mean reward: -0.381 [-100.000, 10.186], mean action: 1.664 [0.000, 3.000],  loss: 337.031323, mae: 274.435892, mean_q: 371.427221, mean_eps: 0.652360
 116074/300000: episode: 1154, duration: 0.835s, episode steps: 125, steps per second: 150, episode reward: -1.152, mean reward: -0.009 [-100.000, 12.956], mean action: 1.656 [0.000, 3.000],  loss: 297.390116, mae: 274.202747, mean_q: 371.576153, mean_eps: 0.651967
 116174/300000: episode: 1155, duration: 0.641s, episode steps: 100, steps per second: 156, episode reward: -20.730, mean reward: -0.207 [-100.000, 17.061], mean action: 1.700 [0.000, 3.000],  loss: 312.069714, mae: 273.345917, mean_q: 369.502829, mean_eps: 0.651630
 116250/300000: episode: 1156, duration: 0.489s, episode steps:  76, steps per second: 155, episode reward: -81.608, mean reward: -1.074 [-100.000,  5.234], mean action: 1.434 [0.000, 3.000],  loss: 328.160920, mae: 277.433337, mean_q: 375.039187, mean_eps: 0.651365
 116327/300000: episode: 1157, duration: 0.537s, episode steps:  77, steps per second: 143, episode reward: -24.508, mean reward: -0.318 [-100.000, 11.872], mean action: 1.519 [0.000, 3.000],  loss: 335.267678, mae: 279.788773, mean_q: 379.904681, mean_eps: 0.651136
 116437/300000: episode: 1158, duration: 0.738s, episode steps: 110, steps per second: 149, episode reward: -143.173, mean reward: -1.302 [-100.000, 17.990], mean action: 1.645 [0.000, 3.000],  loss: 223.287539, mae: 279.283447, mean_q: 378.134988, mean_eps: 0.650856
 116631/300000: episode: 1159, duration: 1.268s, episode steps: 194, steps per second: 153, episode reward: -171.498, mean reward: -0.884 [-100.000, 66.508], mean action: 1.541 [0.000, 3.000],  loss: 294.292279, mae: 280.181565, mean_q: 377.737002, mean_eps: 0.650400
 116747/300000: episode: 1160, duration: 0.772s, episode steps: 116, steps per second: 150, episode reward: -59.466, mean reward: -0.513 [-100.000, 13.185], mean action: 1.724 [0.000, 3.000],  loss: 316.932832, mae: 277.117999, mean_q: 373.525932, mean_eps: 0.649935
 116827/300000: episode: 1161, duration: 0.516s, episode steps:  80, steps per second: 155, episode reward: -35.846, mean reward: -0.448 [-100.000, 18.757], mean action: 1.650 [0.000, 3.000],  loss: 286.871824, mae: 282.392064, mean_q: 380.744857, mean_eps: 0.649641
 116967/300000: episode: 1162, duration: 0.909s, episode steps: 140, steps per second: 154, episode reward: -270.544, mean reward: -1.932 [-100.000,  2.963], mean action: 1.679 [0.000, 3.000],  loss: 453.024606, mae: 280.052421, mean_q: 378.371868, mean_eps: 0.649311
 117064/300000: episode: 1163, duration: 0.635s, episode steps:  97, steps per second: 153, episode reward: -112.559, mean reward: -1.160 [-100.000, 29.373], mean action: 1.588 [0.000, 3.000],  loss: 267.922637, mae: 281.791505, mean_q: 380.865392, mean_eps: 0.648955
 117130/300000: episode: 1164, duration: 0.431s, episode steps:  66, steps per second: 153, episode reward: -46.596, mean reward: -0.706 [-100.000, 13.356], mean action: 1.848 [0.000, 3.000],  loss: 282.616209, mae: 282.065000, mean_q: 380.550483, mean_eps: 0.648710
 117211/300000: episode: 1165, duration: 0.520s, episode steps:  81, steps per second: 156, episode reward: -84.682, mean reward: -1.045 [-100.000,  6.813], mean action: 1.642 [0.000, 3.000],  loss: 200.905668, mae: 286.675342, mean_q: 385.928893, mean_eps: 0.648490
 117299/300000: episode: 1166, duration: 0.576s, episode steps:  88, steps per second: 153, episode reward: -130.444, mean reward: -1.482 [-100.000,  5.011], mean action: 1.636 [0.000, 3.000],  loss: 382.133980, mae: 293.165206, mean_q: 397.189234, mean_eps: 0.648236
 117400/300000: episode: 1167, duration: 0.657s, episode steps: 101, steps per second: 154, episode reward: -98.329, mean reward: -0.974 [-100.000, 15.816], mean action: 1.624 [0.000, 3.000],  loss: 288.769920, mae: 292.126380, mean_q: 396.419329, mean_eps: 0.647953
 117464/300000: episode: 1168, duration: 0.413s, episode steps:  64, steps per second: 155, episode reward: -15.582, mean reward: -0.243 [-100.000, 12.549], mean action: 1.469 [0.000, 3.000],  loss: 287.041773, mae: 293.225322, mean_q: 398.101280, mean_eps: 0.647706
 117579/300000: episode: 1169, duration: 0.719s, episode steps: 115, steps per second: 160, episode reward: -113.656, mean reward: -0.988 [-100.000,  9.027], mean action: 1.539 [0.000, 3.000],  loss: 264.542499, mae: 290.893142, mean_q: 394.257691, mean_eps: 0.647437
 117690/300000: episode: 1170, duration: 0.747s, episode steps: 111, steps per second: 149, episode reward: -112.976, mean reward: -1.018 [-100.000,  6.633], mean action: 1.586 [0.000, 3.000],  loss: 234.927694, mae: 294.283606, mean_q: 399.585546, mean_eps: 0.647098
 117762/300000: episode: 1171, duration: 0.464s, episode steps:  72, steps per second: 155, episode reward: -87.331, mean reward: -1.213 [-100.000,  9.335], mean action: 1.514 [0.000, 3.000],  loss: 267.667034, mae: 296.422259, mean_q: 400.617928, mean_eps: 0.646823
 117864/300000: episode: 1172, duration: 0.659s, episode steps: 102, steps per second: 155, episode reward: -159.822, mean reward: -1.567 [-100.000,  7.228], mean action: 1.657 [0.000, 3.000],  loss: 402.259458, mae: 294.460716, mean_q: 398.510731, mean_eps: 0.646563
 117967/300000: episode: 1173, duration: 0.687s, episode steps: 103, steps per second: 150, episode reward: -91.834, mean reward: -0.892 [-100.000, 19.491], mean action: 1.417 [0.000, 3.000],  loss: 335.482699, mae: 299.964249, mean_q: 406.048931, mean_eps: 0.646255
 118073/300000: episode: 1174, duration: 0.697s, episode steps: 106, steps per second: 152, episode reward: -76.733, mean reward: -0.724 [-100.000,  5.568], mean action: 1.708 [0.000, 3.000],  loss: 493.873520, mae: 303.028159, mean_q: 411.922113, mean_eps: 0.645942
 118214/300000: episode: 1175, duration: 0.904s, episode steps: 141, steps per second: 156, episode reward: -3.542, mean reward: -0.025 [-100.000, 63.195], mean action: 1.589 [0.000, 3.000],  loss: 459.777034, mae: 302.317172, mean_q: 411.590988, mean_eps: 0.645571
 118327/300000: episode: 1176, duration: 0.765s, episode steps: 113, steps per second: 148, episode reward: -128.413, mean reward: -1.136 [-100.000,  4.540], mean action: 1.619 [0.000, 3.000],  loss: 433.636488, mae: 304.058784, mean_q: 414.133606, mean_eps: 0.645190
 118437/300000: episode: 1177, duration: 0.702s, episode steps: 110, steps per second: 157, episode reward: -219.776, mean reward: -1.998 [-100.000,  5.058], mean action: 1.564 [0.000, 3.000],  loss: 873.467066, mae: 315.900892, mean_q: 431.672687, mean_eps: 0.644856
 118523/300000: episode: 1178, duration: 0.552s, episode steps:  86, steps per second: 156, episode reward: -80.460, mean reward: -0.936 [-100.000, 11.820], mean action: 1.709 [0.000, 3.000],  loss: 668.086641, mae: 316.814093, mean_q: 431.251635, mean_eps: 0.644562
 118656/300000: episode: 1179, duration: 0.904s, episode steps: 133, steps per second: 147, episode reward: -57.388, mean reward: -0.431 [-100.000, 13.098], mean action: 1.729 [0.000, 3.000],  loss: 504.016054, mae: 319.431458, mean_q: 435.427978, mean_eps: 0.644233
 118761/300000: episode: 1180, duration: 0.754s, episode steps: 105, steps per second: 139, episode reward: -68.986, mean reward: -0.657 [-100.000, 16.562], mean action: 1.486 [0.000, 3.000],  loss: 705.766262, mae: 325.372330, mean_q: 442.038773, mean_eps: 0.643876
 118867/300000: episode: 1181, duration: 0.762s, episode steps: 106, steps per second: 139, episode reward: -58.305, mean reward: -0.550 [-100.000, 10.542], mean action: 1.660 [0.000, 3.000],  loss: 363.524055, mae: 325.076592, mean_q: 442.997811, mean_eps: 0.643559
 118984/300000: episode: 1182, duration: 0.864s, episode steps: 117, steps per second: 135, episode reward: -61.057, mean reward: -0.522 [-100.000,  7.426], mean action: 1.427 [0.000, 3.000],  loss: 615.194539, mae: 330.581787, mean_q: 450.240694, mean_eps: 0.643225
 119076/300000: episode: 1183, duration: 0.625s, episode steps:  92, steps per second: 147, episode reward: -76.290, mean reward: -0.829 [-100.000, 61.836], mean action: 1.576 [0.000, 3.000],  loss: 591.846102, mae: 340.124431, mean_q: 464.223656, mean_eps: 0.642911
 119172/300000: episode: 1184, duration: 0.653s, episode steps:  96, steps per second: 147, episode reward: -138.317, mean reward: -1.441 [-100.000, 10.319], mean action: 1.625 [0.000, 3.000],  loss: 431.806226, mae: 340.935071, mean_q: 465.909025, mean_eps: 0.642629
 119243/300000: episode: 1185, duration: 0.493s, episode steps:  71, steps per second: 144, episode reward: -53.959, mean reward: -0.760 [-100.000,  6.685], mean action: 1.732 [0.000, 3.000],  loss: 606.152310, mae: 339.672453, mean_q: 464.094176, mean_eps: 0.642379
 119325/300000: episode: 1186, duration: 0.617s, episode steps:  82, steps per second: 133, episode reward: -52.811, mean reward: -0.644 [-100.000,  7.577], mean action: 1.744 [0.000, 3.000],  loss: 417.227058, mae: 341.413473, mean_q: 466.663992, mean_eps: 0.642150
 119427/300000: episode: 1187, duration: 0.688s, episode steps: 102, steps per second: 148, episode reward: -220.698, mean reward: -2.164 [-100.000,  8.075], mean action: 1.686 [0.000, 3.000],  loss: 287.448200, mae: 342.027003, mean_q: 467.980219, mean_eps: 0.641873
 119568/300000: episode: 1188, duration: 0.942s, episode steps: 141, steps per second: 150, episode reward: -167.089, mean reward: -1.185 [-100.000,  8.126], mean action: 1.546 [0.000, 3.000],  loss: 396.820354, mae: 350.375834, mean_q: 478.506856, mean_eps: 0.641509
 119667/300000: episode: 1189, duration: 0.634s, episode steps:  99, steps per second: 156, episode reward: -20.324, mean reward: -0.205 [-100.000, 16.798], mean action: 1.404 [0.000, 3.000],  loss: 328.198140, mae: 352.848664, mean_q: 481.701839, mean_eps: 0.641149
 119749/300000: episode: 1190, duration: 0.527s, episode steps:  82, steps per second: 155, episode reward: -197.816, mean reward: -2.412 [-100.000, 19.665], mean action: 1.756 [0.000, 3.000],  loss: 608.981075, mae: 352.836916, mean_q: 481.652780, mean_eps: 0.640877
 119851/300000: episode: 1191, duration: 0.707s, episode steps: 102, steps per second: 144, episode reward: -247.015, mean reward: -2.422 [-100.000,  7.565], mean action: 1.814 [0.000, 3.000],  loss: 382.826381, mae: 354.894260, mean_q: 484.323023, mean_eps: 0.640601
 119940/300000: episode: 1192, duration: 0.613s, episode steps:  89, steps per second: 145, episode reward: -85.810, mean reward: -0.964 [-100.000,  6.879], mean action: 1.506 [0.000, 3.000],  loss: 410.206870, mae: 355.737453, mean_q: 485.108479, mean_eps: 0.640315
 120005/300000: episode: 1193, duration: 0.416s, episode steps:  65, steps per second: 156, episode reward: -35.290, mean reward: -0.543 [-100.000,  8.463], mean action: 1.754 [0.000, 3.000],  loss: 488.805106, mae: 353.922698, mean_q: 484.646609, mean_eps: 0.640084
 120124/300000: episode: 1194, duration: 0.786s, episode steps: 119, steps per second: 151, episode reward: -48.983, mean reward: -0.412 [-100.000,  8.714], mean action: 1.815 [0.000, 3.000],  loss: 298.460458, mae: 356.411462, mean_q: 486.457039, mean_eps: 0.639808
 120251/300000: episode: 1195, duration: 0.876s, episode steps: 127, steps per second: 145, episode reward: -106.331, mean reward: -0.837 [-100.000, 16.493], mean action: 1.488 [0.000, 3.000],  loss: 411.454313, mae: 356.703217, mean_q: 486.963137, mean_eps: 0.639439
 120418/300000: episode: 1196, duration: 1.078s, episode steps: 167, steps per second: 155, episode reward: -227.239, mean reward: -1.361 [-100.000, 53.595], mean action: 1.653 [0.000, 3.000],  loss: 405.226877, mae: 358.907191, mean_q: 490.611178, mean_eps: 0.638998
 120543/300000: episode: 1197, duration: 0.849s, episode steps: 125, steps per second: 147, episode reward: -51.434, mean reward: -0.411 [-100.000, 13.471], mean action: 1.520 [0.000, 3.000],  loss: 446.355913, mae: 369.883303, mean_q: 505.353867, mean_eps: 0.638560
 120658/300000: episode: 1198, duration: 0.756s, episode steps: 115, steps per second: 152, episode reward: -144.133, mean reward: -1.253 [-100.000, 15.729], mean action: 1.661 [0.000, 3.000],  loss: 598.785529, mae: 377.194111, mean_q: 515.381276, mean_eps: 0.638200
 120760/300000: episode: 1199, duration: 0.649s, episode steps: 102, steps per second: 157, episode reward: -44.931, mean reward: -0.440 [-100.000, 16.538], mean action: 1.745 [0.000, 3.000],  loss: 571.501457, mae: 378.646797, mean_q: 518.685423, mean_eps: 0.637874
 120843/300000: episode: 1200, duration: 0.556s, episode steps:  83, steps per second: 149, episode reward: -24.596, mean reward: -0.296 [-100.000, 18.531], mean action: 1.747 [0.000, 3.000],  loss: 533.241809, mae: 380.228240, mean_q: 520.713871, mean_eps: 0.637597
 120937/300000: episode: 1201, duration: 0.629s, episode steps:  94, steps per second: 149, episode reward: -76.308, mean reward: -0.812 [-100.000, 13.759], mean action: 1.638 [0.000, 3.000],  loss: 763.751335, mae: 383.270876, mean_q: 524.991496, mean_eps: 0.637331
 121040/300000: episode: 1202, duration: 0.648s, episode steps: 103, steps per second: 159, episode reward: -45.498, mean reward: -0.442 [-100.000, 13.068], mean action: 1.456 [0.000, 3.000],  loss: 606.744898, mae: 386.813522, mean_q: 529.075618, mean_eps: 0.637036
 121161/300000: episode: 1203, duration: 0.771s, episode steps: 121, steps per second: 157, episode reward: -118.801, mean reward: -0.982 [-100.000,  9.292], mean action: 1.529 [0.000, 3.000],  loss: 674.656613, mae: 395.999103, mean_q: 541.556367, mean_eps: 0.636700
 121279/300000: episode: 1204, duration: 0.817s, episode steps: 118, steps per second: 144, episode reward: -217.639, mean reward: -1.844 [-100.000,  5.098], mean action: 1.814 [0.000, 3.000],  loss: 768.937008, mae: 396.453146, mean_q: 542.864817, mean_eps: 0.636341
 121386/300000: episode: 1205, duration: 0.679s, episode steps: 107, steps per second: 158, episode reward: -52.338, mean reward: -0.489 [-100.000, 15.844], mean action: 1.757 [0.000, 3.000],  loss: 582.119820, mae: 400.566012, mean_q: 548.383803, mean_eps: 0.636004
 121455/300000: episode: 1206, duration: 0.431s, episode steps:  69, steps per second: 160, episode reward: -21.333, mean reward: -0.309 [-100.000, 15.673], mean action: 1.884 [0.000, 3.000],  loss: 597.871355, mae: 395.101808, mean_q: 540.451749, mean_eps: 0.635740
 121560/300000: episode: 1207, duration: 0.708s, episode steps: 105, steps per second: 148, episode reward: -82.076, mean reward: -0.782 [-100.000,  7.723], mean action: 1.610 [0.000, 3.000],  loss: 432.612803, mae: 390.148393, mean_q: 534.157550, mean_eps: 0.635479
 121670/300000: episode: 1208, duration: 0.728s, episode steps: 110, steps per second: 151, episode reward: -47.306, mean reward: -0.430 [-100.000, 27.896], mean action: 1.764 [0.000, 3.000],  loss: 505.694549, mae: 387.814275, mean_q: 531.915401, mean_eps: 0.635157
 121749/300000: episode: 1209, duration: 0.517s, episode steps:  79, steps per second: 153, episode reward: -154.022, mean reward: -1.950 [-100.000,  6.996], mean action: 1.810 [0.000, 3.000],  loss: 458.150872, mae: 390.372709, mean_q: 534.759423, mean_eps: 0.634873
 121849/300000: episode: 1210, duration: 0.673s, episode steps: 100, steps per second: 149, episode reward: -73.085, mean reward: -0.731 [-100.000, 23.811], mean action: 1.620 [0.000, 3.000],  loss: 464.705442, mae: 394.531815, mean_q: 540.809664, mean_eps: 0.634604
 121957/300000: episode: 1211, duration: 0.695s, episode steps: 108, steps per second: 155, episode reward: -64.443, mean reward: -0.597 [-100.000,  8.782], mean action: 1.565 [0.000, 3.000],  loss: 655.489783, mae: 398.688404, mean_q: 545.470575, mean_eps: 0.634292
 122061/300000: episode: 1212, duration: 0.677s, episode steps: 104, steps per second: 154, episode reward: -94.828, mean reward: -0.912 [-100.000,  9.083], mean action: 1.346 [0.000, 3.000],  loss: 520.830460, mae: 401.052230, mean_q: 549.565825, mean_eps: 0.633974
 122131/300000: episode: 1213, duration: 0.439s, episode steps:  70, steps per second: 160, episode reward: -89.160, mean reward: -1.274 [-100.000,  5.850], mean action: 1.357 [0.000, 3.000],  loss: 845.387165, mae: 389.613461, mean_q: 531.691698, mean_eps: 0.633714
 122230/300000: episode: 1214, duration: 0.674s, episode steps:  99, steps per second: 147, episode reward: -64.942, mean reward: -0.656 [-100.000, 15.922], mean action: 1.556 [0.000, 3.000],  loss: 512.463926, mae: 401.385962, mean_q: 548.622615, mean_eps: 0.633460
 122342/300000: episode: 1215, duration: 0.723s, episode steps: 112, steps per second: 155, episode reward: -57.838, mean reward: -0.516 [-100.000, 11.194], mean action: 1.509 [0.000, 3.000],  loss: 599.283526, mae: 405.201558, mean_q: 554.747316, mean_eps: 0.633143
 122479/300000: episode: 1216, duration: 0.877s, episode steps: 137, steps per second: 156, episode reward: -73.955, mean reward: -0.540 [-100.000,  9.585], mean action: 1.745 [0.000, 3.000],  loss: 507.598523, mae: 408.774175, mean_q: 560.358880, mean_eps: 0.632770
 122574/300000: episode: 1217, duration: 0.668s, episode steps:  95, steps per second: 142, episode reward: -92.902, mean reward: -0.978 [-100.000, 13.165], mean action: 1.589 [0.000, 3.000],  loss: 623.764614, mae: 409.597819, mean_q: 561.879216, mean_eps: 0.632422
 122659/300000: episode: 1218, duration: 0.678s, episode steps:  85, steps per second: 125, episode reward: -14.914, mean reward: -0.175 [-100.000, 12.418], mean action: 1.835 [0.000, 3.000],  loss: 397.504268, mae: 414.206112, mean_q: 567.783059, mean_eps: 0.632152
 122756/300000: episode: 1219, duration: 0.711s, episode steps:  97, steps per second: 136, episode reward: -254.805, mean reward: -2.627 [-100.000, 16.427], mean action: 1.722 [0.000, 3.000],  loss: 570.656949, mae: 409.372043, mean_q: 560.344512, mean_eps: 0.631879
 122855/300000: episode: 1220, duration: 0.758s, episode steps:  99, steps per second: 131, episode reward: -56.455, mean reward: -0.570 [-100.000, 11.556], mean action: 1.606 [0.000, 3.000],  loss: 566.094451, mae: 413.691964, mean_q: 565.894885, mean_eps: 0.631585
 122979/300000: episode: 1221, duration: 0.987s, episode steps: 124, steps per second: 126, episode reward: -36.838, mean reward: -0.297 [-100.000, 59.503], mean action: 1.637 [0.000, 3.000],  loss: 576.160496, mae: 422.438723, mean_q: 578.700679, mean_eps: 0.631250
 123070/300000: episode: 1222, duration: 0.699s, episode steps:  91, steps per second: 130, episode reward: -41.386, mean reward: -0.455 [-100.000, 11.559], mean action: 1.714 [0.000, 3.000],  loss: 410.260355, mae: 425.894364, mean_q: 584.426623, mean_eps: 0.630928
 123175/300000: episode: 1223, duration: 0.759s, episode steps: 105, steps per second: 138, episode reward: -202.206, mean reward: -1.926 [-100.000,  6.069], mean action: 1.781 [0.000, 3.000],  loss: 440.662676, mae: 424.674638, mean_q: 581.958656, mean_eps: 0.630634
 123314/300000: episode: 1224, duration: 0.960s, episode steps: 139, steps per second: 145, episode reward: -22.566, mean reward: -0.162 [-100.000, 17.510], mean action: 1.568 [0.000, 3.000],  loss: 656.358240, mae: 433.999293, mean_q: 593.856312, mean_eps: 0.630268
 123406/300000: episode: 1225, duration: 0.643s, episode steps:  92, steps per second: 143, episode reward: -53.454, mean reward: -0.581 [-100.000, 14.101], mean action: 1.674 [0.000, 3.000],  loss: 415.731380, mae: 435.630098, mean_q: 595.937186, mean_eps: 0.629921
 123514/300000: episode: 1226, duration: 0.708s, episode steps: 108, steps per second: 152, episode reward: -192.150, mean reward: -1.779 [-100.000,  7.922], mean action: 1.657 [0.000, 3.000],  loss: 746.210027, mae: 432.909656, mean_q: 592.174496, mean_eps: 0.629621
 123605/300000: episode: 1227, duration: 0.565s, episode steps:  91, steps per second: 161, episode reward: -108.994, mean reward: -1.198 [-100.000,  9.794], mean action: 1.527 [0.000, 3.000],  loss: 787.049575, mae: 447.955851, mean_q: 613.006978, mean_eps: 0.629323
 123694/300000: episode: 1228, duration: 0.606s, episode steps:  89, steps per second: 147, episode reward: -11.137, mean reward: -0.125 [-100.000, 15.183], mean action: 1.506 [0.000, 3.000],  loss: 914.624211, mae: 450.374300, mean_q: 617.234306, mean_eps: 0.629053
 123866/300000: episode: 1229, duration: 1.170s, episode steps: 172, steps per second: 147, episode reward: -200.675, mean reward: -1.167 [-100.000, 59.882], mean action: 1.581 [0.000, 3.000],  loss: 517.886994, mae: 448.537621, mean_q: 615.233497, mean_eps: 0.628661
 123950/300000: episode: 1230, duration: 0.530s, episode steps:  84, steps per second: 158, episode reward: -47.596, mean reward: -0.567 [-100.000, 10.061], mean action: 1.762 [0.000, 3.000],  loss: 636.496079, mae: 458.573446, mean_q: 628.158905, mean_eps: 0.628277
 124042/300000: episode: 1231, duration: 0.625s, episode steps:  92, steps per second: 147, episode reward: -124.538, mean reward: -1.354 [-100.000,  6.200], mean action: 1.772 [0.000, 3.000],  loss: 411.168578, mae: 454.529799, mean_q: 622.563133, mean_eps: 0.628013
 124143/300000: episode: 1232, duration: 0.653s, episode steps: 101, steps per second: 155, episode reward: -18.917, mean reward: -0.187 [-100.000, 15.777], mean action: 1.584 [0.000, 3.000],  loss: 513.297641, mae: 464.017465, mean_q: 634.067238, mean_eps: 0.627724
 124251/300000: episode: 1233, duration: 0.682s, episode steps: 108, steps per second: 158, episode reward: -97.467, mean reward: -0.902 [-100.000, 13.486], mean action: 1.694 [0.000, 3.000],  loss: 586.380979, mae: 477.714090, mean_q: 653.686704, mean_eps: 0.627410
 124379/300000: episode: 1234, duration: 0.871s, episode steps: 128, steps per second: 147, episode reward: -218.360, mean reward: -1.706 [-100.000, 33.769], mean action: 1.273 [0.000, 3.000],  loss: 541.445710, mae: 471.571549, mean_q: 643.411091, mean_eps: 0.627057
 124477/300000: episode: 1235, duration: 0.638s, episode steps:  98, steps per second: 154, episode reward: -79.989, mean reward: -0.816 [-100.000,  6.622], mean action: 1.612 [0.000, 3.000],  loss: 721.027075, mae: 472.463238, mean_q: 645.229167, mean_eps: 0.626718
 124549/300000: episode: 1236, duration: 0.466s, episode steps:  72, steps per second: 155, episode reward: -54.126, mean reward: -0.752 [-100.000,  7.107], mean action: 1.639 [0.000, 3.000],  loss: 929.235932, mae: 465.440720, mean_q: 634.703974, mean_eps: 0.626463
 124643/300000: episode: 1237, duration: 0.592s, episode steps:  94, steps per second: 159, episode reward: -96.725, mean reward: -1.029 [-100.000,  6.357], mean action: 1.404 [0.000, 3.000],  loss: 694.562697, mae: 468.305927, mean_q: 638.438724, mean_eps: 0.626214
 124763/300000: episode: 1238, duration: 0.819s, episode steps: 120, steps per second: 147, episode reward: -70.633, mean reward: -0.589 [-100.000, 11.462], mean action: 1.533 [0.000, 3.000],  loss: 737.803411, mae: 474.222665, mean_q: 647.440763, mean_eps: 0.625893
 124860/300000: episode: 1239, duration: 0.619s, episode steps:  97, steps per second: 157, episode reward: -63.001, mean reward: -0.649 [-100.000, 10.530], mean action: 1.598 [0.000, 3.000],  loss: 793.181234, mae: 477.334927, mean_q: 651.522447, mean_eps: 0.625567
 124944/300000: episode: 1240, duration: 0.532s, episode steps:  84, steps per second: 158, episode reward: -95.125, mean reward: -1.132 [-100.000, 12.036], mean action: 1.738 [0.000, 3.000],  loss: 406.475937, mae: 486.754938, mean_q: 666.022623, mean_eps: 0.625296
 125075/300000: episode: 1241, duration: 0.892s, episode steps: 131, steps per second: 147, episode reward: -60.249, mean reward: -0.460 [-100.000, 14.238], mean action: 1.443 [0.000, 3.000],  loss: 845.416829, mae: 491.560353, mean_q: 671.847996, mean_eps: 0.624973
 125197/300000: episode: 1242, duration: 0.786s, episode steps: 122, steps per second: 155, episode reward: -176.621, mean reward: -1.448 [-100.000,  9.923], mean action: 1.672 [0.000, 3.000],  loss: 733.124288, mae: 489.950026, mean_q: 670.935289, mean_eps: 0.624594
 125288/300000: episode: 1243, duration: 0.589s, episode steps:  91, steps per second: 154, episode reward: -59.123, mean reward: -0.650 [-100.000, 14.366], mean action: 1.846 [0.000, 3.000],  loss: 885.588209, mae: 493.216580, mean_q: 674.638049, mean_eps: 0.624274
 125415/300000: episode: 1244, duration: 0.870s, episode steps: 127, steps per second: 146, episode reward: -83.049, mean reward: -0.654 [-100.000, 13.243], mean action: 1.732 [0.000, 3.000],  loss: 907.208825, mae: 493.042375, mean_q: 673.527658, mean_eps: 0.623947
 125517/300000: episode: 1245, duration: 0.653s, episode steps: 102, steps per second: 156, episode reward: -101.721, mean reward: -0.997 [-100.000, 10.048], mean action: 1.588 [0.000, 3.000],  loss: 514.566777, mae: 494.204425, mean_q: 675.224717, mean_eps: 0.623603
 125653/300000: episode: 1246, duration: 0.863s, episode steps: 136, steps per second: 158, episode reward: -86.048, mean reward: -0.633 [-100.000, 28.383], mean action: 1.794 [0.000, 3.000],  loss: 666.400840, mae: 491.817180, mean_q: 671.332770, mean_eps: 0.623246
 125901/300000: episode: 1247, duration: 1.634s, episode steps: 248, steps per second: 152, episode reward: -164.382, mean reward: -0.663 [-100.000, 11.796], mean action: 1.645 [0.000, 3.000],  loss: 814.725893, mae: 499.843052, mean_q: 684.555878, mean_eps: 0.622671
 126024/300000: episode: 1248, duration: 0.843s, episode steps: 123, steps per second: 146, episode reward: -13.581, mean reward: -0.110 [-100.000, 17.783], mean action: 1.626 [0.000, 3.000],  loss: 1044.675629, mae: 512.125273, mean_q: 702.773372, mean_eps: 0.622114
 126168/300000: episode: 1249, duration: 0.978s, episode steps: 144, steps per second: 147, episode reward: -239.493, mean reward: -1.663 [-100.000,  3.917], mean action: 1.722 [0.000, 3.000],  loss: 824.809193, mae: 512.373370, mean_q: 702.707510, mean_eps: 0.621713
 126319/300000: episode: 1250, duration: 0.981s, episode steps: 151, steps per second: 154, episode reward: -98.684, mean reward: -0.654 [-100.000, 39.831], mean action: 1.788 [0.000, 3.000],  loss: 1065.020264, mae: 517.877199, mean_q: 710.153235, mean_eps: 0.621271
 126409/300000: episode: 1251, duration: 0.594s, episode steps:  90, steps per second: 152, episode reward: -96.475, mean reward: -1.072 [-100.000,  6.708], mean action: 1.778 [0.000, 3.000],  loss: 1183.799147, mae: 524.133809, mean_q: 719.110713, mean_eps: 0.620909
 126484/300000: episode: 1252, duration: 0.487s, episode steps:  75, steps per second: 154, episode reward: -58.462, mean reward: -0.779 [-100.000, 19.718], mean action: 1.640 [0.000, 3.000],  loss: 1546.548752, mae: 520.757984, mean_q: 714.583085, mean_eps: 0.620662
 126725/300000: episode: 1253, duration: 1.597s, episode steps: 241, steps per second: 151, episode reward: -215.346, mean reward: -0.894 [-100.000, 27.717], mean action: 1.685 [0.000, 3.000],  loss: 935.705118, mae: 526.671890, mean_q: 723.818196, mean_eps: 0.620188
 126866/300000: episode: 1254, duration: 0.911s, episode steps: 141, steps per second: 155, episode reward: -183.748, mean reward: -1.303 [-100.000, 70.029], mean action: 1.567 [0.000, 3.000],  loss: 1524.529512, mae: 538.048310, mean_q: 740.639503, mean_eps: 0.619615
 126994/300000: episode: 1255, duration: 0.829s, episode steps: 128, steps per second: 154, episode reward: -246.189, mean reward: -1.923 [-100.000, 23.805], mean action: 1.602 [0.000, 3.000],  loss: 2157.709647, mae: 550.983741, mean_q: 756.615602, mean_eps: 0.619212
 127091/300000: episode: 1256, duration: 0.696s, episode steps:  97, steps per second: 139, episode reward: -124.256, mean reward: -1.281 [-100.000,  3.501], mean action: 1.670 [0.000, 3.000],  loss: 1676.036250, mae: 554.899849, mean_q: 760.440720, mean_eps: 0.618874
 127219/300000: episode: 1257, duration: 1.025s, episode steps: 128, steps per second: 125, episode reward: -143.533, mean reward: -1.121 [-100.000,  7.415], mean action: 1.648 [0.000, 3.000],  loss: 1124.036858, mae: 560.253765, mean_q: 770.853423, mean_eps: 0.618537
 127366/300000: episode: 1258, duration: 1.026s, episode steps: 147, steps per second: 143, episode reward: -29.205, mean reward: -0.199 [-100.000,  9.937], mean action: 1.646 [0.000, 3.000],  loss: 1443.486346, mae: 561.365880, mean_q: 771.975046, mean_eps: 0.618124
 127468/300000: episode: 1259, duration: 0.651s, episode steps: 102, steps per second: 157, episode reward: -96.984, mean reward: -0.951 [-100.000, 18.341], mean action: 1.686 [0.000, 3.000],  loss: 2042.809279, mae: 569.902292, mean_q: 783.993797, mean_eps: 0.617750
 127576/300000: episode: 1260, duration: 0.728s, episode steps: 108, steps per second: 148, episode reward: -73.344, mean reward: -0.679 [-100.000, 12.534], mean action: 1.565 [0.000, 3.000],  loss: 1720.085628, mae: 572.594486, mean_q: 789.403479, mean_eps: 0.617436
 127697/300000: episode: 1261, duration: 0.827s, episode steps: 121, steps per second: 146, episode reward: -211.622, mean reward: -1.749 [-100.000,  8.268], mean action: 1.719 [0.000, 3.000],  loss: 1963.047533, mae: 563.245590, mean_q: 774.763740, mean_eps: 0.617092
 127798/300000: episode: 1262, duration: 0.734s, episode steps: 101, steps per second: 138, episode reward: -239.018, mean reward: -2.367 [-100.000, 13.248], mean action: 1.634 [0.000, 3.000],  loss: 1238.423984, mae: 568.752702, mean_q: 782.620294, mean_eps: 0.616759
 127886/300000: episode: 1263, duration: 0.735s, episode steps:  88, steps per second: 120, episode reward: -64.657, mean reward: -0.735 [-100.000, 11.018], mean action: 1.477 [0.000, 3.000],  loss: 1468.633895, mae: 579.650539, mean_q: 795.400273, mean_eps: 0.616475
 128023/300000: episode: 1264, duration: 0.963s, episode steps: 137, steps per second: 142, episode reward: -173.008, mean reward: -1.263 [-100.000, 45.258], mean action: 1.650 [0.000, 3.000],  loss: 1706.103587, mae: 567.393318, mean_q: 779.851099, mean_eps: 0.616138
 128119/300000: episode: 1265, duration: 0.613s, episode steps:  96, steps per second: 157, episode reward: -39.070, mean reward: -0.407 [-100.000, 40.037], mean action: 1.740 [0.000, 3.000],  loss: 945.518622, mae: 578.303058, mean_q: 796.446274, mean_eps: 0.615788
 128263/300000: episode: 1266, duration: 1.030s, episode steps: 144, steps per second: 140, episode reward: -49.801, mean reward: -0.346 [-100.000, 70.367], mean action: 1.653 [0.000, 3.000],  loss: 1479.838127, mae: 584.972543, mean_q: 805.952133, mean_eps: 0.615429
 128362/300000: episode: 1267, duration: 0.640s, episode steps:  99, steps per second: 155, episode reward: -115.909, mean reward: -1.171 [-100.000,  7.803], mean action: 1.758 [0.000, 3.000],  loss: 1960.488132, mae: 569.155838, mean_q: 783.192219, mean_eps: 0.615064
 128491/300000: episode: 1268, duration: 0.840s, episode steps: 129, steps per second: 154, episode reward: -295.671, mean reward: -2.292 [-100.000,  6.510], mean action: 1.682 [0.000, 3.000],  loss: 1516.589501, mae: 587.587814, mean_q: 808.484474, mean_eps: 0.614722
 128629/300000: episode: 1269, duration: 1.037s, episode steps: 138, steps per second: 133, episode reward: -48.576, mean reward: -0.352 [-100.000, 12.084], mean action: 1.580 [0.000, 3.000],  loss: 2060.972923, mae: 591.304775, mean_q: 811.897804, mean_eps: 0.614321
 128769/300000: episode: 1270, duration: 1.031s, episode steps: 140, steps per second: 136, episode reward: -208.273, mean reward: -1.488 [-100.000, 56.858], mean action: 1.593 [0.000, 3.000],  loss: 1813.470073, mae: 603.534750, mean_q: 831.205888, mean_eps: 0.613904
 128860/300000: episode: 1271, duration: 0.678s, episode steps:  91, steps per second: 134, episode reward: -239.693, mean reward: -2.634 [-100.000,  3.668], mean action: 1.604 [0.000, 3.000],  loss: 2145.933771, mae: 607.166168, mean_q: 834.714060, mean_eps: 0.613558
 129002/300000: episode: 1272, duration: 0.975s, episode steps: 142, steps per second: 146, episode reward: -2.294, mean reward: -0.016 [-100.000,  8.454], mean action: 1.507 [0.000, 3.000],  loss: 1609.187967, mae: 617.322864, mean_q: 848.245387, mean_eps: 0.613208
 129110/300000: episode: 1273, duration: 0.740s, episode steps: 108, steps per second: 146, episode reward: -123.426, mean reward: -1.143 [-100.000,  6.856], mean action: 1.657 [0.000, 3.000],  loss: 1970.350746, mae: 629.655479, mean_q: 863.585184, mean_eps: 0.612834
 129228/300000: episode: 1274, duration: 0.849s, episode steps: 118, steps per second: 139, episode reward: -209.450, mean reward: -1.775 [-100.000,  3.835], mean action: 1.627 [0.000, 3.000],  loss: 2786.862513, mae: 631.291487, mean_q: 866.564927, mean_eps: 0.612495
 129358/300000: episode: 1275, duration: 0.891s, episode steps: 130, steps per second: 146, episode reward: -158.739, mean reward: -1.221 [-100.000,  2.979], mean action: 1.638 [0.000, 3.000],  loss: 2648.921643, mae: 630.561188, mean_q: 865.375012, mean_eps: 0.612123
 129497/300000: episode: 1276, duration: 0.955s, episode steps: 139, steps per second: 146, episode reward: -40.824, mean reward: -0.294 [-100.000, 10.261], mean action: 1.547 [0.000, 3.000],  loss: 2274.651585, mae: 642.821062, mean_q: 881.537806, mean_eps: 0.611719
 129596/300000: episode: 1277, duration: 0.649s, episode steps:  99, steps per second: 153, episode reward: -7.329, mean reward: -0.074 [-100.000, 20.658], mean action: 1.747 [0.000, 3.000],  loss: 1408.199636, mae: 632.031866, mean_q: 869.057434, mean_eps: 0.611362
 129679/300000: episode: 1278, duration: 0.551s, episode steps:  83, steps per second: 151, episode reward: -58.795, mean reward: -0.708 [-100.000, 10.730], mean action: 1.795 [0.000, 3.000],  loss: 1447.074902, mae: 640.206934, mean_q: 880.073592, mean_eps: 0.611089
 129773/300000: episode: 1279, duration: 0.643s, episode steps:  94, steps per second: 146, episode reward: -17.465, mean reward: -0.186 [-100.000, 14.402], mean action: 1.660 [0.000, 3.000],  loss: 1664.798871, mae: 634.213523, mean_q: 870.415259, mean_eps: 0.610823
 129882/300000: episode: 1280, duration: 0.732s, episode steps: 109, steps per second: 149, episode reward: -50.741, mean reward: -0.466 [-100.000,  6.620], mean action: 1.596 [0.000, 3.000],  loss: 1355.162479, mae: 636.728619, mean_q: 873.389779, mean_eps: 0.610519
 130000/300000: episode: 1281, duration: 0.788s, episode steps: 118, steps per second: 150, episode reward: -51.073, mean reward: -0.433 [-100.000, 19.323], mean action: 1.508 [0.000, 3.000],  loss: 2068.146398, mae: 653.789114, mean_q: 896.246253, mean_eps: 0.610179
 130120/300000: episode: 1282, duration: 0.817s, episode steps: 120, steps per second: 147, episode reward: -456.640, mean reward: -3.805 [-100.000, 14.442], mean action: 1.483 [0.000, 3.000],  loss: 2835.159319, mae: 663.403619, mean_q: 910.119123, mean_eps: 0.609822
 130237/300000: episode: 1283, duration: 0.776s, episode steps: 117, steps per second: 151, episode reward: -3.941, mean reward: -0.034 [-100.000, 21.235], mean action: 1.590 [0.000, 3.000],  loss: 1904.938651, mae: 674.955264, mean_q: 922.639063, mean_eps: 0.609466
 130355/300000: episode: 1284, duration: 0.755s, episode steps: 118, steps per second: 156, episode reward: -111.579, mean reward: -0.946 [-100.000, 16.323], mean action: 1.364 [0.000, 3.000],  loss: 2106.216588, mae: 665.203305, mean_q: 909.941369, mean_eps: 0.609113
 130455/300000: episode: 1285, duration: 0.722s, episode steps: 100, steps per second: 138, episode reward: -183.442, mean reward: -1.834 [-100.000, 14.027], mean action: 1.820 [0.000, 3.000],  loss: 1902.073702, mae: 680.449073, mean_q: 931.431647, mean_eps: 0.608786
 130555/300000: episode: 1286, duration: 0.659s, episode steps: 100, steps per second: 152, episode reward: -140.587, mean reward: -1.406 [-100.000, 13.683], mean action: 1.760 [0.000, 3.000],  loss: 1448.851467, mae: 693.518226, mean_q: 949.779818, mean_eps: 0.608487
 130977/300000: episode: 1287, duration: 2.918s, episode steps: 422, steps per second: 145, episode reward: -147.301, mean reward: -0.349 [-100.000, 70.802], mean action: 1.637 [0.000, 3.000],  loss: 1591.173348, mae: 703.167979, mean_q: 964.306563, mean_eps: 0.607703
 131093/300000: episode: 1288, duration: 0.807s, episode steps: 116, steps per second: 144, episode reward: -175.779, mean reward: -1.515 [-100.000, 46.779], mean action: 1.698 [0.000, 3.000],  loss: 1888.198067, mae: 708.532264, mean_q: 972.140553, mean_eps: 0.606897
 131222/300000: episode: 1289, duration: 0.849s, episode steps: 129, steps per second: 152, episode reward: -39.003, mean reward: -0.302 [-100.000, 10.264], mean action: 1.775 [0.000, 3.000],  loss: 1841.563762, mae: 717.877561, mean_q: 983.533313, mean_eps: 0.606529
 131332/300000: episode: 1290, duration: 0.706s, episode steps: 110, steps per second: 156, episode reward: -143.954, mean reward: -1.309 [-100.000,  9.500], mean action: 1.645 [0.000, 3.000],  loss: 1383.799292, mae: 715.567817, mean_q: 981.446134, mean_eps: 0.606171
 131408/300000: episode: 1291, duration: 0.538s, episode steps:  76, steps per second: 141, episode reward: -186.967, mean reward: -2.460 [-100.000, 19.511], mean action: 1.434 [0.000, 3.000],  loss: 1170.854012, mae: 736.414738, mean_q: 1009.120519, mean_eps: 0.605891
 131524/300000: episode: 1292, duration: 0.764s, episode steps: 116, steps per second: 152, episode reward: -198.797, mean reward: -1.714 [-100.000,  4.861], mean action: 1.405 [0.000, 3.000],  loss: 1831.111399, mae: 717.928343, mean_q: 982.944566, mean_eps: 0.605603
 131645/300000: episode: 1293, duration: 0.801s, episode steps: 121, steps per second: 151, episode reward: -154.711, mean reward: -1.279 [-100.000, 37.371], mean action: 1.793 [0.000, 3.000],  loss: 1872.896508, mae: 719.118507, mean_q: 986.098110, mean_eps: 0.605248
 131761/300000: episode: 1294, duration: 0.807s, episode steps: 116, steps per second: 144, episode reward: -28.901, mean reward: -0.249 [-100.000, 15.792], mean action: 1.741 [0.000, 3.000],  loss: 1250.860761, mae: 730.562849, mean_q: 1002.066901, mean_eps: 0.604893
 131873/300000: episode: 1295, duration: 0.847s, episode steps: 112, steps per second: 132, episode reward: -116.896, mean reward: -1.044 [-100.000, 11.879], mean action: 1.768 [0.000, 3.000],  loss: 1619.701120, mae: 742.018080, mean_q: 1016.708158, mean_eps: 0.604550
 131986/300000: episode: 1296, duration: 0.747s, episode steps: 113, steps per second: 151, episode reward: -169.583, mean reward: -1.501 [-100.000,  6.040], mean action: 1.637 [0.000, 3.000],  loss: 1297.511061, mae: 746.647831, mean_q: 1022.732111, mean_eps: 0.604213
 132067/300000: episode: 1297, duration: 0.552s, episode steps:  81, steps per second: 147, episode reward: -170.268, mean reward: -2.102 [-100.000,  4.045], mean action: 1.506 [0.000, 3.000],  loss: 1369.066114, mae: 742.241550, mean_q: 1015.546720, mean_eps: 0.603922
 132170/300000: episode: 1298, duration: 0.665s, episode steps: 103, steps per second: 155, episode reward: -165.321, mean reward: -1.605 [-100.000, 13.892], mean action: 1.573 [0.000, 3.000],  loss: 1432.164586, mae: 743.790487, mean_q: 1017.872744, mean_eps: 0.603646
 132283/300000: episode: 1299, duration: 0.725s, episode steps: 113, steps per second: 156, episode reward: -272.618, mean reward: -2.413 [-100.000, 91.510], mean action: 1.611 [0.000, 3.000],  loss: 1422.876285, mae: 750.344445, mean_q: 1028.567220, mean_eps: 0.603322
 132402/300000: episode: 1300, duration: 0.966s, episode steps: 119, steps per second: 123, episode reward: -104.098, mean reward: -0.875 [-100.000, 11.323], mean action: 1.672 [0.000, 3.000],  loss: 1481.689631, mae: 748.468911, mean_q: 1025.573296, mean_eps: 0.602974
 132491/300000: episode: 1301, duration: 0.651s, episode steps:  89, steps per second: 137, episode reward: -142.422, mean reward: -1.600 [-100.000,  6.720], mean action: 1.506 [0.000, 3.000],  loss: 1618.668993, mae: 758.222831, mean_q: 1034.795701, mean_eps: 0.602662
 132613/300000: episode: 1302, duration: 0.965s, episode steps: 122, steps per second: 126, episode reward: -108.748, mean reward: -0.891 [-100.000,  6.627], mean action: 1.861 [0.000, 3.000],  loss: 1488.771624, mae: 764.345447, mean_q: 1045.989996, mean_eps: 0.602346
 132742/300000: episode: 1303, duration: 0.929s, episode steps: 129, steps per second: 139, episode reward: -9.473, mean reward: -0.073 [-100.000, 16.516], mean action: 1.822 [0.000, 3.000],  loss: 1652.734435, mae: 764.262692, mean_q: 1044.297240, mean_eps: 0.601969
 132835/300000: episode: 1304, duration: 0.664s, episode steps:  93, steps per second: 140, episode reward: -141.985, mean reward: -1.527 [-100.000,  8.401], mean action: 1.613 [0.000, 3.000],  loss: 919.217478, mae: 779.792764, mean_q: 1066.889516, mean_eps: 0.601636
 132921/300000: episode: 1305, duration: 0.638s, episode steps:  86, steps per second: 135, episode reward: -77.112, mean reward: -0.897 [-100.000,  9.873], mean action: 1.570 [0.000, 3.000],  loss: 1247.025951, mae: 775.930147, mean_q: 1058.932813, mean_eps: 0.601367
 132993/300000: episode: 1306, duration: 0.482s, episode steps:  72, steps per second: 149, episode reward: -95.546, mean reward: -1.327 [-100.000,  6.505], mean action: 1.736 [0.000, 3.000],  loss: 1354.176282, mae: 773.831066, mean_q: 1058.140755, mean_eps: 0.601131
 133124/300000: episode: 1307, duration: 0.869s, episode steps: 131, steps per second: 151, episode reward: -194.833, mean reward: -1.487 [-100.000,  4.619], mean action: 1.519 [0.000, 3.000],  loss: 1325.790949, mae: 781.637939, mean_q: 1069.120900, mean_eps: 0.600826
 133239/300000: episode: 1308, duration: 0.782s, episode steps: 115, steps per second: 147, episode reward: -81.558, mean reward: -0.709 [-100.000, 18.345], mean action: 1.722 [0.000, 3.000],  loss: 1094.340755, mae: 782.945824, mean_q: 1071.124326, mean_eps: 0.600457
 133330/300000: episode: 1309, duration: 0.606s, episode steps:  91, steps per second: 150, episode reward: -144.296, mean reward: -1.586 [-100.000,  9.183], mean action: 1.670 [0.000, 3.000],  loss: 1267.677825, mae: 783.511964, mean_q: 1071.084361, mean_eps: 0.600148
 133466/300000: episode: 1310, duration: 0.896s, episode steps: 136, steps per second: 152, episode reward: -91.584, mean reward: -0.673 [-100.000, 17.854], mean action: 1.632 [0.000, 3.000],  loss: 881.686595, mae: 785.098469, mean_q: 1072.560003, mean_eps: 0.599807
 133596/300000: episode: 1311, duration: 0.883s, episode steps: 130, steps per second: 147, episode reward: -212.278, mean reward: -1.633 [-100.000, 98.388], mean action: 1.731 [0.000, 3.000],  loss: 1478.258439, mae: 787.109547, mean_q: 1074.602116, mean_eps: 0.599408
 133715/300000: episode: 1312, duration: 0.785s, episode steps: 119, steps per second: 152, episode reward: -73.820, mean reward: -0.620 [-100.000, 31.783], mean action: 1.639 [0.000, 3.000],  loss: 1301.680454, mae: 794.618691, mean_q: 1087.175693, mean_eps: 0.599035
 133829/300000: episode: 1313, duration: 0.750s, episode steps: 114, steps per second: 152, episode reward: -31.203, mean reward: -0.274 [-100.000, 14.342], mean action: 1.500 [0.000, 3.000],  loss: 1111.670277, mae: 789.987235, mean_q: 1079.371250, mean_eps: 0.598685
 134273/300000: episode: 1314, duration: 3.108s, episode steps: 444, steps per second: 143, episode reward: -85.481, mean reward: -0.193 [-100.000, 88.021], mean action: 1.766 [0.000, 3.000],  loss: 1389.547225, mae: 789.308307, mean_q: 1078.441946, mean_eps: 0.597849
 134406/300000: episode: 1315, duration: 0.853s, episode steps: 133, steps per second: 156, episode reward: -136.353, mean reward: -1.025 [-100.000, 11.988], mean action: 1.617 [0.000, 3.000],  loss: 1259.773168, mae: 798.008918, mean_q: 1091.189271, mean_eps: 0.596983
 134532/300000: episode: 1316, duration: 0.844s, episode steps: 126, steps per second: 149, episode reward: -232.168, mean reward: -1.843 [-100.000,  8.773], mean action: 1.532 [0.000, 3.000],  loss: 1776.578455, mae: 805.455339, mean_q: 1099.415093, mean_eps: 0.596595
 134965/300000: episode: 1317, duration: 3.324s, episode steps: 433, steps per second: 130, episode reward: -289.532, mean reward: -0.669 [-100.000, 42.730], mean action: 1.635 [0.000, 3.000],  loss: 1493.834059, mae: 815.214597, mean_q: 1113.209743, mean_eps: 0.595756
 135087/300000: episode: 1318, duration: 0.863s, episode steps: 122, steps per second: 141, episode reward: -72.109, mean reward: -0.591 [-100.000,  8.081], mean action: 1.795 [0.000, 3.000],  loss: 1580.093503, mae: 802.777576, mean_q: 1095.072450, mean_eps: 0.594923
 135198/300000: episode: 1319, duration: 0.750s, episode steps: 111, steps per second: 148, episode reward: -184.688, mean reward: -1.664 [-100.000, 71.301], mean action: 1.766 [0.000, 3.000],  loss: 2188.648296, mae: 806.296481, mean_q: 1097.964103, mean_eps: 0.594574
 135301/300000: episode: 1320, duration: 0.673s, episode steps: 103, steps per second: 153, episode reward: -47.970, mean reward: -0.466 [-100.000, 17.874], mean action: 1.738 [0.000, 3.000],  loss: 1144.243219, mae: 798.375456, mean_q: 1088.698061, mean_eps: 0.594253
 135399/300000: episode: 1321, duration: 0.651s, episode steps:  98, steps per second: 150, episode reward: -82.203, mean reward: -0.839 [-100.000, 12.021], mean action: 1.735 [0.000, 3.000],  loss: 1558.675400, mae: 813.830072, mean_q: 1110.086591, mean_eps: 0.593952
 135549/300000: episode: 1322, duration: 1.028s, episode steps: 150, steps per second: 146, episode reward: -79.028, mean reward: -0.527 [-100.000,  9.903], mean action: 1.673 [0.000, 3.000],  loss: 2038.351539, mae: 816.328616, mean_q: 1112.641977, mean_eps: 0.593579
 135643/300000: episode: 1323, duration: 0.599s, episode steps:  94, steps per second: 157, episode reward: -62.820, mean reward: -0.668 [-100.000, 15.532], mean action: 1.574 [0.000, 3.000],  loss: 1861.549850, mae: 807.943126, mean_q: 1100.104893, mean_eps: 0.593214
 135720/300000: episode: 1324, duration: 0.517s, episode steps:  77, steps per second: 149, episode reward: -111.477, mean reward: -1.448 [-100.000, 10.833], mean action: 1.442 [0.000, 3.000],  loss: 2247.401043, mae: 795.471698, mean_q: 1085.950099, mean_eps: 0.592957
 135865/300000: episode: 1325, duration: 0.983s, episode steps: 145, steps per second: 147, episode reward: -31.717, mean reward: -0.219 [-100.000, 17.151], mean action: 1.786 [0.000, 3.000],  loss: 1884.408291, mae: 799.149469, mean_q: 1091.960972, mean_eps: 0.592624
 135976/300000: episode: 1326, duration: 0.727s, episode steps: 111, steps per second: 153, episode reward: -141.378, mean reward: -1.274 [-100.000, 17.505], mean action: 1.712 [0.000, 3.000],  loss: 1855.696198, mae: 783.601164, mean_q: 1071.073760, mean_eps: 0.592240
 136089/300000: episode: 1327, duration: 0.776s, episode steps: 113, steps per second: 146, episode reward: -52.221, mean reward: -0.462 [-100.000,  9.763], mean action: 1.681 [0.000, 3.000],  loss: 1336.367574, mae: 802.254388, mean_q: 1095.461818, mean_eps: 0.591904
 136214/300000: episode: 1328, duration: 0.842s, episode steps: 125, steps per second: 148, episode reward: -56.555, mean reward: -0.452 [-100.000, 18.758], mean action: 1.648 [0.000, 3.000],  loss: 1962.425402, mae: 806.209089, mean_q: 1099.301344, mean_eps: 0.591547
 136416/300000: episode: 1329, duration: 1.373s, episode steps: 202, steps per second: 147, episode reward: -172.380, mean reward: -0.853 [-100.000, 67.666], mean action: 1.594 [0.000, 3.000],  loss: 1717.657656, mae: 800.358692, mean_q: 1091.883237, mean_eps: 0.591057
 136507/300000: episode: 1330, duration: 0.608s, episode steps:  91, steps per second: 150, episode reward: -155.072, mean reward: -1.704 [-100.000, 11.307], mean action: 1.473 [0.000, 3.000],  loss: 1694.484281, mae: 815.004122, mean_q: 1111.343228, mean_eps: 0.590617
 136600/300000: episode: 1331, duration: 0.590s, episode steps:  93, steps per second: 158, episode reward: -46.009, mean reward: -0.495 [-100.000, 19.332], mean action: 1.667 [0.000, 3.000],  loss: 2432.023169, mae: 813.707772, mean_q: 1113.126142, mean_eps: 0.590341
 136696/300000: episode: 1332, duration: 0.644s, episode steps:  96, steps per second: 149, episode reward: 24.791, mean reward:  0.258 [-100.000, 19.777], mean action: 1.615 [0.000, 3.000],  loss: 2075.429015, mae: 810.851561, mean_q: 1107.911399, mean_eps: 0.590058
 136808/300000: episode: 1333, duration: 0.819s, episode steps: 112, steps per second: 137, episode reward: -26.136, mean reward: -0.233 [-100.000, 13.402], mean action: 1.759 [0.000, 3.000],  loss: 2271.837673, mae: 821.953416, mean_q: 1123.547367, mean_eps: 0.589746
 136988/300000: episode: 1334, duration: 1.473s, episode steps: 180, steps per second: 122, episode reward: -40.004, mean reward: -0.222 [-100.000, 10.825], mean action: 1.661 [0.000, 3.000],  loss: 1990.779175, mae: 812.790498, mean_q: 1110.731068, mean_eps: 0.589307
 137110/300000: episode: 1335, duration: 1.024s, episode steps: 122, steps per second: 119, episode reward: -67.548, mean reward: -0.554 [-100.000, 11.824], mean action: 1.713 [0.000, 3.000],  loss: 1770.510801, mae: 822.626170, mean_q: 1124.040599, mean_eps: 0.588855
 137215/300000: episode: 1336, duration: 0.757s, episode steps: 105, steps per second: 139, episode reward: -45.296, mean reward: -0.431 [-100.000, 12.869], mean action: 1.686 [0.000, 3.000],  loss: 2189.102949, mae: 836.696375, mean_q: 1143.473776, mean_eps: 0.588514
 137303/300000: episode: 1337, duration: 0.639s, episode steps:  88, steps per second: 138, episode reward: -136.705, mean reward: -1.553 [-100.000,  5.958], mean action: 1.455 [0.000, 3.000],  loss: 2065.870908, mae: 839.509676, mean_q: 1148.207246, mean_eps: 0.588225
 137422/300000: episode: 1338, duration: 0.907s, episode steps: 119, steps per second: 131, episode reward: -126.519, mean reward: -1.063 [-100.000,  5.945], mean action: 1.571 [0.000, 3.000],  loss: 1708.265734, mae: 833.944515, mean_q: 1138.474280, mean_eps: 0.587914
 137633/300000: episode: 1339, duration: 1.647s, episode steps: 211, steps per second: 128, episode reward: -153.200, mean reward: -0.726 [-100.000,  4.331], mean action: 1.720 [0.000, 3.000],  loss: 2400.187920, mae: 830.390626, mean_q: 1135.533287, mean_eps: 0.587419
 137788/300000: episode: 1340, duration: 1.012s, episode steps: 155, steps per second: 153, episode reward: -229.668, mean reward: -1.482 [-100.000, 48.526], mean action: 1.645 [0.000, 3.000],  loss: 2128.566218, mae: 848.905355, mean_q: 1160.732970, mean_eps: 0.586870
 137898/300000: episode: 1341, duration: 0.814s, episode steps: 110, steps per second: 135, episode reward: -165.201, mean reward: -1.502 [-100.000,  7.244], mean action: 1.645 [0.000, 3.000],  loss: 2002.078237, mae: 860.549883, mean_q: 1178.226806, mean_eps: 0.586472
 138078/300000: episode: 1342, duration: 1.238s, episode steps: 180, steps per second: 145, episode reward: -157.155, mean reward: -0.873 [-100.000, 18.135], mean action: 1.672 [0.000, 3.000],  loss: 2275.466352, mae: 868.473933, mean_q: 1188.777245, mean_eps: 0.586037
 138196/300000: episode: 1343, duration: 0.928s, episode steps: 118, steps per second: 127, episode reward: -123.537, mean reward: -1.047 [-100.000,  5.838], mean action: 1.763 [0.000, 3.000],  loss: 2873.626809, mae: 862.358550, mean_q: 1180.354191, mean_eps: 0.585590
 138327/300000: episode: 1344, duration: 0.954s, episode steps: 131, steps per second: 137, episode reward: -68.646, mean reward: -0.524 [-100.000, 25.217], mean action: 1.733 [0.000, 3.000],  loss: 3437.032818, mae: 879.027114, mean_q: 1202.288857, mean_eps: 0.585217
 138458/300000: episode: 1345, duration: 0.946s, episode steps: 131, steps per second: 138, episode reward: -127.685, mean reward: -0.975 [-100.000, 17.657], mean action: 1.588 [0.000, 3.000],  loss: 2615.789203, mae: 878.852055, mean_q: 1200.126859, mean_eps: 0.584824
 138544/300000: episode: 1346, duration: 0.632s, episode steps:  86, steps per second: 136, episode reward: -52.948, mean reward: -0.616 [-100.000, 13.241], mean action: 1.744 [0.000, 3.000],  loss: 2718.518467, mae: 877.927266, mean_q: 1198.743021, mean_eps: 0.584499
 138926/300000: episode: 1347, duration: 2.648s, episode steps: 382, steps per second: 144, episode reward: -91.559, mean reward: -0.240 [-100.000, 18.463], mean action: 1.675 [0.000, 3.000],  loss: 2565.689759, mae: 904.104509, mean_q: 1236.543111, mean_eps: 0.583797
 138989/300000: episode: 1348, duration: 0.416s, episode steps:  63, steps per second: 151, episode reward: -53.191, mean reward: -0.844 [-100.000, 19.106], mean action: 1.810 [0.000, 3.000],  loss: 2679.012665, mae: 913.874696, mean_q: 1248.341528, mean_eps: 0.583129
 139136/300000: episode: 1349, duration: 1.007s, episode steps: 147, steps per second: 146, episode reward: -16.831, mean reward: -0.114 [-100.000, 11.616], mean action: 1.667 [0.000, 3.000],  loss: 2372.708822, mae: 917.854726, mean_q: 1253.313560, mean_eps: 0.582814
 139290/300000: episode: 1350, duration: 1.025s, episode steps: 154, steps per second: 150, episode reward: -136.129, mean reward: -0.884 [-100.000, 25.738], mean action: 1.617 [0.000, 3.000],  loss: 2056.256883, mae: 926.618932, mean_q: 1267.449851, mean_eps: 0.582363
 139380/300000: episode: 1351, duration: 0.620s, episode steps:  90, steps per second: 145, episode reward: -29.592, mean reward: -0.329 [-100.000, 12.185], mean action: 1.700 [0.000, 3.000],  loss: 3457.729877, mae: 933.807604, mean_q: 1276.083097, mean_eps: 0.581996
 139495/300000: episode: 1352, duration: 0.780s, episode steps: 115, steps per second: 147, episode reward: -66.259, mean reward: -0.576 [-100.000,  9.890], mean action: 1.609 [0.000, 3.000],  loss: 2273.075022, mae: 932.309743, mean_q: 1274.278861, mean_eps: 0.581689
 139593/300000: episode: 1353, duration: 0.637s, episode steps:  98, steps per second: 154, episode reward: -86.821, mean reward: -0.886 [-100.000,  7.575], mean action: 1.571 [0.000, 3.000],  loss: 2731.665568, mae: 933.482629, mean_q: 1276.114609, mean_eps: 0.581369
 139687/300000: episode: 1354, duration: 0.620s, episode steps:  94, steps per second: 152, episode reward: -141.437, mean reward: -1.505 [-100.000, 12.415], mean action: 1.606 [0.000, 3.000],  loss: 2058.452883, mae: 945.932451, mean_q: 1292.004640, mean_eps: 0.581081
 139808/300000: episode: 1355, duration: 0.832s, episode steps: 121, steps per second: 145, episode reward: -57.847, mean reward: -0.478 [-100.000,  8.834], mean action: 1.793 [0.000, 3.000],  loss: 2465.008777, mae: 941.048833, mean_q: 1287.395274, mean_eps: 0.580759
 140106/300000: episode: 1356, duration: 2.037s, episode steps: 298, steps per second: 146, episode reward: -173.535, mean reward: -0.582 [-100.000, 33.950], mean action: 1.691 [0.000, 3.000],  loss: 3134.671547, mae: 936.140385, mean_q: 1281.289317, mean_eps: 0.580130
 140211/300000: episode: 1357, duration: 0.685s, episode steps: 105, steps per second: 153, episode reward: -21.397, mean reward: -0.204 [-100.000,  5.825], mean action: 1.533 [0.000, 3.000],  loss: 3817.328873, mae: 935.799096, mean_q: 1278.610002, mean_eps: 0.579526
 140328/300000: episode: 1358, duration: 0.759s, episode steps: 117, steps per second: 154, episode reward: -75.083, mean reward: -0.642 [-100.000, 10.922], mean action: 1.513 [0.000, 3.000],  loss: 3274.652304, mae: 940.255145, mean_q: 1286.246093, mean_eps: 0.579193
 140462/300000: episode: 1359, duration: 0.927s, episode steps: 134, steps per second: 144, episode reward: -141.489, mean reward: -1.056 [-100.000,  5.688], mean action: 1.493 [0.000, 3.000],  loss: 2649.831437, mae: 936.446154, mean_q: 1282.117380, mean_eps: 0.578816
 140593/300000: episode: 1360, duration: 0.844s, episode steps: 131, steps per second: 155, episode reward: -46.013, mean reward: -0.351 [-100.000, 19.724], mean action: 1.473 [0.000, 3.000],  loss: 3214.239181, mae: 938.492092, mean_q: 1284.586880, mean_eps: 0.578419
 140708/300000: episode: 1361, duration: 0.790s, episode steps: 115, steps per second: 145, episode reward: -50.959, mean reward: -0.443 [-100.000,  9.926], mean action: 1.809 [0.000, 3.000],  loss: 3529.132721, mae: 935.227304, mean_q: 1280.909926, mean_eps: 0.578050
 140868/300000: episode: 1362, duration: 1.051s, episode steps: 160, steps per second: 152, episode reward: -32.647, mean reward: -0.204 [-100.000, 14.589], mean action: 1.775 [0.000, 3.000],  loss: 4084.256702, mae: 950.021750, mean_q: 1299.302139, mean_eps: 0.577638
 140941/300000: episode: 1363, duration: 0.469s, episode steps:  73, steps per second: 156, episode reward: -53.578, mean reward: -0.734 [-100.000,  9.165], mean action: 1.753 [0.000, 3.000],  loss: 3542.236452, mae: 962.059658, mean_q: 1315.517979, mean_eps: 0.577288
 141083/300000: episode: 1364, duration: 0.977s, episode steps: 142, steps per second: 145, episode reward: -312.633, mean reward: -2.202 [-100.000, 49.394], mean action: 1.451 [0.000, 3.000],  loss: 4192.908721, mae: 961.195825, mean_q: 1315.443705, mean_eps: 0.576966
 141250/300000: episode: 1365, duration: 1.127s, episode steps: 167, steps per second: 148, episode reward: -210.392, mean reward: -1.260 [-100.000,  4.390], mean action: 1.587 [0.000, 3.000],  loss: 3836.540502, mae: 974.709103, mean_q: 1333.227626, mean_eps: 0.576502
 141398/300000: episode: 1366, duration: 1.009s, episode steps: 148, steps per second: 147, episode reward: -182.379, mean reward: -1.232 [-100.000, 49.036], mean action: 1.757 [0.000, 3.000],  loss: 3617.515126, mae: 977.500062, mean_q: 1337.735659, mean_eps: 0.576029
 141540/300000: episode: 1367, duration: 0.929s, episode steps: 142, steps per second: 153, episode reward: -98.061, mean reward: -0.691 [-100.000,  9.401], mean action: 1.606 [0.000, 3.000],  loss: 4969.760004, mae: 992.940214, mean_q: 1356.016007, mean_eps: 0.575595
 141628/300000: episode: 1368, duration: 0.588s, episode steps:  88, steps per second: 150, episode reward: -135.185, mean reward: -1.536 [-100.000, 17.363], mean action: 1.614 [0.000, 3.000],  loss: 4647.699379, mae: 997.355705, mean_q: 1363.773651, mean_eps: 0.575249
 141739/300000: episode: 1369, duration: 0.778s, episode steps: 111, steps per second: 143, episode reward: 23.255, mean reward:  0.210 [-100.000, 20.644], mean action: 1.712 [0.000, 3.000],  loss: 4851.457667, mae: 991.203199, mean_q: 1355.632720, mean_eps: 0.574951
 141852/300000: episode: 1370, duration: 0.852s, episode steps: 113, steps per second: 133, episode reward: -53.572, mean reward: -0.474 [-100.000,  8.108], mean action: 1.566 [0.000, 3.000],  loss: 2966.641862, mae: 986.325124, mean_q: 1351.732768, mean_eps: 0.574615
 142285/300000: episode: 1371, duration: 3.447s, episode steps: 433, steps per second: 126, episode reward: -308.465, mean reward: -0.712 [-100.000, 27.256], mean action: 1.695 [0.000, 3.000],  loss: 4322.975677, mae: 1014.994072, mean_q: 1388.333954, mean_eps: 0.573796
 142383/300000: episode: 1372, duration: 0.668s, episode steps:  98, steps per second: 147, episode reward: -141.112, mean reward: -1.440 [-100.000,  8.378], mean action: 1.561 [0.000, 3.000],  loss: 4303.845793, mae: 1017.115012, mean_q: 1387.973283, mean_eps: 0.572999
 142487/300000: episode: 1373, duration: 0.678s, episode steps: 104, steps per second: 153, episode reward: -80.714, mean reward: -0.776 [-100.000, 15.937], mean action: 1.683 [0.000, 3.000],  loss: 4946.860415, mae: 1031.121992, mean_q: 1410.194027, mean_eps: 0.572696
 142594/300000: episode: 1374, duration: 0.746s, episode steps: 107, steps per second: 143, episode reward: -30.067, mean reward: -0.281 [-100.000,  8.802], mean action: 1.748 [0.000, 3.000],  loss: 4462.401723, mae: 1033.014014, mean_q: 1410.649403, mean_eps: 0.572380
 142845/300000: episode: 1375, duration: 1.689s, episode steps: 251, steps per second: 149, episode reward: -280.888, mean reward: -1.119 [-100.000, 50.043], mean action: 1.637 [0.000, 3.000],  loss: 3859.372251, mae: 1033.316127, mean_q: 1412.527513, mean_eps: 0.571843
 142997/300000: episode: 1376, duration: 1.005s, episode steps: 152, steps per second: 151, episode reward: -82.546, mean reward: -0.543 [-100.000, 10.877], mean action: 1.671 [0.000, 3.000],  loss: 4683.568411, mae: 1026.628615, mean_q: 1402.134947, mean_eps: 0.571238
 143129/300000: episode: 1377, duration: 0.853s, episode steps: 132, steps per second: 155, episode reward: -242.643, mean reward: -1.838 [-100.000, 30.573], mean action: 1.667 [0.000, 3.000],  loss: 4642.477005, mae: 1023.187933, mean_q: 1396.761340, mean_eps: 0.570813
 143224/300000: episode: 1378, duration: 0.640s, episode steps:  95, steps per second: 148, episode reward: -117.872, mean reward: -1.241 [-100.000, 40.908], mean action: 1.653 [0.000, 3.000],  loss: 4015.224082, mae: 1010.486832, mean_q: 1377.235077, mean_eps: 0.570472
 143398/300000: episode: 1379, duration: 1.163s, episode steps: 174, steps per second: 150, episode reward:  1.092, mean reward:  0.006 [-100.000, 37.891], mean action: 1.684 [0.000, 3.000],  loss: 3341.159697, mae: 1032.458486, mean_q: 1408.892575, mean_eps: 0.570068
 143499/300000: episode: 1380, duration: 0.681s, episode steps: 101, steps per second: 148, episode reward: -148.745, mean reward: -1.473 [-100.000,  9.525], mean action: 1.564 [0.000, 3.000],  loss: 3987.996578, mae: 1043.255508, mean_q: 1423.591214, mean_eps: 0.569656
 143594/300000: episode: 1381, duration: 0.624s, episode steps:  95, steps per second: 152, episode reward: -47.191, mean reward: -0.497 [-100.000, 21.763], mean action: 1.726 [0.000, 3.000],  loss: 3730.211647, mae: 1059.046489, mean_q: 1445.519254, mean_eps: 0.569362
 143728/300000: episode: 1382, duration: 0.862s, episode steps: 134, steps per second: 155, episode reward: -52.223, mean reward: -0.390 [-100.000, 12.265], mean action: 1.851 [0.000, 3.000],  loss: 3433.214245, mae: 1054.508218, mean_q: 1436.922397, mean_eps: 0.569018
 143899/300000: episode: 1383, duration: 1.156s, episode steps: 171, steps per second: 148, episode reward:  7.414, mean reward:  0.043 [-100.000, 58.210], mean action: 1.772 [0.000, 3.000],  loss: 3834.948984, mae: 1036.610957, mean_q: 1414.036407, mean_eps: 0.568561
 144013/300000: episode: 1384, duration: 0.736s, episode steps: 114, steps per second: 155, episode reward: -48.048, mean reward: -0.421 [-100.000, 60.440], mean action: 1.596 [0.000, 3.000],  loss: 4299.259563, mae: 1055.286524, mean_q: 1439.668340, mean_eps: 0.568133
 144175/300000: episode: 1385, duration: 1.146s, episode steps: 162, steps per second: 141, episode reward: -22.702, mean reward: -0.140 [-100.000, 12.387], mean action: 1.611 [0.000, 3.000],  loss: 3509.395521, mae: 1059.370355, mean_q: 1442.452749, mean_eps: 0.567720
 144279/300000: episode: 1386, duration: 0.675s, episode steps: 104, steps per second: 154, episode reward: -37.880, mean reward: -0.364 [-100.000, 11.709], mean action: 1.808 [0.000, 3.000],  loss: 3240.280910, mae: 1055.678446, mean_q: 1437.550055, mean_eps: 0.567321
 144665/300000: episode: 1387, duration: 2.769s, episode steps: 386, steps per second: 139, episode reward: -258.524, mean reward: -0.670 [-100.000, 88.771], mean action: 1.655 [0.000, 3.000],  loss: 4249.774398, mae: 1057.292900, mean_q: 1441.170780, mean_eps: 0.566585
 144746/300000: episode: 1388, duration: 0.600s, episode steps:  81, steps per second: 135, episode reward: -121.531, mean reward: -1.500 [-100.000,  9.486], mean action: 1.728 [0.000, 3.000],  loss: 3685.088657, mae: 1067.492169, mean_q: 1455.677875, mean_eps: 0.565885
 144851/300000: episode: 1389, duration: 0.762s, episode steps: 105, steps per second: 138, episode reward: -14.026, mean reward: -0.134 [-100.000, 18.070], mean action: 1.762 [0.000, 3.000],  loss: 5565.525318, mae: 1072.463530, mean_q: 1460.438008, mean_eps: 0.565606
 144940/300000: episode: 1390, duration: 0.596s, episode steps:  89, steps per second: 149, episode reward: -97.485, mean reward: -1.095 [-100.000,  8.992], mean action: 1.551 [0.000, 3.000],  loss: 3330.126433, mae: 1058.947447, mean_q: 1443.928257, mean_eps: 0.565315
 145161/300000: episode: 1391, duration: 1.489s, episode steps: 221, steps per second: 148, episode reward: -198.186, mean reward: -0.897 [-100.000, 56.051], mean action: 1.674 [0.000, 3.000],  loss: 5067.565867, mae: 1078.773673, mean_q: 1472.070468, mean_eps: 0.564850
 145264/300000: episode: 1392, duration: 0.683s, episode steps: 103, steps per second: 151, episode reward: -72.170, mean reward: -0.701 [-100.000, 14.469], mean action: 1.602 [0.000, 3.000],  loss: 5176.275593, mae: 1087.780573, mean_q: 1480.392630, mean_eps: 0.564364
 145376/300000: episode: 1393, duration: 0.733s, episode steps: 112, steps per second: 153, episode reward: -68.231, mean reward: -0.609 [-100.000, 34.371], mean action: 1.830 [0.000, 3.000],  loss: 4770.291998, mae: 1065.632041, mean_q: 1452.725899, mean_eps: 0.564041
 145500/300000: episode: 1394, duration: 0.857s, episode steps: 124, steps per second: 145, episode reward: -307.646, mean reward: -2.481 [-100.000, 73.807], mean action: 1.565 [0.000, 3.000],  loss: 5435.464698, mae: 1067.762806, mean_q: 1454.727207, mean_eps: 0.563688
 145592/300000: episode: 1395, duration: 0.603s, episode steps:  92, steps per second: 152, episode reward:  2.368, mean reward:  0.026 [-100.000, 18.096], mean action: 1.783 [0.000, 3.000],  loss: 3497.629321, mae: 1070.605906, mean_q: 1459.984341, mean_eps: 0.563363
 145740/300000: episode: 1396, duration: 1.001s, episode steps: 148, steps per second: 148, episode reward: -82.810, mean reward: -0.560 [-100.000, 10.113], mean action: 1.716 [0.000, 3.000],  loss: 4094.039642, mae: 1056.777111, mean_q: 1442.930690, mean_eps: 0.563004
 145869/300000: episode: 1397, duration: 0.858s, episode steps: 129, steps per second: 150, episode reward: -14.925, mean reward: -0.116 [-100.000, 16.492], mean action: 1.558 [0.000, 3.000],  loss: 4691.494101, mae: 1043.910309, mean_q: 1422.826368, mean_eps: 0.562588
 146032/300000: episode: 1398, duration: 1.100s, episode steps: 163, steps per second: 148, episode reward: -209.191, mean reward: -1.283 [-100.000, 20.664], mean action: 1.755 [0.000, 3.000],  loss: 4090.456534, mae: 1044.462778, mean_q: 1426.781188, mean_eps: 0.562150
 146118/300000: episode: 1399, duration: 0.579s, episode steps:  86, steps per second: 148, episode reward: -21.040, mean reward: -0.245 [-100.000,  6.153], mean action: 1.605 [0.000, 3.000],  loss: 4083.919949, mae: 1061.321453, mean_q: 1444.853548, mean_eps: 0.561777
 146202/300000: episode: 1400, duration: 0.540s, episode steps:  84, steps per second: 156, episode reward: -61.098, mean reward: -0.727 [-100.000,  8.709], mean action: 1.714 [0.000, 3.000],  loss: 6019.456971, mae: 1048.629755, mean_q: 1428.858676, mean_eps: 0.561522
 146302/300000: episode: 1401, duration: 0.654s, episode steps: 100, steps per second: 153, episode reward: -83.516, mean reward: -0.835 [-100.000, 16.024], mean action: 1.610 [0.000, 3.000],  loss: 3894.785090, mae: 1047.354270, mean_q: 1427.863705, mean_eps: 0.561246
 146404/300000: episode: 1402, duration: 0.716s, episode steps: 102, steps per second: 142, episode reward: -122.094, mean reward: -1.197 [-100.000, 15.557], mean action: 1.657 [0.000, 3.000],  loss: 4658.501576, mae: 1048.960033, mean_q: 1428.705034, mean_eps: 0.560943
 146527/300000: episode: 1403, duration: 0.797s, episode steps: 123, steps per second: 154, episode reward: -120.368, mean reward: -0.979 [-100.000, 11.669], mean action: 1.748 [0.000, 3.000],  loss: 3949.444112, mae: 1050.410100, mean_q: 1432.470554, mean_eps: 0.560605
 146634/300000: episode: 1404, duration: 0.682s, episode steps: 107, steps per second: 157, episode reward: -122.576, mean reward: -1.146 [-100.000, 10.055], mean action: 1.636 [0.000, 3.000],  loss: 4202.212395, mae: 1042.205153, mean_q: 1421.624169, mean_eps: 0.560260
 146725/300000: episode: 1405, duration: 0.624s, episode steps:  91, steps per second: 146, episode reward: -64.920, mean reward: -0.713 [-100.000, 10.277], mean action: 1.758 [0.000, 3.000],  loss: 3003.207581, mae: 1049.668081, mean_q: 1430.950600, mean_eps: 0.559963
 146883/300000: episode: 1406, duration: 1.047s, episode steps: 158, steps per second: 151, episode reward: -184.076, mean reward: -1.165 [-100.000, 43.859], mean action: 1.620 [0.000, 3.000],  loss: 4161.058669, mae: 1057.806274, mean_q: 1442.158330, mean_eps: 0.559589
 146980/300000: episode: 1407, duration: 0.620s, episode steps:  97, steps per second: 157, episode reward: -90.765, mean reward: -0.936 [-100.000, 11.749], mean action: 1.660 [0.000, 3.000],  loss: 4628.814511, mae: 1059.261351, mean_q: 1442.697780, mean_eps: 0.559207
 147073/300000: episode: 1408, duration: 0.658s, episode steps:  93, steps per second: 141, episode reward: -3.376, mean reward: -0.036 [-100.000, 29.012], mean action: 1.882 [0.000, 3.000],  loss: 3582.818249, mae: 1051.681790, mean_q: 1434.728795, mean_eps: 0.558922
 147181/300000: episode: 1409, duration: 0.691s, episode steps: 108, steps per second: 156, episode reward: -109.796, mean reward: -1.017 [-100.000,  5.832], mean action: 1.491 [0.000, 3.000],  loss: 4176.792686, mae: 1054.631718, mean_q: 1437.789824, mean_eps: 0.558621
 147293/300000: episode: 1410, duration: 0.721s, episode steps: 112, steps per second: 155, episode reward: -161.539, mean reward: -1.442 [-100.000, 43.263], mean action: 1.652 [0.000, 3.000],  loss: 4359.900166, mae: 1042.210706, mean_q: 1422.331432, mean_eps: 0.558291
 147383/300000: episode: 1411, duration: 0.641s, episode steps:  90, steps per second: 140, episode reward: -437.607, mean reward: -4.862 [-100.000,  0.416], mean action: 2.011 [0.000, 3.000],  loss: 4289.880722, mae: 1040.221485, mean_q: 1416.217989, mean_eps: 0.557987
 147469/300000: episode: 1412, duration: 0.555s, episode steps:  86, steps per second: 155, episode reward: -38.481, mean reward: -0.447 [-100.000, 11.067], mean action: 1.616 [0.000, 3.000],  loss: 4431.439508, mae: 1051.377017, mean_q: 1431.072223, mean_eps: 0.557724
 147564/300000: episode: 1413, duration: 0.619s, episode steps:  95, steps per second: 154, episode reward: -51.274, mean reward: -0.540 [-100.000, 18.299], mean action: 1.674 [0.000, 3.000],  loss: 4891.193709, mae: 1059.136320, mean_q: 1445.090454, mean_eps: 0.557452
 147680/300000: episode: 1414, duration: 0.827s, episode steps: 116, steps per second: 140, episode reward: -99.962, mean reward: -0.862 [-100.000,  7.015], mean action: 1.552 [0.000, 3.000],  loss: 3562.032646, mae: 1055.710437, mean_q: 1439.451099, mean_eps: 0.557136
 147758/300000: episode: 1415, duration: 0.575s, episode steps:  78, steps per second: 136, episode reward: -50.526, mean reward: -0.648 [-100.000,  8.881], mean action: 1.782 [0.000, 3.000],  loss: 4342.593471, mae: 1069.169128, mean_q: 1455.079939, mean_eps: 0.556845
 147872/300000: episode: 1416, duration: 0.926s, episode steps: 114, steps per second: 123, episode reward: -58.509, mean reward: -0.513 [-100.000, 27.793], mean action: 1.728 [0.000, 3.000],  loss: 3720.783781, mae: 1050.885275, mean_q: 1429.927036, mean_eps: 0.556557
 147998/300000: episode: 1417, duration: 1.032s, episode steps: 126, steps per second: 122, episode reward: -46.873, mean reward: -0.372 [-100.000, 38.459], mean action: 1.667 [0.000, 3.000],  loss: 3954.218336, mae: 1057.063718, mean_q: 1440.199962, mean_eps: 0.556196
 148107/300000: episode: 1418, duration: 0.764s, episode steps: 109, steps per second: 143, episode reward: -78.704, mean reward: -0.722 [-100.000, 11.330], mean action: 1.633 [0.000, 3.000],  loss: 4408.045729, mae: 1048.517428, mean_q: 1426.213714, mean_eps: 0.555844
 149107/300000: episode: 1419, duration: 7.812s, episode steps: 1000, steps per second: 128, episode reward: -6.122, mean reward: -0.006 [-20.971, 21.739], mean action: 1.574 [0.000, 3.000],  loss: 3868.786043, mae: 1076.752214, mean_q: 1464.213419, mean_eps: 0.554181
 149235/300000: episode: 1420, duration: 0.817s, episode steps: 128, steps per second: 157, episode reward: -91.991, mean reward: -0.719 [-100.000, 12.240], mean action: 1.742 [0.000, 3.000],  loss: 2865.691141, mae: 1093.591456, mean_q: 1486.480068, mean_eps: 0.552489
 149559/300000: episode: 1421, duration: 2.201s, episode steps: 324, steps per second: 147, episode reward: -90.693, mean reward: -0.280 [-100.000, 23.327], mean action: 1.660 [0.000, 3.000],  loss: 4171.031728, mae: 1100.731642, mean_q: 1496.581410, mean_eps: 0.551811
 149707/300000: episode: 1422, duration: 0.963s, episode steps: 148, steps per second: 154, episode reward: -137.064, mean reward: -0.926 [-100.000, 32.859], mean action: 1.730 [0.000, 3.000],  loss: 3764.183480, mae: 1108.628823, mean_q: 1508.152570, mean_eps: 0.551103
 149820/300000: episode: 1423, duration: 0.765s, episode steps: 113, steps per second: 148, episode reward: -45.128, mean reward: -0.399 [-100.000,  8.360], mean action: 1.372 [0.000, 3.000],  loss: 4446.723355, mae: 1093.716963, mean_q: 1486.765469, mean_eps: 0.550711
 149934/300000: episode: 1424, duration: 0.784s, episode steps: 114, steps per second: 145, episode reward: -136.408, mean reward: -1.197 [-100.000,  3.610], mean action: 1.851 [0.000, 3.000],  loss: 4178.773252, mae: 1096.598593, mean_q: 1491.650732, mean_eps: 0.550370
 150081/300000: episode: 1425, duration: 0.978s, episode steps: 147, steps per second: 150, episode reward: -52.936, mean reward: -0.360 [-100.000, 17.058], mean action: 1.612 [0.000, 3.000],  loss: 3842.993679, mae: 1086.054068, mean_q: 1475.736428, mean_eps: 0.549979
 150196/300000: episode: 1426, duration: 0.730s, episode steps: 115, steps per second: 157, episode reward: -57.513, mean reward: -0.500 [-100.000, 11.803], mean action: 1.409 [0.000, 3.000],  loss: 3653.174958, mae: 1071.276740, mean_q: 1456.611320, mean_eps: 0.549586
 150302/300000: episode: 1427, duration: 0.685s, episode steps: 106, steps per second: 155, episode reward: -59.600, mean reward: -0.562 [-100.000, 32.000], mean action: 1.462 [0.000, 3.000],  loss: 3612.072264, mae: 1090.989093, mean_q: 1482.860259, mean_eps: 0.549255
 151302/300000: episode: 1428, duration: 7.727s, episode steps: 1000, steps per second: 129, episode reward: -37.588, mean reward: -0.038 [-23.266, 20.282], mean action: 1.676 [0.000, 3.000],  loss: 3675.229311, mae: 1121.991255, mean_q: 1525.554734, mean_eps: 0.547596
 151435/300000: episode: 1429, duration: 0.945s, episode steps: 133, steps per second: 141, episode reward: -47.848, mean reward: -0.360 [-100.000,  9.762], mean action: 1.857 [0.000, 3.000],  loss: 4567.870251, mae: 1158.367518, mean_q: 1572.335014, mean_eps: 0.545896
 151549/300000: episode: 1430, duration: 0.868s, episode steps: 114, steps per second: 131, episode reward: -233.807, mean reward: -2.051 [-100.000, 38.798], mean action: 1.333 [0.000, 3.000],  loss: 2975.579610, mae: 1149.285598, mean_q: 1560.783039, mean_eps: 0.545525
 151675/300000: episode: 1431, duration: 0.884s, episode steps: 126, steps per second: 142, episode reward: -59.162, mean reward: -0.470 [-100.000, 18.566], mean action: 1.651 [0.000, 3.000],  loss: 3144.704603, mae: 1135.546641, mean_q: 1542.121948, mean_eps: 0.545166
 151812/300000: episode: 1432, duration: 0.962s, episode steps: 137, steps per second: 142, episode reward: -29.995, mean reward: -0.219 [-100.000,  9.107], mean action: 1.796 [0.000, 3.000],  loss: 3543.551773, mae: 1145.664993, mean_q: 1555.738403, mean_eps: 0.544771
 151957/300000: episode: 1433, duration: 0.969s, episode steps: 145, steps per second: 150, episode reward: -26.377, mean reward: -0.182 [-100.000, 16.423], mean action: 1.586 [0.000, 3.000],  loss: 2468.598688, mae: 1127.540095, mean_q: 1530.593985, mean_eps: 0.544348
 152289/300000: episode: 1434, duration: 2.240s, episode steps: 332, steps per second: 148, episode reward: -228.870, mean reward: -0.689 [-100.000, 20.969], mean action: 1.678 [0.000, 3.000],  loss: 3778.568996, mae: 1144.443661, mean_q: 1553.509452, mean_eps: 0.543633
 152399/300000: episode: 1435, duration: 0.723s, episode steps: 110, steps per second: 152, episode reward: -95.979, mean reward: -0.873 [-100.000, 10.310], mean action: 1.745 [0.000, 3.000],  loss: 3166.313756, mae: 1163.013693, mean_q: 1577.487588, mean_eps: 0.542969
 152498/300000: episode: 1436, duration: 0.677s, episode steps:  99, steps per second: 146, episode reward:  7.824, mean reward:  0.079 [-100.000, 16.228], mean action: 1.596 [0.000, 3.000],  loss: 3489.720194, mae: 1139.689550, mean_q: 1544.110031, mean_eps: 0.542656
 152569/300000: episode: 1437, duration: 0.463s, episode steps:  71, steps per second: 153, episode reward: -134.821, mean reward: -1.899 [-100.000,  6.335], mean action: 1.817 [0.000, 3.000],  loss: 5026.303902, mae: 1149.728622, mean_q: 1560.089125, mean_eps: 0.542401
 152685/300000: episode: 1438, duration: 0.752s, episode steps: 116, steps per second: 154, episode reward: -94.655, mean reward: -0.816 [-100.000, 12.210], mean action: 1.638 [0.000, 3.000],  loss: 4443.069272, mae: 1140.325473, mean_q: 1544.822892, mean_eps: 0.542121
 153685/300000: episode: 1439, duration: 7.409s, episode steps: 1000, steps per second: 135, episode reward: 27.888, mean reward:  0.028 [-24.099, 46.911], mean action: 1.595 [0.000, 3.000],  loss: 3613.229659, mae: 1153.889523, mean_q: 1562.711776, mean_eps: 0.540446
 153839/300000: episode: 1440, duration: 0.990s, episode steps: 154, steps per second: 156, episode reward: -14.081, mean reward: -0.091 [-100.000, 34.802], mean action: 1.799 [0.000, 3.000],  loss: 4609.445070, mae: 1179.879677, mean_q: 1596.147837, mean_eps: 0.538716
 153969/300000: episode: 1441, duration: 0.884s, episode steps: 130, steps per second: 147, episode reward: -111.000, mean reward: -0.854 [-100.000,  8.891], mean action: 1.777 [0.000, 3.000],  loss: 3783.879320, mae: 1182.273369, mean_q: 1601.310306, mean_eps: 0.538289
 154066/300000: episode: 1442, duration: 0.658s, episode steps:  97, steps per second: 148, episode reward: -154.775, mean reward: -1.596 [-100.000, 16.126], mean action: 1.041 [0.000, 3.000],  loss: 4223.945847, mae: 1186.430664, mean_q: 1604.977392, mean_eps: 0.537949
 154185/300000: episode: 1443, duration: 0.764s, episode steps: 119, steps per second: 156, episode reward: -88.585, mean reward: -0.744 [-100.000,  8.871], mean action: 1.689 [0.000, 3.000],  loss: 4148.537008, mae: 1178.991967, mean_q: 1595.126295, mean_eps: 0.537625
 154324/300000: episode: 1444, duration: 0.932s, episode steps: 139, steps per second: 149, episode reward: -154.263, mean reward: -1.110 [-100.000, 22.776], mean action: 1.691 [0.000, 3.000],  loss: 2913.340312, mae: 1168.848272, mean_q: 1582.568796, mean_eps: 0.537238
 154436/300000: episode: 1445, duration: 0.761s, episode steps: 112, steps per second: 147, episode reward: -59.892, mean reward: -0.535 [-100.000, 17.989], mean action: 1.473 [0.000, 3.000],  loss: 3686.398560, mae: 1162.035721, mean_q: 1572.649496, mean_eps: 0.536861
 154539/300000: episode: 1446, duration: 0.674s, episode steps: 103, steps per second: 153, episode reward: -23.628, mean reward: -0.229 [-100.000, 22.649], mean action: 1.738 [0.000, 3.000],  loss: 3665.192224, mae: 1164.893405, mean_q: 1576.861861, mean_eps: 0.536539
 154652/300000: episode: 1447, duration: 0.762s, episode steps: 113, steps per second: 148, episode reward: -129.862, mean reward: -1.149 [-100.000,  5.127], mean action: 1.611 [0.000, 3.000],  loss: 4539.446298, mae: 1153.659847, mean_q: 1560.916908, mean_eps: 0.536215
 154753/300000: episode: 1448, duration: 0.664s, episode steps: 101, steps per second: 152, episode reward: -87.257, mean reward: -0.864 [-100.000,  8.455], mean action: 1.604 [0.000, 3.000],  loss: 3434.069325, mae: 1151.295278, mean_q: 1558.243443, mean_eps: 0.535894
 154833/300000: episode: 1449, duration: 0.525s, episode steps:  80, steps per second: 152, episode reward: -68.030, mean reward: -0.850 [-100.000, 11.572], mean action: 1.600 [0.000, 3.000],  loss: 3003.141349, mae: 1141.609695, mean_q: 1544.524429, mean_eps: 0.535623
 154919/300000: episode: 1450, duration: 0.593s, episode steps:  86, steps per second: 145, episode reward: -33.654, mean reward: -0.391 [-100.000, 11.827], mean action: 1.442 [0.000, 3.000],  loss: 2683.570091, mae: 1143.804855, mean_q: 1547.313837, mean_eps: 0.535373
 155033/300000: episode: 1451, duration: 0.753s, episode steps: 114, steps per second: 151, episode reward: -137.749, mean reward: -1.208 [-100.000,  4.188], mean action: 1.605 [0.000, 3.000],  loss: 3445.094501, mae: 1126.463190, mean_q: 1523.781582, mean_eps: 0.535073
 155126/300000: episode: 1452, duration: 0.592s, episode steps:  93, steps per second: 157, episode reward: -102.379, mean reward: -1.101 [-100.000,  9.257], mean action: 1.882 [0.000, 3.000],  loss: 2778.465823, mae: 1108.989716, mean_q: 1502.566496, mean_eps: 0.534763
 155212/300000: episode: 1453, duration: 0.559s, episode steps:  86, steps per second: 154, episode reward: -109.984, mean reward: -1.279 [-100.000,  6.685], mean action: 1.395 [0.000, 3.000],  loss: 3894.223013, mae: 1133.256981, mean_q: 1532.073965, mean_eps: 0.534495
 155370/300000: episode: 1454, duration: 1.085s, episode steps: 158, steps per second: 146, episode reward: -196.918, mean reward: -1.246 [-100.000, 36.974], mean action: 1.620 [0.000, 3.000],  loss: 2914.091772, mae: 1107.843512, mean_q: 1498.054262, mean_eps: 0.534128
 155478/300000: episode: 1455, duration: 0.715s, episode steps: 108, steps per second: 151, episode reward: -73.424, mean reward: -0.680 [-100.000,  5.803], mean action: 1.685 [0.000, 3.000],  loss: 2330.383734, mae: 1095.651818, mean_q: 1483.299299, mean_eps: 0.533729
 155627/300000: episode: 1456, duration: 1.008s, episode steps: 149, steps per second: 148, episode reward: -94.126, mean reward: -0.632 [-100.000, 16.811], mean action: 1.725 [0.000, 3.000],  loss: 2403.316126, mae: 1105.539625, mean_q: 1494.706836, mean_eps: 0.533344
 155704/300000: episode: 1457, duration: 0.494s, episode steps:  77, steps per second: 156, episode reward: -9.455, mean reward: -0.123 [-100.000, 16.938], mean action: 1.688 [0.000, 3.000],  loss: 2460.078411, mae: 1097.791804, mean_q: 1485.201999, mean_eps: 0.533005
 155832/300000: episode: 1458, duration: 0.823s, episode steps: 128, steps per second: 156, episode reward:  5.879, mean reward:  0.046 [-100.000, 13.013], mean action: 1.812 [0.000, 3.000],  loss: 3411.840219, mae: 1094.649977, mean_q: 1479.217255, mean_eps: 0.532698
 155959/300000: episode: 1459, duration: 0.883s, episode steps: 127, steps per second: 144, episode reward: -97.247, mean reward: -0.766 [-100.000,  5.926], mean action: 1.717 [0.000, 3.000],  loss: 1331.044150, mae: 1099.936830, mean_q: 1489.828705, mean_eps: 0.532315
 156119/300000: episode: 1460, duration: 1.025s, episode steps: 160, steps per second: 156, episode reward: -447.522, mean reward: -2.797 [-100.000, 44.136], mean action: 1.631 [0.000, 3.000],  loss: 2758.694323, mae: 1097.163413, mean_q: 1483.540437, mean_eps: 0.531885
 156231/300000: episode: 1461, duration: 0.766s, episode steps: 112, steps per second: 146, episode reward: -60.138, mean reward: -0.537 [-100.000, 13.238], mean action: 1.670 [0.000, 3.000],  loss: 2818.280185, mae: 1089.309795, mean_q: 1474.360253, mean_eps: 0.531477
 156469/300000: episode: 1462, duration: 1.554s, episode steps: 238, steps per second: 153, episode reward: -150.561, mean reward: -0.633 [-100.000, 16.022], mean action: 1.605 [0.000, 3.000],  loss: 2445.643709, mae: 1097.575976, mean_q: 1485.069359, mean_eps: 0.530951
 156614/300000: episode: 1463, duration: 0.971s, episode steps: 145, steps per second: 149, episode reward: -174.798, mean reward: -1.206 [-100.000,  7.491], mean action: 1.676 [0.000, 3.000],  loss: 2818.261990, mae: 1085.253225, mean_q: 1467.406367, mean_eps: 0.530377
 156720/300000: episode: 1464, duration: 0.689s, episode steps: 106, steps per second: 154, episode reward: 28.554, mean reward:  0.269 [-100.000, 15.027], mean action: 1.802 [0.000, 3.000],  loss: 2129.223600, mae: 1069.660832, mean_q: 1447.393030, mean_eps: 0.530000
 156854/300000: episode: 1465, duration: 0.893s, episode steps: 134, steps per second: 150, episode reward: -71.841, mean reward: -0.536 [-100.000,  7.079], mean action: 1.813 [0.000, 3.000],  loss: 2105.882949, mae: 1058.156987, mean_q: 1431.778655, mean_eps: 0.529640
 156967/300000: episode: 1466, duration: 0.795s, episode steps: 113, steps per second: 142, episode reward: -20.444, mean reward: -0.181 [-100.000, 17.092], mean action: 1.301 [0.000, 3.000],  loss: 2184.958370, mae: 1056.495927, mean_q: 1427.152025, mean_eps: 0.529270
 157030/300000: episode: 1467, duration: 0.414s, episode steps:  63, steps per second: 152, episode reward: -29.562, mean reward: -0.469 [-100.000, 12.009], mean action: 1.651 [0.000, 3.000],  loss: 3052.095964, mae: 1052.848219, mean_q: 1423.959899, mean_eps: 0.529006
 157125/300000: episode: 1468, duration: 0.622s, episode steps:  95, steps per second: 153, episode reward: -67.722, mean reward: -0.713 [-100.000, 11.330], mean action: 1.516 [0.000, 3.000],  loss: 2494.360834, mae: 1055.841625, mean_q: 1426.684850, mean_eps: 0.528769
 157536/300000: episode: 1469, duration: 3.119s, episode steps: 411, steps per second: 132, episode reward: -12.244, mean reward: -0.030 [-100.000, 16.668], mean action: 1.591 [0.000, 3.000],  loss: 2265.126436, mae: 1042.500089, mean_q: 1410.142512, mean_eps: 0.528010
 157648/300000: episode: 1470, duration: 0.820s, episode steps: 112, steps per second: 137, episode reward: -91.147, mean reward: -0.814 [-100.000,  9.951], mean action: 1.812 [0.000, 3.000],  loss: 2050.962727, mae: 1025.227699, mean_q: 1387.722189, mean_eps: 0.527226
 157793/300000: episode: 1471, duration: 1.010s, episode steps: 145, steps per second: 143, episode reward: -190.426, mean reward: -1.313 [-100.000, 34.239], mean action: 1.628 [0.000, 3.000],  loss: 2255.992874, mae: 1042.759493, mean_q: 1411.460871, mean_eps: 0.526840
 157906/300000: episode: 1472, duration: 0.750s, episode steps: 113, steps per second: 151, episode reward: -23.218, mean reward: -0.205 [-100.000, 10.543], mean action: 1.673 [0.000, 3.000],  loss: 2624.194964, mae: 1038.272084, mean_q: 1404.109457, mean_eps: 0.526453
 158066/300000: episode: 1473, duration: 1.072s, episode steps: 160, steps per second: 149, episode reward: -22.095, mean reward: -0.138 [-100.000, 15.793], mean action: 1.800 [0.000, 3.000],  loss: 2246.988817, mae: 1042.953400, mean_q: 1410.413755, mean_eps: 0.526043
 158153/300000: episode: 1474, duration: 0.621s, episode steps:  87, steps per second: 140, episode reward: -24.073, mean reward: -0.277 [-100.000, 20.984], mean action: 1.632 [0.000, 3.000],  loss: 1958.072815, mae: 1034.875869, mean_q: 1400.728799, mean_eps: 0.525673
 158244/300000: episode: 1475, duration: 0.592s, episode steps:  91, steps per second: 154, episode reward: -85.280, mean reward: -0.937 [-100.000, 12.008], mean action: 1.648 [0.000, 3.000],  loss: 2265.723985, mae: 1029.099295, mean_q: 1391.110323, mean_eps: 0.525406
 158373/300000: episode: 1476, duration: 0.844s, episode steps: 129, steps per second: 153, episode reward: -333.223, mean reward: -2.583 [-100.000, 40.978], mean action: 1.721 [0.000, 3.000],  loss: 2236.390129, mae: 1024.369759, mean_q: 1387.787770, mean_eps: 0.525076
 158484/300000: episode: 1477, duration: 0.795s, episode steps: 111, steps per second: 140, episode reward: -46.270, mean reward: -0.417 [-100.000, 10.442], mean action: 1.703 [0.000, 3.000],  loss: 2170.546078, mae: 1029.912806, mean_q: 1393.885761, mean_eps: 0.524716
 158602/300000: episode: 1478, duration: 0.763s, episode steps: 118, steps per second: 155, episode reward: -87.575, mean reward: -0.742 [-100.000,  7.812], mean action: 1.949 [0.000, 3.000],  loss: 2056.123542, mae: 1013.435794, mean_q: 1370.508796, mean_eps: 0.524373
 158815/300000: episode: 1479, duration: 1.415s, episode steps: 213, steps per second: 151, episode reward: -178.300, mean reward: -0.837 [-100.000, 38.773], mean action: 1.714 [0.000, 3.000],  loss: 1796.712342, mae: 1008.985599, mean_q: 1365.025644, mean_eps: 0.523876
 158914/300000: episode: 1480, duration: 0.666s, episode steps:  99, steps per second: 149, episode reward: -56.970, mean reward: -0.575 [-100.000, 18.052], mean action: 1.717 [0.000, 3.000],  loss: 2298.782777, mae: 996.055229, mean_q: 1349.622295, mean_eps: 0.523408
 159005/300000: episode: 1481, duration: 0.630s, episode steps:  91, steps per second: 145, episode reward: -71.262, mean reward: -0.783 [-100.000,  6.420], mean action: 1.802 [0.000, 3.000],  loss: 2375.644666, mae: 995.624711, mean_q: 1346.877974, mean_eps: 0.523123
 159154/300000: episode: 1482, duration: 1.026s, episode steps: 149, steps per second: 145, episode reward: -77.054, mean reward: -0.517 [-100.000, 13.061], mean action: 1.792 [0.000, 3.000],  loss: 2204.027545, mae: 1000.679897, mean_q: 1354.449106, mean_eps: 0.522763
 159305/300000: episode: 1483, duration: 0.972s, episode steps: 151, steps per second: 155, episode reward: 32.519, mean reward:  0.215 [-100.000, 16.302], mean action: 1.404 [0.000, 3.000],  loss: 2432.240429, mae: 994.730195, mean_q: 1344.867869, mean_eps: 0.522313
 159411/300000: episode: 1484, duration: 0.726s, episode steps: 106, steps per second: 146, episode reward: -121.849, mean reward: -1.150 [-100.000,  9.947], mean action: 1.566 [0.000, 3.000],  loss: 2375.586080, mae: 976.811864, mean_q: 1321.842973, mean_eps: 0.521927
 159544/300000: episode: 1485, duration: 0.854s, episode steps: 133, steps per second: 156, episode reward: -6.768, mean reward: -0.051 [-100.000, 14.498], mean action: 1.752 [0.000, 3.000],  loss: 1771.321463, mae: 980.634877, mean_q: 1326.603262, mean_eps: 0.521569
 159624/300000: episode: 1486, duration: 0.532s, episode steps:  80, steps per second: 150, episode reward: -40.037, mean reward: -0.500 [-100.000, 16.628], mean action: 1.762 [0.000, 3.000],  loss: 2338.465817, mae: 972.597718, mean_q: 1313.840527, mean_eps: 0.521250
 159702/300000: episode: 1487, duration: 0.523s, episode steps:  78, steps per second: 149, episode reward: -21.561, mean reward: -0.276 [-100.000, 17.042], mean action: 1.577 [0.000, 3.000],  loss: 1711.659472, mae: 977.957243, mean_q: 1323.457069, mean_eps: 0.521012
 159818/300000: episode: 1488, duration: 0.771s, episode steps: 116, steps per second: 151, episode reward: -36.852, mean reward: -0.318 [-100.000,  9.601], mean action: 1.353 [0.000, 3.000],  loss: 1853.683596, mae: 973.395329, mean_q: 1317.939057, mean_eps: 0.520722
 159949/300000: episode: 1489, duration: 0.851s, episode steps: 131, steps per second: 154, episode reward: -102.112, mean reward: -0.779 [-100.000,  8.189], mean action: 1.924 [0.000, 3.000],  loss: 2337.076762, mae: 966.530508, mean_q: 1306.292870, mean_eps: 0.520351
 160045/300000: episode: 1490, duration: 0.650s, episode steps:  96, steps per second: 148, episode reward: -64.016, mean reward: -0.667 [-100.000,  5.933], mean action: 1.854 [0.000, 3.000],  loss: 2467.100249, mae: 958.419703, mean_q: 1294.164457, mean_eps: 0.520011
 160177/300000: episode: 1491, duration: 0.872s, episode steps: 132, steps per second: 151, episode reward: 29.791, mean reward:  0.226 [-100.000, 19.674], mean action: 1.417 [0.000, 3.000],  loss: 1797.000435, mae: 964.635413, mean_q: 1305.598145, mean_eps: 0.519668
 160322/300000: episode: 1492, duration: 0.935s, episode steps: 145, steps per second: 155, episode reward: -9.809, mean reward: -0.068 [-100.000, 19.955], mean action: 1.593 [0.000, 3.000],  loss: 1659.688378, mae: 956.122948, mean_q: 1290.130064, mean_eps: 0.519253
 160419/300000: episode: 1493, duration: 0.671s, episode steps:  97, steps per second: 145, episode reward: -67.402, mean reward: -0.695 [-100.000, 41.967], mean action: 1.773 [0.000, 3.000],  loss: 2343.095700, mae: 939.168410, mean_q: 1269.782628, mean_eps: 0.518890
 160503/300000: episode: 1494, duration: 0.553s, episode steps:  84, steps per second: 152, episode reward: -132.688, mean reward: -1.580 [-100.000, 16.517], mean action: 1.667 [0.000, 3.000],  loss: 1812.026834, mae: 941.675654, mean_q: 1271.921871, mean_eps: 0.518618
 160603/300000: episode: 1495, duration: 0.641s, episode steps: 100, steps per second: 156, episode reward: -63.057, mean reward: -0.631 [-100.000,  9.043], mean action: 1.620 [0.000, 3.000],  loss: 1934.591848, mae: 938.903475, mean_q: 1268.244353, mean_eps: 0.518342
 160711/300000: episode: 1496, duration: 0.883s, episode steps: 108, steps per second: 122, episode reward: -77.590, mean reward: -0.718 [-100.000,  7.844], mean action: 1.676 [0.000, 3.000],  loss: 2290.520615, mae: 940.778606, mean_q: 1270.982354, mean_eps: 0.518030
 160819/300000: episode: 1497, duration: 0.945s, episode steps: 108, steps per second: 114, episode reward: -8.664, mean reward: -0.080 [-100.000, 19.771], mean action: 1.630 [0.000, 3.000],  loss: 2432.479173, mae: 939.941276, mean_q: 1269.041364, mean_eps: 0.517707
 160973/300000: episode: 1498, duration: 1.226s, episode steps: 154, steps per second: 126, episode reward: -155.350, mean reward: -1.009 [-100.000, 10.554], mean action: 1.792 [0.000, 3.000],  loss: 2151.730388, mae: 930.463836, mean_q: 1255.874130, mean_eps: 0.517313
 161087/300000: episode: 1499, duration: 0.882s, episode steps: 114, steps per second: 129, episode reward: -48.608, mean reward: -0.426 [-100.000,  7.815], mean action: 1.623 [0.000, 3.000],  loss: 2153.812696, mae: 925.737555, mean_q: 1250.237887, mean_eps: 0.516911
 161246/300000: episode: 1500, duration: 1.196s, episode steps: 159, steps per second: 133, episode reward: -192.203, mean reward: -1.209 [-100.000, 16.592], mean action: 1.786 [0.000, 3.000],  loss: 1771.250199, mae: 919.193156, mean_q: 1243.403855, mean_eps: 0.516502
 161373/300000: episode: 1501, duration: 0.880s, episode steps: 127, steps per second: 144, episode reward: -73.182, mean reward: -0.576 [-100.000,  6.053], mean action: 1.795 [0.000, 3.000],  loss: 2067.536418, mae: 911.754443, mean_q: 1231.672404, mean_eps: 0.516073
 161473/300000: episode: 1502, duration: 0.667s, episode steps: 100, steps per second: 150, episode reward: 28.811, mean reward:  0.288 [-100.000, 19.751], mean action: 1.580 [0.000, 3.000],  loss: 1087.378728, mae: 913.084984, mean_q: 1233.873917, mean_eps: 0.515733
 161601/300000: episode: 1503, duration: 0.865s, episode steps: 128, steps per second: 148, episode reward: -18.694, mean reward: -0.146 [-100.000, 15.217], mean action: 1.711 [0.000, 3.000],  loss: 2278.686418, mae: 923.931146, mean_q: 1248.713336, mean_eps: 0.515390
 161699/300000: episode: 1504, duration: 0.663s, episode steps:  98, steps per second: 148, episode reward: -56.832, mean reward: -0.580 [-100.000,  7.904], mean action: 1.592 [0.000, 3.000],  loss: 2074.555853, mae: 927.620859, mean_q: 1253.621530, mean_eps: 0.515052
 161808/300000: episode: 1505, duration: 0.706s, episode steps: 109, steps per second: 154, episode reward: -73.566, mean reward: -0.675 [-100.000,  6.378], mean action: 1.615 [0.000, 3.000],  loss: 1838.576993, mae: 930.895354, mean_q: 1259.162799, mean_eps: 0.514741
 161904/300000: episode: 1506, duration: 0.677s, episode steps:  96, steps per second: 142, episode reward: -55.072, mean reward: -0.574 [-100.000, 12.537], mean action: 1.427 [0.000, 3.000],  loss: 2181.300316, mae: 920.191298, mean_q: 1242.794771, mean_eps: 0.514433
 162014/300000: episode: 1507, duration: 0.738s, episode steps: 110, steps per second: 149, episode reward: -97.101, mean reward: -0.883 [-100.000,  6.219], mean action: 1.527 [0.000, 3.000],  loss: 1890.656206, mae: 916.805227, mean_q: 1239.615882, mean_eps: 0.514125
 162120/300000: episode: 1508, duration: 0.679s, episode steps: 106, steps per second: 156, episode reward: -74.497, mean reward: -0.703 [-100.000,  6.000], mean action: 1.736 [0.000, 3.000],  loss: 1411.786432, mae: 915.706554, mean_q: 1239.974522, mean_eps: 0.513800
 162236/300000: episode: 1509, duration: 0.832s, episode steps: 116, steps per second: 139, episode reward: -52.088, mean reward: -0.449 [-100.000,  6.124], mean action: 1.802 [0.000, 3.000],  loss: 1685.950012, mae: 903.316391, mean_q: 1222.098190, mean_eps: 0.513467
 162336/300000: episode: 1510, duration: 0.654s, episode steps: 100, steps per second: 153, episode reward: -40.045, mean reward: -0.400 [-100.000,  8.228], mean action: 1.780 [0.000, 3.000],  loss: 2018.297018, mae: 909.963749, mean_q: 1230.272426, mean_eps: 0.513144
 162459/300000: episode: 1511, duration: 0.791s, episode steps: 123, steps per second: 156, episode reward: -95.415, mean reward: -0.776 [-100.000, 12.542], mean action: 1.675 [0.000, 3.000],  loss: 1677.080248, mae: 909.350870, mean_q: 1229.731815, mean_eps: 0.512809
 162571/300000: episode: 1512, duration: 0.777s, episode steps: 112, steps per second: 144, episode reward: -20.074, mean reward: -0.179 [-100.000, 17.493], mean action: 1.598 [0.000, 3.000],  loss: 2181.256301, mae: 903.906883, mean_q: 1223.011665, mean_eps: 0.512456
 162744/300000: episode: 1513, duration: 1.139s, episode steps: 173, steps per second: 152, episode reward: -15.714, mean reward: -0.091 [-100.000, 10.786], mean action: 1.873 [0.000, 3.000],  loss: 1669.712043, mae: 900.054114, mean_q: 1218.576324, mean_eps: 0.512029
 162821/300000: episode: 1514, duration: 0.526s, episode steps:  77, steps per second: 146, episode reward: -33.386, mean reward: -0.434 [-100.000, 10.052], mean action: 1.571 [0.000, 3.000],  loss: 1478.536082, mae: 896.387806, mean_q: 1213.510890, mean_eps: 0.511654
 162962/300000: episode: 1515, duration: 0.947s, episode steps: 141, steps per second: 149, episode reward: -28.017, mean reward: -0.199 [-100.000, 36.255], mean action: 1.660 [0.000, 3.000],  loss: 1901.525257, mae: 896.708656, mean_q: 1212.196020, mean_eps: 0.511327
 163106/300000: episode: 1516, duration: 0.923s, episode steps: 144, steps per second: 156, episode reward: -15.895, mean reward: -0.110 [-100.000, 20.930], mean action: 1.701 [0.000, 3.000],  loss: 1827.848789, mae: 896.484520, mean_q: 1213.539113, mean_eps: 0.510900
 163183/300000: episode: 1517, duration: 0.550s, episode steps:  77, steps per second: 140, episode reward: -54.472, mean reward: -0.707 [-100.000, 11.151], mean action: 1.766 [0.000, 3.000],  loss: 2007.898051, mae: 907.821849, mean_q: 1229.055176, mean_eps: 0.510568
 163308/300000: episode: 1518, duration: 0.838s, episode steps: 125, steps per second: 149, episode reward: -28.918, mean reward: -0.231 [-100.000,  8.277], mean action: 1.384 [0.000, 3.000],  loss: 1594.624945, mae: 905.852839, mean_q: 1226.442898, mean_eps: 0.510265
 163412/300000: episode: 1519, duration: 0.669s, episode steps: 104, steps per second: 155, episode reward: -53.401, mean reward: -0.513 [-100.000, 11.812], mean action: 1.577 [0.000, 3.000],  loss: 2167.615589, mae: 897.576407, mean_q: 1213.631669, mean_eps: 0.509922
 163498/300000: episode: 1520, duration: 0.594s, episode steps:  86, steps per second: 145, episode reward: -10.514, mean reward: -0.122 [-100.000, 14.258], mean action: 1.663 [0.000, 3.000],  loss: 2091.709678, mae: 896.663845, mean_q: 1213.003022, mean_eps: 0.509637
 163649/300000: episode: 1521, duration: 0.993s, episode steps: 151, steps per second: 152, episode reward: -5.302, mean reward: -0.035 [-100.000, 18.705], mean action: 1.821 [0.000, 3.000],  loss: 1301.689425, mae: 901.436255, mean_q: 1219.702745, mean_eps: 0.509281
 163774/300000: episode: 1522, duration: 0.809s, episode steps: 125, steps per second: 155, episode reward: -1.200, mean reward: -0.010 [-100.000, 13.208], mean action: 1.688 [0.000, 3.000],  loss: 1464.292174, mae: 893.374878, mean_q: 1209.114677, mean_eps: 0.508867
 163845/300000: episode: 1523, duration: 0.511s, episode steps:  71, steps per second: 139, episode reward: -23.130, mean reward: -0.326 [-100.000, 20.147], mean action: 1.437 [0.000, 3.000],  loss: 1218.223909, mae: 886.730517, mean_q: 1201.062091, mean_eps: 0.508573
 163948/300000: episode: 1524, duration: 0.674s, episode steps: 103, steps per second: 153, episode reward: -24.321, mean reward: -0.236 [-100.000, 13.458], mean action: 1.631 [0.000, 3.000],  loss: 1225.317611, mae: 880.921619, mean_q: 1191.540894, mean_eps: 0.508312
 164069/300000: episode: 1525, duration: 0.777s, episode steps: 121, steps per second: 156, episode reward: -61.299, mean reward: -0.507 [-100.000, 10.408], mean action: 1.868 [0.000, 3.000],  loss: 1687.300034, mae: 881.670611, mean_q: 1191.149425, mean_eps: 0.507976
 164222/300000: episode: 1526, duration: 1.039s, episode steps: 153, steps per second: 147, episode reward:  3.414, mean reward:  0.022 [-100.000, 18.463], mean action: 1.752 [0.000, 3.000],  loss: 1793.001194, mae: 879.531719, mean_q: 1189.209258, mean_eps: 0.507565
 164305/300000: episode: 1527, duration: 0.543s, episode steps:  83, steps per second: 153, episode reward: -54.530, mean reward: -0.657 [-100.000, 16.696], mean action: 1.759 [0.000, 3.000],  loss: 1100.442617, mae: 878.703600, mean_q: 1189.451803, mean_eps: 0.507211
 164412/300000: episode: 1528, duration: 0.697s, episode steps: 107, steps per second: 154, episode reward: -50.423, mean reward: -0.471 [-100.000,  8.445], mean action: 1.607 [0.000, 3.000],  loss: 1178.909622, mae: 863.623796, mean_q: 1169.564394, mean_eps: 0.506926
 164528/300000: episode: 1529, duration: 0.816s, episode steps: 116, steps per second: 142, episode reward: -133.870, mean reward: -1.154 [-100.000, 20.638], mean action: 1.767 [0.000, 3.000],  loss: 1190.309081, mae: 860.074058, mean_q: 1165.012102, mean_eps: 0.506592
 164670/300000: episode: 1530, duration: 0.911s, episode steps: 142, steps per second: 156, episode reward: -178.027, mean reward: -1.254 [-100.000, 20.148], mean action: 1.824 [0.000, 3.000],  loss: 1191.599071, mae: 862.550460, mean_q: 1168.301592, mean_eps: 0.506205
 164767/300000: episode: 1531, duration: 0.639s, episode steps:  97, steps per second: 152, episode reward: -11.092, mean reward: -0.114 [-100.000, 20.145], mean action: 1.639 [0.000, 3.000],  loss: 1270.903932, mae: 857.299442, mean_q: 1160.871527, mean_eps: 0.505846
 164912/300000: episode: 1532, duration: 0.968s, episode steps: 145, steps per second: 150, episode reward: -186.829, mean reward: -1.288 [-100.000, 24.316], mean action: 1.855 [0.000, 3.000],  loss: 1793.185598, mae: 850.574948, mean_q: 1150.838626, mean_eps: 0.505483
 164995/300000: episode: 1533, duration: 0.549s, episode steps:  83, steps per second: 151, episode reward: -10.349, mean reward: -0.125 [-100.000, 17.097], mean action: 1.614 [0.000, 3.000],  loss: 1552.136385, mae: 850.673657, mean_q: 1151.634169, mean_eps: 0.505141
 165134/300000: episode: 1534, duration: 0.916s, episode steps: 139, steps per second: 152, episode reward: -2.580, mean reward: -0.019 [-100.000, 20.536], mean action: 1.540 [0.000, 3.000],  loss: 1620.426207, mae: 845.433160, mean_q: 1144.651821, mean_eps: 0.504808
 165247/300000: episode: 1535, duration: 0.752s, episode steps: 113, steps per second: 150, episode reward: -156.137, mean reward: -1.382 [-100.000, 15.398], mean action: 1.743 [0.000, 3.000],  loss: 1326.432427, mae: 836.662089, mean_q: 1133.418805, mean_eps: 0.504430
 165351/300000: episode: 1536, duration: 0.668s, episode steps: 104, steps per second: 156, episode reward: -63.914, mean reward: -0.615 [-100.000, 17.965], mean action: 1.654 [0.000, 3.000],  loss: 1514.669732, mae: 841.230713, mean_q: 1138.426660, mean_eps: 0.504104
 165427/300000: episode: 1537, duration: 0.518s, episode steps:  76, steps per second: 147, episode reward: -102.902, mean reward: -1.354 [-100.000,  7.685], mean action: 1.711 [0.000, 3.000],  loss: 1312.294934, mae: 843.124335, mean_q: 1142.005854, mean_eps: 0.503835
 166427/300000: episode: 1538, duration: 7.613s, episode steps: 1000, steps per second: 131, episode reward: -36.289, mean reward: -0.036 [-23.872, 26.424], mean action: 1.635 [0.000, 3.000],  loss: 1419.639147, mae: 831.402818, mean_q: 1125.847669, mean_eps: 0.502221
 166516/300000: episode: 1539, duration: 0.584s, episode steps:  89, steps per second: 152, episode reward: -40.334, mean reward: -0.453 [-100.000,  8.611], mean action: 1.562 [0.000, 3.000],  loss: 1399.831090, mae: 830.939044, mean_q: 1124.220602, mean_eps: 0.500587
 166598/300000: episode: 1540, duration: 0.553s, episode steps:  82, steps per second: 148, episode reward: -62.774, mean reward: -0.766 [-100.000, 12.505], mean action: 1.415 [0.000, 3.000],  loss: 1360.091494, mae: 823.684607, mean_q: 1114.360102, mean_eps: 0.500330
 166672/300000: episode: 1541, duration: 0.547s, episode steps:  74, steps per second: 135, episode reward: -38.871, mean reward: -0.525 [-100.000, 20.600], mean action: 1.649 [0.000, 3.000],  loss: 1212.261588, mae: 838.456379, mean_q: 1133.821551, mean_eps: 0.500096
 166745/300000: episode: 1542, duration: 0.560s, episode steps:  73, steps per second: 130, episode reward: -76.838, mean reward: -1.053 [-100.000, 15.746], mean action: 1.808 [0.000, 3.000],  loss: 1413.279467, mae: 827.001315, mean_q: 1119.822343, mean_eps: 0.499876
 166875/300000: episode: 1543, duration: 0.952s, episode steps: 130, steps per second: 137, episode reward: -78.978, mean reward: -0.608 [-100.000, 14.826], mean action: 1.662 [0.000, 3.000],  loss: 1418.298727, mae: 827.594238, mean_q: 1119.838585, mean_eps: 0.499572
 166985/300000: episode: 1544, duration: 0.795s, episode steps: 110, steps per second: 138, episode reward: -159.754, mean reward: -1.452 [-100.000,  5.771], mean action: 1.727 [0.000, 3.000],  loss: 1400.085462, mae: 820.927959, mean_q: 1112.807535, mean_eps: 0.499212
 167064/300000: episode: 1545, duration: 0.550s, episode steps:  79, steps per second: 144, episode reward: -55.275, mean reward: -0.700 [-100.000,  9.947], mean action: 1.519 [0.000, 3.000],  loss: 1248.978398, mae: 824.641970, mean_q: 1118.064593, mean_eps: 0.498928
 168064/300000: episode: 1546, duration: 7.267s, episode steps: 1000, steps per second: 138, episode reward: -32.605, mean reward: -0.033 [-25.715, 24.827], mean action: 1.877 [0.000, 3.000],  loss: 1235.943435, mae: 819.192154, mean_q: 1109.293846, mean_eps: 0.497310
 168406/300000: episode: 1547, duration: 2.291s, episode steps: 342, steps per second: 149, episode reward: -95.252, mean reward: -0.279 [-100.000, 33.235], mean action: 1.722 [0.000, 3.000],  loss: 1194.425505, mae: 813.784025, mean_q: 1101.888409, mean_eps: 0.495296
 168549/300000: episode: 1548, duration: 0.943s, episode steps: 143, steps per second: 152, episode reward: -24.927, mean reward: -0.174 [-100.000,  8.311], mean action: 1.552 [0.000, 3.000],  loss: 1876.275664, mae: 802.248166, mean_q: 1085.397110, mean_eps: 0.494569
 168686/300000: episode: 1549, duration: 0.875s, episode steps: 137, steps per second: 157, episode reward: -11.280, mean reward: -0.082 [-100.000, 11.825], mean action: 1.547 [0.000, 3.000],  loss: 1134.179976, mae: 796.691064, mean_q: 1078.595877, mean_eps: 0.494149
 168794/300000: episode: 1550, duration: 0.754s, episode steps: 108, steps per second: 143, episode reward: -23.868, mean reward: -0.221 [-100.000,  8.617], mean action: 1.583 [0.000, 3.000],  loss: 1415.812235, mae: 798.870330, mean_q: 1083.277959, mean_eps: 0.493782
 168875/300000: episode: 1551, duration: 0.539s, episode steps:  81, steps per second: 150, episode reward: -50.267, mean reward: -0.621 [-100.000,  7.996], mean action: 1.864 [0.000, 3.000],  loss: 1404.952511, mae: 795.223717, mean_q: 1076.794519, mean_eps: 0.493498
 169000/300000: episode: 1552, duration: 0.796s, episode steps: 125, steps per second: 157, episode reward: -24.788, mean reward: -0.198 [-100.000,  6.710], mean action: 1.384 [0.000, 3.000],  loss: 1105.433745, mae: 788.454738, mean_q: 1067.288236, mean_eps: 0.493189
 169149/300000: episode: 1553, duration: 1.022s, episode steps: 149, steps per second: 146, episode reward: -158.348, mean reward: -1.063 [-100.000, 12.067], mean action: 1.819 [0.000, 3.000],  loss: 1233.829642, mae: 776.082085, mean_q: 1051.102950, mean_eps: 0.492778
 169243/300000: episode: 1554, duration: 0.611s, episode steps:  94, steps per second: 154, episode reward: 11.113, mean reward:  0.118 [-100.000, 13.820], mean action: 1.511 [0.000, 3.000],  loss: 1156.743640, mae: 782.822742, mean_q: 1060.889362, mean_eps: 0.492414
 169340/300000: episode: 1555, duration: 0.632s, episode steps:  97, steps per second: 154, episode reward: -54.464, mean reward: -0.561 [-100.000, 96.958], mean action: 1.639 [0.000, 3.000],  loss: 894.953404, mae: 771.759790, mean_q: 1046.440574, mean_eps: 0.492127
 169459/300000: episode: 1556, duration: 0.816s, episode steps: 119, steps per second: 146, episode reward: -44.694, mean reward: -0.376 [-100.000, 17.387], mean action: 1.807 [0.000, 3.000],  loss: 1110.230218, mae: 766.903802, mean_q: 1038.303135, mean_eps: 0.491803
 169572/300000: episode: 1557, duration: 0.736s, episode steps: 113, steps per second: 154, episode reward: -75.017, mean reward: -0.664 [-100.000,  9.380], mean action: 1.770 [0.000, 3.000],  loss: 1347.974953, mae: 766.181174, mean_q: 1037.932972, mean_eps: 0.491455
 170572/300000: episode: 1558, duration: 7.566s, episode steps: 1000, steps per second: 132, episode reward: 81.257, mean reward:  0.081 [-24.541, 38.390], mean action: 1.590 [0.000, 3.000],  loss: 1145.641841, mae: 749.030379, mean_q: 1015.516079, mean_eps: 0.489785
 170716/300000: episode: 1559, duration: 1.050s, episode steps: 144, steps per second: 137, episode reward: -37.597, mean reward: -0.261 [-100.000, 11.411], mean action: 1.451 [0.000, 3.000],  loss: 1761.518872, mae: 745.116686, mean_q: 1009.497773, mean_eps: 0.488070
 170874/300000: episode: 1560, duration: 1.199s, episode steps: 158, steps per second: 132, episode reward: -145.311, mean reward: -0.920 [-100.000, 10.338], mean action: 1.823 [0.000, 3.000],  loss: 1002.926629, mae: 751.687587, mean_q: 1019.002096, mean_eps: 0.487617
 171018/300000: episode: 1561, duration: 0.948s, episode steps: 144, steps per second: 152, episode reward: -49.104, mean reward: -0.341 [-100.000, 17.996], mean action: 1.792 [0.000, 3.000],  loss: 1224.962634, mae: 741.325774, mean_q: 1004.783759, mean_eps: 0.487164
 171140/300000: episode: 1562, duration: 0.779s, episode steps: 122, steps per second: 157, episode reward: -67.024, mean reward: -0.549 [-100.000, 11.285], mean action: 1.689 [0.000, 3.000],  loss: 1097.633399, mae: 736.623274, mean_q: 999.319143, mean_eps: 0.486764
 171267/300000: episode: 1563, duration: 0.859s, episode steps: 127, steps per second: 148, episode reward: -83.726, mean reward: -0.659 [-100.000, 11.624], mean action: 1.811 [0.000, 3.000],  loss: 1236.907329, mae: 735.121409, mean_q: 996.233457, mean_eps: 0.486391
 171359/300000: episode: 1564, duration: 0.617s, episode steps:  92, steps per second: 149, episode reward: -82.363, mean reward: -0.895 [-100.000, 12.166], mean action: 1.696 [0.000, 3.000],  loss: 1333.044612, mae: 728.093525, mean_q: 986.368241, mean_eps: 0.486062
 171440/300000: episode: 1565, duration: 0.529s, episode steps:  81, steps per second: 153, episode reward: 12.611, mean reward:  0.156 [-100.000, 16.247], mean action: 1.815 [0.000, 3.000],  loss: 1032.423233, mae: 727.062394, mean_q: 986.848478, mean_eps: 0.485803
 171538/300000: episode: 1566, duration: 0.681s, episode steps:  98, steps per second: 144, episode reward: -13.581, mean reward: -0.139 [-100.000, 14.596], mean action: 1.480 [0.000, 3.000],  loss: 913.587578, mae: 725.880707, mean_q: 985.497567, mean_eps: 0.485534
 171715/300000: episode: 1567, duration: 1.164s, episode steps: 177, steps per second: 152, episode reward: -130.318, mean reward: -0.736 [-100.000, 16.873], mean action: 1.740 [0.000, 3.000],  loss: 1114.473257, mae: 715.818098, mean_q: 970.757425, mean_eps: 0.485122
 171858/300000: episode: 1568, duration: 0.962s, episode steps: 143, steps per second: 149, episode reward: -124.722, mean reward: -0.872 [-100.000,  3.849], mean action: 1.797 [0.000, 3.000],  loss: 1396.642962, mae: 712.207342, mean_q: 966.438046, mean_eps: 0.484642
 171999/300000: episode: 1569, duration: 0.915s, episode steps: 141, steps per second: 154, episode reward: -92.244, mean reward: -0.654 [-100.000,  6.867], mean action: 1.773 [0.000, 3.000],  loss: 1120.312867, mae: 709.022210, mean_q: 961.279123, mean_eps: 0.484216
 172102/300000: episode: 1570, duration: 0.706s, episode steps: 103, steps per second: 146, episode reward:  4.113, mean reward:  0.040 [-100.000, 15.083], mean action: 1.825 [0.000, 3.000],  loss: 1250.332998, mae: 700.346216, mean_q: 950.488584, mean_eps: 0.483850
 172238/300000: episode: 1571, duration: 0.920s, episode steps: 136, steps per second: 148, episode reward: 18.919, mean reward:  0.139 [-100.000, 19.642], mean action: 1.566 [0.000, 3.000],  loss: 1024.644246, mae: 704.239148, mean_q: 955.935501, mean_eps: 0.483491
 172374/300000: episode: 1572, duration: 0.861s, episode steps: 136, steps per second: 158, episode reward: -44.107, mean reward: -0.324 [-100.000, 12.771], mean action: 1.485 [0.000, 3.000],  loss: 1624.051547, mae: 694.767096, mean_q: 943.522751, mean_eps: 0.483083
 172443/300000: episode: 1573, duration: 0.445s, episode steps:  69, steps per second: 155, episode reward: -68.433, mean reward: -0.992 [-100.000,  5.469], mean action: 1.609 [0.000, 3.000],  loss: 973.632861, mae: 700.666408, mean_q: 950.317485, mean_eps: 0.482776
 172575/300000: episode: 1574, duration: 0.910s, episode steps: 132, steps per second: 145, episode reward: -45.490, mean reward: -0.345 [-100.000, 22.543], mean action: 1.917 [0.000, 3.000],  loss: 1257.659293, mae: 695.427819, mean_q: 944.819660, mean_eps: 0.482474
 172710/300000: episode: 1575, duration: 0.863s, episode steps: 135, steps per second: 156, episode reward: -39.277, mean reward: -0.291 [-100.000, 66.341], mean action: 1.570 [0.000, 3.000],  loss: 1369.926671, mae: 689.093561, mean_q: 935.165373, mean_eps: 0.482074
 172789/300000: episode: 1576, duration: 0.517s, episode steps:  79, steps per second: 153, episode reward: -10.218, mean reward: -0.129 [-100.000, 10.976], mean action: 1.456 [0.000, 3.000],  loss: 1036.630616, mae: 687.315434, mean_q: 931.390713, mean_eps: 0.481753
 172907/300000: episode: 1577, duration: 0.801s, episode steps: 118, steps per second: 147, episode reward:  0.069, mean reward:  0.001 [-100.000,  9.468], mean action: 1.475 [0.000, 3.000],  loss: 793.775654, mae: 688.279827, mean_q: 934.038544, mean_eps: 0.481457
 173014/300000: episode: 1578, duration: 0.705s, episode steps: 107, steps per second: 152, episode reward: -61.985, mean reward: -0.579 [-100.000, 21.831], mean action: 1.579 [0.000, 3.000],  loss: 1023.047303, mae: 684.792430, mean_q: 930.811611, mean_eps: 0.481120
 173132/300000: episode: 1579, duration: 0.782s, episode steps: 118, steps per second: 151, episode reward: -60.193, mean reward: -0.510 [-100.000,  8.875], mean action: 1.703 [0.000, 3.000],  loss: 1567.615176, mae: 677.788438, mean_q: 920.028743, mean_eps: 0.480782
 174132/300000: episode: 1580, duration: 7.513s, episode steps: 1000, steps per second: 133, episode reward: 80.653, mean reward:  0.081 [-24.414, 26.436], mean action: 1.579 [0.000, 3.000],  loss: 1122.310482, mae: 670.339161, mean_q: 910.102081, mean_eps: 0.479106
 174237/300000: episode: 1581, duration: 0.678s, episode steps: 105, steps per second: 155, episode reward: 23.003, mean reward:  0.219 [-100.000, 18.071], mean action: 1.552 [0.000, 3.000],  loss: 1407.983558, mae: 666.729464, mean_q: 905.438815, mean_eps: 0.477448
 174329/300000: episode: 1582, duration: 0.615s, episode steps:  92, steps per second: 150, episode reward: -20.600, mean reward: -0.224 [-100.000, 19.003], mean action: 1.435 [0.000, 3.000],  loss: 1065.707298, mae: 663.690931, mean_q: 900.176366, mean_eps: 0.477152
 174442/300000: episode: 1583, duration: 0.733s, episode steps: 113, steps per second: 154, episode reward: -21.270, mean reward: -0.188 [-100.000, 22.446], mean action: 1.478 [0.000, 3.000],  loss: 1028.173175, mae: 661.760325, mean_q: 898.852083, mean_eps: 0.476845
 174547/300000: episode: 1584, duration: 0.666s, episode steps: 105, steps per second: 158, episode reward: -15.874, mean reward: -0.151 [-100.000, 14.938], mean action: 1.390 [0.000, 3.000],  loss: 973.262801, mae: 660.628563, mean_q: 896.728071, mean_eps: 0.476518
 174667/300000: episode: 1585, duration: 0.832s, episode steps: 120, steps per second: 144, episode reward: -81.050, mean reward: -0.675 [-100.000, 17.295], mean action: 1.725 [0.000, 3.000],  loss: 1043.658994, mae: 661.120953, mean_q: 897.220298, mean_eps: 0.476181
 174762/300000: episode: 1586, duration: 0.669s, episode steps:  95, steps per second: 142, episode reward: -33.360, mean reward: -0.351 [-100.000, 18.175], mean action: 1.547 [0.000, 3.000],  loss: 1423.952938, mae: 659.185383, mean_q: 895.528515, mean_eps: 0.475858
 174883/300000: episode: 1587, duration: 0.797s, episode steps: 121, steps per second: 152, episode reward: -44.438, mean reward: -0.367 [-100.000, 10.961], mean action: 1.711 [0.000, 3.000],  loss: 1097.392361, mae: 666.353605, mean_q: 904.267591, mean_eps: 0.475534
 174981/300000: episode: 1588, duration: 0.682s, episode steps:  98, steps per second: 144, episode reward: -168.545, mean reward: -1.720 [-100.000, 31.783], mean action: 1.888 [0.000, 3.000],  loss: 963.426926, mae: 660.575519, mean_q: 897.363028, mean_eps: 0.475205
 175064/300000: episode: 1589, duration: 0.551s, episode steps:  83, steps per second: 151, episode reward: -41.761, mean reward: -0.503 [-100.000, 19.552], mean action: 1.723 [0.000, 3.000],  loss: 856.936248, mae: 669.116303, mean_q: 907.893438, mean_eps: 0.474934
 175215/300000: episode: 1590, duration: 0.974s, episode steps: 151, steps per second: 155, episode reward: -22.356, mean reward: -0.148 [-100.000, 11.205], mean action: 1.715 [0.000, 3.000],  loss: 1336.947993, mae: 661.771190, mean_q: 897.520377, mean_eps: 0.474583
 175317/300000: episode: 1591, duration: 0.704s, episode steps: 102, steps per second: 145, episode reward: -70.754, mean reward: -0.694 [-100.000, 12.446], mean action: 1.569 [0.000, 3.000],  loss: 1045.408834, mae: 654.707756, mean_q: 887.477540, mean_eps: 0.474203
 175439/300000: episode: 1592, duration: 0.793s, episode steps: 122, steps per second: 154, episode reward: -4.916, mean reward: -0.040 [-100.000, 19.150], mean action: 1.508 [0.000, 3.000],  loss: 928.221482, mae: 649.556735, mean_q: 880.001881, mean_eps: 0.473867
 175538/300000: episode: 1593, duration: 0.633s, episode steps:  99, steps per second: 156, episode reward: -40.095, mean reward: -0.405 [-100.000, 12.863], mean action: 1.667 [0.000, 3.000],  loss: 927.550406, mae: 648.648682, mean_q: 879.221487, mean_eps: 0.473536
 175658/300000: episode: 1594, duration: 0.826s, episode steps: 120, steps per second: 145, episode reward: -17.156, mean reward: -0.143 [-100.000, 19.962], mean action: 1.800 [0.000, 3.000],  loss: 1033.921590, mae: 640.383670, mean_q: 866.557338, mean_eps: 0.473208
 175786/300000: episode: 1595, duration: 0.862s, episode steps: 128, steps per second: 148, episode reward: -37.507, mean reward: -0.293 [-100.000, 17.745], mean action: 1.844 [0.000, 3.000],  loss: 964.915081, mae: 634.476747, mean_q: 859.169387, mean_eps: 0.472836
 175864/300000: episode: 1596, duration: 0.514s, episode steps:  78, steps per second: 152, episode reward: -47.914, mean reward: -0.614 [-100.000, 12.536], mean action: 1.397 [0.000, 3.000],  loss: 778.339993, mae: 628.787972, mean_q: 852.764220, mean_eps: 0.472527
 175958/300000: episode: 1597, duration: 0.679s, episode steps:  94, steps per second: 138, episode reward: -60.684, mean reward: -0.646 [-100.000, 11.245], mean action: 1.468 [0.000, 3.000],  loss: 823.680858, mae: 622.707137, mean_q: 843.186393, mean_eps: 0.472269
 176078/300000: episode: 1598, duration: 0.804s, episode steps: 120, steps per second: 149, episode reward: 12.756, mean reward:  0.106 [-100.000,  9.770], mean action: 1.925 [0.000, 3.000],  loss: 1116.847449, mae: 630.442728, mean_q: 855.341953, mean_eps: 0.471948
 176193/300000: episode: 1599, duration: 0.747s, episode steps: 115, steps per second: 154, episode reward: -21.760, mean reward: -0.189 [-100.000, 16.319], mean action: 1.643 [0.000, 3.000],  loss: 1171.201256, mae: 626.411932, mean_q: 848.756901, mean_eps: 0.471595
 176307/300000: episode: 1600, duration: 0.908s, episode steps: 114, steps per second: 126, episode reward:  1.460, mean reward:  0.013 [-100.000, 14.551], mean action: 1.658 [0.000, 3.000],  loss: 793.525538, mae: 619.030134, mean_q: 838.226800, mean_eps: 0.471252
 176413/300000: episode: 1601, duration: 0.776s, episode steps: 106, steps per second: 137, episode reward: -47.277, mean reward: -0.446 [-100.000, 17.155], mean action: 1.821 [0.000, 3.000],  loss: 858.700580, mae: 614.809006, mean_q: 834.871357, mean_eps: 0.470921
 176499/300000: episode: 1602, duration: 0.624s, episode steps:  86, steps per second: 138, episode reward: -134.141, mean reward: -1.560 [-100.000, 22.532], mean action: 1.756 [0.000, 3.000],  loss: 1116.563900, mae: 618.469886, mean_q: 837.230083, mean_eps: 0.470633
 177499/300000: episode: 1603, duration: 7.350s, episode steps: 1000, steps per second: 136, episode reward: 75.627, mean reward:  0.076 [-22.517, 26.815], mean action: 1.659 [0.000, 3.000],  loss: 794.344367, mae: 609.737009, mean_q: 826.290955, mean_eps: 0.469004
 177614/300000: episode: 1604, duration: 0.740s, episode steps: 115, steps per second: 155, episode reward: -46.352, mean reward: -0.403 [-100.000, 15.441], mean action: 1.461 [0.000, 3.000],  loss: 861.096480, mae: 601.497508, mean_q: 814.423611, mean_eps: 0.467332
 178614/300000: episode: 1605, duration: 7.474s, episode steps: 1000, steps per second: 134, episode reward: 35.231, mean reward:  0.035 [-23.534, 26.406], mean action: 1.639 [0.000, 3.000],  loss: 855.431698, mae: 589.560438, mean_q: 798.601907, mean_eps: 0.465660
 178724/300000: episode: 1606, duration: 0.719s, episode steps: 110, steps per second: 153, episode reward: -74.360, mean reward: -0.676 [-100.000, 12.438], mean action: 1.518 [0.000, 3.000],  loss: 832.185485, mae: 571.835575, mean_q: 775.564424, mean_eps: 0.463994
 178856/300000: episode: 1607, duration: 0.854s, episode steps: 132, steps per second: 155, episode reward: -17.168, mean reward: -0.130 [-100.000, 15.900], mean action: 1.485 [0.000, 3.000],  loss: 742.176730, mae: 573.058193, mean_q: 776.477039, mean_eps: 0.463632
 178939/300000: episode: 1608, duration: 0.586s, episode steps:  83, steps per second: 142, episode reward: -15.839, mean reward: -0.191 [-100.000, 22.200], mean action: 1.711 [0.000, 3.000],  loss: 727.282881, mae: 572.182349, mean_q: 774.077393, mean_eps: 0.463309
 179041/300000: episode: 1609, duration: 0.669s, episode steps: 102, steps per second: 153, episode reward: -54.466, mean reward: -0.534 [-100.000,  9.695], mean action: 1.794 [0.000, 3.000],  loss: 1097.352876, mae: 565.893400, mean_q: 765.816464, mean_eps: 0.463031
 179154/300000: episode: 1610, duration: 0.738s, episode steps: 113, steps per second: 153, episode reward: 27.334, mean reward:  0.242 [-100.000, 14.095], mean action: 1.681 [0.000, 3.000],  loss: 665.167008, mae: 561.009662, mean_q: 760.244142, mean_eps: 0.462709
 179272/300000: episode: 1611, duration: 0.823s, episode steps: 118, steps per second: 143, episode reward: -40.256, mean reward: -0.341 [-100.000, 26.783], mean action: 1.669 [0.000, 3.000],  loss: 763.000155, mae: 558.006691, mean_q: 755.585513, mean_eps: 0.462362
 179376/300000: episode: 1612, duration: 0.689s, episode steps: 104, steps per second: 151, episode reward: -105.268, mean reward: -1.012 [-100.000, 11.556], mean action: 1.798 [0.000, 3.000],  loss: 638.890860, mae: 559.283044, mean_q: 755.967370, mean_eps: 0.462029
 179484/300000: episode: 1613, duration: 0.686s, episode steps: 108, steps per second: 157, episode reward: -97.319, mean reward: -0.901 [-100.000, 10.646], mean action: 1.500 [0.000, 3.000],  loss: 960.939611, mae: 559.349160, mean_q: 756.593374, mean_eps: 0.461711
 179600/300000: episode: 1614, duration: 0.777s, episode steps: 116, steps per second: 149, episode reward: -112.141, mean reward: -0.967 [-100.000, 11.020], mean action: 1.647 [0.000, 3.000],  loss: 725.862710, mae: 553.008270, mean_q: 748.361754, mean_eps: 0.461375
 179724/300000: episode: 1615, duration: 0.947s, episode steps: 124, steps per second: 131, episode reward: -73.306, mean reward: -0.591 [-100.000, 16.724], mean action: 1.556 [0.000, 3.000],  loss: 701.504209, mae: 551.587117, mean_q: 746.100708, mean_eps: 0.461015
 179814/300000: episode: 1616, duration: 0.649s, episode steps:  90, steps per second: 139, episode reward: -14.881, mean reward: -0.165 [-100.000, 14.142], mean action: 1.611 [0.000, 3.000],  loss: 836.918152, mae: 557.479704, mean_q: 753.303633, mean_eps: 0.460695
 179969/300000: episode: 1617, duration: 1.149s, episode steps: 155, steps per second: 135, episode reward: -113.577, mean reward: -0.733 [-100.000, 22.753], mean action: 1.761 [0.000, 3.000],  loss: 642.484813, mae: 551.227666, mean_q: 744.782133, mean_eps: 0.460327
 180054/300000: episode: 1618, duration: 0.616s, episode steps:  85, steps per second: 138, episode reward: -42.608, mean reward: -0.501 [-100.000, 12.449], mean action: 1.741 [0.000, 3.000],  loss: 800.719832, mae: 551.454018, mean_q: 746.205062, mean_eps: 0.459967
 180142/300000: episode: 1619, duration: 0.634s, episode steps:  88, steps per second: 139, episode reward: -21.060, mean reward: -0.239 [-100.000, 20.257], mean action: 1.693 [0.000, 3.000],  loss: 675.926152, mae: 548.107328, mean_q: 740.868374, mean_eps: 0.459707
 180252/300000: episode: 1620, duration: 0.800s, episode steps: 110, steps per second: 137, episode reward: -35.716, mean reward: -0.325 [-100.000, 22.798], mean action: 1.600 [0.000, 3.000],  loss: 671.236359, mae: 539.475595, mean_q: 728.819031, mean_eps: 0.459411
 180352/300000: episode: 1621, duration: 0.655s, episode steps: 100, steps per second: 153, episode reward: -59.234, mean reward: -0.592 [-100.000,  8.851], mean action: 1.460 [0.000, 3.000],  loss: 581.764315, mae: 541.255069, mean_q: 731.729976, mean_eps: 0.459096
 180723/300000: episode: 1622, duration: 2.512s, episode steps: 371, steps per second: 148, episode reward: -203.420, mean reward: -0.548 [-100.000, 19.954], mean action: 1.501 [0.000, 3.000],  loss: 515.662747, mae: 536.962997, mean_q: 726.191878, mean_eps: 0.458389
 180820/300000: episode: 1623, duration: 0.648s, episode steps:  97, steps per second: 150, episode reward: -71.410, mean reward: -0.736 [-100.000,  9.922], mean action: 1.639 [0.000, 3.000],  loss: 497.839645, mae: 531.514566, mean_q: 718.586029, mean_eps: 0.457687
 180946/300000: episode: 1624, duration: 0.806s, episode steps: 126, steps per second: 156, episode reward: -6.794, mean reward: -0.054 [-100.000, 12.086], mean action: 1.667 [0.000, 3.000],  loss: 547.991247, mae: 525.401065, mean_q: 709.518646, mean_eps: 0.457353
 181061/300000: episode: 1625, duration: 0.735s, episode steps: 115, steps per second: 156, episode reward: -102.134, mean reward: -0.888 [-100.000, 11.133], mean action: 1.661 [0.000, 3.000],  loss: 685.183701, mae: 521.563491, mean_q: 704.779003, mean_eps: 0.456991
 181169/300000: episode: 1626, duration: 0.746s, episode steps: 108, steps per second: 145, episode reward: -136.961, mean reward: -1.268 [-100.000,  3.731], mean action: 1.731 [0.000, 3.000],  loss: 865.379353, mae: 518.015052, mean_q: 699.501740, mean_eps: 0.456657
 181255/300000: episode: 1627, duration: 0.549s, episode steps:  86, steps per second: 157, episode reward: -71.015, mean reward: -0.826 [-100.000, 11.217], mean action: 1.640 [0.000, 3.000],  loss: 718.432308, mae: 518.862022, mean_q: 701.901946, mean_eps: 0.456365
 181342/300000: episode: 1628, duration: 0.564s, episode steps:  87, steps per second: 154, episode reward: -41.004, mean reward: -0.471 [-100.000, 12.320], mean action: 1.494 [0.000, 3.000],  loss: 377.601372, mae: 518.530733, mean_q: 700.957527, mean_eps: 0.456106
 181475/300000: episode: 1629, duration: 0.885s, episode steps: 133, steps per second: 150, episode reward: -32.737, mean reward: -0.246 [-100.000, 12.531], mean action: 1.782 [0.000, 3.000],  loss: 583.099693, mae: 516.786611, mean_q: 698.358337, mean_eps: 0.455776
 181592/300000: episode: 1630, duration: 0.759s, episode steps: 117, steps per second: 154, episode reward: -77.278, mean reward: -0.660 [-100.000, 10.215], mean action: 1.752 [0.000, 3.000],  loss: 596.015574, mae: 510.704649, mean_q: 690.262187, mean_eps: 0.455401
 181681/300000: episode: 1631, duration: 0.573s, episode steps:  89, steps per second: 155, episode reward: -60.297, mean reward: -0.677 [-100.000, 25.052], mean action: 1.876 [0.000, 3.000],  loss: 640.929843, mae: 511.242299, mean_q: 690.510897, mean_eps: 0.455092
 181820/300000: episode: 1632, duration: 0.928s, episode steps: 139, steps per second: 150, episode reward: -83.473, mean reward: -0.601 [-100.000,  6.254], mean action: 1.885 [0.000, 3.000],  loss: 617.447576, mae: 513.601036, mean_q: 693.993450, mean_eps: 0.454750
 181920/300000: episode: 1633, duration: 0.660s, episode steps: 100, steps per second: 152, episode reward: -92.560, mean reward: -0.926 [-100.000,  6.970], mean action: 1.740 [0.000, 3.000],  loss: 579.093966, mae: 501.730816, mean_q: 677.939172, mean_eps: 0.454391
 182030/300000: episode: 1634, duration: 0.705s, episode steps: 110, steps per second: 156, episode reward: -136.572, mean reward: -1.242 [-100.000,  4.995], mean action: 1.845 [0.000, 3.000],  loss: 596.657551, mae: 501.003212, mean_q: 677.972799, mean_eps: 0.454076
 182129/300000: episode: 1635, duration: 0.704s, episode steps:  99, steps per second: 141, episode reward: -4.388, mean reward: -0.044 [-100.000, 20.437], mean action: 1.293 [0.000, 3.000],  loss: 492.684740, mae: 495.696565, mean_q: 671.483139, mean_eps: 0.453763
 182262/300000: episode: 1636, duration: 0.856s, episode steps: 133, steps per second: 155, episode reward: 24.248, mean reward:  0.182 [-100.000, 13.929], mean action: 1.617 [0.000, 3.000],  loss: 601.032825, mae: 495.761797, mean_q: 671.188313, mean_eps: 0.453415
 182326/300000: episode: 1637, duration: 0.411s, episode steps:  64, steps per second: 156, episode reward: -66.332, mean reward: -1.036 [-100.000,  7.958], mean action: 1.578 [0.000, 3.000],  loss: 544.686682, mae: 494.578812, mean_q: 669.762691, mean_eps: 0.453120
 183326/300000: episode: 1638, duration: 7.910s, episode steps: 1000, steps per second: 126, episode reward: 21.428, mean reward:  0.021 [-23.726, 28.543], mean action: 1.457 [0.000, 3.000],  loss: 622.909791, mae: 496.453265, mean_q: 672.248725, mean_eps: 0.451524
 183428/300000: episode: 1639, duration: 0.733s, episode steps: 102, steps per second: 139, episode reward: -0.524, mean reward: -0.005 [-100.000, 18.407], mean action: 1.814 [0.000, 3.000],  loss: 688.419001, mae: 506.918947, mean_q: 686.023269, mean_eps: 0.449871
 183582/300000: episode: 1640, duration: 1.109s, episode steps: 154, steps per second: 139, episode reward: -72.646, mean reward: -0.472 [-100.000,  9.718], mean action: 1.851 [0.000, 3.000],  loss: 695.296829, mae: 502.872194, mean_q: 681.710634, mean_eps: 0.449487
 183756/300000: episode: 1641, duration: 1.169s, episode steps: 174, steps per second: 149, episode reward: -227.857, mean reward: -1.310 [-100.000, 21.734], mean action: 1.764 [0.000, 3.000],  loss: 737.157674, mae: 496.747908, mean_q: 672.351828, mean_eps: 0.448994
 183871/300000: episode: 1642, duration: 0.841s, episode steps: 115, steps per second: 137, episode reward: -132.677, mean reward: -1.154 [-100.000, 11.700], mean action: 1.783 [0.000, 3.000],  loss: 532.653835, mae: 490.072911, mean_q: 662.835031, mean_eps: 0.448561
 183997/300000: episode: 1643, duration: 0.819s, episode steps: 126, steps per second: 154, episode reward: 20.459, mean reward:  0.162 [-100.000, 10.048], mean action: 1.706 [0.000, 3.000],  loss: 536.153537, mae: 493.575175, mean_q: 666.675861, mean_eps: 0.448199
 184101/300000: episode: 1644, duration: 0.661s, episode steps: 104, steps per second: 157, episode reward: -132.066, mean reward: -1.270 [-100.000, 16.564], mean action: 1.750 [0.000, 3.000],  loss: 663.104876, mae: 493.795222, mean_q: 668.374440, mean_eps: 0.447855
 185101/300000: episode: 1645, duration: 7.282s, episode steps: 1000, steps per second: 137, episode reward: 154.885, mean reward:  0.155 [-23.447, 25.591], mean action: 0.997 [0.000, 3.000],  loss: 590.300313, mae: 487.176321, mean_q: 658.773757, mean_eps: 0.446198
 185269/300000: episode: 1646, duration: 1.075s, episode steps: 168, steps per second: 156, episode reward: -33.663, mean reward: -0.200 [-100.000,  8.801], mean action: 1.679 [0.000, 3.000],  loss: 572.139659, mae: 485.715219, mean_q: 656.100776, mean_eps: 0.444447
 185372/300000: episode: 1647, duration: 0.700s, episode steps: 103, steps per second: 147, episode reward: -29.621, mean reward: -0.288 [-100.000, 12.031], mean action: 1.650 [0.000, 3.000],  loss: 370.784535, mae: 490.358190, mean_q: 662.497022, mean_eps: 0.444040
 185494/300000: episode: 1648, duration: 0.836s, episode steps: 122, steps per second: 146, episode reward: 11.933, mean reward:  0.098 [-100.000, 21.194], mean action: 1.713 [0.000, 3.000],  loss: 593.686112, mae: 484.062832, mean_q: 654.188844, mean_eps: 0.443702
 185584/300000: episode: 1649, duration: 0.641s, episode steps:  90, steps per second: 140, episode reward: -59.082, mean reward: -0.656 [-100.000,  8.510], mean action: 1.444 [0.000, 3.000],  loss: 690.366799, mae: 478.974685, mean_q: 646.799334, mean_eps: 0.443385
 185697/300000: episode: 1650, duration: 0.856s, episode steps: 113, steps per second: 132, episode reward: 12.844, mean reward:  0.114 [-100.000, 27.409], mean action: 1.575 [0.000, 3.000],  loss: 674.360041, mae: 479.400934, mean_q: 647.976368, mean_eps: 0.443080
 185805/300000: episode: 1651, duration: 0.749s, episode steps: 108, steps per second: 144, episode reward: -28.653, mean reward: -0.265 [-100.000, 22.768], mean action: 1.611 [0.000, 3.000],  loss: 588.670793, mae: 473.763990, mean_q: 640.641643, mean_eps: 0.442749
 185889/300000: episode: 1652, duration: 0.583s, episode steps:  84, steps per second: 144, episode reward: -37.382, mean reward: -0.445 [-100.000,  7.929], mean action: 1.810 [0.000, 3.000],  loss: 356.315986, mae: 469.697809, mean_q: 635.550212, mean_eps: 0.442461
 186016/300000: episode: 1653, duration: 0.888s, episode steps: 127, steps per second: 143, episode reward: -38.497, mean reward: -0.303 [-100.000, 18.170], mean action: 1.654 [0.000, 3.000],  loss: 544.267035, mae: 460.761937, mean_q: 622.811397, mean_eps: 0.442144
 187016/300000: episode: 1654, duration: 7.307s, episode steps: 1000, steps per second: 137, episode reward: 98.383, mean reward:  0.098 [-23.599, 23.352], mean action: 1.195 [0.000, 3.000],  loss: 511.749294, mae: 446.232949, mean_q: 602.650823, mean_eps: 0.440453
 187110/300000: episode: 1655, duration: 0.604s, episode steps:  94, steps per second: 156, episode reward: -57.699, mean reward: -0.614 [-100.000, 11.355], mean action: 1.372 [0.000, 3.000],  loss: 381.542114, mae: 451.476110, mean_q: 610.407756, mean_eps: 0.438813
 187217/300000: episode: 1656, duration: 0.703s, episode steps: 107, steps per second: 152, episode reward: -454.300, mean reward: -4.246 [-100.000,  3.805], mean action: 1.607 [0.000, 3.000],  loss: 517.964835, mae: 448.187977, mean_q: 605.260823, mean_eps: 0.438511
 188217/300000: episode: 1657, duration: 7.585s, episode steps: 1000, steps per second: 132, episode reward: -45.180, mean reward: -0.045 [-24.214, 25.017], mean action: 1.548 [0.000, 3.000],  loss: 438.018524, mae: 443.589606, mean_q: 599.304266, mean_eps: 0.436851
 188334/300000: episode: 1658, duration: 0.744s, episode steps: 117, steps per second: 157, episode reward: -72.842, mean reward: -0.623 [-100.000, 11.315], mean action: 1.521 [0.000, 3.000],  loss: 461.538880, mae: 448.335780, mean_q: 605.266290, mean_eps: 0.435175
 188428/300000: episode: 1659, duration: 0.631s, episode steps:  94, steps per second: 149, episode reward: -62.209, mean reward: -0.662 [-100.000, 13.667], mean action: 1.543 [0.000, 3.000],  loss: 469.519644, mae: 442.275573, mean_q: 597.219184, mean_eps: 0.434859
 188548/300000: episode: 1660, duration: 0.764s, episode steps: 120, steps per second: 157, episode reward: -27.907, mean reward: -0.233 [-100.000, 10.972], mean action: 1.575 [0.000, 3.000],  loss: 445.942780, mae: 438.660212, mean_q: 591.919221, mean_eps: 0.434538
 188635/300000: episode: 1661, duration: 0.554s, episode steps:  87, steps per second: 157, episode reward: -14.127, mean reward: -0.162 [-100.000, 10.026], mean action: 1.747 [0.000, 3.000],  loss: 431.787143, mae: 436.037218, mean_q: 590.362456, mean_eps: 0.434227
 188750/300000: episode: 1662, duration: 0.781s, episode steps: 115, steps per second: 147, episode reward: -208.381, mean reward: -1.812 [-100.000, 16.281], mean action: 1.809 [0.000, 3.000],  loss: 434.534803, mae: 438.540351, mean_q: 592.849938, mean_eps: 0.433924
 188855/300000: episode: 1663, duration: 0.680s, episode steps: 105, steps per second: 154, episode reward: -77.410, mean reward: -0.737 [-100.000, 20.106], mean action: 1.343 [0.000, 3.000],  loss: 396.214784, mae: 439.278884, mean_q: 593.677483, mean_eps: 0.433594
 188968/300000: episode: 1664, duration: 0.860s, episode steps: 113, steps per second: 131, episode reward: -279.079, mean reward: -2.470 [-100.000,  4.597], mean action: 1.690 [0.000, 3.000],  loss: 482.175822, mae: 437.280013, mean_q: 589.254021, mean_eps: 0.433267
 189324/300000: episode: 1665, duration: 2.673s, episode steps: 356, steps per second: 133, episode reward: -184.720, mean reward: -0.519 [-100.000, 18.518], mean action: 1.610 [0.000, 3.000],  loss: 541.282330, mae: 436.940985, mean_q: 589.603888, mean_eps: 0.432564
 189423/300000: episode: 1666, duration: 0.683s, episode steps:  99, steps per second: 145, episode reward: -75.201, mean reward: -0.760 [-100.000,  4.449], mean action: 1.707 [0.000, 3.000],  loss: 485.732538, mae: 439.219684, mean_q: 593.459236, mean_eps: 0.431881
 189685/300000: episode: 1667, duration: 1.818s, episode steps: 262, steps per second: 144, episode reward: -206.179, mean reward: -0.787 [-100.000, 39.918], mean action: 1.832 [0.000, 3.000],  loss: 407.028088, mae: 439.620969, mean_q: 594.105888, mean_eps: 0.431339
 190685/300000: episode: 1668, duration: 7.278s, episode steps: 1000, steps per second: 137, episode reward: 138.994, mean reward:  0.139 [-23.920, 23.260], mean action: 1.786 [0.000, 3.000],  loss: 408.534026, mae: 438.481166, mean_q: 591.778424, mean_eps: 0.429447
 190851/300000: episode: 1669, duration: 1.097s, episode steps: 166, steps per second: 151, episode reward: 16.973, mean reward:  0.102 [-100.000, 29.083], mean action: 1.825 [0.000, 3.000],  loss: 399.514458, mae: 436.343922, mean_q: 588.618207, mean_eps: 0.427697
 190953/300000: episode: 1670, duration: 0.649s, episode steps: 102, steps per second: 157, episode reward: -319.421, mean reward: -3.132 [-100.000, 12.467], mean action: 1.539 [0.000, 3.000],  loss: 421.347890, mae: 425.528837, mean_q: 573.612901, mean_eps: 0.427295
 191040/300000: episode: 1671, duration: 0.558s, episode steps:  87, steps per second: 156, episode reward: -403.509, mean reward: -4.638 [-100.000,  3.302], mean action: 1.839 [0.000, 3.000],  loss: 438.362500, mae: 428.008348, mean_q: 576.331050, mean_eps: 0.427012
 191120/300000: episode: 1672, duration: 0.529s, episode steps:  80, steps per second: 151, episode reward: -408.636, mean reward: -5.108 [-100.000,  0.331], mean action: 1.788 [0.000, 3.000],  loss: 325.660480, mae: 424.987195, mean_q: 573.061916, mean_eps: 0.426762
 191203/300000: episode: 1673, duration: 0.558s, episode steps:  83, steps per second: 149, episode reward: -249.863, mean reward: -3.010 [-100.000, 12.354], mean action: 1.675 [0.000, 3.000],  loss: 367.489828, mae: 428.579617, mean_q: 576.720716, mean_eps: 0.426517
 192203/300000: episode: 1674, duration: 7.432s, episode steps: 1000, steps per second: 135, episode reward: 65.488, mean reward:  0.065 [-23.123, 23.924], mean action: 1.352 [0.000, 3.000],  loss: 404.603092, mae: 420.599964, mean_q: 566.521769, mean_eps: 0.424893
 192305/300000: episode: 1675, duration: 0.677s, episode steps: 102, steps per second: 151, episode reward: -306.948, mean reward: -3.009 [-100.000,  1.714], mean action: 1.892 [0.000, 3.000],  loss: 397.580706, mae: 414.989569, mean_q: 558.807300, mean_eps: 0.423239
 192404/300000: episode: 1676, duration: 0.646s, episode steps:  99, steps per second: 153, episode reward: -15.646, mean reward: -0.158 [-100.000, 11.656], mean action: 1.697 [0.000, 3.000],  loss: 467.479705, mae: 414.069158, mean_q: 557.895799, mean_eps: 0.422938
 192468/300000: episode: 1677, duration: 0.408s, episode steps:  64, steps per second: 157, episode reward: -55.357, mean reward: -0.865 [-100.000, 10.028], mean action: 1.844 [0.000, 3.000],  loss: 330.716402, mae: 409.416170, mean_q: 551.628430, mean_eps: 0.422693
 192585/300000: episode: 1678, duration: 0.758s, episode steps: 117, steps per second: 154, episode reward: -162.029, mean reward: -1.385 [-100.000,  2.538], mean action: 1.590 [0.000, 3.000],  loss: 359.307332, mae: 407.187723, mean_q: 547.096271, mean_eps: 0.422422
 192684/300000: episode: 1679, duration: 0.673s, episode steps:  99, steps per second: 147, episode reward: -400.343, mean reward: -4.044 [-100.000,  1.990], mean action: 1.657 [0.000, 3.000],  loss: 331.062585, mae: 408.842682, mean_q: 550.488136, mean_eps: 0.422098
 192776/300000: episode: 1680, duration: 0.613s, episode steps:  92, steps per second: 150, episode reward: -418.043, mean reward: -4.544 [-100.000,  0.521], mean action: 1.457 [0.000, 3.000],  loss: 540.738483, mae: 405.974236, mean_q: 546.688624, mean_eps: 0.421812
 192873/300000: episode: 1681, duration: 0.615s, episode steps:  97, steps per second: 158, episode reward: -179.964, mean reward: -1.855 [-100.000,  8.188], mean action: 1.753 [0.000, 3.000],  loss: 309.194284, mae: 404.745140, mean_q: 545.371853, mean_eps: 0.421528
 192963/300000: episode: 1682, duration: 0.582s, episode steps:  90, steps per second: 155, episode reward: -109.235, mean reward: -1.214 [-100.000, 10.870], mean action: 1.844 [0.000, 3.000],  loss: 335.913663, mae: 404.460522, mean_q: 544.609961, mean_eps: 0.421248
 193298/300000: episode: 1683, duration: 2.284s, episode steps: 335, steps per second: 147, episode reward: -137.953, mean reward: -0.412 [-100.000, 18.530], mean action: 1.931 [0.000, 3.000],  loss: 220.741918, mae: 403.378789, mean_q: 542.939305, mean_eps: 0.420610
 193395/300000: episode: 1684, duration: 0.626s, episode steps:  97, steps per second: 155, episode reward: -56.344, mean reward: -0.581 [-100.000, 17.230], mean action: 1.588 [0.000, 3.000],  loss: 234.833928, mae: 393.710234, mean_q: 529.727937, mean_eps: 0.419962
 193485/300000: episode: 1685, duration: 0.566s, episode steps:  90, steps per second: 159, episode reward: -217.641, mean reward: -2.418 [-100.000, 24.521], mean action: 1.422 [0.000, 3.000],  loss: 481.124051, mae: 390.127786, mean_q: 524.907526, mean_eps: 0.419681
 194485/300000: episode: 1686, duration: 7.552s, episode steps: 1000, steps per second: 132, episode reward: 16.292, mean reward:  0.016 [-24.472, 27.831], mean action: 1.641 [0.000, 3.000],  loss: 303.119933, mae: 379.300877, mean_q: 509.545495, mean_eps: 0.418047
 194603/300000: episode: 1687, duration: 0.760s, episode steps: 118, steps per second: 155, episode reward: -56.640, mean reward: -0.480 [-100.000, 10.528], mean action: 1.737 [0.000, 3.000],  loss: 272.548460, mae: 374.293635, mean_q: 502.423665, mean_eps: 0.416370
 194693/300000: episode: 1688, duration: 0.602s, episode steps:  90, steps per second: 149, episode reward:  5.676, mean reward:  0.063 [-100.000, 16.573], mean action: 1.622 [0.000, 3.000],  loss: 275.870519, mae: 369.275935, mean_q: 496.748953, mean_eps: 0.416057
 194853/300000: episode: 1689, duration: 1.202s, episode steps: 160, steps per second: 133, episode reward: -70.130, mean reward: -0.438 [-100.000, 18.732], mean action: 1.712 [0.000, 3.000],  loss: 310.784871, mae: 370.541843, mean_q: 498.911881, mean_eps: 0.415683
 194989/300000: episode: 1690, duration: 0.960s, episode steps: 136, steps per second: 142, episode reward: 41.189, mean reward:  0.303 [-100.000, 67.275], mean action: 1.596 [0.000, 3.000],  loss: 300.402870, mae: 366.964187, mean_q: 494.296686, mean_eps: 0.415239
 195096/300000: episode: 1691, duration: 0.748s, episode steps: 107, steps per second: 143, episode reward: -21.728, mean reward: -0.203 [-100.000,  9.788], mean action: 1.551 [0.000, 3.000],  loss: 234.095537, mae: 363.746801, mean_q: 488.668097, mean_eps: 0.414874
 195196/300000: episode: 1692, duration: 0.694s, episode steps: 100, steps per second: 144, episode reward: 30.263, mean reward:  0.303 [-100.000, 17.668], mean action: 1.760 [0.000, 3.000],  loss: 291.070822, mae: 361.288730, mean_q: 486.594557, mean_eps: 0.414563
 195273/300000: episode: 1693, duration: 0.524s, episode steps:  77, steps per second: 147, episode reward: -11.703, mean reward: -0.152 [-100.000, 13.600], mean action: 1.636 [0.000, 3.000],  loss: 204.304687, mae: 358.993961, mean_q: 483.331334, mean_eps: 0.414298
 195705/300000: episode: 1694, duration: 2.919s, episode steps: 432, steps per second: 148, episode reward: -292.471, mean reward: -0.677 [-100.000, 18.334], mean action: 1.722 [0.000, 3.000],  loss: 282.173234, mae: 364.082722, mean_q: 489.681781, mean_eps: 0.413535
 195788/300000: episode: 1695, duration: 0.555s, episode steps:  83, steps per second: 150, episode reward: -2.531, mean reward: -0.030 [-100.000, 17.179], mean action: 1.699 [0.000, 3.000],  loss: 299.704482, mae: 363.804363, mean_q: 489.106046, mean_eps: 0.412762
 195876/300000: episode: 1696, duration: 0.572s, episode steps:  88, steps per second: 154, episode reward: -36.612, mean reward: -0.416 [-100.000,  7.442], mean action: 1.580 [0.000, 3.000],  loss: 318.630888, mae: 358.155212, mean_q: 481.266503, mean_eps: 0.412506
 196478/300000: episode: 1697, duration: 4.449s, episode steps: 602, steps per second: 135, episode reward: -362.713, mean reward: -0.603 [-100.000, 13.787], mean action: 1.703 [0.000, 3.000],  loss: 240.138267, mae: 355.161060, mean_q: 478.529355, mean_eps: 0.411471
 196610/300000: episode: 1698, duration: 0.842s, episode steps: 132, steps per second: 157, episode reward: -50.949, mean reward: -0.386 [-100.000,  7.335], mean action: 1.841 [0.000, 3.000],  loss: 253.841961, mae: 350.331164, mean_q: 471.976063, mean_eps: 0.410369
 196686/300000: episode: 1699, duration: 0.517s, episode steps:  76, steps per second: 147, episode reward: -45.300, mean reward: -0.596 [-100.000,  9.567], mean action: 1.776 [0.000, 3.000],  loss: 448.331611, mae: 349.972025, mean_q: 470.561879, mean_eps: 0.410057
 196795/300000: episode: 1700, duration: 0.696s, episode steps: 109, steps per second: 157, episode reward: -24.451, mean reward: -0.224 [-100.000, 10.748], mean action: 1.560 [0.000, 3.000],  loss: 202.623061, mae: 346.395188, mean_q: 467.073792, mean_eps: 0.409780
 197795/300000: episode: 1701, duration: 7.757s, episode steps: 1000, steps per second: 129, episode reward: 60.704, mean reward:  0.061 [-23.418, 24.737], mean action: 1.917 [0.000, 3.000],  loss: 248.878286, mae: 343.932479, mean_q: 462.397928, mean_eps: 0.408116
 197886/300000: episode: 1702, duration: 0.583s, episode steps:  91, steps per second: 156, episode reward: -3.287, mean reward: -0.036 [-100.000, 19.322], mean action: 1.725 [0.000, 3.000],  loss: 256.472376, mae: 343.500480, mean_q: 461.806408, mean_eps: 0.406480
 198001/300000: episode: 1703, duration: 0.751s, episode steps: 115, steps per second: 153, episode reward: -4.420, mean reward: -0.038 [-100.000, 11.439], mean action: 1.783 [0.000, 3.000],  loss: 229.228587, mae: 346.131613, mean_q: 464.491822, mean_eps: 0.406171
 198106/300000: episode: 1704, duration: 0.683s, episode steps: 105, steps per second: 154, episode reward: -174.444, mean reward: -1.661 [-100.000, 43.695], mean action: 1.495 [0.000, 3.000],  loss: 372.359760, mae: 340.454736, mean_q: 457.474864, mean_eps: 0.405841
 198247/300000: episode: 1705, duration: 1.057s, episode steps: 141, steps per second: 133, episode reward: 13.127, mean reward:  0.093 [-100.000, 17.128], mean action: 1.404 [0.000, 3.000],  loss: 284.291487, mae: 339.869370, mean_q: 457.149895, mean_eps: 0.405472
 198356/300000: episode: 1706, duration: 0.806s, episode steps: 109, steps per second: 135, episode reward:  3.342, mean reward:  0.031 [-100.000, 15.711], mean action: 1.661 [0.000, 3.000],  loss: 239.681252, mae: 335.741593, mean_q: 452.169941, mean_eps: 0.405097
 198477/300000: episode: 1707, duration: 0.885s, episode steps: 121, steps per second: 137, episode reward:  4.661, mean reward:  0.039 [-100.000, 11.733], mean action: 1.554 [0.000, 3.000],  loss: 257.594002, mae: 334.681874, mean_q: 450.798079, mean_eps: 0.404752
 198771/300000: episode: 1708, duration: 2.106s, episode steps: 294, steps per second: 140, episode reward: -133.355, mean reward: -0.454 [-100.000, 28.375], mean action: 1.609 [0.000, 3.000],  loss: 219.629699, mae: 333.986187, mean_q: 449.911952, mean_eps: 0.404129
 199771/300000: episode: 1709, duration: 7.568s, episode steps: 1000, steps per second: 132, episode reward: 96.539, mean reward:  0.097 [-22.010, 25.832], mean action: 1.580 [0.000, 3.000],  loss: 229.698241, mae: 329.416840, mean_q: 443.464515, mean_eps: 0.402188
 199870/300000: episode: 1710, duration: 0.659s, episode steps:  99, steps per second: 150, episode reward: -4.907, mean reward: -0.050 [-100.000, 18.681], mean action: 1.465 [0.000, 3.000],  loss: 237.378872, mae: 328.213127, mean_q: 441.322763, mean_eps: 0.400540
 199953/300000: episode: 1711, duration: 0.538s, episode steps:  83, steps per second: 154, episode reward: -23.447, mean reward: -0.282 [-100.000, 16.174], mean action: 1.313 [0.000, 3.000],  loss: 179.332049, mae: 327.643176, mean_q: 440.509594, mean_eps: 0.400267
 200093/300000: episode: 1712, duration: 0.886s, episode steps: 140, steps per second: 158, episode reward: -2.676, mean reward: -0.019 [-100.000, 20.600], mean action: 1.607 [0.000, 3.000],  loss: 201.499365, mae: 327.038232, mean_q: 439.795047, mean_eps: 0.399932
 200177/300000: episode: 1713, duration: 0.545s, episode steps:  84, steps per second: 154, episode reward: -36.514, mean reward: -0.435 [-100.000, 14.901], mean action: 1.655 [0.000, 3.000],  loss: 208.483770, mae: 322.247292, mean_q: 432.668596, mean_eps: 0.399597
 200277/300000: episode: 1714, duration: 0.679s, episode steps: 100, steps per second: 147, episode reward: -25.858, mean reward: -0.259 [-100.000, 10.902], mean action: 1.800 [0.000, 3.000],  loss: 279.854279, mae: 322.838033, mean_q: 433.614600, mean_eps: 0.399321
 200359/300000: episode: 1715, duration: 0.523s, episode steps:  82, steps per second: 157, episode reward: -36.657, mean reward: -0.447 [-100.000,  7.131], mean action: 1.744 [0.000, 3.000],  loss: 300.865148, mae: 319.964269, mean_q: 431.175037, mean_eps: 0.399048
 200464/300000: episode: 1716, duration: 0.696s, episode steps: 105, steps per second: 151, episode reward: -8.386, mean reward: -0.080 [-100.000, 13.068], mean action: 1.438 [0.000, 3.000],  loss: 192.422040, mae: 319.469880, mean_q: 430.374626, mean_eps: 0.398767
 201464/300000: episode: 1717, duration: 7.178s, episode steps: 1000, steps per second: 139, episode reward: 81.711, mean reward:  0.082 [-24.322, 24.697], mean action: 1.622 [0.000, 3.000],  loss: 201.082740, mae: 316.349590, mean_q: 425.994567, mean_eps: 0.397109
 202464/300000: episode: 1718, duration: 7.612s, episode steps: 1000, steps per second: 131, episode reward: -30.880, mean reward: -0.031 [-23.880, 18.969], mean action: 1.697 [0.000, 3.000],  loss: 181.184953, mae: 311.335025, mean_q: 418.724157, mean_eps: 0.394110
 202584/300000: episode: 1719, duration: 0.780s, episode steps: 120, steps per second: 154, episode reward: 18.096, mean reward:  0.151 [-100.000, 14.701], mean action: 1.608 [0.000, 3.000],  loss: 179.947583, mae: 306.481904, mean_q: 411.158171, mean_eps: 0.392429
 202692/300000: episode: 1720, duration: 0.708s, episode steps: 108, steps per second: 153, episode reward: -18.509, mean reward: -0.171 [-100.000, 15.661], mean action: 1.583 [0.000, 3.000],  loss: 150.209829, mae: 303.653077, mean_q: 408.341350, mean_eps: 0.392088
 203692/300000: episode: 1721, duration: 7.605s, episode steps: 1000, steps per second: 131, episode reward: -5.745, mean reward: -0.006 [-21.983, 22.745], mean action: 1.607 [0.000, 3.000],  loss: 177.418255, mae: 300.438445, mean_q: 403.601841, mean_eps: 0.390425
 203828/300000: episode: 1722, duration: 1.004s, episode steps: 136, steps per second: 136, episode reward: -1.935, mean reward: -0.014 [-100.000, 14.466], mean action: 1.618 [0.000, 3.000],  loss: 190.661897, mae: 299.714926, mean_q: 403.306154, mean_eps: 0.388721
 203941/300000: episode: 1723, duration: 0.773s, episode steps: 113, steps per second: 146, episode reward: -80.085, mean reward: -0.709 [-100.000, 17.050], mean action: 1.389 [0.000, 3.000],  loss: 166.819848, mae: 299.856048, mean_q: 403.347360, mean_eps: 0.388348
 204062/300000: episode: 1724, duration: 0.903s, episode steps: 121, steps per second: 134, episode reward:  2.559, mean reward:  0.021 [-100.000, 19.267], mean action: 1.736 [0.000, 3.000],  loss: 191.617070, mae: 295.991699, mean_q: 398.509574, mean_eps: 0.387997
 204177/300000: episode: 1725, duration: 0.803s, episode steps: 115, steps per second: 143, episode reward: -178.512, mean reward: -1.552 [-100.000, 61.506], mean action: 1.791 [0.000, 3.000],  loss: 199.657876, mae: 292.402782, mean_q: 393.781905, mean_eps: 0.387643
 204265/300000: episode: 1726, duration: 0.624s, episode steps:  88, steps per second: 141, episode reward: 12.722, mean reward:  0.145 [-100.000, 20.753], mean action: 1.580 [0.000, 3.000],  loss: 132.585986, mae: 289.689481, mean_q: 389.710114, mean_eps: 0.387338
 204403/300000: episode: 1727, duration: 0.999s, episode steps: 138, steps per second: 138, episode reward: -285.628, mean reward: -2.070 [-100.000, 47.322], mean action: 1.493 [0.000, 3.000],  loss: 136.123447, mae: 289.647670, mean_q: 389.800897, mean_eps: 0.386999
 205403/300000: episode: 1728, duration: 7.647s, episode steps: 1000, steps per second: 131, episode reward: 88.567, mean reward:  0.089 [-21.069, 49.607], mean action: 1.946 [0.000, 3.000],  loss: 212.470831, mae: 283.729377, mean_q: 381.681588, mean_eps: 0.385293
 205532/300000: episode: 1729, duration: 0.869s, episode steps: 129, steps per second: 149, episode reward: 36.116, mean reward:  0.280 [-100.000, 18.520], mean action: 1.791 [0.000, 3.000],  loss: 176.271429, mae: 276.210980, mean_q: 372.189592, mean_eps: 0.383599
 205671/300000: episode: 1730, duration: 0.883s, episode steps: 139, steps per second: 157, episode reward: -2.735, mean reward: -0.020 [-100.000, 18.963], mean action: 1.554 [0.000, 3.000],  loss: 192.637037, mae: 274.571670, mean_q: 369.445348, mean_eps: 0.383197
 206671/300000: episode: 1731, duration: 7.359s, episode steps: 1000, steps per second: 136, episode reward: 41.029, mean reward:  0.041 [-21.829, 24.988], mean action: 1.336 [0.000, 3.000],  loss: 163.510626, mae: 270.638390, mean_q: 363.995637, mean_eps: 0.381489
 207671/300000: episode: 1732, duration: 7.881s, episode steps: 1000, steps per second: 127, episode reward: -55.958, mean reward: -0.056 [-21.944, 21.622], mean action: 1.619 [0.000, 3.000],  loss: 148.996023, mae: 260.137294, mean_q: 349.115632, mean_eps: 0.378489
 207772/300000: episode: 1733, duration: 0.676s, episode steps: 101, steps per second: 150, episode reward: -126.758, mean reward: -1.255 [-100.000,  2.634], mean action: 1.614 [0.000, 3.000],  loss: 168.698943, mae: 260.949413, mean_q: 350.611534, mean_eps: 0.376837
 207887/300000: episode: 1734, duration: 0.813s, episode steps: 115, steps per second: 141, episode reward: -21.747, mean reward: -0.189 [-100.000, 17.971], mean action: 1.826 [0.000, 3.000],  loss: 160.395646, mae: 260.198215, mean_q: 349.319744, mean_eps: 0.376513
 208230/300000: episode: 1735, duration: 2.282s, episode steps: 343, steps per second: 150, episode reward: -175.624, mean reward: -0.512 [-100.000, 13.672], mean action: 1.863 [0.000, 3.000],  loss: 157.210837, mae: 255.649632, mean_q: 343.870622, mean_eps: 0.375826
 209230/300000: episode: 1736, duration: 7.740s, episode steps: 1000, steps per second: 129, episode reward: 55.342, mean reward:  0.055 [-24.426, 36.839], mean action: 1.737 [0.000, 3.000],  loss: 152.620644, mae: 247.173071, mean_q: 332.939766, mean_eps: 0.373812
 209471/300000: episode: 1737, duration: 1.580s, episode steps: 241, steps per second: 153, episode reward: -286.155, mean reward: -1.187 [-100.000,  5.409], mean action: 1.631 [0.000, 3.000],  loss: 144.668602, mae: 245.038568, mean_q: 330.170552, mean_eps: 0.371950
 209639/300000: episode: 1738, duration: 1.111s, episode steps: 168, steps per second: 151, episode reward: -50.105, mean reward: -0.298 [-100.000,  7.896], mean action: 1.821 [0.000, 3.000],  loss: 145.321059, mae: 244.004022, mean_q: 328.258845, mean_eps: 0.371336
 209718/300000: episode: 1739, duration: 0.508s, episode steps:  79, steps per second: 155, episode reward: -11.933, mean reward: -0.151 [-100.000, 12.432], mean action: 2.063 [0.000, 3.000],  loss: 147.547952, mae: 244.996874, mean_q: 330.724500, mean_eps: 0.370966
 210718/300000: episode: 1740, duration: 7.503s, episode steps: 1000, steps per second: 133, episode reward: -18.489, mean reward: -0.018 [-23.792, 22.543], mean action: 1.704 [0.000, 3.000],  loss: 131.149326, mae: 240.239112, mean_q: 323.497702, mean_eps: 0.369347
 211718/300000: episode: 1741, duration: 7.395s, episode steps: 1000, steps per second: 135, episode reward: 22.792, mean reward:  0.023 [-19.384, 15.308], mean action: 1.936 [0.000, 3.000],  loss: 131.306984, mae: 233.731786, mean_q: 313.968675, mean_eps: 0.366347
 211811/300000: episode: 1742, duration: 0.611s, episode steps:  93, steps per second: 152, episode reward: -17.162, mean reward: -0.185 [-100.000, 15.031], mean action: 1.806 [0.000, 3.000],  loss: 152.194140, mae: 233.274709, mean_q: 313.580948, mean_eps: 0.364708
 211928/300000: episode: 1743, duration: 0.765s, episode steps: 117, steps per second: 153, episode reward: -11.672, mean reward: -0.100 [-100.000, 17.745], mean action: 1.812 [0.000, 3.000],  loss: 124.173748, mae: 231.751338, mean_q: 311.302138, mean_eps: 0.364393
 212151/300000: episode: 1744, duration: 1.463s, episode steps: 223, steps per second: 152, episode reward: -174.679, mean reward: -0.783 [-100.000, 16.090], mean action: 1.700 [0.000, 3.000],  loss: 144.954001, mae: 233.752224, mean_q: 313.816367, mean_eps: 0.363883
 212256/300000: episode: 1745, duration: 0.670s, episode steps: 105, steps per second: 157, episode reward:  8.198, mean reward:  0.078 [-100.000, 13.534], mean action: 1.286 [0.000, 3.000],  loss: 116.411336, mae: 230.927298, mean_q: 309.477146, mean_eps: 0.363391
 213256/300000: episode: 1746, duration: 7.881s, episode steps: 1000, steps per second: 127, episode reward: -52.822, mean reward: -0.053 [-23.095, 23.133], mean action: 1.671 [0.000, 3.000],  loss: 116.598691, mae: 224.059378, mean_q: 300.811470, mean_eps: 0.361734
 213359/300000: episode: 1747, duration: 0.670s, episode steps: 103, steps per second: 154, episode reward: -79.234, mean reward: -0.769 [-100.000, 12.704], mean action: 1.524 [0.000, 3.000],  loss: 105.155824, mae: 222.237116, mean_q: 298.232108, mean_eps: 0.360079
 214359/300000: episode: 1748, duration: 7.083s, episode steps: 1000, steps per second: 141, episode reward: 46.855, mean reward:  0.047 [-22.518, 23.675], mean action: 1.263 [0.000, 3.000],  loss: 104.535953, mae: 218.322363, mean_q: 293.916042, mean_eps: 0.358424
 214515/300000: episode: 1749, duration: 0.997s, episode steps: 156, steps per second: 156, episode reward: -89.405, mean reward: -0.573 [-100.000, 16.597], mean action: 1.808 [0.000, 3.000],  loss: 122.955255, mae: 215.387701, mean_q: 290.089049, mean_eps: 0.356691
 214621/300000: episode: 1750, duration: 0.671s, episode steps: 106, steps per second: 158, episode reward: -19.541, mean reward: -0.184 [-100.000, 16.440], mean action: 1.566 [0.000, 3.000],  loss: 97.399013, mae: 215.046726, mean_q: 289.316247, mean_eps: 0.356298
 215621/300000: episode: 1751, duration: 7.972s, episode steps: 1000, steps per second: 125, episode reward: -5.407, mean reward: -0.005 [-19.528, 18.326], mean action: 1.762 [0.000, 3.000],  loss: 93.825596, mae: 212.185952, mean_q: 286.054401, mean_eps: 0.354638
 215729/300000: episode: 1752, duration: 0.686s, episode steps: 108, steps per second: 157, episode reward: -29.478, mean reward: -0.273 [-100.000, 12.409], mean action: 1.620 [0.000, 3.000],  loss: 121.194641, mae: 213.432902, mean_q: 287.869247, mean_eps: 0.352977
 216729/300000: episode: 1753, duration: 8.129s, episode steps: 1000, steps per second: 123, episode reward: 49.324, mean reward:  0.049 [-20.719, 28.457], mean action: 1.715 [0.000, 3.000],  loss: 96.682021, mae: 212.212311, mean_q: 286.342975, mean_eps: 0.351315
 216912/300000: episode: 1754, duration: 1.241s, episode steps: 183, steps per second: 147, episode reward: -103.459, mean reward: -0.565 [-100.000,  9.161], mean action: 1.699 [0.000, 3.000],  loss: 90.569494, mae: 209.821779, mean_q: 283.654350, mean_eps: 0.349540
 217912/300000: episode: 1755, duration: 7.303s, episode steps: 1000, steps per second: 137, episode reward: -48.052, mean reward: -0.048 [-20.129, 21.516], mean action: 1.827 [0.000, 3.000],  loss: 105.668188, mae: 207.668145, mean_q: 280.787130, mean_eps: 0.347766
 217999/300000: episode: 1756, duration: 0.547s, episode steps:  87, steps per second: 159, episode reward: 27.457, mean reward:  0.316 [-100.000, 12.251], mean action: 1.678 [0.000, 3.000],  loss: 87.153563, mae: 203.175809, mean_q: 274.579003, mean_eps: 0.346135
 218123/300000: episode: 1757, duration: 0.842s, episode steps: 124, steps per second: 147, episode reward: -3.754, mean reward: -0.030 [-100.000, 16.585], mean action: 1.823 [0.000, 3.000],  loss: 98.968179, mae: 204.059985, mean_q: 275.763256, mean_eps: 0.345819
 218234/300000: episode: 1758, duration: 0.711s, episode steps: 111, steps per second: 156, episode reward: -62.674, mean reward: -0.565 [-100.000, 10.638], mean action: 1.559 [0.000, 3.000],  loss: 83.731345, mae: 203.518063, mean_q: 274.961679, mean_eps: 0.345466
 218476/300000: episode: 1759, duration: 1.606s, episode steps: 242, steps per second: 151, episode reward: -220.395, mean reward: -0.911 [-100.000, 12.368], mean action: 1.740 [0.000, 3.000],  loss: 95.109369, mae: 203.355269, mean_q: 274.918562, mean_eps: 0.344936
 218602/300000: episode: 1760, duration: 0.802s, episode steps: 126, steps per second: 157, episode reward: -105.684, mean reward: -0.839 [-100.000, 16.822], mean action: 1.817 [0.000, 3.000],  loss: 106.295456, mae: 201.518839, mean_q: 272.312614, mean_eps: 0.344384
 219602/300000: episode: 1761, duration: 7.009s, episode steps: 1000, steps per second: 143, episode reward: 150.242, mean reward:  0.150 [-21.816, 22.605], mean action: 1.801 [0.000, 3.000],  loss: 81.296592, mae: 202.022372, mean_q: 273.088432, mean_eps: 0.342696
 219738/300000: episode: 1762, duration: 0.944s, episode steps: 136, steps per second: 144, episode reward:  8.916, mean reward:  0.066 [-100.000, 11.483], mean action: 1.743 [0.000, 3.000],  loss: 79.046622, mae: 200.374073, mean_q: 271.107868, mean_eps: 0.340991
 219891/300000: episode: 1763, duration: 0.973s, episode steps: 153, steps per second: 157, episode reward: -345.692, mean reward: -2.259 [-100.000,  4.892], mean action: 1.824 [0.000, 3.000],  loss: 77.970708, mae: 200.091483, mean_q: 270.649714, mean_eps: 0.340558
 220406/300000: episode: 1764, duration: 3.591s, episode steps: 515, steps per second: 143, episode reward: -160.657, mean reward: -0.312 [-100.000, 22.456], mean action: 1.757 [0.000, 3.000],  loss: 100.427902, mae: 199.293126, mean_q: 269.370545, mean_eps: 0.339556
 221406/300000: episode: 1765, duration: 7.288s, episode steps: 1000, steps per second: 137, episode reward:  9.674, mean reward:  0.010 [-21.431, 26.780], mean action: 1.746 [0.000, 3.000],  loss: 73.969839, mae: 193.501457, mean_q: 261.348579, mean_eps: 0.337284
 221509/300000: episode: 1766, duration: 0.701s, episode steps: 103, steps per second: 147, episode reward: 19.254, mean reward:  0.187 [-100.000, 17.026], mean action: 1.786 [0.000, 3.000],  loss: 86.164768, mae: 189.895169, mean_q: 256.339595, mean_eps: 0.335629
 222509/300000: episode: 1767, duration: 7.450s, episode steps: 1000, steps per second: 134, episode reward: 69.083, mean reward:  0.069 [-20.877, 21.158], mean action: 1.510 [0.000, 3.000],  loss: 78.922172, mae: 187.706762, mean_q: 253.297904, mean_eps: 0.333974
 222651/300000: episode: 1768, duration: 0.927s, episode steps: 142, steps per second: 153, episode reward: -79.165, mean reward: -0.558 [-100.000, 10.643], mean action: 1.465 [0.000, 3.000],  loss: 79.067010, mae: 186.004788, mean_q: 251.187112, mean_eps: 0.332261
 222772/300000: episode: 1769, duration: 0.782s, episode steps: 121, steps per second: 155, episode reward: -26.206, mean reward: -0.217 [-100.000, 14.410], mean action: 1.240 [0.000, 3.000],  loss: 83.124333, mae: 187.235918, mean_q: 252.636268, mean_eps: 0.331867
 222863/300000: episode: 1770, duration: 0.578s, episode steps:  91, steps per second: 158, episode reward: -50.440, mean reward: -0.554 [-100.000, 11.552], mean action: 1.308 [0.000, 3.000],  loss: 65.342697, mae: 188.278448, mean_q: 254.205879, mean_eps: 0.331549
 222968/300000: episode: 1771, duration: 0.685s, episode steps: 105, steps per second: 153, episode reward: -30.162, mean reward: -0.287 [-100.000,  8.068], mean action: 1.505 [0.000, 3.000],  loss: 85.433398, mae: 185.788382, mean_q: 250.402201, mean_eps: 0.331255
 223091/300000: episode: 1772, duration: 0.833s, episode steps: 123, steps per second: 148, episode reward: -61.993, mean reward: -0.504 [-100.000,  6.590], mean action: 1.821 [0.000, 3.000],  loss: 89.881696, mae: 185.997475, mean_q: 251.042662, mean_eps: 0.330913
 223209/300000: episode: 1773, duration: 0.755s, episode steps: 118, steps per second: 156, episode reward: -51.145, mean reward: -0.433 [-100.000,  8.777], mean action: 1.898 [0.000, 3.000],  loss: 84.741226, mae: 185.466388, mean_q: 249.883072, mean_eps: 0.330551
 224209/300000: episode: 1774, duration: 7.494s, episode steps: 1000, steps per second: 133, episode reward: 41.638, mean reward:  0.042 [-21.364, 58.711], mean action: 1.401 [0.000, 3.000],  loss: 87.195513, mae: 182.342784, mean_q: 245.785761, mean_eps: 0.328875
 224649/300000: episode: 1775, duration: 2.968s, episode steps: 440, steps per second: 148, episode reward: -281.651, mean reward: -0.640 [-100.000, 15.720], mean action: 1.611 [0.000, 3.000],  loss: 69.073944, mae: 178.936099, mean_q: 241.187920, mean_eps: 0.326715
 224792/300000: episode: 1776, duration: 0.920s, episode steps: 143, steps per second: 156, episode reward: -200.178, mean reward: -1.400 [-100.000, 38.472], mean action: 1.434 [0.000, 3.000],  loss: 82.538476, mae: 179.082048, mean_q: 241.297772, mean_eps: 0.325840
 225792/300000: episode: 1777, duration: 8.298s, episode steps: 1000, steps per second: 121, episode reward: 63.266, mean reward:  0.063 [-24.837, 22.181], mean action: 1.575 [0.000, 3.000],  loss: 70.785601, mae: 176.566143, mean_q: 238.126098, mean_eps: 0.324126
 226792/300000: episode: 1778, duration: 7.607s, episode steps: 1000, steps per second: 131, episode reward: 84.411, mean reward:  0.084 [-22.150, 24.250], mean action: 1.262 [0.000, 3.000],  loss: 69.070790, mae: 172.360885, mean_q: 232.598531, mean_eps: 0.321126
 227048/300000: episode: 1779, duration: 1.686s, episode steps: 256, steps per second: 152, episode reward: -281.178, mean reward: -1.098 [-100.000, 30.610], mean action: 1.680 [0.000, 3.000],  loss: 58.039174, mae: 172.237344, mean_q: 232.224366, mean_eps: 0.319241
 227161/300000: episode: 1780, duration: 0.734s, episode steps: 113, steps per second: 154, episode reward: -258.282, mean reward: -2.286 [-100.000,  4.224], mean action: 1.673 [0.000, 3.000],  loss: 67.769230, mae: 172.041550, mean_q: 231.993197, mean_eps: 0.318688
 227291/300000: episode: 1781, duration: 0.829s, episode steps: 130, steps per second: 157, episode reward: -256.872, mean reward: -1.976 [-100.000,  3.072], mean action: 1.638 [0.000, 3.000],  loss: 105.978905, mae: 174.371010, mean_q: 234.766355, mean_eps: 0.318323
 228291/300000: episode: 1782, duration: 7.304s, episode steps: 1000, steps per second: 137, episode reward: -19.495, mean reward: -0.019 [-23.267, 23.577], mean action: 1.589 [0.000, 3.000],  loss: 74.595941, mae: 172.632732, mean_q: 232.704578, mean_eps: 0.316628
 228518/300000: episode: 1783, duration: 1.477s, episode steps: 227, steps per second: 154, episode reward: -39.561, mean reward: -0.174 [-100.000, 12.956], mean action: 1.731 [0.000, 3.000],  loss: 61.465956, mae: 169.480587, mean_q: 228.518357, mean_eps: 0.314788
 228654/300000: episode: 1784, duration: 0.899s, episode steps: 136, steps per second: 151, episode reward: -9.291, mean reward: -0.068 [-100.000, 17.627], mean action: 1.728 [0.000, 3.000],  loss: 59.672751, mae: 169.089361, mean_q: 228.177680, mean_eps: 0.314244
 229654/300000: episode: 1785, duration: 7.343s, episode steps: 1000, steps per second: 136, episode reward: 54.183, mean reward:  0.054 [-23.623, 22.858], mean action: 1.627 [0.000, 3.000],  loss: 62.106068, mae: 164.845499, mean_q: 222.072158, mean_eps: 0.312539
 230654/300000: episode: 1786, duration: 7.339s, episode steps: 1000, steps per second: 136, episode reward: 40.156, mean reward:  0.040 [-23.301, 24.884], mean action: 1.645 [0.000, 3.000],  loss: 59.400749, mae: 156.629334, mean_q: 211.168608, mean_eps: 0.309539
 230758/300000: episode: 1787, duration: 0.733s, episode steps: 104, steps per second: 142, episode reward: 12.945, mean reward:  0.124 [-100.000, 19.809], mean action: 1.702 [0.000, 3.000],  loss: 70.066755, mae: 151.794616, mean_q: 204.630273, mean_eps: 0.307883
 230880/300000: episode: 1788, duration: 0.896s, episode steps: 122, steps per second: 136, episode reward: 28.006, mean reward:  0.230 [-100.000, 14.830], mean action: 1.385 [0.000, 3.000],  loss: 57.568920, mae: 151.846267, mean_q: 204.871293, mean_eps: 0.307544
 231039/300000: episode: 1789, duration: 1.159s, episode steps: 159, steps per second: 137, episode reward: -447.159, mean reward: -2.812 [-100.000,  3.912], mean action: 1.535 [0.000, 3.000],  loss: 68.159165, mae: 152.904583, mean_q: 206.299804, mean_eps: 0.307123
 231179/300000: episode: 1790, duration: 0.955s, episode steps: 140, steps per second: 147, episode reward: -108.350, mean reward: -0.774 [-100.000, 10.217], mean action: 1.757 [0.000, 3.000],  loss: 64.607633, mae: 154.498745, mean_q: 207.974187, mean_eps: 0.306674
 231331/300000: episode: 1791, duration: 1.080s, episode steps: 152, steps per second: 141, episode reward: -292.343, mean reward: -1.923 [-100.000,  3.814], mean action: 1.579 [0.000, 3.000],  loss: 59.806554, mae: 157.253061, mean_q: 212.035302, mean_eps: 0.306236
 231459/300000: episode: 1792, duration: 0.840s, episode steps: 128, steps per second: 152, episode reward: -17.290, mean reward: -0.135 [-100.000,  7.760], mean action: 1.859 [0.000, 3.000],  loss: 56.226022, mae: 158.681789, mean_q: 213.925449, mean_eps: 0.305816
 232459/300000: episode: 1793, duration: 7.072s, episode steps: 1000, steps per second: 141, episode reward: 110.321, mean reward:  0.110 [-21.627, 23.551], mean action: 1.308 [0.000, 3.000],  loss: 66.885576, mae: 159.166366, mean_q: 214.455945, mean_eps: 0.304125
 232625/300000: episode: 1794, duration: 1.099s, episode steps: 166, steps per second: 151, episode reward: -17.729, mean reward: -0.107 [-100.000, 12.111], mean action: 1.795 [0.000, 3.000],  loss: 53.029299, mae: 156.290792, mean_q: 210.625321, mean_eps: 0.302376
 232791/300000: episode: 1795, duration: 1.064s, episode steps: 166, steps per second: 156, episode reward: -312.340, mean reward: -1.882 [-100.000, 33.840], mean action: 1.596 [0.000, 3.000],  loss: 57.735588, mae: 154.287635, mean_q: 207.664521, mean_eps: 0.301878
 232959/300000: episode: 1796, duration: 1.135s, episode steps: 168, steps per second: 148, episode reward:  5.779, mean reward:  0.034 [-100.000, 16.476], mean action: 1.655 [0.000, 3.000],  loss: 59.972766, mae: 154.678163, mean_q: 208.217902, mean_eps: 0.301376
 233294/300000: episode: 1797, duration: 2.258s, episode steps: 335, steps per second: 148, episode reward: -42.892, mean reward: -0.128 [-100.000, 19.317], mean action: 1.719 [0.000, 3.000],  loss: 66.296270, mae: 156.125702, mean_q: 210.072954, mean_eps: 0.300622
 234294/300000: episode: 1798, duration: 7.396s, episode steps: 1000, steps per second: 135, episode reward: -34.473, mean reward: -0.034 [-21.589, 21.573], mean action: 1.811 [0.000, 3.000],  loss: 62.790266, mae: 153.998238, mean_q: 207.294328, mean_eps: 0.298620
 235294/300000: episode: 1799, duration: 8.107s, episode steps: 1000, steps per second: 123, episode reward: 80.709, mean reward:  0.081 [-24.006, 23.539], mean action: 1.455 [0.000, 3.000],  loss: 51.044730, mae: 152.481739, mean_q: 205.185881, mean_eps: 0.295620
 235770/300000: episode: 1800, duration: 3.311s, episode steps: 476, steps per second: 144, episode reward: 194.631, mean reward:  0.409 [-22.699, 100.000], mean action: 1.336 [0.000, 3.000],  loss: 54.981901, mae: 152.109782, mean_q: 204.395427, mean_eps: 0.293406
 235967/300000: episode: 1801, duration: 1.276s, episode steps: 197, steps per second: 154, episode reward: -39.062, mean reward: -0.198 [-100.000, 13.498], mean action: 1.822 [0.000, 3.000],  loss: 41.015288, mae: 152.900220, mean_q: 205.760705, mean_eps: 0.292396
 236309/300000: episode: 1802, duration: 2.275s, episode steps: 342, steps per second: 150, episode reward: -114.777, mean reward: -0.336 [-100.000, 14.333], mean action: 1.722 [0.000, 3.000],  loss: 55.115278, mae: 156.065294, mean_q: 209.332597, mean_eps: 0.291587
 236538/300000: episode: 1803, duration: 1.522s, episode steps: 229, steps per second: 151, episode reward: -235.907, mean reward: -1.030 [-100.000,  8.581], mean action: 1.786 [0.000, 3.000],  loss: 70.495217, mae: 155.670803, mean_q: 208.622417, mean_eps: 0.290731
 237398/300000: episode: 1804, duration: 6.406s, episode steps: 860, steps per second: 134, episode reward: -124.507, mean reward: -0.145 [-100.000, 28.871], mean action: 1.649 [0.000, 3.000],  loss: 51.503959, mae: 152.239149, mean_q: 204.624800, mean_eps: 0.289098
 237540/300000: episode: 1805, duration: 0.919s, episode steps: 142, steps per second: 154, episode reward: 21.295, mean reward:  0.150 [-100.000, 24.411], mean action: 1.669 [0.000, 3.000],  loss: 45.179728, mae: 151.661361, mean_q: 204.005226, mean_eps: 0.287595
 237666/300000: episode: 1806, duration: 0.862s, episode steps: 126, steps per second: 146, episode reward: -14.967, mean reward: -0.119 [-100.000, 22.811], mean action: 1.683 [0.000, 3.000],  loss: 59.687235, mae: 152.061109, mean_q: 204.475206, mean_eps: 0.287192
 238666/300000: episode: 1807, duration: 7.296s, episode steps: 1000, steps per second: 137, episode reward: 67.149, mean reward:  0.067 [-21.217, 24.007], mean action: 1.460 [0.000, 3.000],  loss: 55.343419, mae: 148.717161, mean_q: 199.831889, mean_eps: 0.285503
 239057/300000: episode: 1808, duration: 2.669s, episode steps: 391, steps per second: 146, episode reward: -179.096, mean reward: -0.458 [-100.000, 21.330], mean action: 1.867 [0.000, 3.000],  loss: 45.266095, mae: 144.873263, mean_q: 194.533773, mean_eps: 0.283417
 240057/300000: episode: 1809, duration: 7.601s, episode steps: 1000, steps per second: 132, episode reward: 30.505, mean reward:  0.031 [-20.791, 24.402], mean action: 1.652 [0.000, 3.000],  loss: 51.053004, mae: 145.817346, mean_q: 195.639969, mean_eps: 0.281330
 241057/300000: episode: 1810, duration: 7.659s, episode steps: 1000, steps per second: 131, episode reward: 60.457, mean reward:  0.060 [-23.382, 24.076], mean action: 1.630 [0.000, 3.000],  loss: 45.461956, mae: 136.104807, mean_q: 182.562617, mean_eps: 0.278330
 241366/300000: episode: 1811, duration: 2.027s, episode steps: 309, steps per second: 152, episode reward: -139.076, mean reward: -0.450 [-100.000, 11.162], mean action: 1.858 [0.000, 3.000],  loss: 38.852592, mae: 128.648785, mean_q: 172.209991, mean_eps: 0.276367
 241478/300000: episode: 1812, duration: 0.747s, episode steps: 112, steps per second: 150, episode reward: -161.032, mean reward: -1.438 [-100.000, 11.561], mean action: 1.946 [0.000, 3.000],  loss: 39.323333, mae: 130.831624, mean_q: 175.110174, mean_eps: 0.275736
 241726/300000: episode: 1813, duration: 1.616s, episode steps: 248, steps per second: 153, episode reward: -392.122, mean reward: -1.581 [-100.000, 91.049], mean action: 1.593 [0.000, 3.000],  loss: 40.955995, mae: 132.031176, mean_q: 176.886961, mean_eps: 0.275195
 241839/300000: episode: 1814, duration: 0.744s, episode steps: 113, steps per second: 152, episode reward: -384.006, mean reward: -3.398 [-100.000, 14.019], mean action: 1.805 [0.000, 3.000],  loss: 38.111884, mae: 131.536836, mean_q: 175.167476, mean_eps: 0.274654
 242131/300000: episode: 1815, duration: 1.963s, episode steps: 292, steps per second: 149, episode reward: -64.289, mean reward: -0.220 [-100.000, 20.848], mean action: 1.808 [0.000, 3.000],  loss: 54.114051, mae: 131.211134, mean_q: 174.502211, mean_eps: 0.274046
 242290/300000: episode: 1816, duration: 1.023s, episode steps: 159, steps per second: 155, episode reward: -220.163, mean reward: -1.385 [-100.000,  1.895], mean action: 1.698 [0.000, 3.000],  loss: 54.447232, mae: 129.985047, mean_q: 172.623708, mean_eps: 0.273370
 242417/300000: episode: 1817, duration: 0.920s, episode steps: 127, steps per second: 138, episode reward: -220.960, mean reward: -1.740 [-100.000, 16.109], mean action: 1.843 [0.000, 3.000],  loss: 56.073344, mae: 129.057061, mean_q: 171.275508, mean_eps: 0.272941
 242559/300000: episode: 1818, duration: 0.927s, episode steps: 142, steps per second: 153, episode reward: -3.337, mean reward: -0.024 [-100.000, 39.549], mean action: 1.655 [0.000, 3.000],  loss: 50.949040, mae: 129.547028, mean_q: 172.224919, mean_eps: 0.272537
 242719/300000: episode: 1819, duration: 1.075s, episode steps: 160, steps per second: 149, episode reward: -114.911, mean reward: -0.718 [-100.000, 13.933], mean action: 1.738 [0.000, 3.000],  loss: 52.292214, mae: 130.068891, mean_q: 172.668110, mean_eps: 0.272084
 242866/300000: episode: 1820, duration: 0.972s, episode steps: 147, steps per second: 151, episode reward: -275.973, mean reward: -1.877 [-100.000, 10.211], mean action: 1.776 [0.000, 3.000],  loss: 42.635811, mae: 129.846425, mean_q: 172.586392, mean_eps: 0.271624
 243014/300000: episode: 1821, duration: 0.945s, episode steps: 148, steps per second: 157, episode reward: -163.713, mean reward: -1.106 [-100.000,  2.549], mean action: 1.581 [0.000, 3.000],  loss: 47.560778, mae: 130.397622, mean_q: 173.276908, mean_eps: 0.271181
 243145/300000: episode: 1822, duration: 0.890s, episode steps: 131, steps per second: 147, episode reward: -137.696, mean reward: -1.051 [-100.000,  3.083], mean action: 1.656 [0.000, 3.000],  loss: 38.512701, mae: 129.950187, mean_q: 172.194039, mean_eps: 0.270763
 243728/300000: episode: 1823, duration: 4.234s, episode steps: 583, steps per second: 138, episode reward: -145.143, mean reward: -0.249 [-100.000, 23.664], mean action: 1.280 [0.000, 3.000],  loss: 50.000612, mae: 129.848614, mean_q: 172.031882, mean_eps: 0.269692
 243852/300000: episode: 1824, duration: 0.870s, episode steps: 124, steps per second: 143, episode reward: -138.229, mean reward: -1.115 [-100.000,  2.841], mean action: 1.419 [0.000, 3.000],  loss: 47.559717, mae: 128.040355, mean_q: 169.708758, mean_eps: 0.268632
 244074/300000: episode: 1825, duration: 1.617s, episode steps: 222, steps per second: 137, episode reward: 22.273, mean reward:  0.100 [-100.000, 22.442], mean action: 1.793 [0.000, 3.000],  loss: 36.818403, mae: 128.759545, mean_q: 169.752510, mean_eps: 0.268112
 244222/300000: episode: 1826, duration: 0.997s, episode steps: 148, steps per second: 149, episode reward: -106.481, mean reward: -0.719 [-100.000, 25.527], mean action: 1.723 [0.000, 3.000],  loss: 54.432080, mae: 130.940401, mean_q: 173.515568, mean_eps: 0.267558
 244593/300000: episode: 1827, duration: 2.548s, episode steps: 371, steps per second: 146, episode reward: -183.272, mean reward: -0.494 [-100.000, 14.807], mean action: 1.714 [0.000, 3.000],  loss: 51.470400, mae: 130.437086, mean_q: 173.292315, mean_eps: 0.266779
 244724/300000: episode: 1828, duration: 0.842s, episode steps: 131, steps per second: 156, episode reward: -397.028, mean reward: -3.031 [-100.000,  2.045], mean action: 1.458 [0.000, 3.000],  loss: 48.780896, mae: 130.420807, mean_q: 173.152165, mean_eps: 0.266026
 245724/300000: episode: 1829, duration: 7.392s, episode steps: 1000, steps per second: 135, episode reward: 72.966, mean reward:  0.073 [-23.817, 23.580], mean action: 1.594 [0.000, 3.000],  loss: 54.293920, mae: 132.295308, mean_q: 175.714463, mean_eps: 0.264330
 245838/300000: episode: 1830, duration: 0.758s, episode steps: 114, steps per second: 150, episode reward: -1.245, mean reward: -0.011 [-100.000, 12.857], mean action: 1.579 [0.000, 3.000],  loss: 49.780591, mae: 130.190335, mean_q: 173.302118, mean_eps: 0.262658
 246265/300000: episode: 1831, duration: 2.841s, episode steps: 427, steps per second: 150, episode reward: -414.125, mean reward: -0.970 [-100.000, 15.557], mean action: 1.705 [0.000, 3.000],  loss: 42.827305, mae: 127.768957, mean_q: 169.985646, mean_eps: 0.261847
 247265/300000: episode: 1832, duration: 7.259s, episode steps: 1000, steps per second: 138, episode reward: 37.682, mean reward:  0.038 [-23.648, 27.542], mean action: 1.867 [0.000, 3.000],  loss: 49.663254, mae: 126.804092, mean_q: 168.252120, mean_eps: 0.259706
 247393/300000: episode: 1833, duration: 0.829s, episode steps: 128, steps per second: 154, episode reward:  6.704, mean reward:  0.052 [-100.000,  8.638], mean action: 1.562 [0.000, 3.000],  loss: 40.101403, mae: 125.059910, mean_q: 166.849295, mean_eps: 0.258014
 247577/300000: episode: 1834, duration: 1.185s, episode steps: 184, steps per second: 155, episode reward: -185.048, mean reward: -1.006 [-100.000, 23.351], mean action: 1.549 [0.000, 3.000],  loss: 55.570015, mae: 127.541361, mean_q: 170.303485, mean_eps: 0.257546
 248577/300000: episode: 1835, duration: 7.321s, episode steps: 1000, steps per second: 137, episode reward: 109.602, mean reward:  0.110 [-21.845, 23.011], mean action: 1.368 [0.000, 3.000],  loss: 44.628046, mae: 127.681210, mean_q: 170.688060, mean_eps: 0.255771
 248918/300000: episode: 1836, duration: 2.274s, episode steps: 341, steps per second: 150, episode reward: -151.366, mean reward: -0.444 [-100.000, 12.969], mean action: 1.789 [0.000, 3.000],  loss: 37.011146, mae: 128.591688, mean_q: 171.893690, mean_eps: 0.253759
 249049/300000: episode: 1837, duration: 0.835s, episode steps: 131, steps per second: 157, episode reward: -189.834, mean reward: -1.449 [-100.000,  8.132], mean action: 1.695 [0.000, 3.000],  loss: 46.090887, mae: 130.626612, mean_q: 174.489106, mean_eps: 0.253051
 249184/300000: episode: 1838, duration: 0.906s, episode steps: 135, steps per second: 149, episode reward: -5.810, mean reward: -0.043 [-100.000, 15.021], mean action: 1.696 [0.000, 3.000],  loss: 46.745673, mae: 132.221095, mean_q: 176.433024, mean_eps: 0.252652
 249333/300000: episode: 1839, duration: 1.079s, episode steps: 149, steps per second: 138, episode reward: -115.166, mean reward: -0.773 [-100.000, 10.928], mean action: 1.913 [0.000, 3.000],  loss: 48.065841, mae: 130.165791, mean_q: 173.759052, mean_eps: 0.252226
 249626/300000: episode: 1840, duration: 2.116s, episode steps: 293, steps per second: 138, episode reward: -21.987, mean reward: -0.075 [-100.000, 12.345], mean action: 1.768 [0.000, 3.000],  loss: 50.303252, mae: 129.954654, mean_q: 173.627551, mean_eps: 0.251563
 250626/300000: episode: 1841, duration: 7.772s, episode steps: 1000, steps per second: 129, episode reward: -77.136, mean reward: -0.077 [-24.779, 21.712], mean action: 1.796 [0.000, 3.000],  loss: 48.844454, mae: 131.529378, mean_q: 175.862554, mean_eps: 0.249623
 250791/300000: episode: 1842, duration: 1.049s, episode steps: 165, steps per second: 157, episode reward: -172.069, mean reward: -1.043 [-100.000, 10.746], mean action: 1.812 [0.000, 3.000],  loss: 55.993008, mae: 128.306862, mean_q: 171.210073, mean_eps: 0.247876
 251146/300000: episode: 1843, duration: 2.418s, episode steps: 355, steps per second: 147, episode reward: -30.964, mean reward: -0.087 [-100.000, 22.948], mean action: 1.783 [0.000, 3.000],  loss: 54.995618, mae: 127.757934, mean_q: 170.912378, mean_eps: 0.247096
 251309/300000: episode: 1844, duration: 1.144s, episode steps: 163, steps per second: 142, episode reward: -73.823, mean reward: -0.453 [-100.000,  4.134], mean action: 1.945 [0.000, 3.000],  loss: 50.164282, mae: 127.617481, mean_q: 170.852023, mean_eps: 0.246319
 251522/300000: episode: 1845, duration: 1.380s, episode steps: 213, steps per second: 154, episode reward: -148.434, mean reward: -0.697 [-100.000, 21.471], mean action: 1.638 [0.000, 3.000],  loss: 54.188466, mae: 127.829927, mean_q: 171.107498, mean_eps: 0.245755
 252522/300000: episode: 1846, duration: 7.677s, episode steps: 1000, steps per second: 130, episode reward: 105.644, mean reward:  0.106 [-25.485, 22.857], mean action: 1.648 [0.000, 3.000],  loss: 47.809269, mae: 126.753678, mean_q: 170.111224, mean_eps: 0.243935
 252608/300000: episode: 1847, duration: 0.554s, episode steps:  86, steps per second: 155, episode reward: -42.067, mean reward: -0.489 [-100.000, 11.385], mean action: 1.698 [0.000, 3.000],  loss: 40.898272, mae: 124.782190, mean_q: 167.110475, mean_eps: 0.242306
 253608/300000: episode: 1848, duration: 7.734s, episode steps: 1000, steps per second: 129, episode reward: 72.678, mean reward:  0.073 [-22.999, 22.853], mean action: 1.825 [0.000, 3.000],  loss: 43.276565, mae: 123.777442, mean_q: 165.881113, mean_eps: 0.240677
 254608/300000: episode: 1849, duration: 7.062s, episode steps: 1000, steps per second: 142, episode reward: 134.916, mean reward:  0.135 [-23.414, 22.649], mean action: 1.152 [0.000, 3.000],  loss: 40.673758, mae: 116.824328, mean_q: 156.518537, mean_eps: 0.237677
 254744/300000: episode: 1850, duration: 0.889s, episode steps: 136, steps per second: 153, episode reward: -123.713, mean reward: -0.910 [-100.000,  9.520], mean action: 1.728 [0.000, 3.000],  loss: 41.181635, mae: 112.729635, mean_q: 150.755714, mean_eps: 0.235974
 254901/300000: episode: 1851, duration: 1.045s, episode steps: 157, steps per second: 150, episode reward: -233.983, mean reward: -1.490 [-100.000,  6.629], mean action: 1.885 [0.000, 3.000],  loss: 43.766313, mae: 113.651491, mean_q: 152.406963, mean_eps: 0.235534
 255901/300000: episode: 1852, duration: 7.225s, episode steps: 1000, steps per second: 138, episode reward: 63.454, mean reward:  0.063 [-21.119, 22.647], mean action: 1.836 [0.000, 3.000],  loss: 44.350783, mae: 111.060443, mean_q: 148.553054, mean_eps: 0.233798
 256216/300000: episode: 1853, duration: 2.084s, episode steps: 315, steps per second: 151, episode reward: -234.118, mean reward: -0.743 [-100.000, 13.361], mean action: 1.686 [0.000, 3.000],  loss: 51.005480, mae: 108.999030, mean_q: 145.670177, mean_eps: 0.231826
 257216/300000: episode: 1854, duration: 7.539s, episode steps: 1000, steps per second: 133, episode reward: 26.090, mean reward:  0.026 [-21.964, 23.687], mean action: 1.678 [0.000, 3.000],  loss: 38.318057, mae: 107.911676, mean_q: 144.511037, mean_eps: 0.229853
 257305/300000: episode: 1855, duration: 0.565s, episode steps:  89, steps per second: 158, episode reward: -106.419, mean reward: -1.196 [-100.000, 12.630], mean action: 1.180 [0.000, 3.000],  loss: 40.451299, mae: 108.873625, mean_q: 145.854114, mean_eps: 0.228220
 257509/300000: episode: 1856, duration: 1.334s, episode steps: 204, steps per second: 153, episode reward: -137.405, mean reward: -0.674 [-100.000, 13.949], mean action: 1.819 [0.000, 3.000],  loss: 45.942939, mae: 110.620915, mean_q: 148.442746, mean_eps: 0.227780
 258509/300000: episode: 1857, duration: 7.448s, episode steps: 1000, steps per second: 134, episode reward: 102.427, mean reward:  0.102 [-21.829, 22.494], mean action: 1.378 [0.000, 3.000],  loss: 40.703910, mae: 109.340007, mean_q: 146.466425, mean_eps: 0.225974
 258620/300000: episode: 1858, duration: 0.789s, episode steps: 111, steps per second: 141, episode reward:  0.996, mean reward:  0.009 [-100.000, 18.248], mean action: 1.820 [0.000, 3.000],  loss: 45.710240, mae: 105.897640, mean_q: 141.402979, mean_eps: 0.224308
 259620/300000: episode: 1859, duration: 7.717s, episode steps: 1000, steps per second: 130, episode reward: 106.046, mean reward:  0.106 [-20.480, 23.047], mean action: 1.455 [0.000, 3.000],  loss: 37.664980, mae: 106.025533, mean_q: 141.835262, mean_eps: 0.222642
 260620/300000: episode: 1860, duration: 6.922s, episode steps: 1000, steps per second: 144, episode reward: 124.829, mean reward:  0.125 [-22.141, 22.349], mean action: 1.344 [0.000, 3.000],  loss: 38.666868, mae: 108.354115, mean_q: 144.836891, mean_eps: 0.219642
 260786/300000: episode: 1861, duration: 1.123s, episode steps: 166, steps per second: 148, episode reward: 30.498, mean reward:  0.184 [-100.000, 23.304], mean action: 1.934 [0.000, 3.000],  loss: 32.869868, mae: 108.841950, mean_q: 145.480049, mean_eps: 0.217892
 261786/300000: episode: 1862, duration: 7.322s, episode steps: 1000, steps per second: 137, episode reward: 38.841, mean reward:  0.039 [-24.182, 23.527], mean action: 1.585 [0.000, 3.000],  loss: 30.744799, mae: 106.340668, mean_q: 142.084834, mean_eps: 0.216143
 261919/300000: episode: 1863, duration: 1.028s, episode steps: 133, steps per second: 129, episode reward: -122.166, mean reward: -0.919 [-100.000,  4.185], mean action: 1.857 [0.000, 3.000],  loss: 37.542247, mae: 103.988514, mean_q: 139.115190, mean_eps: 0.214444
 262048/300000: episode: 1864, duration: 0.996s, episode steps: 129, steps per second: 130, episode reward: -235.985, mean reward: -1.829 [-100.000,  3.104], mean action: 1.713 [0.000, 3.000],  loss: 23.903985, mae: 105.499275, mean_q: 141.126745, mean_eps: 0.214051
 262184/300000: episode: 1865, duration: 1.034s, episode steps: 136, steps per second: 131, episode reward: -171.347, mean reward: -1.260 [-100.000,  5.100], mean action: 1.985 [0.000, 3.000],  loss: 26.333613, mae: 103.475405, mean_q: 138.238673, mean_eps: 0.213653
 262275/300000: episode: 1866, duration: 0.699s, episode steps:  91, steps per second: 130, episode reward: -69.952, mean reward: -0.769 [-100.000,  7.986], mean action: 1.473 [0.000, 3.000],  loss: 22.745605, mae: 104.152074, mean_q: 138.991839, mean_eps: 0.213313
 262943/300000: episode: 1867, duration: 4.808s, episode steps: 668, steps per second: 139, episode reward: -350.901, mean reward: -0.525 [-100.000, 21.527], mean action: 1.843 [0.000, 3.000],  loss: 31.552934, mae: 103.029634, mean_q: 137.507912, mean_eps: 0.212174
 263943/300000: episode: 1868, duration: 7.578s, episode steps: 1000, steps per second: 132, episode reward: -138.858, mean reward: -0.139 [-22.703, 20.904], mean action: 1.735 [0.000, 3.000],  loss: 30.427891, mae: 100.928111, mean_q: 134.798370, mean_eps: 0.209672
 264254/300000: episode: 1869, duration: 2.082s, episode steps: 311, steps per second: 149, episode reward: -235.929, mean reward: -0.759 [-100.000, 22.371], mean action: 1.920 [0.000, 3.000],  loss: 35.374673, mae: 99.376107, mean_q: 132.549722, mean_eps: 0.207706
 264545/300000: episode: 1870, duration: 1.933s, episode steps: 291, steps per second: 151, episode reward: -190.396, mean reward: -0.654 [-100.000, 12.205], mean action: 1.818 [0.000, 3.000],  loss: 25.356125, mae: 99.569039, mean_q: 132.591610, mean_eps: 0.206803
 265055/300000: episode: 1871, duration: 3.488s, episode steps: 510, steps per second: 146, episode reward: -213.374, mean reward: -0.418 [-100.000, 23.220], mean action: 1.688 [0.000, 3.000],  loss: 26.500385, mae: 99.337390, mean_q: 132.213704, mean_eps: 0.205601
 265310/300000: episode: 1872, duration: 1.738s, episode steps: 255, steps per second: 147, episode reward: -205.685, mean reward: -0.807 [-100.000, 11.022], mean action: 1.678 [0.000, 3.000],  loss: 25.035654, mae: 98.313407, mean_q: 131.059648, mean_eps: 0.204454
 266222/300000: episode: 1873, duration: 6.690s, episode steps: 912, steps per second: 136, episode reward: 246.512, mean reward:  0.270 [-22.527, 100.000], mean action: 1.249 [0.000, 3.000],  loss: 23.849280, mae: 99.031326, mean_q: 131.326643, mean_eps: 0.202703
 266360/300000: episode: 1874, duration: 0.888s, episode steps: 138, steps per second: 155, episode reward:  7.269, mean reward:  0.053 [-100.000, 13.086], mean action: 1.870 [0.000, 3.000],  loss: 23.121130, mae: 97.235360, mean_q: 128.692890, mean_eps: 0.201128
 267360/300000: episode: 1875, duration: 7.240s, episode steps: 1000, steps per second: 138, episode reward: -65.558, mean reward: -0.066 [-20.382, 23.403], mean action: 1.734 [0.000, 3.000],  loss: 25.626604, mae: 94.628525, mean_q: 125.537362, mean_eps: 0.199421
 267646/300000: episode: 1876, duration: 2.003s, episode steps: 286, steps per second: 143, episode reward: -213.474, mean reward: -0.746 [-100.000, 12.699], mean action: 1.706 [0.000, 3.000],  loss: 27.833184, mae: 92.467319, mean_q: 122.330778, mean_eps: 0.197493
 267812/300000: episode: 1877, duration: 1.216s, episode steps: 166, steps per second: 137, episode reward: -136.162, mean reward: -0.820 [-100.000, 18.681], mean action: 1.711 [0.000, 3.000],  loss: 27.300187, mae: 91.785661, mean_q: 121.576880, mean_eps: 0.196815
 268046/300000: episode: 1878, duration: 1.693s, episode steps: 234, steps per second: 138, episode reward: -9.993, mean reward: -0.043 [-100.000, 19.498], mean action: 1.739 [0.000, 3.000],  loss: 28.132975, mae: 91.270764, mean_q: 120.514598, mean_eps: 0.196214
 268103/300000: episode: 1879, duration: 0.384s, episode steps:  57, steps per second: 148, episode reward: -114.462, mean reward: -2.008 [-100.000, 16.149], mean action: 1.702 [0.000, 3.000],  loss: 20.787057, mae: 91.186409, mean_q: 120.229090, mean_eps: 0.195778
 268231/300000: episode: 1880, duration: 0.847s, episode steps: 128, steps per second: 151, episode reward: -38.463, mean reward: -0.300 [-100.000, 12.379], mean action: 1.656 [0.000, 3.000],  loss: 31.368902, mae: 89.156367, mean_q: 117.502752, mean_eps: 0.195500
 268413/300000: episode: 1881, duration: 1.192s, episode steps: 182, steps per second: 153, episode reward: -287.899, mean reward: -1.582 [-100.000,  6.825], mean action: 1.874 [0.000, 3.000],  loss: 29.131513, mae: 90.305667, mean_q: 119.302630, mean_eps: 0.195035
 269413/300000: episode: 1882, duration: 7.388s, episode steps: 1000, steps per second: 135, episode reward: 52.677, mean reward:  0.053 [-23.320, 23.137], mean action: 1.680 [0.000, 3.000],  loss: 27.481493, mae: 89.353865, mean_q: 118.039577, mean_eps: 0.193262
 270413/300000: episode: 1883, duration: 7.418s, episode steps: 1000, steps per second: 135, episode reward: 85.614, mean reward:  0.086 [-23.553, 24.045], mean action: 1.489 [0.000, 3.000],  loss: 25.897608, mae: 87.848634, mean_q: 115.383944, mean_eps: 0.190263
 270669/300000: episode: 1884, duration: 1.704s, episode steps: 256, steps per second: 150, episode reward: -191.493, mean reward: -0.748 [-100.000, 22.955], mean action: 1.430 [0.000, 3.000],  loss: 28.739135, mae: 87.776923, mean_q: 114.411062, mean_eps: 0.188378
 270771/300000: episode: 1885, duration: 0.646s, episode steps: 102, steps per second: 158, episode reward: -72.852, mean reward: -0.714 [-100.000,  9.655], mean action: 1.627 [0.000, 3.000],  loss: 15.917504, mae: 88.865563, mean_q: 116.286977, mean_eps: 0.187841
 271771/300000: episode: 1886, duration: 8.178s, episode steps: 1000, steps per second: 122, episode reward: 109.725, mean reward:  0.110 [-21.100, 22.749], mean action: 1.840 [0.000, 3.000],  loss: 21.972189, mae: 85.664435, mean_q: 112.920805, mean_eps: 0.186188
 272771/300000: episode: 1887, duration: 7.070s, episode steps: 1000, steps per second: 141, episode reward: 154.148, mean reward:  0.154 [-21.850, 22.658], mean action: 1.497 [0.000, 3.000],  loss: 17.737527, mae: 82.318983, mean_q: 108.550545, mean_eps: 0.183188
 273771/300000: episode: 1888, duration: 7.390s, episode steps: 1000, steps per second: 135, episode reward: 123.227, mean reward:  0.123 [-24.158, 23.154], mean action: 1.089 [0.000, 3.000],  loss: 18.221375, mae: 81.425426, mean_q: 107.284618, mean_eps: 0.180188
 274771/300000: episode: 1889, duration: 6.996s, episode steps: 1000, steps per second: 143, episode reward: 100.911, mean reward:  0.101 [-22.860, 23.358], mean action: 1.255 [0.000, 3.000],  loss: 17.810121, mae: 79.248946, mean_q: 104.073008, mean_eps: 0.177188
 274976/300000: episode: 1890, duration: 1.323s, episode steps: 205, steps per second: 155, episode reward: -102.273, mean reward: -0.499 [-100.000,  8.676], mean action: 1.600 [0.000, 3.000],  loss: 15.658064, mae: 78.491528, mean_q: 103.109820, mean_eps: 0.175381
 275976/300000: episode: 1891, duration: 7.000s, episode steps: 1000, steps per second: 143, episode reward: 160.008, mean reward:  0.160 [-19.603, 22.952], mean action: 1.513 [0.000, 3.000],  loss: 18.100454, mae: 76.111627, mean_q: 99.793285, mean_eps: 0.173573
 276103/300000: episode: 1892, duration: 0.833s, episode steps: 127, steps per second: 152, episode reward: -164.515, mean reward: -1.295 [-100.000,  2.824], mean action: 1.882 [0.000, 3.000],  loss: 17.319308, mae: 73.624974, mean_q: 95.631650, mean_eps: 0.171883
 276204/300000: episode: 1893, duration: 0.663s, episode steps: 101, steps per second: 152, episode reward: -44.260, mean reward: -0.438 [-100.000, 82.733], mean action: 1.376 [0.000, 3.000],  loss: 22.316698, mae: 74.140141, mean_q: 97.425078, mean_eps: 0.171541
 276442/300000: episode: 1894, duration: 1.662s, episode steps: 238, steps per second: 143, episode reward: -159.304, mean reward: -0.669 [-100.000,  8.631], mean action: 1.786 [0.000, 3.000],  loss: 20.458032, mae: 75.757262, mean_q: 99.062478, mean_eps: 0.171032
 276895/300000: episode: 1895, duration: 3.193s, episode steps: 453, steps per second: 142, episode reward: 272.872, mean reward:  0.602 [-17.361, 100.000], mean action: 1.391 [0.000, 3.000],  loss: 22.084093, mae: 75.015429, mean_q: 98.142820, mean_eps: 0.169996
 276989/300000: episode: 1896, duration: 0.671s, episode steps:  94, steps per second: 140, episode reward: -386.919, mean reward: -4.116 [-100.000,  2.225], mean action: 1.160 [0.000, 3.000],  loss: 20.795213, mae: 75.896010, mean_q: 99.267241, mean_eps: 0.169175
 277105/300000: episode: 1897, duration: 0.786s, episode steps: 116, steps per second: 148, episode reward: -118.030, mean reward: -1.017 [-100.000,  9.336], mean action: 1.621 [0.000, 3.000],  loss: 19.098458, mae: 76.165686, mean_q: 100.006388, mean_eps: 0.168860
 277246/300000: episode: 1898, duration: 1.014s, episode steps: 141, steps per second: 139, episode reward: 29.293, mean reward:  0.208 [-100.000, 13.305], mean action: 2.035 [0.000, 3.000],  loss: 19.855844, mae: 76.492638, mean_q: 100.579547, mean_eps: 0.168475
 277341/300000: episode: 1899, duration: 0.629s, episode steps:  95, steps per second: 151, episode reward: -226.558, mean reward: -2.385 [-100.000, 40.246], mean action: 1.811 [0.000, 3.000],  loss: 20.634138, mae: 76.705191, mean_q: 100.859615, mean_eps: 0.168121
 277480/300000: episode: 1900, duration: 0.893s, episode steps: 139, steps per second: 156, episode reward:  0.008, mean reward:  0.000 [-100.000, 16.303], mean action: 1.942 [0.000, 3.000],  loss: 24.917652, mae: 75.799238, mean_q: 99.503794, mean_eps: 0.167770
 277845/300000: episode: 1901, duration: 2.495s, episode steps: 365, steps per second: 146, episode reward: -87.927, mean reward: -0.241 [-100.000, 19.478], mean action: 1.688 [0.000, 3.000],  loss: 17.821414, mae: 75.522105, mean_q: 99.712544, mean_eps: 0.167014
 278845/300000: episode: 1902, duration: 7.321s, episode steps: 1000, steps per second: 137, episode reward: 125.315, mean reward:  0.125 [-21.355, 22.810], mean action: 1.150 [0.000, 3.000],  loss: 23.981922, mae: 75.389515, mean_q: 99.265220, mean_eps: 0.164966
 279683/300000: episode: 1903, duration: 6.048s, episode steps: 838, steps per second: 139, episode reward: 244.432, mean reward:  0.292 [-21.037, 100.000], mean action: 1.737 [0.000, 3.000],  loss: 25.619537, mae: 76.704779, mean_q: 100.803097, mean_eps: 0.162209
 279907/300000: episode: 1904, duration: 1.449s, episode steps: 224, steps per second: 155, episode reward: -5.920, mean reward: -0.026 [-100.000, 12.830], mean action: 1.938 [0.000, 3.000],  loss: 22.244118, mae: 78.997399, mean_q: 103.959857, mean_eps: 0.160616
 280019/300000: episode: 1905, duration: 0.762s, episode steps: 112, steps per second: 147, episode reward: -189.589, mean reward: -1.693 [-100.000,  5.846], mean action: 1.839 [0.000, 3.000],  loss: 25.329559, mae: 80.508524, mean_q: 106.084037, mean_eps: 0.160113
 281019/300000: episode: 1906, duration: 7.464s, episode steps: 1000, steps per second: 134, episode reward: 134.948, mean reward:  0.135 [-24.943, 23.385], mean action: 0.789 [0.000, 3.000],  loss: 22.626667, mae: 81.223992, mean_q: 106.857082, mean_eps: 0.158445
 282019/300000: episode: 1907, duration: 6.920s, episode steps: 1000, steps per second: 145, episode reward: 141.172, mean reward:  0.141 [-20.241, 22.795], mean action: 1.575 [0.000, 3.000],  loss: 21.923923, mae: 78.023091, mean_q: 102.547627, mean_eps: 0.155445
 283019/300000: episode: 1908, duration: 7.380s, episode steps: 1000, steps per second: 136, episode reward: 90.691, mean reward:  0.091 [-20.008, 21.532], mean action: 1.595 [0.000, 3.000],  loss: 19.235116, mae: 75.073465, mean_q: 98.691518, mean_eps: 0.152445
 283828/300000: episode: 1909, duration: 5.967s, episode steps: 809, steps per second: 136, episode reward: 239.456, mean reward:  0.296 [-20.510, 100.000], mean action: 1.361 [0.000, 3.000],  loss: 18.363529, mae: 73.216848, mean_q: 96.251779, mean_eps: 0.149731
 284828/300000: episode: 1910, duration: 7.355s, episode steps: 1000, steps per second: 136, episode reward: 118.095, mean reward:  0.118 [-20.416, 22.916], mean action: 1.221 [0.000, 3.000],  loss: 15.648550, mae: 71.878796, mean_q: 94.147806, mean_eps: 0.147017
 285105/300000: episode: 1911, duration: 1.859s, episode steps: 277, steps per second: 149, episode reward: -32.853, mean reward: -0.119 [-100.000, 10.463], mean action: 1.859 [0.000, 3.000],  loss: 16.025426, mae: 74.353739, mean_q: 97.999356, mean_eps: 0.145102
 286105/300000: episode: 1912, duration: 7.206s, episode steps: 1000, steps per second: 139, episode reward: 142.094, mean reward:  0.142 [-21.541, 21.890], mean action: 1.082 [0.000, 3.000],  loss: 19.671919, mae: 75.744666, mean_q: 100.122261, mean_eps: 0.143186
 287105/300000: episode: 1913, duration: 7.434s, episode steps: 1000, steps per second: 135, episode reward: 91.265, mean reward:  0.091 [-19.705, 22.992], mean action: 1.294 [0.000, 3.000],  loss: 14.990077, mae: 73.748156, mean_q: 97.533535, mean_eps: 0.140186
 287489/300000: episode: 1914, duration: 2.643s, episode steps: 384, steps per second: 145, episode reward: 254.134, mean reward:  0.662 [-22.853, 100.000], mean action: 1.315 [0.000, 3.000],  loss: 14.648049, mae: 71.990880, mean_q: 95.741053, mean_eps: 0.138110
 287708/300000: episode: 1915, duration: 1.444s, episode steps: 219, steps per second: 152, episode reward: 202.370, mean reward:  0.924 [-14.778, 100.000], mean action: 2.137 [0.000, 3.000],  loss: 14.485866, mae: 71.993783, mean_q: 96.221308, mean_eps: 0.137206
 287820/300000: episode: 1916, duration: 0.773s, episode steps: 112, steps per second: 145, episode reward: -121.340, mean reward: -1.083 [-100.000,  4.095], mean action: 1.196 [0.000, 3.000],  loss: 11.107283, mae: 72.492213, mean_q: 96.905374, mean_eps: 0.136709
 288133/300000: episode: 1917, duration: 2.086s, episode steps: 313, steps per second: 150, episode reward: -112.854, mean reward: -0.361 [-100.000, 11.550], mean action: 1.489 [0.000, 3.000],  loss: 15.903934, mae: 72.492130, mean_q: 97.048175, mean_eps: 0.136072
 289133/300000: episode: 1918, duration: 7.134s, episode steps: 1000, steps per second: 140, episode reward: 73.698, mean reward:  0.074 [-21.378, 22.870], mean action: 1.407 [0.000, 3.000],  loss: 14.005474, mae: 70.984476, mean_q: 94.987310, mean_eps: 0.134102
 289252/300000: episode: 1919, duration: 0.842s, episode steps: 119, steps per second: 141, episode reward: -74.486, mean reward: -0.626 [-100.000, 14.561], mean action: 1.597 [0.000, 3.000],  loss: 12.967778, mae: 72.815013, mean_q: 97.624025, mean_eps: 0.132424
 289362/300000: episode: 1920, duration: 0.881s, episode steps: 110, steps per second: 125, episode reward: -227.315, mean reward: -2.067 [-100.000,  3.478], mean action: 1.891 [0.000, 3.000],  loss: 13.489524, mae: 72.857568, mean_q: 97.411395, mean_eps: 0.132080
 289481/300000: episode: 1921, duration: 0.837s, episode steps: 119, steps per second: 142, episode reward: -93.735, mean reward: -0.788 [-100.000,  9.883], mean action: 1.529 [0.000, 3.000],  loss: 15.203432, mae: 72.810575, mean_q: 97.293245, mean_eps: 0.131737
 290476/300000: episode: 1922, duration: 7.066s, episode steps: 995, steps per second: 141, episode reward: 231.051, mean reward:  0.232 [-18.959, 100.000], mean action: 1.171 [0.000, 3.000],  loss: 14.840133, mae: 69.418099, mean_q: 92.575360, mean_eps: 0.130066
 290564/300000: episode: 1923, duration: 0.602s, episode steps:  88, steps per second: 146, episode reward: -57.720, mean reward: -0.656 [-100.000, 17.092], mean action: 1.898 [0.000, 3.000],  loss: 13.184662, mae: 68.208035, mean_q: 90.964458, mean_eps: 0.128441
 290727/300000: episode: 1924, duration: 1.062s, episode steps: 163, steps per second: 154, episode reward: -339.028, mean reward: -2.080 [-100.000,  6.316], mean action: 1.503 [0.000, 3.000],  loss: 11.818096, mae: 68.222804, mean_q: 91.103689, mean_eps: 0.128065
 290911/300000: episode: 1925, duration: 1.222s, episode steps: 184, steps per second: 151, episode reward: -27.974, mean reward: -0.152 [-100.000, 17.582], mean action: 1.842 [0.000, 3.000],  loss: 11.614499, mae: 69.003858, mean_q: 92.407027, mean_eps: 0.127544
 291058/300000: episode: 1926, duration: 0.937s, episode steps: 147, steps per second: 157, episode reward: -336.525, mean reward: -2.289 [-100.000, 10.365], mean action: 1.456 [0.000, 3.000],  loss: 13.387370, mae: 70.180954, mean_q: 93.542176, mean_eps: 0.127048
 292058/300000: episode: 1927, duration: 6.802s, episode steps: 1000, steps per second: 147, episode reward: 153.456, mean reward:  0.153 [-22.983, 25.514], mean action: 1.067 [0.000, 3.000],  loss: 13.739512, mae: 70.728323, mean_q: 94.180299, mean_eps: 0.125327
 292227/300000: episode: 1928, duration: 1.136s, episode steps: 169, steps per second: 149, episode reward: -278.388, mean reward: -1.647 [-100.000,  5.344], mean action: 1.615 [0.000, 3.000],  loss: 15.629498, mae: 69.745689, mean_q: 92.813284, mean_eps: 0.123574
 292330/300000: episode: 1929, duration: 0.661s, episode steps: 103, steps per second: 156, episode reward: -38.460, mean reward: -0.373 [-100.000, 14.236], mean action: 1.883 [0.000, 3.000],  loss: 12.507511, mae: 70.310738, mean_q: 93.351082, mean_eps: 0.123166
 292588/300000: episode: 1930, duration: 1.729s, episode steps: 258, steps per second: 149, episode reward: -223.602, mean reward: -0.867 [-100.000, 135.846], mean action: 1.810 [0.000, 3.000],  loss: 12.548091, mae: 69.924279, mean_q: 92.423138, mean_eps: 0.122624
 292906/300000: episode: 1931, duration: 2.114s, episode steps: 318, steps per second: 150, episode reward: -226.441, mean reward: -0.712 [-100.000, 11.142], mean action: 1.623 [0.000, 3.000],  loss: 16.111564, mae: 72.730033, mean_q: 96.125648, mean_eps: 0.121760
 293456/300000: episode: 1932, duration: 4.079s, episode steps: 550, steps per second: 135, episode reward: 196.331, mean reward:  0.357 [-15.412, 100.000], mean action: 1.547 [0.000, 3.000],  loss: 17.666913, mae: 71.975159, mean_q: 94.697027, mean_eps: 0.120458
 294456/300000: episode: 1933, duration: 7.055s, episode steps: 1000, steps per second: 142, episode reward: 140.174, mean reward:  0.140 [-19.056, 22.619], mean action: 1.171 [0.000, 3.000],  loss: 13.005398, mae: 68.583971, mean_q: 90.081877, mean_eps: 0.118133
 295456/300000: episode: 1934, duration: 7.551s, episode steps: 1000, steps per second: 132, episode reward: 45.759, mean reward:  0.046 [-20.923, 23.765], mean action: 1.271 [0.000, 3.000],  loss: 17.010299, mae: 66.866013, mean_q: 88.474563, mean_eps: 0.115133
 296456/300000: episode: 1935, duration: 7.845s, episode steps: 1000, steps per second: 127, episode reward: 47.219, mean reward:  0.047 [-24.083, 20.793], mean action: 1.662 [0.000, 3.000],  loss: 15.767101, mae: 66.592085, mean_q: 88.351889, mean_eps: 0.112133
 296536/300000: episode: 1936, duration: 0.518s, episode steps:  80, steps per second: 154, episode reward: 45.147, mean reward:  0.564 [-100.000, 18.848], mean action: 1.562 [0.000, 3.000],  loss: 9.897244, mae: 65.997088, mean_q: 87.667070, mean_eps: 0.110513
 296785/300000: episode: 1937, duration: 1.631s, episode steps: 249, steps per second: 153, episode reward: -40.842, mean reward: -0.164 [-100.000, 17.090], mean action: 1.807 [0.000, 3.000],  loss: 13.854461, mae: 67.938671, mean_q: 90.422679, mean_eps: 0.110020
 297408/300000: episode: 1938, duration: 4.451s, episode steps: 623, steps per second: 140, episode reward: 215.886, mean reward:  0.347 [-23.352, 100.000], mean action: 1.801 [0.000, 3.000],  loss: 15.985025, mae: 67.903242, mean_q: 90.466105, mean_eps: 0.108712
 298408/300000: episode: 1939, duration: 7.661s, episode steps: 1000, steps per second: 131, episode reward: 88.399, mean reward:  0.088 [-22.909, 23.389], mean action: 1.667 [0.000, 3.000],  loss: 15.063001, mae: 67.328930, mean_q: 89.317684, mean_eps: 0.106277
 298475/300000: episode: 1940, duration: 0.505s, episode steps:  67, steps per second: 133, episode reward: -143.333, mean reward: -2.139 [-100.000,  5.630], mean action: 1.254 [0.000, 3.000],  loss: 12.434834, mae: 66.467759, mean_q: 88.328281, mean_eps: 0.104677
 298625/300000: episode: 1941, duration: 1.129s, episode steps: 150, steps per second: 133, episode reward: -314.829, mean reward: -2.099 [-100.000,  2.412], mean action: 1.347 [0.000, 3.000],  loss: 9.532382, mae: 66.977489, mean_q: 88.693603, mean_eps: 0.104351
 298874/300000: episode: 1942, duration: 1.820s, episode steps: 249, steps per second: 137, episode reward: -41.366, mean reward: -0.166 [-100.000, 10.579], mean action: 1.827 [0.000, 3.000],  loss: 17.547484, mae: 67.145370, mean_q: 89.267180, mean_eps: 0.103753
 299119/300000: episode: 1943, duration: 1.721s, episode steps: 245, steps per second: 142, episode reward:  5.645, mean reward:  0.023 [-100.000, 22.904], mean action: 1.653 [0.000, 3.000],  loss: 15.695427, mae: 66.333360, mean_q: 88.051335, mean_eps: 0.103012
 299265/300000: episode: 1944, duration: 0.988s, episode steps: 146, steps per second: 148, episode reward: 20.486, mean reward:  0.140 [-100.000, 21.647], mean action: 1.521 [0.000, 3.000],  loss: 13.411470, mae: 65.842039, mean_q: 87.218991, mean_eps: 0.102425
 299360/300000: episode: 1945, duration: 0.627s, episode steps:  95, steps per second: 152, episode reward: -9.402, mean reward: -0.099 [-100.000, 17.697], mean action: 1.853 [0.000, 3.000],  loss: 19.489531, mae: 67.785036, mean_q: 90.326061, mean_eps: 0.102064
 299429/300000: episode: 1946, duration: 0.436s, episode steps:  69, steps per second: 158, episode reward: -161.439, mean reward: -2.340 [-100.000,  5.843], mean action: 1.739 [0.000, 3.000],  loss: 27.799785, mae: 69.158186, mean_q: 92.057625, mean_eps: 0.101818
 299895/300000: episode: 1947, duration: 3.229s, episode steps: 466, steps per second: 144, episode reward: -214.433, mean reward: -0.460 [-100.000,  6.244], mean action: 1.777 [0.000, 3.000],  loss: 15.887103, mae: 70.597457, mean_q: 93.928292, mean_eps: 0.101015
done, took 2085.644 seconds
Testing for 5 episodes ...
Episode 1: reward: -663.912, steps: 296
Episode 2: reward: 221.515, steps: 416
Episode 3: reward: 186.095, steps: 474
Episode 4: reward: 240.793, steps: 241
Episode 5: reward: -232.097, steps: 257
Training for 300000 steps ...
    130/300000: episode: 1, duration: 0.810s, episode steps: 130, steps per second: 161, episode reward: -210.127, mean reward: -1.616 [-100.000, 19.365], mean action: 1.646 [0.000, 3.000],  loss: 20.691357, mae: 69.876447, mean_q: 92.269455, mean_eps: 0.999790
    187/300000: episode: 2, duration: 0.374s, episode steps:  57, steps per second: 153, episode reward: -57.787, mean reward: -1.014 [-100.000, 13.008], mean action: 1.526 [0.000, 3.000],  loss: 14.327860, mae: 70.459270, mean_q: 93.360599, mean_eps: 0.999526
    283/300000: episode: 3, duration: 0.610s, episode steps:  96, steps per second: 157, episode reward: -304.329, mean reward: -3.170 [-100.000, 29.241], mean action: 1.333 [0.000, 3.000],  loss: 23.695890, mae: 71.863476, mean_q: 95.076481, mean_eps: 0.999296
    384/300000: episode: 4, duration: 0.669s, episode steps: 101, steps per second: 151, episode reward: -110.834, mean reward: -1.097 [-100.000, 15.095], mean action: 1.426 [0.000, 3.000],  loss: 23.820619, mae: 72.319826, mean_q: 94.720347, mean_eps: 0.999001
    451/300000: episode: 5, duration: 0.474s, episode steps:  67, steps per second: 141, episode reward: -79.988, mean reward: -1.194 [-100.000, 11.328], mean action: 1.448 [0.000, 3.000],  loss: 23.166903, mae: 74.275183, mean_q: 97.942586, mean_eps: 0.998749
    559/300000: episode: 6, duration: 0.723s, episode steps: 108, steps per second: 149, episode reward: -460.104, mean reward: -4.260 [-100.000,  1.160], mean action: 1.491 [0.000, 3.000],  loss: 19.413165, mae: 73.711795, mean_q: 97.077930, mean_eps: 0.998487
    624/300000: episode: 7, duration: 0.456s, episode steps:  65, steps per second: 142, episode reward: -76.897, mean reward: -1.183 [-100.000, 11.298], mean action: 1.631 [0.000, 3.000],  loss: 20.960173, mae: 72.965017, mean_q: 96.331096, mean_eps: 0.998227
    691/300000: episode: 8, duration: 0.458s, episode steps:  67, steps per second: 146, episode reward: -120.285, mean reward: -1.795 [-100.000,  5.572], mean action: 1.388 [0.000, 3.000],  loss: 25.467010, mae: 72.375952, mean_q: 95.578583, mean_eps: 0.998029
    781/300000: episode: 9, duration: 0.585s, episode steps:  90, steps per second: 154, episode reward: -197.271, mean reward: -2.192 [-100.000, 25.031], mean action: 1.322 [0.000, 3.000],  loss: 19.278982, mae: 73.625255, mean_q: 97.229767, mean_eps: 0.997794
    887/300000: episode: 10, duration: 0.667s, episode steps: 106, steps per second: 159, episode reward: -326.549, mean reward: -3.081 [-100.000,  1.058], mean action: 1.538 [0.000, 3.000],  loss: 27.355866, mae: 73.236168, mean_q: 96.141758, mean_eps: 0.997499
    960/300000: episode: 11, duration: 0.472s, episode steps:  73, steps per second: 155, episode reward: -238.835, mean reward: -3.272 [-100.000,  5.050], mean action: 1.411 [0.000, 3.000],  loss: 19.320103, mae: 73.579009, mean_q: 96.788606, mean_eps: 0.997231
   1076/300000: episode: 12, duration: 0.740s, episode steps: 116, steps per second: 157, episode reward: -339.163, mean reward: -2.924 [-100.000, 24.430], mean action: 1.560 [0.000, 3.000],  loss: 26.078441, mae: 72.637482, mean_q: 94.565799, mean_eps: 0.996948
   1187/300000: episode: 13, duration: 0.702s, episode steps: 111, steps per second: 158, episode reward: -307.418, mean reward: -2.770 [-100.000, 111.633], mean action: 1.595 [0.000, 3.000],  loss: 23.627060, mae: 72.979017, mean_q: 95.393763, mean_eps: 0.996607
   1276/300000: episode: 14, duration: 0.553s, episode steps:  89, steps per second: 161, episode reward: -237.567, mean reward: -2.669 [-100.000, 40.390], mean action: 1.472 [0.000, 3.000],  loss: 25.881551, mae: 72.059295, mean_q: 94.786710, mean_eps: 0.996307
   1380/300000: episode: 15, duration: 0.655s, episode steps: 104, steps per second: 159, episode reward: -108.686, mean reward: -1.045 [-100.000, 21.787], mean action: 1.577 [0.000, 3.000],  loss: 29.713529, mae: 72.639646, mean_q: 95.412189, mean_eps: 0.996018
   1451/300000: episode: 16, duration: 0.491s, episode steps:  71, steps per second: 144, episode reward: -163.837, mean reward: -2.308 [-100.000,  5.483], mean action: 1.535 [0.000, 3.000],  loss: 22.239822, mae: 72.068575, mean_q: 94.490361, mean_eps: 0.995755
   1514/300000: episode: 17, duration: 0.410s, episode steps:  63, steps per second: 154, episode reward: -86.405, mean reward: -1.372 [-100.000, 16.459], mean action: 1.524 [0.000, 3.000],  loss: 28.381717, mae: 72.379719, mean_q: 94.511485, mean_eps: 0.995554
   1574/300000: episode: 18, duration: 0.373s, episode steps:  60, steps per second: 161, episode reward: -89.726, mean reward: -1.495 [-100.000, 10.900], mean action: 1.350 [0.000, 3.000],  loss: 18.387195, mae: 72.215209, mean_q: 93.609628, mean_eps: 0.995369
   1680/300000: episode: 19, duration: 0.683s, episode steps: 106, steps per second: 155, episode reward: -188.538, mean reward: -1.779 [-100.000,  1.396], mean action: 1.660 [0.000, 3.000],  loss: 15.081179, mae: 70.781066, mean_q: 91.761558, mean_eps: 0.995120
   1754/300000: episode: 20, duration: 0.471s, episode steps:  74, steps per second: 157, episode reward: -81.097, mean reward: -1.096 [-100.000, 13.619], mean action: 1.635 [0.000, 3.000],  loss: 20.571037, mae: 70.936661, mean_q: 92.126687, mean_eps: 0.994851
   1841/300000: episode: 21, duration: 0.672s, episode steps:  87, steps per second: 129, episode reward: -93.809, mean reward: -1.078 [-100.000, 13.767], mean action: 1.540 [0.000, 3.000],  loss: 21.607516, mae: 72.263786, mean_q: 92.997601, mean_eps: 0.994609
   1964/300000: episode: 22, duration: 0.836s, episode steps: 123, steps per second: 147, episode reward: -260.690, mean reward: -2.119 [-100.000,  4.248], mean action: 1.504 [0.000, 3.000],  loss: 26.068864, mae: 72.792620, mean_q: 94.543872, mean_eps: 0.994294
   2079/300000: episode: 23, duration: 0.774s, episode steps: 115, steps per second: 149, episode reward: -91.210, mean reward: -0.793 [-100.000, 10.532], mean action: 1.383 [0.000, 3.000],  loss: 23.444401, mae: 73.021321, mean_q: 94.749243, mean_eps: 0.993937
   2150/300000: episode: 24, duration: 0.464s, episode steps:  71, steps per second: 153, episode reward: -131.540, mean reward: -1.853 [-100.000, 13.846], mean action: 1.606 [0.000, 3.000],  loss: 16.831620, mae: 72.116003, mean_q: 94.787052, mean_eps: 0.993658
   2224/300000: episode: 25, duration: 0.469s, episode steps:  74, steps per second: 158, episode reward: -98.919, mean reward: -1.337 [-100.000, 11.861], mean action: 1.568 [0.000, 3.000],  loss: 15.406382, mae: 72.907175, mean_q: 95.328551, mean_eps: 0.993441
   2299/300000: episode: 26, duration: 0.558s, episode steps:  75, steps per second: 134, episode reward: -125.730, mean reward: -1.676 [-100.000, 18.449], mean action: 1.453 [0.000, 3.000],  loss: 42.507758, mae: 72.482273, mean_q: 93.504832, mean_eps: 0.993217
   2397/300000: episode: 27, duration: 0.821s, episode steps:  98, steps per second: 119, episode reward: -63.481, mean reward: -0.648 [-100.000,  8.155], mean action: 1.633 [0.000, 3.000],  loss: 15.093805, mae: 73.239990, mean_q: 95.244380, mean_eps: 0.992957
   2483/300000: episode: 28, duration: 0.577s, episode steps:  86, steps per second: 149, episode reward: -168.200, mean reward: -1.956 [-100.000,  9.642], mean action: 1.244 [0.000, 3.000],  loss: 13.934459, mae: 73.896750, mean_q: 96.642169, mean_eps: 0.992681
   2584/300000: episode: 29, duration: 0.679s, episode steps: 101, steps per second: 149, episode reward: -378.706, mean reward: -3.750 [-100.000,  0.945], mean action: 1.703 [0.000, 3.000],  loss: 16.794292, mae: 74.929443, mean_q: 97.329690, mean_eps: 0.992401
   2669/300000: episode: 30, duration: 0.561s, episode steps:  85, steps per second: 151, episode reward: -104.198, mean reward: -1.226 [-100.000,  7.062], mean action: 1.529 [0.000, 3.000],  loss: 27.513947, mae: 75.420457, mean_q: 98.038158, mean_eps: 0.992122
   2748/300000: episode: 31, duration: 0.535s, episode steps:  79, steps per second: 148, episode reward: -83.196, mean reward: -1.053 [-100.000, 11.913], mean action: 1.532 [0.000, 3.000],  loss: 25.147280, mae: 74.740082, mean_q: 96.762090, mean_eps: 0.991876
   2814/300000: episode: 32, duration: 0.437s, episode steps:  66, steps per second: 151, episode reward: -146.909, mean reward: -2.226 [-100.000, 33.055], mean action: 1.394 [0.000, 3.000],  loss: 14.743156, mae: 75.922022, mean_q: 98.338378, mean_eps: 0.991658
   2918/300000: episode: 33, duration: 0.647s, episode steps: 104, steps per second: 161, episode reward: -123.385, mean reward: -1.186 [-100.000,  8.290], mean action: 1.404 [0.000, 3.000],  loss: 23.673770, mae: 77.354009, mean_q: 100.305574, mean_eps: 0.991403
   3013/300000: episode: 34, duration: 0.620s, episode steps:  95, steps per second: 153, episode reward: -130.498, mean reward: -1.374 [-100.000,  9.722], mean action: 1.516 [0.000, 3.000],  loss: 34.617016, mae: 79.547920, mean_q: 103.548347, mean_eps: 0.991105
   3078/300000: episode: 35, duration: 0.409s, episode steps:  65, steps per second: 159, episode reward: -209.102, mean reward: -3.217 [-100.000,  6.505], mean action: 1.615 [0.000, 3.000],  loss: 11.025742, mae: 79.044944, mean_q: 102.437764, mean_eps: 0.990865
   3145/300000: episode: 36, duration: 0.433s, episode steps:  67, steps per second: 155, episode reward: -116.941, mean reward: -1.745 [-100.000, 10.538], mean action: 1.373 [0.000, 3.000],  loss: 25.181183, mae: 79.089001, mean_q: 102.372860, mean_eps: 0.990667
   3267/300000: episode: 37, duration: 0.988s, episode steps: 122, steps per second: 124, episode reward: -187.654, mean reward: -1.538 [-100.000,  6.137], mean action: 1.475 [0.000, 3.000],  loss: 26.494322, mae: 79.860006, mean_q: 103.731814, mean_eps: 0.990384
   3356/300000: episode: 38, duration: 0.679s, episode steps:  89, steps per second: 131, episode reward: -139.416, mean reward: -1.566 [-100.000, 11.661], mean action: 1.506 [0.000, 3.000],  loss: 48.947245, mae: 81.527883, mean_q: 105.667581, mean_eps: 0.990067
   3491/300000: episode: 39, duration: 0.956s, episode steps: 135, steps per second: 141, episode reward: -136.855, mean reward: -1.014 [-100.000, 10.220], mean action: 1.600 [0.000, 3.000],  loss: 19.175524, mae: 83.192073, mean_q: 109.219202, mean_eps: 0.989731
   3553/300000: episode: 40, duration: 0.477s, episode steps:  62, steps per second: 130, episode reward: -76.012, mean reward: -1.226 [-100.000,  8.260], mean action: 1.516 [0.000, 3.000],  loss: 18.961152, mae: 82.691746, mean_q: 108.354306, mean_eps: 0.989436
   3648/300000: episode: 41, duration: 0.637s, episode steps:  95, steps per second: 149, episode reward: -83.059, mean reward: -0.874 [-100.000, 13.992], mean action: 1.242 [0.000, 3.000],  loss: 16.071741, mae: 83.086193, mean_q: 109.127896, mean_eps: 0.989200
   3730/300000: episode: 42, duration: 0.521s, episode steps:  82, steps per second: 157, episode reward: -86.915, mean reward: -1.060 [-100.000, 15.714], mean action: 1.439 [0.000, 3.000],  loss: 30.629794, mae: 82.098542, mean_q: 107.111883, mean_eps: 0.988934
   3839/300000: episode: 43, duration: 0.795s, episode steps: 109, steps per second: 137, episode reward: -402.553, mean reward: -3.693 [-100.000,  1.723], mean action: 1.615 [0.000, 3.000],  loss: 21.360148, mae: 82.473704, mean_q: 107.238067, mean_eps: 0.988648
   3931/300000: episode: 44, duration: 0.607s, episode steps:  92, steps per second: 151, episode reward: -100.995, mean reward: -1.098 [-100.000, 59.142], mean action: 1.424 [0.000, 3.000],  loss: 23.614076, mae: 82.162590, mean_q: 107.370445, mean_eps: 0.988346
   4044/300000: episode: 45, duration: 0.861s, episode steps: 113, steps per second: 131, episode reward: -256.474, mean reward: -2.270 [-100.000, 36.692], mean action: 1.327 [0.000, 3.000],  loss: 26.554760, mae: 82.014332, mean_q: 106.919820, mean_eps: 0.988039
   4127/300000: episode: 46, duration: 0.736s, episode steps:  83, steps per second: 113, episode reward: -132.673, mean reward: -1.598 [-100.000,  5.885], mean action: 1.542 [0.000, 3.000],  loss: 22.291010, mae: 82.974467, mean_q: 108.687025, mean_eps: 0.987745
   4286/300000: episode: 47, duration: 1.269s, episode steps: 159, steps per second: 125, episode reward: -264.375, mean reward: -1.663 [-100.000,  4.477], mean action: 1.553 [0.000, 3.000],  loss: 21.594652, mae: 85.019734, mean_q: 110.594099, mean_eps: 0.987382
   4414/300000: episode: 48, duration: 0.988s, episode steps: 128, steps per second: 129, episode reward: -289.321, mean reward: -2.260 [-100.000, 118.424], mean action: 1.445 [0.000, 3.000],  loss: 23.376063, mae: 85.385333, mean_q: 111.348712, mean_eps: 0.986951
   4485/300000: episode: 49, duration: 0.650s, episode steps:  71, steps per second: 109, episode reward: -62.091, mean reward: -0.875 [-100.000, 15.585], mean action: 1.704 [0.000, 3.000],  loss: 35.988160, mae: 85.925411, mean_q: 110.794344, mean_eps: 0.986653
   4585/300000: episode: 50, duration: 0.816s, episode steps: 100, steps per second: 122, episode reward: -286.287, mean reward: -2.863 [-100.000,  0.595], mean action: 1.620 [0.000, 3.000],  loss: 17.528992, mae: 86.507295, mean_q: 112.202760, mean_eps: 0.986396
   4677/300000: episode: 51, duration: 0.885s, episode steps:  92, steps per second: 104, episode reward: -244.555, mean reward: -2.658 [-100.000,  5.613], mean action: 1.315 [0.000, 3.000],  loss: 32.653493, mae: 86.012589, mean_q: 111.724995, mean_eps: 0.986108
   4767/300000: episode: 52, duration: 0.900s, episode steps:  90, steps per second: 100, episode reward: -401.154, mean reward: -4.457 [-100.000, 73.028], mean action: 1.567 [0.000, 3.000],  loss: 28.415709, mae: 85.401543, mean_q: 110.034534, mean_eps: 0.985836
   4884/300000: episode: 53, duration: 1.003s, episode steps: 117, steps per second: 117, episode reward: -138.548, mean reward: -1.184 [-100.000,  7.691], mean action: 1.419 [0.000, 3.000],  loss: 30.274652, mae: 85.962036, mean_q: 111.285623, mean_eps: 0.985525
   4965/300000: episode: 54, duration: 0.639s, episode steps:  81, steps per second: 127, episode reward: 30.952, mean reward:  0.382 [-100.000, 106.947], mean action: 1.346 [0.000, 3.000],  loss: 24.707860, mae: 85.502103, mean_q: 109.987301, mean_eps: 0.985228
   5054/300000: episode: 55, duration: 0.694s, episode steps:  89, steps per second: 128, episode reward: -351.800, mean reward: -3.953 [-100.000,  2.629], mean action: 1.719 [0.000, 3.000],  loss: 27.697285, mae: 86.017376, mean_q: 111.547489, mean_eps: 0.984973
   5149/300000: episode: 56, duration: 0.822s, episode steps:  95, steps per second: 116, episode reward: -398.155, mean reward: -4.191 [-100.000,  0.735], mean action: 1.547 [0.000, 3.000],  loss: 23.656027, mae: 86.751864, mean_q: 111.768761, mean_eps: 0.984697
   5238/300000: episode: 57, duration: 0.668s, episode steps:  89, steps per second: 133, episode reward: -279.537, mean reward: -3.141 [-100.000, 104.064], mean action: 1.517 [0.000, 3.000],  loss: 23.595674, mae: 86.328259, mean_q: 110.933515, mean_eps: 0.984421
   5295/300000: episode: 58, duration: 0.447s, episode steps:  57, steps per second: 128, episode reward: -125.082, mean reward: -2.194 [-100.000, 36.008], mean action: 1.404 [0.000, 3.000],  loss: 21.940687, mae: 85.064848, mean_q: 109.620455, mean_eps: 0.984202
   5392/300000: episode: 59, duration: 0.702s, episode steps:  97, steps per second: 138, episode reward: -115.059, mean reward: -1.186 [-100.000, 11.134], mean action: 1.505 [0.000, 3.000],  loss: 29.846106, mae: 85.601768, mean_q: 110.488615, mean_eps: 0.983971
   5484/300000: episode: 60, duration: 0.650s, episode steps:  92, steps per second: 142, episode reward: -299.696, mean reward: -3.258 [-100.000, -0.021], mean action: 1.728 [0.000, 3.000],  loss: 25.083226, mae: 84.768378, mean_q: 109.164880, mean_eps: 0.983688
   5578/300000: episode: 61, duration: 0.663s, episode steps:  94, steps per second: 142, episode reward: -94.223, mean reward: -1.002 [-100.000,  7.404], mean action: 1.606 [0.000, 3.000],  loss: 27.464109, mae: 84.097550, mean_q: 107.493878, mean_eps: 0.983409
   5693/300000: episode: 62, duration: 0.774s, episode steps: 115, steps per second: 149, episode reward: -270.780, mean reward: -2.355 [-100.000,  1.111], mean action: 1.626 [0.000, 3.000],  loss: 29.474458, mae: 84.051889, mean_q: 107.961780, mean_eps: 0.983095
   5780/300000: episode: 63, duration: 0.562s, episode steps:  87, steps per second: 155, episode reward: 10.035, mean reward:  0.115 [-100.000, 103.515], mean action: 1.483 [0.000, 3.000],  loss: 29.810204, mae: 82.831193, mean_q: 106.395017, mean_eps: 0.982792
   5877/300000: episode: 64, duration: 0.664s, episode steps:  97, steps per second: 146, episode reward: -263.710, mean reward: -2.719 [-100.000,  2.674], mean action: 1.433 [0.000, 3.000],  loss: 22.800353, mae: 82.066468, mean_q: 104.765185, mean_eps: 0.982516
   5983/300000: episode: 65, duration: 0.715s, episode steps: 106, steps per second: 148, episode reward: -236.988, mean reward: -2.236 [-100.000,  7.726], mean action: 1.406 [0.000, 3.000],  loss: 29.469492, mae: 83.239877, mean_q: 106.290435, mean_eps: 0.982212
   6050/300000: episode: 66, duration: 0.427s, episode steps:  67, steps per second: 157, episode reward: -116.411, mean reward: -1.737 [-100.000, 10.309], mean action: 1.478 [0.000, 3.000],  loss: 20.476661, mae: 82.208747, mean_q: 104.405615, mean_eps: 0.981952
   6121/300000: episode: 67, duration: 0.456s, episode steps:  71, steps per second: 156, episode reward: -39.290, mean reward: -0.553 [-100.000, 22.607], mean action: 1.507 [0.000, 3.000],  loss: 29.743802, mae: 82.288814, mean_q: 104.690563, mean_eps: 0.981745
   6224/300000: episode: 68, duration: 0.706s, episode steps: 103, steps per second: 146, episode reward: -246.723, mean reward: -2.395 [-100.000,  1.376], mean action: 1.602 [0.000, 3.000],  loss: 29.676253, mae: 85.570266, mean_q: 109.377913, mean_eps: 0.981484
   6303/300000: episode: 69, duration: 0.533s, episode steps:  79, steps per second: 148, episode reward: -117.447, mean reward: -1.487 [-100.000,  6.530], mean action: 1.405 [0.000, 3.000],  loss: 40.348575, mae: 85.086500, mean_q: 108.372311, mean_eps: 0.981211
   6394/300000: episode: 70, duration: 0.613s, episode steps:  91, steps per second: 148, episode reward: -181.088, mean reward: -1.990 [-100.000, 25.072], mean action: 1.352 [0.000, 3.000],  loss: 40.086085, mae: 84.786630, mean_q: 107.704755, mean_eps: 0.980956
   6496/300000: episode: 71, duration: 0.701s, episode steps: 102, steps per second: 146, episode reward: -217.309, mean reward: -2.130 [-100.000,  7.317], mean action: 1.402 [0.000, 3.000],  loss: 36.197616, mae: 86.170909, mean_q: 109.654256, mean_eps: 0.980666
   6584/300000: episode: 72, duration: 0.599s, episode steps:  88, steps per second: 147, episode reward: -131.420, mean reward: -1.493 [-100.000,  5.912], mean action: 1.568 [0.000, 3.000],  loss: 39.918174, mae: 86.470180, mean_q: 109.960852, mean_eps: 0.980382
   6709/300000: episode: 73, duration: 0.848s, episode steps: 125, steps per second: 147, episode reward: -142.438, mean reward: -1.140 [-100.000, 43.707], mean action: 1.424 [0.000, 3.000],  loss: 43.068685, mae: 86.849844, mean_q: 111.654993, mean_eps: 0.980062
   6802/300000: episode: 74, duration: 0.685s, episode steps:  93, steps per second: 136, episode reward: -272.676, mean reward: -2.932 [-100.000,  6.605], mean action: 1.559 [0.000, 3.000],  loss: 51.771851, mae: 87.067942, mean_q: 111.387120, mean_eps: 0.979735
   6896/300000: episode: 75, duration: 0.734s, episode steps:  94, steps per second: 128, episode reward: -132.346, mean reward: -1.408 [-100.000,  6.031], mean action: 1.319 [0.000, 3.000],  loss: 24.673466, mae: 88.735236, mean_q: 113.408035, mean_eps: 0.979455
   6957/300000: episode: 76, duration: 0.503s, episode steps:  61, steps per second: 121, episode reward: -168.680, mean reward: -2.765 [-100.000,  9.005], mean action: 1.557 [0.000, 3.000],  loss: 26.225779, mae: 86.515909, mean_q: 110.811708, mean_eps: 0.979222
   7048/300000: episode: 77, duration: 0.670s, episode steps:  91, steps per second: 136, episode reward: -148.607, mean reward: -1.633 [-100.000,  5.567], mean action: 1.484 [0.000, 3.000],  loss: 42.685131, mae: 87.790418, mean_q: 113.481171, mean_eps: 0.978994
   7156/300000: episode: 78, duration: 0.807s, episode steps: 108, steps per second: 134, episode reward: -270.498, mean reward: -2.505 [-100.000,  0.402], mean action: 1.426 [0.000, 3.000],  loss: 35.009086, mae: 87.057302, mean_q: 111.827321, mean_eps: 0.978695
   7218/300000: episode: 79, duration: 0.469s, episode steps:  62, steps per second: 132, episode reward: -242.147, mean reward: -3.906 [-100.000, 22.058], mean action: 1.129 [0.000, 3.000],  loss: 31.111423, mae: 86.570381, mean_q: 110.781695, mean_eps: 0.978441
   7305/300000: episode: 80, duration: 0.774s, episode steps:  87, steps per second: 112, episode reward: -252.372, mean reward: -2.901 [-100.000, 100.494], mean action: 1.552 [0.000, 3.000],  loss: 33.014224, mae: 84.914807, mean_q: 108.374545, mean_eps: 0.978217
   7368/300000: episode: 81, duration: 0.504s, episode steps:  63, steps per second: 125, episode reward: -281.208, mean reward: -4.464 [-100.000,  3.690], mean action: 1.556 [0.000, 3.000],  loss: 42.461408, mae: 84.810345, mean_q: 109.506153, mean_eps: 0.977992
   7497/300000: episode: 82, duration: 1.054s, episode steps: 129, steps per second: 122, episode reward: -70.098, mean reward: -0.543 [-100.000, 32.608], mean action: 1.473 [0.000, 3.000],  loss: 45.958137, mae: 86.351490, mean_q: 111.045559, mean_eps: 0.977704
   7573/300000: episode: 83, duration: 0.549s, episode steps:  76, steps per second: 138, episode reward: -161.603, mean reward: -2.126 [-100.000,  8.074], mean action: 1.526 [0.000, 3.000],  loss: 39.829426, mae: 85.479068, mean_q: 109.588918, mean_eps: 0.977397
   7638/300000: episode: 84, duration: 0.473s, episode steps:  65, steps per second: 138, episode reward: -131.398, mean reward: -2.022 [-100.000,  6.064], mean action: 1.723 [0.000, 3.000],  loss: 42.069192, mae: 86.497814, mean_q: 111.307315, mean_eps: 0.977185
   8638/300000: episode: 85, duration: 7.855s, episode steps: 1000, steps per second: 127, episode reward: 69.997, mean reward:  0.070 [-24.534, 90.646], mean action: 1.498 [0.000, 3.000],  loss: 34.483906, mae: 89.303587, mean_q: 114.739165, mean_eps: 0.975588
   8722/300000: episode: 86, duration: 0.612s, episode steps:  84, steps per second: 137, episode reward: -173.426, mean reward: -2.065 [-100.000, 14.973], mean action: 1.786 [0.000, 3.000],  loss: 32.127181, mae: 92.540581, mean_q: 119.130566, mean_eps: 0.973961
   8827/300000: episode: 87, duration: 0.821s, episode steps: 105, steps per second: 128, episode reward: -105.946, mean reward: -1.009 [-100.000, 20.814], mean action: 1.543 [0.000, 3.000],  loss: 41.502707, mae: 91.918439, mean_q: 119.194533, mean_eps: 0.973678
   8930/300000: episode: 88, duration: 0.744s, episode steps: 103, steps per second: 138, episode reward: -323.275, mean reward: -3.139 [-100.000,  0.142], mean action: 1.320 [0.000, 3.000],  loss: 52.870012, mae: 93.627950, mean_q: 121.490621, mean_eps: 0.973366
   9008/300000: episode: 89, duration: 0.515s, episode steps:  78, steps per second: 152, episode reward: -93.838, mean reward: -1.203 [-100.000, 11.842], mean action: 1.423 [0.000, 3.000],  loss: 36.112582, mae: 93.011757, mean_q: 119.685719, mean_eps: 0.973094
   9137/300000: episode: 90, duration: 0.874s, episode steps: 129, steps per second: 148, episode reward: -175.021, mean reward: -1.357 [-100.000, 22.881], mean action: 1.488 [0.000, 3.000],  loss: 26.312955, mae: 93.962226, mean_q: 122.261684, mean_eps: 0.972784
   9193/300000: episode: 91, duration: 0.372s, episode steps:  56, steps per second: 151, episode reward: -125.184, mean reward: -2.235 [-100.000, 38.355], mean action: 1.643 [0.000, 3.000],  loss: 31.652518, mae: 93.216184, mean_q: 119.621796, mean_eps: 0.972506
   9304/300000: episode: 92, duration: 0.734s, episode steps: 111, steps per second: 151, episode reward: -106.739, mean reward: -0.962 [-100.000, 12.067], mean action: 1.477 [0.000, 3.000],  loss: 37.172201, mae: 93.817937, mean_q: 120.717419, mean_eps: 0.972256
   9373/300000: episode: 93, duration: 0.463s, episode steps:  69, steps per second: 149, episode reward: -85.008, mean reward: -1.232 [-100.000, 42.173], mean action: 1.449 [0.000, 3.000],  loss: 38.833776, mae: 94.189457, mean_q: 120.301277, mean_eps: 0.971986
   9449/300000: episode: 94, duration: 0.517s, episode steps:  76, steps per second: 147, episode reward: -199.989, mean reward: -2.631 [-100.000,  6.891], mean action: 1.461 [0.000, 3.000],  loss: 42.955382, mae: 95.186201, mean_q: 124.034178, mean_eps: 0.971768
   9540/300000: episode: 95, duration: 0.584s, episode steps:  91, steps per second: 156, episode reward: -129.875, mean reward: -1.427 [-100.000,  8.230], mean action: 1.846 [0.000, 3.000],  loss: 47.795065, mae: 96.148938, mean_q: 125.309351, mean_eps: 0.971518
   9638/300000: episode: 96, duration: 0.609s, episode steps:  98, steps per second: 161, episode reward: -469.311, mean reward: -4.789 [-100.000, 27.680], mean action: 1.469 [0.000, 3.000],  loss: 24.662120, mae: 95.006188, mean_q: 123.537769, mean_eps: 0.971235
   9738/300000: episode: 97, duration: 0.664s, episode steps: 100, steps per second: 151, episode reward: -131.749, mean reward: -1.317 [-100.000,  7.958], mean action: 1.390 [0.000, 3.000],  loss: 39.789486, mae: 94.799990, mean_q: 123.082853, mean_eps: 0.970938
   9831/300000: episode: 98, duration: 0.615s, episode steps:  93, steps per second: 151, episode reward: -240.411, mean reward: -2.585 [-100.000, 115.436], mean action: 1.677 [0.000, 3.000],  loss: 28.133473, mae: 95.763812, mean_q: 124.243782, mean_eps: 0.970648
   9894/300000: episode: 99, duration: 0.417s, episode steps:  63, steps per second: 151, episode reward: -77.946, mean reward: -1.237 [-100.000, 11.503], mean action: 1.635 [0.000, 3.000],  loss: 38.390679, mae: 96.748460, mean_q: 124.618154, mean_eps: 0.970414
   9992/300000: episode: 100, duration: 0.649s, episode steps:  98, steps per second: 151, episode reward: -163.828, mean reward: -1.672 [-100.000,  8.940], mean action: 1.755 [0.000, 3.000],  loss: 53.784871, mae: 97.328537, mean_q: 126.975356, mean_eps: 0.970172
  10096/300000: episode: 101, duration: 0.696s, episode steps: 104, steps per second: 149, episode reward: -118.335, mean reward: -1.138 [-100.000,  7.707], mean action: 1.250 [0.000, 3.000],  loss: 45.283970, mae: 97.743981, mean_q: 127.164835, mean_eps: 0.969870
  10166/300000: episode: 102, duration: 0.456s, episode steps:  70, steps per second: 154, episode reward: -94.786, mean reward: -1.354 [-100.000,  9.665], mean action: 1.614 [0.000, 3.000],  loss: 21.452108, mae: 97.592211, mean_q: 127.242604, mean_eps: 0.969609
  10228/300000: episode: 103, duration: 0.403s, episode steps:  62, steps per second: 154, episode reward: -180.885, mean reward: -2.918 [-100.000,  3.354], mean action: 1.694 [0.000, 3.000],  loss: 25.995597, mae: 99.204172, mean_q: 129.296311, mean_eps: 0.969410
  10304/300000: episode: 104, duration: 0.484s, episode steps:  76, steps per second: 157, episode reward: -118.378, mean reward: -1.558 [-100.000, 14.677], mean action: 1.342 [0.000, 3.000],  loss: 45.935419, mae: 98.874409, mean_q: 128.440926, mean_eps: 0.969204
  10366/300000: episode: 105, duration: 0.431s, episode steps:  62, steps per second: 144, episode reward: -70.873, mean reward: -1.143 [-100.000,  8.567], mean action: 1.548 [0.000, 3.000],  loss: 41.155048, mae: 98.834663, mean_q: 127.710441, mean_eps: 0.968996
  10437/300000: episode: 106, duration: 0.507s, episode steps:  71, steps per second: 140, episode reward: -69.369, mean reward: -0.977 [-100.000, 13.070], mean action: 1.648 [0.000, 3.000],  loss: 46.460733, mae: 98.774777, mean_q: 128.535982, mean_eps: 0.968797
  10551/300000: episode: 107, duration: 0.741s, episode steps: 114, steps per second: 154, episode reward: -333.810, mean reward: -2.928 [-100.000,  0.992], mean action: 1.579 [0.000, 3.000],  loss: 34.214482, mae: 98.593337, mean_q: 127.763142, mean_eps: 0.968519
  10609/300000: episode: 108, duration: 0.393s, episode steps:  58, steps per second: 147, episode reward: -99.273, mean reward: -1.712 [-100.000,  8.795], mean action: 1.397 [0.000, 3.000],  loss: 32.658703, mae: 99.911784, mean_q: 130.382793, mean_eps: 0.968261
  10702/300000: episode: 109, duration: 0.623s, episode steps:  93, steps per second: 149, episode reward: -98.815, mean reward: -1.063 [-100.000,  5.367], mean action: 1.699 [0.000, 3.000],  loss: 50.545124, mae: 98.450047, mean_q: 127.501597, mean_eps: 0.968035
  10786/300000: episode: 110, duration: 0.551s, episode steps:  84, steps per second: 152, episode reward: -154.744, mean reward: -1.842 [-100.000,  5.950], mean action: 1.536 [0.000, 3.000],  loss: 36.190067, mae: 99.125359, mean_q: 127.390228, mean_eps: 0.967769
  10849/300000: episode: 111, duration: 0.404s, episode steps:  63, steps per second: 156, episode reward: -57.846, mean reward: -0.918 [-100.000, 11.882], mean action: 1.619 [0.000, 3.000],  loss: 51.145543, mae: 99.397164, mean_q: 129.027882, mean_eps: 0.967549
  10967/300000: episode: 112, duration: 0.750s, episode steps: 118, steps per second: 157, episode reward: -145.433, mean reward: -1.232 [-100.000,  6.973], mean action: 1.542 [0.000, 3.000],  loss: 34.777729, mae: 99.125042, mean_q: 128.939244, mean_eps: 0.967277
  11083/300000: episode: 113, duration: 0.817s, episode steps: 116, steps per second: 142, episode reward: -429.939, mean reward: -3.706 [-100.000,  1.094], mean action: 1.595 [0.000, 3.000],  loss: 34.073204, mae: 99.285993, mean_q: 128.163351, mean_eps: 0.966926
  11191/300000: episode: 114, duration: 0.696s, episode steps: 108, steps per second: 155, episode reward: -165.363, mean reward: -1.531 [-100.000, 31.276], mean action: 1.667 [0.000, 3.000],  loss: 46.346364, mae: 97.293134, mean_q: 125.199658, mean_eps: 0.966591
  11293/300000: episode: 115, duration: 0.651s, episode steps: 102, steps per second: 157, episode reward: -401.241, mean reward: -3.934 [-100.000,  5.384], mean action: 1.500 [0.000, 3.000],  loss: 32.651048, mae: 99.446288, mean_q: 128.287548, mean_eps: 0.966276
  11376/300000: episode: 116, duration: 0.564s, episode steps:  83, steps per second: 147, episode reward: -198.909, mean reward: -2.396 [-100.000, 25.132], mean action: 1.386 [0.000, 3.000],  loss: 51.270758, mae: 98.477507, mean_q: 126.568390, mean_eps: 0.965998
  11474/300000: episode: 117, duration: 0.642s, episode steps:  98, steps per second: 153, episode reward: -482.062, mean reward: -4.919 [-100.000, 40.558], mean action: 1.643 [0.000, 3.000],  loss: 72.674287, mae: 98.513267, mean_q: 126.029317, mean_eps: 0.965727
  11582/300000: episode: 118, duration: 0.699s, episode steps: 108, steps per second: 155, episode reward: -176.170, mean reward: -1.631 [-100.000,  6.293], mean action: 1.500 [0.000, 3.000],  loss: 48.274062, mae: 98.129433, mean_q: 125.326621, mean_eps: 0.965417
  11701/300000: episode: 119, duration: 0.815s, episode steps: 119, steps per second: 146, episode reward: -75.213, mean reward: -0.632 [-100.000, 93.772], mean action: 1.462 [0.000, 3.000],  loss: 43.147976, mae: 96.756538, mean_q: 121.982074, mean_eps: 0.965077
  11826/300000: episode: 120, duration: 0.804s, episode steps: 125, steps per second: 156, episode reward: -389.897, mean reward: -3.119 [-100.000, 108.154], mean action: 1.592 [0.000, 3.000],  loss: 36.553035, mae: 96.271586, mean_q: 121.627625, mean_eps: 0.964711
  11887/300000: episode: 121, duration: 0.380s, episode steps:  61, steps per second: 161, episode reward: -84.453, mean reward: -1.384 [-100.000, 16.159], mean action: 1.689 [0.000, 3.000],  loss: 36.408309, mae: 96.949100, mean_q: 124.758666, mean_eps: 0.964432
  12024/300000: episode: 122, duration: 1.009s, episode steps: 137, steps per second: 136, episode reward: -341.848, mean reward: -2.495 [-100.000, 61.703], mean action: 1.555 [0.000, 3.000],  loss: 45.720574, mae: 97.107197, mean_q: 124.248018, mean_eps: 0.964135
  12136/300000: episode: 123, duration: 0.738s, episode steps: 112, steps per second: 152, episode reward: -170.614, mean reward: -1.523 [-100.000,  3.225], mean action: 1.625 [0.000, 3.000],  loss: 47.962769, mae: 95.861693, mean_q: 121.351337, mean_eps: 0.963762
  12229/300000: episode: 124, duration: 0.597s, episode steps:  93, steps per second: 156, episode reward: -295.024, mean reward: -3.172 [-100.000,  2.193], mean action: 1.247 [0.000, 3.000],  loss: 34.380707, mae: 96.527323, mean_q: 121.392409, mean_eps: 0.963454
  12307/300000: episode: 125, duration: 0.505s, episode steps:  78, steps per second: 155, episode reward: -100.568, mean reward: -1.289 [-100.000,  7.546], mean action: 1.397 [0.000, 3.000],  loss: 55.309685, mae: 95.000442, mean_q: 117.773474, mean_eps: 0.963198
  12393/300000: episode: 126, duration: 0.584s, episode steps:  86, steps per second: 147, episode reward: -141.388, mean reward: -1.644 [-100.000,  6.631], mean action: 1.395 [0.000, 3.000],  loss: 54.496510, mae: 93.904593, mean_q: 118.605032, mean_eps: 0.962952
  12462/300000: episode: 127, duration: 0.447s, episode steps:  69, steps per second: 155, episode reward: -154.032, mean reward: -2.232 [-100.000,  8.337], mean action: 1.536 [0.000, 3.000],  loss: 59.882888, mae: 94.121244, mean_q: 118.707990, mean_eps: 0.962719
  12619/300000: episode: 128, duration: 1.035s, episode steps: 157, steps per second: 152, episode reward: -186.476, mean reward: -1.188 [-100.000, 37.426], mean action: 1.624 [0.000, 3.000],  loss: 43.529391, mae: 95.674847, mean_q: 121.342823, mean_eps: 0.962380
  12733/300000: episode: 129, duration: 0.788s, episode steps: 114, steps per second: 145, episode reward: -53.619, mean reward: -0.470 [-100.000, 21.442], mean action: 1.667 [0.000, 3.000],  loss: 48.507233, mae: 95.572093, mean_q: 119.560886, mean_eps: 0.961973
  12839/300000: episode: 130, duration: 0.688s, episode steps: 106, steps per second: 154, episode reward: -143.592, mean reward: -1.355 [-100.000,  7.383], mean action: 1.575 [0.000, 3.000],  loss: 40.200528, mae: 96.362752, mean_q: 121.583038, mean_eps: 0.961643
  12945/300000: episode: 131, duration: 0.690s, episode steps: 106, steps per second: 154, episode reward: -184.507, mean reward: -1.741 [-100.000,  7.702], mean action: 1.575 [0.000, 3.000],  loss: 51.582802, mae: 97.347749, mean_q: 123.186637, mean_eps: 0.961325
  13076/300000: episode: 132, duration: 0.896s, episode steps: 131, steps per second: 146, episode reward: -17.863, mean reward: -0.136 [-100.000, 109.337], mean action: 1.458 [0.000, 3.000],  loss: 44.230542, mae: 96.924340, mean_q: 122.375110, mean_eps: 0.960970
  13182/300000: episode: 133, duration: 0.685s, episode steps: 106, steps per second: 155, episode reward: -243.323, mean reward: -2.296 [-100.000,  5.152], mean action: 1.585 [0.000, 3.000],  loss: 50.157295, mae: 97.273514, mean_q: 123.114184, mean_eps: 0.960615
  13267/300000: episode: 134, duration: 0.540s, episode steps:  85, steps per second: 157, episode reward: -261.373, mean reward: -3.075 [-100.000,  9.908], mean action: 1.600 [0.000, 3.000],  loss: 54.000326, mae: 97.409878, mean_q: 121.516654, mean_eps: 0.960328
  13377/300000: episode: 135, duration: 0.766s, episode steps: 110, steps per second: 144, episode reward: -85.973, mean reward: -0.782 [-100.000, 15.379], mean action: 1.518 [0.000, 3.000],  loss: 62.822134, mae: 99.080136, mean_q: 123.607342, mean_eps: 0.960035
  13474/300000: episode: 136, duration: 0.629s, episode steps:  97, steps per second: 154, episode reward: -2.493, mean reward: -0.026 [-100.000, 95.967], mean action: 1.670 [0.000, 3.000],  loss: 54.475795, mae: 98.574861, mean_q: 123.406333, mean_eps: 0.959725
  13558/300000: episode: 137, duration: 0.539s, episode steps:  84, steps per second: 156, episode reward: -119.066, mean reward: -1.417 [-100.000,  6.551], mean action: 1.702 [0.000, 3.000],  loss: 63.230556, mae: 98.987841, mean_q: 124.948037, mean_eps: 0.959453
  13646/300000: episode: 138, duration: 0.611s, episode steps:  88, steps per second: 144, episode reward: -124.428, mean reward: -1.414 [-100.000,  8.546], mean action: 1.523 [0.000, 3.000],  loss: 44.767913, mae: 99.205175, mean_q: 125.307564, mean_eps: 0.959195
  13751/300000: episode: 139, duration: 0.691s, episode steps: 105, steps per second: 152, episode reward: -160.866, mean reward: -1.532 [-100.000, 10.739], mean action: 1.495 [0.000, 3.000],  loss: 34.962913, mae: 97.990324, mean_q: 124.262642, mean_eps: 0.958906
  13829/300000: episode: 140, duration: 0.504s, episode steps:  78, steps per second: 155, episode reward: -136.578, mean reward: -1.751 [-100.000,  8.661], mean action: 1.551 [0.000, 3.000],  loss: 41.625557, mae: 98.894164, mean_q: 124.802404, mean_eps: 0.958631
  13890/300000: episode: 141, duration: 0.402s, episode steps:  61, steps per second: 152, episode reward: -85.003, mean reward: -1.393 [-100.000,  6.258], mean action: 1.197 [0.000, 3.000],  loss: 49.206878, mae: 98.582452, mean_q: 125.287058, mean_eps: 0.958423
  13990/300000: episode: 142, duration: 0.692s, episode steps: 100, steps per second: 144, episode reward: -117.521, mean reward: -1.175 [-100.000,  7.121], mean action: 1.470 [0.000, 3.000],  loss: 53.821211, mae: 100.029100, mean_q: 127.724191, mean_eps: 0.958182
  14086/300000: episode: 143, duration: 0.640s, episode steps:  96, steps per second: 150, episode reward: -82.999, mean reward: -0.865 [-100.000, 13.288], mean action: 1.427 [0.000, 3.000],  loss: 46.408578, mae: 100.932805, mean_q: 128.557758, mean_eps: 0.957888
  14172/300000: episode: 144, duration: 0.553s, episode steps:  86, steps per second: 156, episode reward: -102.581, mean reward: -1.193 [-100.000, 15.995], mean action: 1.663 [0.000, 3.000],  loss: 67.729312, mae: 101.022808, mean_q: 130.212837, mean_eps: 0.957615
  14247/300000: episode: 145, duration: 0.479s, episode steps:  75, steps per second: 157, episode reward: -81.659, mean reward: -1.089 [-100.000,  8.586], mean action: 1.467 [0.000, 3.000],  loss: 39.478673, mae: 102.587700, mean_q: 132.708361, mean_eps: 0.957373
  14357/300000: episode: 146, duration: 0.783s, episode steps: 110, steps per second: 141, episode reward: 54.684, mean reward:  0.497 [-100.000, 131.297], mean action: 1.627 [0.000, 3.000],  loss: 54.221154, mae: 101.093101, mean_q: 130.901935, mean_eps: 0.957096
  14452/300000: episode: 147, duration: 0.680s, episode steps:  95, steps per second: 140, episode reward: -125.762, mean reward: -1.324 [-100.000, 27.267], mean action: 1.432 [0.000, 3.000],  loss: 62.243561, mae: 99.049193, mean_q: 126.624569, mean_eps: 0.956788
  14520/300000: episode: 148, duration: 0.478s, episode steps:  68, steps per second: 142, episode reward: -77.311, mean reward: -1.137 [-100.000, 12.217], mean action: 1.529 [0.000, 3.000],  loss: 45.216770, mae: 98.900646, mean_q: 126.390332, mean_eps: 0.956543
  14628/300000: episode: 149, duration: 0.805s, episode steps: 108, steps per second: 134, episode reward: -88.546, mean reward: -0.820 [-100.000, 16.487], mean action: 1.481 [0.000, 3.000],  loss: 50.728054, mae: 98.497296, mean_q: 125.631513, mean_eps: 0.956279
  14755/300000: episode: 150, duration: 0.874s, episode steps: 127, steps per second: 145, episode reward: -97.561, mean reward: -0.768 [-100.000, 11.518], mean action: 1.449 [0.000, 3.000],  loss: 45.425732, mae: 100.334182, mean_q: 127.659478, mean_eps: 0.955927
  14885/300000: episode: 151, duration: 0.883s, episode steps: 130, steps per second: 147, episode reward: -173.961, mean reward: -1.338 [-100.000,  8.167], mean action: 1.446 [0.000, 3.000],  loss: 58.285191, mae: 102.185636, mean_q: 130.753370, mean_eps: 0.955541
  14968/300000: episode: 152, duration: 0.574s, episode steps:  83, steps per second: 145, episode reward: -134.189, mean reward: -1.617 [-100.000, 10.396], mean action: 1.530 [0.000, 3.000],  loss: 51.755669, mae: 100.210176, mean_q: 128.155006, mean_eps: 0.955222
  15102/300000: episode: 153, duration: 0.909s, episode steps: 134, steps per second: 147, episode reward: -387.775, mean reward: -2.894 [-100.000, 14.755], mean action: 1.590 [0.000, 3.000],  loss: 63.212969, mae: 101.994219, mean_q: 130.127036, mean_eps: 0.954897
  15207/300000: episode: 154, duration: 0.703s, episode steps: 105, steps per second: 149, episode reward: -257.747, mean reward: -2.455 [-100.000, 32.106], mean action: 1.467 [0.000, 3.000],  loss: 51.853455, mae: 101.251241, mean_q: 129.267249, mean_eps: 0.954538
  15309/300000: episode: 155, duration: 0.673s, episode steps: 102, steps per second: 152, episode reward: -188.166, mean reward: -1.845 [-100.000, 77.201], mean action: 1.431 [0.000, 3.000],  loss: 79.844658, mae: 102.063801, mean_q: 129.067909, mean_eps: 0.954228
  15441/300000: episode: 156, duration: 0.836s, episode steps: 132, steps per second: 158, episode reward: -102.315, mean reward: -0.775 [-100.000,  9.838], mean action: 1.674 [0.000, 3.000],  loss: 61.358681, mae: 102.940336, mean_q: 131.284204, mean_eps: 0.953877
  15534/300000: episode: 157, duration: 0.628s, episode steps:  93, steps per second: 148, episode reward: -136.927, mean reward: -1.472 [-100.000, 13.980], mean action: 1.387 [0.000, 3.000],  loss: 57.061348, mae: 103.072032, mean_q: 130.367891, mean_eps: 0.953539
  15627/300000: episode: 158, duration: 0.639s, episode steps:  93, steps per second: 145, episode reward: -55.863, mean reward: -0.601 [-100.000, 50.233], mean action: 1.516 [0.000, 3.000],  loss: 79.232642, mae: 104.030856, mean_q: 132.362588, mean_eps: 0.953260
  15759/300000: episode: 159, duration: 0.850s, episode steps: 132, steps per second: 155, episode reward: -153.794, mean reward: -1.165 [-100.000,  7.802], mean action: 1.364 [0.000, 3.000],  loss: 85.971367, mae: 104.831995, mean_q: 134.589578, mean_eps: 0.952922
  15849/300000: episode: 160, duration: 0.584s, episode steps:  90, steps per second: 154, episode reward: -228.907, mean reward: -2.543 [-100.000,  4.603], mean action: 1.556 [0.000, 3.000],  loss: 57.108306, mae: 103.695067, mean_q: 133.122486, mean_eps: 0.952590
  15941/300000: episode: 161, duration: 0.618s, episode steps:  92, steps per second: 149, episode reward: -84.076, mean reward: -0.914 [-100.000, 11.758], mean action: 1.500 [0.000, 3.000],  loss: 71.175278, mae: 104.836642, mean_q: 133.416095, mean_eps: 0.952317
  16009/300000: episode: 162, duration: 0.444s, episode steps:  68, steps per second: 153, episode reward: -208.318, mean reward: -3.063 [-100.000, 11.712], mean action: 1.529 [0.000, 3.000],  loss: 69.448577, mae: 105.821231, mean_q: 133.990498, mean_eps: 0.952076
  16074/300000: episode: 163, duration: 0.429s, episode steps:  65, steps per second: 152, episode reward: -154.447, mean reward: -2.376 [-100.000, 55.729], mean action: 1.477 [0.000, 3.000],  loss: 63.084302, mae: 104.873713, mean_q: 133.282652, mean_eps: 0.951877
  16163/300000: episode: 164, duration: 0.584s, episode steps:  89, steps per second: 152, episode reward: -242.274, mean reward: -2.722 [-100.000, 29.937], mean action: 1.551 [0.000, 3.000],  loss: 131.717275, mae: 105.271673, mean_q: 133.387798, mean_eps: 0.951646
  16252/300000: episode: 165, duration: 0.673s, episode steps:  89, steps per second: 132, episode reward: -151.731, mean reward: -1.705 [-100.000, 14.195], mean action: 1.427 [0.000, 3.000],  loss: 78.171805, mae: 105.250287, mean_q: 134.510926, mean_eps: 0.951379
  16323/300000: episode: 166, duration: 0.459s, episode steps:  71, steps per second: 155, episode reward: -56.269, mean reward: -0.793 [-100.000, 11.677], mean action: 1.549 [0.000, 3.000],  loss: 69.111405, mae: 105.728135, mean_q: 135.133892, mean_eps: 0.951139
  16443/300000: episode: 167, duration: 0.759s, episode steps: 120, steps per second: 158, episode reward: -151.056, mean reward: -1.259 [-100.000,  6.940], mean action: 1.367 [0.000, 3.000],  loss: 42.510227, mae: 104.399696, mean_q: 133.521364, mean_eps: 0.950852
  16551/300000: episode: 168, duration: 0.731s, episode steps: 108, steps per second: 148, episode reward: -292.352, mean reward: -2.707 [-100.000,  1.122], mean action: 1.454 [0.000, 3.000],  loss: 47.221072, mae: 104.912937, mean_q: 133.266181, mean_eps: 0.950511
  16635/300000: episode: 169, duration: 0.539s, episode steps:  84, steps per second: 156, episode reward: -276.607, mean reward: -3.293 [-100.000, 15.125], mean action: 1.524 [0.000, 3.000],  loss: 45.882194, mae: 105.130386, mean_q: 132.882757, mean_eps: 0.950223
  16742/300000: episode: 170, duration: 0.691s, episode steps: 107, steps per second: 155, episode reward: -232.259, mean reward: -2.171 [-100.000,  5.333], mean action: 1.421 [0.000, 3.000],  loss: 43.396694, mae: 104.810595, mean_q: 133.166629, mean_eps: 0.949936
  16810/300000: episode: 171, duration: 0.454s, episode steps:  68, steps per second: 150, episode reward: -83.555, mean reward: -1.229 [-100.000, 11.428], mean action: 1.515 [0.000, 3.000],  loss: 67.519242, mae: 103.819948, mean_q: 130.361422, mean_eps: 0.949674
  16905/300000: episode: 172, duration: 0.675s, episode steps:  95, steps per second: 141, episode reward: -150.931, mean reward: -1.589 [-100.000, 10.264], mean action: 1.379 [0.000, 3.000],  loss: 43.080737, mae: 103.844273, mean_q: 131.567051, mean_eps: 0.949429
  16984/300000: episode: 173, duration: 0.516s, episode steps:  79, steps per second: 153, episode reward: -126.519, mean reward: -1.602 [-100.000, 20.859], mean action: 1.696 [0.000, 3.000],  loss: 39.310870, mae: 103.389101, mean_q: 130.234420, mean_eps: 0.949168
  17064/300000: episode: 174, duration: 0.520s, episode steps:  80, steps per second: 154, episode reward: -183.909, mean reward: -2.299 [-100.000, 26.486], mean action: 1.725 [0.000, 3.000],  loss: 56.975128, mae: 102.094307, mean_q: 129.110076, mean_eps: 0.948929
  17139/300000: episode: 175, duration: 0.471s, episode steps:  75, steps per second: 159, episode reward: -19.722, mean reward: -0.263 [-100.000, 64.478], mean action: 1.533 [0.000, 3.000],  loss: 58.010834, mae: 102.925170, mean_q: 128.799396, mean_eps: 0.948697
  17247/300000: episode: 176, duration: 0.734s, episode steps: 108, steps per second: 147, episode reward: -357.709, mean reward: -3.312 [-100.000,  5.184], mean action: 1.454 [0.000, 3.000],  loss: 65.152078, mae: 101.783572, mean_q: 125.751022, mean_eps: 0.948423
  17335/300000: episode: 177, duration: 0.576s, episode steps:  88, steps per second: 153, episode reward: -124.731, mean reward: -1.417 [-100.000, 17.528], mean action: 1.659 [0.000, 3.000],  loss: 60.340144, mae: 99.774929, mean_q: 122.724333, mean_eps: 0.948128
  17450/300000: episode: 178, duration: 0.748s, episode steps: 115, steps per second: 154, episode reward: -421.857, mean reward: -3.668 [-100.000,  6.048], mean action: 1.513 [0.000, 3.000],  loss: 55.376478, mae: 98.977280, mean_q: 123.323348, mean_eps: 0.947824
  17563/300000: episode: 179, duration: 0.795s, episode steps: 113, steps per second: 142, episode reward: -118.849, mean reward: -1.052 [-100.000, 41.470], mean action: 1.522 [0.000, 3.000],  loss: 61.255501, mae: 98.533421, mean_q: 121.557780, mean_eps: 0.947482
  17665/300000: episode: 180, duration: 0.674s, episode steps: 102, steps per second: 151, episode reward: -463.916, mean reward: -4.548 [-100.000, 52.527], mean action: 1.696 [0.000, 3.000],  loss: 51.747066, mae: 98.759565, mean_q: 122.668163, mean_eps: 0.947160
  17728/300000: episode: 181, duration: 0.408s, episode steps:  63, steps per second: 154, episode reward: -124.118, mean reward: -1.970 [-100.000,  8.730], mean action: 1.619 [0.000, 3.000],  loss: 53.041996, mae: 98.313948, mean_q: 122.271777, mean_eps: 0.946912
  17809/300000: episode: 182, duration: 0.552s, episode steps:  81, steps per second: 147, episode reward: -97.639, mean reward: -1.205 [-100.000,  7.017], mean action: 1.506 [0.000, 3.000],  loss: 50.705609, mae: 97.158243, mean_q: 119.221944, mean_eps: 0.946696
  17916/300000: episode: 183, duration: 0.721s, episode steps: 107, steps per second: 148, episode reward: -103.964, mean reward: -0.972 [-100.000,  6.397], mean action: 1.514 [0.000, 3.000],  loss: 69.569635, mae: 98.082839, mean_q: 121.164699, mean_eps: 0.946414
  18043/300000: episode: 184, duration: 0.798s, episode steps: 127, steps per second: 159, episode reward: -60.482, mean reward: -0.476 [-100.000, 12.350], mean action: 1.528 [0.000, 3.000],  loss: 72.478019, mae: 97.963134, mean_q: 120.488309, mean_eps: 0.946063
  18132/300000: episode: 185, duration: 0.606s, episode steps:  89, steps per second: 147, episode reward: -105.162, mean reward: -1.182 [-100.000, 12.724], mean action: 1.551 [0.000, 3.000],  loss: 50.310999, mae: 96.708774, mean_q: 117.787576, mean_eps: 0.945739
  18283/300000: episode: 186, duration: 1.224s, episode steps: 151, steps per second: 123, episode reward: -144.750, mean reward: -0.959 [-100.000,  6.703], mean action: 1.662 [0.000, 3.000],  loss: 63.740469, mae: 98.377372, mean_q: 120.797448, mean_eps: 0.945379
  18347/300000: episode: 187, duration: 0.492s, episode steps:  64, steps per second: 130, episode reward: -219.369, mean reward: -3.428 [-100.000,  6.400], mean action: 1.656 [0.000, 3.000],  loss: 52.663984, mae: 97.980051, mean_q: 120.309515, mean_eps: 0.945056
  18465/300000: episode: 188, duration: 0.887s, episode steps: 118, steps per second: 133, episode reward: -74.389, mean reward: -0.630 [-100.000, 12.255], mean action: 1.475 [0.000, 3.000],  loss: 63.915504, mae: 97.356613, mean_q: 120.124907, mean_eps: 0.944783
  18592/300000: episode: 189, duration: 0.875s, episode steps: 127, steps per second: 145, episode reward: -166.988, mean reward: -1.315 [-100.000,  6.659], mean action: 1.512 [0.000, 3.000],  loss: 64.668961, mae: 98.671232, mean_q: 122.865837, mean_eps: 0.944416
  18677/300000: episode: 190, duration: 0.591s, episode steps:  85, steps per second: 144, episode reward: -165.500, mean reward: -1.947 [-100.000,  5.492], mean action: 1.565 [0.000, 3.000],  loss: 43.983101, mae: 100.101891, mean_q: 123.236569, mean_eps: 0.944098
  18747/300000: episode: 191, duration: 0.540s, episode steps:  70, steps per second: 130, episode reward: -137.436, mean reward: -1.963 [-100.000, 14.855], mean action: 1.700 [0.000, 3.000],  loss: 90.522001, mae: 99.404108, mean_q: 124.761387, mean_eps: 0.943865
  18861/300000: episode: 192, duration: 0.805s, episode steps: 114, steps per second: 142, episode reward: -303.296, mean reward: -2.660 [-100.000,  2.305], mean action: 1.518 [0.000, 3.000],  loss: 53.690965, mae: 100.282786, mean_q: 123.775272, mean_eps: 0.943589
  18925/300000: episode: 193, duration: 0.416s, episode steps:  64, steps per second: 154, episode reward: -152.737, mean reward: -2.387 [-100.000, 15.126], mean action: 1.359 [0.000, 3.000],  loss: 45.580267, mae: 99.411408, mean_q: 122.795752, mean_eps: 0.943323
  19001/300000: episode: 194, duration: 0.497s, episode steps:  76, steps per second: 153, episode reward: -78.538, mean reward: -1.033 [-100.000, 19.894], mean action: 1.447 [0.000, 3.000],  loss: 48.094049, mae: 99.085572, mean_q: 121.652133, mean_eps: 0.943113
  19091/300000: episode: 195, duration: 0.629s, episode steps:  90, steps per second: 143, episode reward: -129.051, mean reward: -1.434 [-100.000, 10.009], mean action: 1.556 [0.000, 3.000],  loss: 61.498059, mae: 98.276180, mean_q: 121.924421, mean_eps: 0.942863
  19198/300000: episode: 196, duration: 0.694s, episode steps: 107, steps per second: 154, episode reward: -84.294, mean reward: -0.788 [-100.000,  8.511], mean action: 1.477 [0.000, 3.000],  loss: 67.134908, mae: 98.615009, mean_q: 120.058292, mean_eps: 0.942568
  19274/300000: episode: 197, duration: 0.492s, episode steps:  76, steps per second: 155, episode reward: -165.883, mean reward: -2.183 [-100.000, 28.552], mean action: 1.395 [0.000, 3.000],  loss: 41.877667, mae: 97.978889, mean_q: 119.761805, mean_eps: 0.942294
  19328/300000: episode: 198, duration: 0.356s, episode steps:  54, steps per second: 152, episode reward: -85.993, mean reward: -1.592 [-100.000, 11.605], mean action: 1.241 [0.000, 3.000],  loss: 78.333131, mae: 96.994609, mean_q: 117.412154, mean_eps: 0.942099
  19394/300000: episode: 199, duration: 0.459s, episode steps:  66, steps per second: 144, episode reward: -104.515, mean reward: -1.584 [-100.000, 21.462], mean action: 1.667 [0.000, 3.000],  loss: 53.515198, mae: 96.432547, mean_q: 115.762097, mean_eps: 0.941918
  19462/300000: episode: 200, duration: 0.446s, episode steps:  68, steps per second: 152, episode reward: -95.313, mean reward: -1.402 [-100.000, 10.169], mean action: 1.485 [0.000, 3.000],  loss: 47.894279, mae: 96.487364, mean_q: 115.424798, mean_eps: 0.941717
  19566/300000: episode: 201, duration: 0.675s, episode steps: 104, steps per second: 154, episode reward: -280.608, mean reward: -2.698 [-100.000,  5.600], mean action: 1.692 [0.000, 3.000],  loss: 39.762408, mae: 97.454432, mean_q: 117.132611, mean_eps: 0.941460
  19666/300000: episode: 202, duration: 0.646s, episode steps: 100, steps per second: 155, episode reward: -102.767, mean reward: -1.028 [-100.000,  7.785], mean action: 1.460 [0.000, 3.000],  loss: 42.043162, mae: 96.846016, mean_q: 116.302305, mean_eps: 0.941154
  19759/300000: episode: 203, duration: 0.634s, episode steps:  93, steps per second: 147, episode reward: -371.224, mean reward: -3.992 [-100.000, -0.529], mean action: 1.656 [0.000, 3.000],  loss: 63.017363, mae: 97.108413, mean_q: 115.916605, mean_eps: 0.940864
  19855/300000: episode: 204, duration: 0.631s, episode steps:  96, steps per second: 152, episode reward: -78.694, mean reward: -0.820 [-100.000, 10.905], mean action: 1.625 [0.000, 3.000],  loss: 59.224752, mae: 95.758104, mean_q: 114.207436, mean_eps: 0.940580
  19931/300000: episode: 205, duration: 0.483s, episode steps:  76, steps per second: 157, episode reward: -101.658, mean reward: -1.338 [-100.000, 11.583], mean action: 1.539 [0.000, 3.000],  loss: 49.977966, mae: 96.242807, mean_q: 114.943720, mean_eps: 0.940323
  20009/300000: episode: 206, duration: 0.552s, episode steps:  78, steps per second: 141, episode reward: -88.756, mean reward: -1.138 [-100.000, 11.587], mean action: 1.731 [0.000, 3.000],  loss: 59.458760, mae: 96.127247, mean_q: 116.076515, mean_eps: 0.940091
  20117/300000: episode: 207, duration: 0.737s, episode steps: 108, steps per second: 147, episode reward: -253.839, mean reward: -2.350 [-100.000,  1.083], mean action: 1.574 [0.000, 3.000],  loss: 54.817864, mae: 97.030714, mean_q: 116.279568, mean_eps: 0.939812
  20235/300000: episode: 208, duration: 0.772s, episode steps: 118, steps per second: 153, episode reward: -105.344, mean reward: -0.893 [-100.000, 10.212], mean action: 1.534 [0.000, 3.000],  loss: 42.652016, mae: 96.414318, mean_q: 115.931998, mean_eps: 0.939473
  20311/300000: episode: 209, duration: 0.500s, episode steps:  76, steps per second: 152, episode reward: -104.806, mean reward: -1.379 [-100.000,  6.570], mean action: 1.579 [0.000, 3.000],  loss: 43.797719, mae: 98.718110, mean_q: 119.595507, mean_eps: 0.939183
  20428/300000: episode: 210, duration: 0.797s, episode steps: 117, steps per second: 147, episode reward: -189.222, mean reward: -1.617 [-100.000,  8.156], mean action: 1.342 [0.000, 3.000],  loss: 68.695636, mae: 96.981491, mean_q: 116.817018, mean_eps: 0.938893
  20549/300000: episode: 211, duration: 0.788s, episode steps: 121, steps per second: 153, episode reward: -105.134, mean reward: -0.869 [-100.000, 13.946], mean action: 1.603 [0.000, 3.000],  loss: 71.481533, mae: 95.385117, mean_q: 115.462792, mean_eps: 0.938536
  20609/300000: episode: 212, duration: 0.402s, episode steps:  60, steps per second: 149, episode reward: -131.296, mean reward: -2.188 [-100.000,  6.696], mean action: 1.583 [0.000, 3.000],  loss: 38.930927, mae: 94.937670, mean_q: 113.334347, mean_eps: 0.938264
  20735/300000: episode: 213, duration: 0.847s, episode steps: 126, steps per second: 149, episode reward: -219.737, mean reward: -1.744 [-100.000,  1.670], mean action: 1.651 [0.000, 3.000],  loss: 54.536049, mae: 94.889213, mean_q: 113.857692, mean_eps: 0.937986
  20844/300000: episode: 214, duration: 0.739s, episode steps: 109, steps per second: 147, episode reward: -83.983, mean reward: -0.770 [-100.000, 65.996], mean action: 1.349 [0.000, 3.000],  loss: 41.087930, mae: 94.674594, mean_q: 114.449052, mean_eps: 0.937633
  20920/300000: episode: 215, duration: 0.532s, episode steps:  76, steps per second: 143, episode reward: -95.045, mean reward: -1.251 [-100.000,  6.410], mean action: 1.382 [0.000, 3.000],  loss: 30.984641, mae: 93.411364, mean_q: 112.297924, mean_eps: 0.937356
  20995/300000: episode: 216, duration: 0.566s, episode steps:  75, steps per second: 132, episode reward: -69.656, mean reward: -0.929 [-100.000,  8.056], mean action: 1.587 [0.000, 3.000],  loss: 74.563179, mae: 94.732826, mean_q: 114.779144, mean_eps: 0.937129
  21055/300000: episode: 217, duration: 0.399s, episode steps:  60, steps per second: 150, episode reward: -41.064, mean reward: -0.684 [-100.000, 14.611], mean action: 1.283 [0.000, 3.000],  loss: 44.455152, mae: 95.343153, mean_q: 117.086531, mean_eps: 0.936927
  21193/300000: episode: 218, duration: 0.879s, episode steps: 138, steps per second: 157, episode reward: -166.466, mean reward: -1.206 [-100.000, 18.956], mean action: 1.580 [0.000, 3.000],  loss: 36.567351, mae: 94.949897, mean_q: 115.449783, mean_eps: 0.936629
  21285/300000: episode: 219, duration: 0.615s, episode steps:  92, steps per second: 150, episode reward: -104.190, mean reward: -1.133 [-100.000, 16.800], mean action: 1.641 [0.000, 3.000],  loss: 59.384343, mae: 96.680739, mean_q: 118.125656, mean_eps: 0.936284
  21365/300000: episode: 220, duration: 0.551s, episode steps:  80, steps per second: 145, episode reward: -139.294, mean reward: -1.741 [-100.000, 10.921], mean action: 1.637 [0.000, 3.000],  loss: 49.594566, mae: 97.624661, mean_q: 118.984024, mean_eps: 0.936026
  21451/300000: episode: 221, duration: 0.580s, episode steps:  86, steps per second: 148, episode reward: -227.056, mean reward: -2.640 [-100.000,  5.567], mean action: 1.395 [0.000, 3.000],  loss: 104.817088, mae: 95.939592, mean_q: 116.258208, mean_eps: 0.935777
  21516/300000: episode: 222, duration: 0.421s, episode steps:  65, steps per second: 154, episode reward: -45.437, mean reward: -0.699 [-100.000, 49.585], mean action: 1.646 [0.000, 3.000],  loss: 57.122704, mae: 96.464328, mean_q: 116.656294, mean_eps: 0.935551
  21607/300000: episode: 223, duration: 0.606s, episode steps:  91, steps per second: 150, episode reward: -127.167, mean reward: -1.397 [-100.000, 26.733], mean action: 1.604 [0.000, 3.000],  loss: 89.031577, mae: 95.612029, mean_q: 117.686785, mean_eps: 0.935317
  21697/300000: episode: 224, duration: 0.600s, episode steps:  90, steps per second: 150, episode reward: -105.705, mean reward: -1.175 [-100.000, 11.477], mean action: 1.556 [0.000, 3.000],  loss: 59.886828, mae: 96.813543, mean_q: 118.380255, mean_eps: 0.935045
  21826/300000: episode: 225, duration: 0.819s, episode steps: 129, steps per second: 157, episode reward: -163.699, mean reward: -1.269 [-100.000,  4.073], mean action: 1.682 [0.000, 3.000],  loss: 47.457491, mae: 97.323681, mean_q: 118.491253, mean_eps: 0.934717
  21953/300000: episode: 226, duration: 0.842s, episode steps: 127, steps per second: 151, episode reward: -191.882, mean reward: -1.511 [-100.000,  5.266], mean action: 1.433 [0.000, 3.000],  loss: 79.944612, mae: 98.898004, mean_q: 121.867252, mean_eps: 0.934333
  22085/300000: episode: 227, duration: 0.885s, episode steps: 132, steps per second: 149, episode reward: -164.761, mean reward: -1.248 [-100.000,  7.330], mean action: 1.614 [0.000, 3.000],  loss: 81.540428, mae: 97.307160, mean_q: 119.489227, mean_eps: 0.933945
  22200/300000: episode: 228, duration: 0.736s, episode steps: 115, steps per second: 156, episode reward: -219.034, mean reward: -1.905 [-100.000,  7.315], mean action: 1.435 [0.000, 3.000],  loss: 110.276959, mae: 96.782927, mean_q: 119.137807, mean_eps: 0.933574
  22262/300000: episode: 229, duration: 0.393s, episode steps:  62, steps per second: 158, episode reward: -90.321, mean reward: -1.457 [-100.000,  6.941], mean action: 1.726 [0.000, 3.000],  loss: 59.446843, mae: 96.514017, mean_q: 119.346518, mean_eps: 0.933308
  22351/300000: episode: 230, duration: 0.613s, episode steps:  89, steps per second: 145, episode reward: -103.500, mean reward: -1.163 [-100.000,  6.219], mean action: 1.494 [0.000, 3.000],  loss: 77.654913, mae: 96.964050, mean_q: 118.807024, mean_eps: 0.933082
  22440/300000: episode: 231, duration: 0.577s, episode steps:  89, steps per second: 154, episode reward: -127.886, mean reward: -1.437 [-100.000,  8.653], mean action: 1.663 [0.000, 3.000],  loss: 77.184039, mae: 98.948719, mean_q: 123.524606, mean_eps: 0.932815
  22531/300000: episode: 232, duration: 0.603s, episode steps:  91, steps per second: 151, episode reward: -299.652, mean reward: -3.293 [-100.000, 126.907], mean action: 1.593 [0.000, 3.000],  loss: 76.154882, mae: 98.269799, mean_q: 122.304205, mean_eps: 0.932545
  22633/300000: episode: 233, duration: 0.716s, episode steps: 102, steps per second: 142, episode reward: -150.184, mean reward: -1.472 [-100.000,  2.459], mean action: 1.451 [0.000, 3.000],  loss: 86.889256, mae: 99.637723, mean_q: 123.735126, mean_eps: 0.932255
  22743/300000: episode: 234, duration: 0.711s, episode steps: 110, steps per second: 155, episode reward: -160.548, mean reward: -1.460 [-100.000,  8.381], mean action: 1.518 [0.000, 3.000],  loss: 95.656939, mae: 97.122966, mean_q: 120.571312, mean_eps: 0.931937
  22882/300000: episode: 235, duration: 0.883s, episode steps: 139, steps per second: 157, episode reward: -202.875, mean reward: -1.460 [-100.000, 35.373], mean action: 1.468 [0.000, 3.000],  loss: 71.288881, mae: 96.128311, mean_q: 117.552213, mean_eps: 0.931564
  22974/300000: episode: 236, duration: 0.615s, episode steps:  92, steps per second: 150, episode reward: -117.709, mean reward: -1.279 [-100.000, 12.291], mean action: 1.435 [0.000, 3.000],  loss: 47.593678, mae: 97.393227, mean_q: 119.937419, mean_eps: 0.931218
  23083/300000: episode: 237, duration: 0.717s, episode steps: 109, steps per second: 152, episode reward: -76.660, mean reward: -0.703 [-100.000, 12.071], mean action: 1.523 [0.000, 3.000],  loss: 64.592513, mae: 99.384176, mean_q: 123.578065, mean_eps: 0.930916
  23186/300000: episode: 238, duration: 0.725s, episode steps: 103, steps per second: 142, episode reward: -93.928, mean reward: -0.912 [-100.000, 63.566], mean action: 1.583 [0.000, 3.000],  loss: 52.990681, mae: 98.535602, mean_q: 122.231262, mean_eps: 0.930598
  23292/300000: episode: 239, duration: 0.829s, episode steps: 106, steps per second: 128, episode reward: -117.920, mean reward: -1.112 [-100.000, 10.361], mean action: 1.538 [0.000, 3.000],  loss: 66.761615, mae: 97.227824, mean_q: 120.900705, mean_eps: 0.930284
  23370/300000: episode: 240, duration: 0.555s, episode steps:  78, steps per second: 141, episode reward: -320.030, mean reward: -4.103 [-100.000, 90.622], mean action: 1.538 [0.000, 3.000],  loss: 64.150987, mae: 98.968055, mean_q: 122.880277, mean_eps: 0.930009
  23458/300000: episode: 241, duration: 0.584s, episode steps:  88, steps per second: 151, episode reward: -92.145, mean reward: -1.047 [-100.000,  7.600], mean action: 1.477 [0.000, 3.000],  loss: 74.754561, mae: 99.347597, mean_q: 124.126889, mean_eps: 0.929760
  23531/300000: episode: 242, duration: 0.484s, episode steps:  73, steps per second: 151, episode reward: -54.054, mean reward: -0.740 [-100.000, 15.674], mean action: 1.630 [0.000, 3.000],  loss: 62.648616, mae: 96.269611, mean_q: 119.116137, mean_eps: 0.929518
  23606/300000: episode: 243, duration: 0.551s, episode steps:  75, steps per second: 136, episode reward: -95.187, mean reward: -1.269 [-100.000, 12.421], mean action: 1.520 [0.000, 3.000],  loss: 52.769289, mae: 95.314792, mean_q: 117.159692, mean_eps: 0.929296
  23705/300000: episode: 244, duration: 0.745s, episode steps:  99, steps per second: 133, episode reward: -157.164, mean reward: -1.588 [-100.000,  6.288], mean action: 1.566 [0.000, 3.000],  loss: 55.520724, mae: 97.165332, mean_q: 119.691342, mean_eps: 0.929035
  23790/300000: episode: 245, duration: 0.565s, episode steps:  85, steps per second: 150, episode reward: -95.592, mean reward: -1.125 [-100.000,  6.627], mean action: 1.529 [0.000, 3.000],  loss: 47.703418, mae: 96.486164, mean_q: 117.886095, mean_eps: 0.928759
  23852/300000: episode: 246, duration: 0.453s, episode steps:  62, steps per second: 137, episode reward: -80.143, mean reward: -1.293 [-100.000, 55.161], mean action: 1.452 [0.000, 3.000],  loss: 58.016192, mae: 95.751463, mean_q: 117.312105, mean_eps: 0.928538
  23923/300000: episode: 247, duration: 0.530s, episode steps:  71, steps per second: 134, episode reward: -61.243, mean reward: -0.863 [-100.000, 15.389], mean action: 1.606 [0.000, 3.000],  loss: 55.823199, mae: 97.689426, mean_q: 119.841552, mean_eps: 0.928339
  23997/300000: episode: 248, duration: 0.472s, episode steps:  74, steps per second: 157, episode reward: -167.742, mean reward: -2.267 [-100.000,  9.239], mean action: 1.365 [0.000, 3.000],  loss: 95.073280, mae: 98.089640, mean_q: 120.419216, mean_eps: 0.928121
  24115/300000: episode: 249, duration: 0.871s, episode steps: 118, steps per second: 136, episode reward: -424.781, mean reward: -3.600 [-100.000,  1.959], mean action: 1.449 [0.000, 3.000],  loss: 77.756135, mae: 95.459909, mean_q: 116.764844, mean_eps: 0.927833
  24202/300000: episode: 250, duration: 0.706s, episode steps:  87, steps per second: 123, episode reward: -212.987, mean reward: -2.448 [-100.000,  7.392], mean action: 1.379 [0.000, 3.000],  loss: 62.070970, mae: 97.655426, mean_q: 119.704574, mean_eps: 0.927526
  24283/300000: episode: 251, duration: 0.597s, episode steps:  81, steps per second: 136, episode reward: -44.677, mean reward: -0.552 [-100.000, 17.795], mean action: 1.556 [0.000, 3.000],  loss: 62.851819, mae: 96.814219, mean_q: 118.565342, mean_eps: 0.927274
  24395/300000: episode: 252, duration: 0.779s, episode steps: 112, steps per second: 144, episode reward: -130.846, mean reward: -1.168 [-100.000,  6.345], mean action: 1.509 [0.000, 3.000],  loss: 79.415216, mae: 97.532833, mean_q: 117.659567, mean_eps: 0.926984
  24503/300000: episode: 253, duration: 0.858s, episode steps: 108, steps per second: 126, episode reward: -168.952, mean reward: -1.564 [-100.000,  7.453], mean action: 1.593 [0.000, 3.000],  loss: 78.364284, mae: 98.730006, mean_q: 120.080169, mean_eps: 0.926655
  24595/300000: episode: 254, duration: 0.736s, episode steps:  92, steps per second: 125, episode reward: -290.501, mean reward: -3.158 [-100.000,  0.829], mean action: 1.717 [0.000, 3.000],  loss: 72.775674, mae: 99.648309, mean_q: 122.465098, mean_eps: 0.926355
  24698/300000: episode: 255, duration: 0.826s, episode steps: 103, steps per second: 125, episode reward: -116.152, mean reward: -1.128 [-100.000,  9.851], mean action: 1.631 [0.000, 3.000],  loss: 83.993630, mae: 99.308662, mean_q: 122.076034, mean_eps: 0.926062
  24766/300000: episode: 256, duration: 0.577s, episode steps:  68, steps per second: 118, episode reward: -72.581, mean reward: -1.067 [-100.000,  6.656], mean action: 1.485 [0.000, 3.000],  loss: 88.006917, mae: 100.145800, mean_q: 122.450899, mean_eps: 0.925806
  24887/300000: episode: 257, duration: 0.884s, episode steps: 121, steps per second: 137, episode reward: -155.345, mean reward: -1.284 [-100.000, 46.540], mean action: 1.579 [0.000, 3.000],  loss: 53.267926, mae: 101.487825, mean_q: 124.751913, mean_eps: 0.925522
  24959/300000: episode: 258, duration: 0.518s, episode steps:  72, steps per second: 139, episode reward: -70.452, mean reward: -0.979 [-100.000,  8.624], mean action: 1.611 [0.000, 3.000],  loss: 97.947399, mae: 100.813291, mean_q: 123.825123, mean_eps: 0.925233
  25078/300000: episode: 259, duration: 0.871s, episode steps: 119, steps per second: 137, episode reward: -129.562, mean reward: -1.089 [-100.000, 36.065], mean action: 1.445 [0.000, 3.000],  loss: 68.594134, mae: 102.256834, mean_q: 125.334014, mean_eps: 0.924946
  25149/300000: episode: 260, duration: 0.530s, episode steps:  71, steps per second: 134, episode reward: -181.514, mean reward: -2.557 [-100.000,  3.994], mean action: 1.338 [0.000, 3.000],  loss: 41.086025, mae: 102.357133, mean_q: 125.375125, mean_eps: 0.924661
  25278/300000: episode: 261, duration: 1.080s, episode steps: 129, steps per second: 119, episode reward: -174.060, mean reward: -1.349 [-100.000,  3.562], mean action: 1.457 [0.000, 3.000],  loss: 58.297216, mae: 101.832437, mean_q: 123.544708, mean_eps: 0.924361
  25374/300000: episode: 262, duration: 1.077s, episode steps:  96, steps per second:  89, episode reward: -141.668, mean reward: -1.476 [-100.000, 14.558], mean action: 1.667 [0.000, 3.000],  loss: 75.664296, mae: 102.445637, mean_q: 124.161094, mean_eps: 0.924023
  25477/300000: episode: 263, duration: 0.700s, episode steps: 103, steps per second: 147, episode reward: -82.248, mean reward: -0.799 [-100.000, 15.438], mean action: 1.408 [0.000, 3.000],  loss: 53.204781, mae: 103.636837, mean_q: 126.972189, mean_eps: 0.923725
  25571/300000: episode: 264, duration: 0.646s, episode steps:  94, steps per second: 145, episode reward: -344.788, mean reward: -3.668 [-100.000,  4.446], mean action: 1.543 [0.000, 3.000],  loss: 62.931747, mae: 99.826483, mean_q: 122.012365, mean_eps: 0.923429
  25657/300000: episode: 265, duration: 0.575s, episode steps:  86, steps per second: 150, episode reward: -376.506, mean reward: -4.378 [-100.000,  0.022], mean action: 1.453 [0.000, 3.000],  loss: 52.125655, mae: 99.671428, mean_q: 121.021687, mean_eps: 0.923160
  25781/300000: episode: 266, duration: 0.830s, episode steps: 124, steps per second: 149, episode reward: -345.979, mean reward: -2.790 [-100.000,  3.579], mean action: 1.371 [0.000, 3.000],  loss: 49.246306, mae: 98.744224, mean_q: 118.863913, mean_eps: 0.922845
  25853/300000: episode: 267, duration: 0.464s, episode steps:  72, steps per second: 155, episode reward: -98.036, mean reward: -1.362 [-100.000,  6.425], mean action: 1.486 [0.000, 3.000],  loss: 57.367662, mae: 100.562338, mean_q: 121.010659, mean_eps: 0.922551
  25919/300000: episode: 268, duration: 0.465s, episode steps:  66, steps per second: 142, episode reward: -89.768, mean reward: -1.360 [-100.000, 13.507], mean action: 1.470 [0.000, 3.000],  loss: 67.081049, mae: 99.447470, mean_q: 119.516562, mean_eps: 0.922343
  25992/300000: episode: 269, duration: 0.486s, episode steps:  73, steps per second: 150, episode reward: -321.330, mean reward: -4.402 [-100.000, 79.463], mean action: 1.205 [0.000, 3.000],  loss: 79.897617, mae: 101.366255, mean_q: 121.160574, mean_eps: 0.922135
  26081/300000: episode: 270, duration: 0.654s, episode steps:  89, steps per second: 136, episode reward: -237.558, mean reward: -2.669 [-100.000,  5.400], mean action: 1.315 [0.000, 3.000],  loss: 48.361151, mae: 101.857758, mean_q: 120.513996, mean_eps: 0.921892
  26177/300000: episode: 271, duration: 0.962s, episode steps:  96, steps per second: 100, episode reward: -434.719, mean reward: -4.528 [-100.000,  0.622], mean action: 1.458 [0.000, 3.000],  loss: 68.148743, mae: 101.826688, mean_q: 121.809369, mean_eps: 0.921615
  26276/300000: episode: 272, duration: 0.820s, episode steps:  99, steps per second: 121, episode reward: -320.638, mean reward: -3.239 [-100.000,  0.774], mean action: 1.556 [0.000, 3.000],  loss: 63.873712, mae: 103.283763, mean_q: 123.459635, mean_eps: 0.921322
  26380/300000: episode: 273, duration: 0.752s, episode steps: 104, steps per second: 138, episode reward: -107.396, mean reward: -1.033 [-100.000, 11.063], mean action: 1.529 [0.000, 3.000],  loss: 95.228536, mae: 106.826852, mean_q: 130.144749, mean_eps: 0.921018
  26469/300000: episode: 274, duration: 0.683s, episode steps:  89, steps per second: 130, episode reward: -347.562, mean reward: -3.905 [-100.000, -0.071], mean action: 1.708 [0.000, 3.000],  loss: 56.606906, mae: 107.202490, mean_q: 129.874012, mean_eps: 0.920728
  26557/300000: episode: 275, duration: 0.786s, episode steps:  88, steps per second: 112, episode reward: -111.240, mean reward: -1.264 [-100.000,  6.301], mean action: 1.443 [0.000, 3.000],  loss: 87.786164, mae: 108.180945, mean_q: 131.692790, mean_eps: 0.920462
  26646/300000: episode: 276, duration: 0.675s, episode steps:  89, steps per second: 132, episode reward: -126.918, mean reward: -1.426 [-100.000, 10.664], mean action: 1.753 [0.000, 3.000],  loss: 87.562978, mae: 106.461882, mean_q: 128.647873, mean_eps: 0.920197
  26767/300000: episode: 277, duration: 0.822s, episode steps: 121, steps per second: 147, episode reward: -154.306, mean reward: -1.275 [-100.000,  5.396], mean action: 1.653 [0.000, 3.000],  loss: 83.425586, mae: 107.756222, mean_q: 131.339307, mean_eps: 0.919882
  26861/300000: episode: 278, duration: 0.605s, episode steps:  94, steps per second: 155, episode reward: -224.385, mean reward: -2.387 [-100.000, 44.544], mean action: 1.489 [0.000, 3.000],  loss: 81.917745, mae: 110.317520, mean_q: 133.319417, mean_eps: 0.919559
  26990/300000: episode: 279, duration: 0.828s, episode steps: 129, steps per second: 156, episode reward: -143.155, mean reward: -1.110 [-100.000,  5.834], mean action: 1.527 [0.000, 3.000],  loss: 62.433065, mae: 108.041920, mean_q: 130.710921, mean_eps: 0.919225
  27101/300000: episode: 280, duration: 0.767s, episode steps: 111, steps per second: 145, episode reward: -129.967, mean reward: -1.171 [-100.000,  5.764], mean action: 1.730 [0.000, 3.000],  loss: 76.475841, mae: 107.350282, mean_q: 129.742451, mean_eps: 0.918865
  27179/300000: episode: 281, duration: 0.495s, episode steps:  78, steps per second: 158, episode reward: -416.530, mean reward: -5.340 [-100.000,  1.095], mean action: 1.769 [0.000, 3.000],  loss: 78.546878, mae: 108.262400, mean_q: 130.680817, mean_eps: 0.918581
  27304/300000: episode: 282, duration: 0.789s, episode steps: 125, steps per second: 158, episode reward: -349.472, mean reward: -2.796 [-100.000, 99.145], mean action: 1.552 [0.000, 3.000],  loss: 75.164116, mae: 108.515563, mean_q: 132.547098, mean_eps: 0.918277
  27417/300000: episode: 283, duration: 0.756s, episode steps: 113, steps per second: 149, episode reward: -270.512, mean reward: -2.394 [-100.000, 17.636], mean action: 1.416 [0.000, 3.000],  loss: 74.671884, mae: 110.214954, mean_q: 136.605145, mean_eps: 0.917920
  27501/300000: episode: 284, duration: 0.591s, episode steps:  84, steps per second: 142, episode reward: -345.804, mean reward: -4.117 [-100.000,  5.429], mean action: 1.464 [0.000, 3.000],  loss: 44.967476, mae: 110.542753, mean_q: 136.409867, mean_eps: 0.917624
  27596/300000: episode: 285, duration: 0.711s, episode steps:  95, steps per second: 134, episode reward: -129.473, mean reward: -1.363 [-100.000,  7.165], mean action: 1.579 [0.000, 3.000],  loss: 54.031393, mae: 113.622564, mean_q: 141.069643, mean_eps: 0.917356
  27702/300000: episode: 286, duration: 0.826s, episode steps: 106, steps per second: 128, episode reward: -37.013, mean reward: -0.349 [-100.000, 51.576], mean action: 1.585 [0.000, 3.000],  loss: 85.432303, mae: 110.928962, mean_q: 137.788463, mean_eps: 0.917054
  27818/300000: episode: 287, duration: 0.814s, episode steps: 116, steps per second: 142, episode reward: -162.663, mean reward: -1.402 [-100.000,  5.918], mean action: 1.310 [0.000, 3.000],  loss: 58.189668, mae: 109.546268, mean_q: 137.809648, mean_eps: 0.916722
  27924/300000: episode: 288, duration: 0.725s, episode steps: 106, steps per second: 146, episode reward: -264.873, mean reward: -2.499 [-100.000, 48.232], mean action: 1.387 [0.000, 3.000],  loss: 75.191171, mae: 109.564056, mean_q: 137.781244, mean_eps: 0.916388
  27996/300000: episode: 289, duration: 0.545s, episode steps:  72, steps per second: 132, episode reward: -145.809, mean reward: -2.025 [-100.000, 19.621], mean action: 1.389 [0.000, 3.000],  loss: 60.997346, mae: 111.413926, mean_q: 140.662304, mean_eps: 0.916121
  28088/300000: episode: 290, duration: 0.641s, episode steps:  92, steps per second: 143, episode reward: -213.875, mean reward: -2.325 [-100.000,  7.616], mean action: 1.554 [0.000, 3.000],  loss: 66.520249, mae: 113.047619, mean_q: 142.986029, mean_eps: 0.915875
  28169/300000: episode: 291, duration: 0.531s, episode steps:  81, steps per second: 152, episode reward: -95.376, mean reward: -1.177 [-100.000, 14.175], mean action: 1.506 [0.000, 3.000],  loss: 41.258501, mae: 111.307791, mean_q: 140.883886, mean_eps: 0.915616
  28260/300000: episode: 292, duration: 0.588s, episode steps:  91, steps per second: 155, episode reward: -131.550, mean reward: -1.446 [-100.000, 11.714], mean action: 1.626 [0.000, 3.000],  loss: 65.095855, mae: 109.657263, mean_q: 138.609718, mean_eps: 0.915358
  28363/300000: episode: 293, duration: 0.696s, episode steps: 103, steps per second: 148, episode reward: -151.140, mean reward: -1.467 [-100.000,  6.412], mean action: 1.417 [0.000, 3.000],  loss: 50.553094, mae: 112.703978, mean_q: 142.824937, mean_eps: 0.915067
  28440/300000: episode: 294, duration: 0.489s, episode steps:  77, steps per second: 157, episode reward: -235.814, mean reward: -3.063 [-100.000, 34.586], mean action: 1.532 [0.000, 3.000],  loss: 61.471359, mae: 112.572248, mean_q: 141.865501, mean_eps: 0.914797
  28535/300000: episode: 295, duration: 0.586s, episode steps:  95, steps per second: 162, episode reward: -89.174, mean reward: -0.939 [-100.000,  8.243], mean action: 1.432 [0.000, 3.000],  loss: 67.300092, mae: 112.922054, mean_q: 143.087990, mean_eps: 0.914539
  28623/300000: episode: 296, duration: 0.597s, episode steps:  88, steps per second: 147, episode reward: -100.901, mean reward: -1.147 [-100.000, 13.121], mean action: 1.386 [0.000, 3.000],  loss: 43.013167, mae: 115.409795, mean_q: 146.438536, mean_eps: 0.914264
  28708/300000: episode: 297, duration: 0.548s, episode steps:  85, steps per second: 155, episode reward: -122.037, mean reward: -1.436 [-100.000,  7.865], mean action: 1.506 [0.000, 3.000],  loss: 48.492648, mae: 113.580964, mean_q: 143.429293, mean_eps: 0.914005
  28841/300000: episode: 298, duration: 0.845s, episode steps: 133, steps per second: 157, episode reward: -95.883, mean reward: -0.721 [-100.000,  8.947], mean action: 1.368 [0.000, 3.000],  loss: 63.432084, mae: 112.873442, mean_q: 140.559127, mean_eps: 0.913678
  28953/300000: episode: 299, duration: 0.751s, episode steps: 112, steps per second: 149, episode reward: -97.660, mean reward: -0.872 [-100.000,  6.600], mean action: 1.500 [0.000, 3.000],  loss: 54.956407, mae: 111.851893, mean_q: 138.245951, mean_eps: 0.913310
  29077/300000: episode: 300, duration: 0.813s, episode steps: 124, steps per second: 152, episode reward: -126.821, mean reward: -1.023 [-100.000, 13.474], mean action: 1.556 [0.000, 3.000],  loss: 47.704874, mae: 113.913054, mean_q: 139.465330, mean_eps: 0.912956
  29161/300000: episode: 301, duration: 0.542s, episode steps:  84, steps per second: 155, episode reward: -102.506, mean reward: -1.220 [-100.000,  9.002], mean action: 1.488 [0.000, 3.000],  loss: 77.829950, mae: 114.122707, mean_q: 139.923262, mean_eps: 0.912644
  29231/300000: episode: 302, duration: 0.461s, episode steps:  70, steps per second: 152, episode reward: -95.862, mean reward: -1.369 [-100.000, 12.914], mean action: 1.357 [0.000, 3.000],  loss: 48.340825, mae: 115.377368, mean_q: 141.811801, mean_eps: 0.912413
  29353/300000: episode: 303, duration: 0.814s, episode steps: 122, steps per second: 150, episode reward: -102.901, mean reward: -0.843 [-100.000, 11.833], mean action: 1.516 [0.000, 3.000],  loss: 52.985469, mae: 118.849336, mean_q: 147.418259, mean_eps: 0.912126
  29453/300000: episode: 304, duration: 0.638s, episode steps: 100, steps per second: 157, episode reward: -249.877, mean reward: -2.499 [-100.000, 31.490], mean action: 1.360 [0.000, 3.000],  loss: 62.259177, mae: 120.411399, mean_q: 149.137742, mean_eps: 0.911793
  29568/300000: episode: 305, duration: 0.729s, episode steps: 115, steps per second: 158, episode reward: -288.266, mean reward: -2.507 [-100.000,  8.667], mean action: 1.496 [0.000, 3.000],  loss: 55.199664, mae: 118.682610, mean_q: 145.534453, mean_eps: 0.911470
  29663/300000: episode: 306, duration: 0.675s, episode steps:  95, steps per second: 141, episode reward: -316.085, mean reward: -3.327 [-100.000, 12.523], mean action: 1.411 [0.000, 3.000],  loss: 75.903415, mae: 118.875349, mean_q: 144.780964, mean_eps: 0.911155
  29786/300000: episode: 307, duration: 0.919s, episode steps: 123, steps per second: 134, episode reward: -224.603, mean reward: -1.826 [-100.000,  5.566], mean action: 1.593 [0.000, 3.000],  loss: 42.952527, mae: 123.380339, mean_q: 150.553036, mean_eps: 0.910828
  29856/300000: episode: 308, duration: 0.518s, episode steps:  70, steps per second: 135, episode reward: -195.146, mean reward: -2.788 [-100.000,  5.823], mean action: 1.600 [0.000, 3.000],  loss: 63.368149, mae: 120.172710, mean_q: 146.678465, mean_eps: 0.910538
  29962/300000: episode: 309, duration: 0.733s, episode steps: 106, steps per second: 145, episode reward: -142.721, mean reward: -1.346 [-100.000,  7.113], mean action: 1.679 [0.000, 3.000],  loss: 67.823171, mae: 123.462450, mean_q: 151.596269, mean_eps: 0.910275
  30081/300000: episode: 310, duration: 0.766s, episode steps: 119, steps per second: 155, episode reward: -129.138, mean reward: -1.085 [-100.000,  8.957], mean action: 1.563 [0.000, 3.000],  loss: 60.570497, mae: 122.273377, mean_q: 148.964498, mean_eps: 0.909937
  30177/300000: episode: 311, duration: 0.617s, episode steps:  96, steps per second: 155, episode reward: -188.939, mean reward: -1.968 [-100.000, 10.025], mean action: 1.510 [0.000, 3.000],  loss: 33.560701, mae: 121.517718, mean_q: 149.724353, mean_eps: 0.909614
  30259/300000: episode: 312, duration: 0.610s, episode steps:  82, steps per second: 134, episode reward: -202.562, mean reward: -2.470 [-100.000,  7.656], mean action: 1.439 [0.000, 3.000],  loss: 90.406408, mae: 124.987998, mean_q: 154.589627, mean_eps: 0.909348
  30374/300000: episode: 313, duration: 0.868s, episode steps: 115, steps per second: 133, episode reward: -75.123, mean reward: -0.653 [-100.000, 16.672], mean action: 1.565 [0.000, 3.000],  loss: 63.562850, mae: 126.250195, mean_q: 157.576526, mean_eps: 0.909052
  30477/300000: episode: 314, duration: 0.731s, episode steps: 103, steps per second: 141, episode reward: -248.136, mean reward: -2.409 [-100.000,  1.213], mean action: 1.583 [0.000, 3.000],  loss: 58.065747, mae: 128.522936, mean_q: 161.056803, mean_eps: 0.908725
  30583/300000: episode: 315, duration: 0.818s, episode steps: 106, steps per second: 130, episode reward: -126.839, mean reward: -1.197 [-100.000,  5.755], mean action: 1.575 [0.000, 3.000],  loss: 47.103484, mae: 131.872395, mean_q: 166.309330, mean_eps: 0.908412
  30717/300000: episode: 316, duration: 1.001s, episode steps: 134, steps per second: 134, episode reward: -154.502, mean reward: -1.153 [-100.000,  8.066], mean action: 1.619 [0.000, 3.000],  loss: 56.552557, mae: 129.193461, mean_q: 162.058117, mean_eps: 0.908052
  30787/300000: episode: 317, duration: 0.661s, episode steps:  70, steps per second: 106, episode reward: -144.262, mean reward: -2.061 [-100.000, 14.059], mean action: 1.614 [0.000, 3.000],  loss: 51.550161, mae: 128.998093, mean_q: 160.880900, mean_eps: 0.907746
  30931/300000: episode: 318, duration: 1.320s, episode steps: 144, steps per second: 109, episode reward: -147.972, mean reward: -1.028 [-100.000, 10.309], mean action: 1.632 [0.000, 3.000],  loss: 80.599969, mae: 135.717234, mean_q: 172.111006, mean_eps: 0.907424
  31046/300000: episode: 319, duration: 1.031s, episode steps: 115, steps per second: 112, episode reward: -87.284, mean reward: -0.759 [-100.000,  6.999], mean action: 1.635 [0.000, 3.000],  loss: 61.890611, mae: 137.029590, mean_q: 172.958114, mean_eps: 0.907036
  31132/300000: episode: 320, duration: 0.601s, episode steps:  86, steps per second: 143, episode reward: -138.797, mean reward: -1.614 [-100.000, 25.765], mean action: 1.488 [0.000, 3.000],  loss: 60.137889, mae: 136.828259, mean_q: 172.658236, mean_eps: 0.906734
  31258/300000: episode: 321, duration: 0.814s, episode steps: 126, steps per second: 155, episode reward: -291.325, mean reward: -2.312 [-100.000, 67.069], mean action: 1.492 [0.000, 3.000],  loss: 70.993583, mae: 140.240144, mean_q: 179.793788, mean_eps: 0.906416
  31329/300000: episode: 322, duration: 0.450s, episode steps:  71, steps per second: 158, episode reward: -83.003, mean reward: -1.169 [-100.000, 17.817], mean action: 1.620 [0.000, 3.000],  loss: 49.528118, mae: 143.251704, mean_q: 184.458105, mean_eps: 0.906121
  31409/300000: episode: 323, duration: 0.551s, episode steps:  80, steps per second: 145, episode reward: -287.964, mean reward: -3.600 [-100.000, 60.381], mean action: 1.250 [0.000, 3.000],  loss: 70.981636, mae: 144.906843, mean_q: 187.683878, mean_eps: 0.905894
  31495/300000: episode: 324, duration: 0.558s, episode steps:  86, steps per second: 154, episode reward: -164.871, mean reward: -1.917 [-100.000,  5.613], mean action: 1.663 [0.000, 3.000],  loss: 68.929088, mae: 143.636361, mean_q: 184.154596, mean_eps: 0.905645
  31561/300000: episode: 325, duration: 0.482s, episode steps:  66, steps per second: 137, episode reward: -54.310, mean reward: -0.823 [-100.000, 16.936], mean action: 1.470 [0.000, 3.000],  loss: 71.467713, mae: 147.245476, mean_q: 187.997163, mean_eps: 0.905418
  31622/300000: episode: 326, duration: 0.406s, episode steps:  61, steps per second: 150, episode reward: -198.049, mean reward: -3.247 [-100.000,  4.804], mean action: 1.443 [0.000, 3.000],  loss: 50.757722, mae: 143.727066, mean_q: 183.800619, mean_eps: 0.905227
  31682/300000: episode: 327, duration: 0.473s, episode steps:  60, steps per second: 127, episode reward: -78.892, mean reward: -1.315 [-100.000,  6.816], mean action: 1.333 [0.000, 3.000],  loss: 39.306472, mae: 143.839129, mean_q: 183.461507, mean_eps: 0.905046
  31753/300000: episode: 328, duration: 0.530s, episode steps:  71, steps per second: 134, episode reward: -76.985, mean reward: -1.084 [-100.000, 13.799], mean action: 1.521 [0.000, 3.000],  loss: 54.690065, mae: 147.037644, mean_q: 190.586764, mean_eps: 0.904849
  31852/300000: episode: 329, duration: 0.717s, episode steps:  99, steps per second: 138, episode reward: -120.867, mean reward: -1.221 [-100.000,  8.313], mean action: 1.535 [0.000, 3.000],  loss: 88.491551, mae: 146.712386, mean_q: 187.192087, mean_eps: 0.904594
  31939/300000: episode: 330, duration: 0.610s, episode steps:  87, steps per second: 143, episode reward: -155.020, mean reward: -1.782 [-100.000, 41.724], mean action: 1.494 [0.000, 3.000],  loss: 82.263268, mae: 145.143904, mean_q: 185.594687, mean_eps: 0.904315
  32062/300000: episode: 331, duration: 0.849s, episode steps: 123, steps per second: 145, episode reward: -214.529, mean reward: -1.744 [-100.000,  1.461], mean action: 1.683 [0.000, 3.000],  loss: 67.056085, mae: 150.641381, mean_q: 192.719487, mean_eps: 0.904000
  32186/300000: episode: 332, duration: 0.809s, episode steps: 124, steps per second: 153, episode reward: -200.078, mean reward: -1.614 [-100.000,  5.268], mean action: 1.508 [0.000, 3.000],  loss: 106.660552, mae: 152.601781, mean_q: 195.409366, mean_eps: 0.903630
  32307/300000: episode: 333, duration: 0.802s, episode steps: 121, steps per second: 151, episode reward: -235.615, mean reward: -1.947 [-100.000, 16.291], mean action: 1.471 [0.000, 3.000],  loss: 62.567839, mae: 151.442313, mean_q: 194.358203, mean_eps: 0.903262
  32395/300000: episode: 334, duration: 0.569s, episode steps:  88, steps per second: 155, episode reward: -74.473, mean reward: -0.846 [-100.000,  5.961], mean action: 1.648 [0.000, 3.000],  loss: 53.947496, mae: 153.132453, mean_q: 196.168556, mean_eps: 0.902949
  32537/300000: episode: 335, duration: 0.901s, episode steps: 142, steps per second: 158, episode reward: -71.316, mean reward: -0.502 [-100.000,  8.495], mean action: 1.570 [0.000, 3.000],  loss: 55.318306, mae: 152.506831, mean_q: 194.633872, mean_eps: 0.902604
  32659/300000: episode: 336, duration: 0.894s, episode steps: 122, steps per second: 136, episode reward: -109.660, mean reward: -0.899 [-100.000,  6.613], mean action: 1.566 [0.000, 3.000],  loss: 46.282382, mae: 153.562913, mean_q: 196.960099, mean_eps: 0.902207
  32749/300000: episode: 337, duration: 0.608s, episode steps:  90, steps per second: 148, episode reward: -40.431, mean reward: -0.449 [-100.000, 13.409], mean action: 1.633 [0.000, 3.000],  loss: 44.873361, mae: 155.124815, mean_q: 198.846253, mean_eps: 0.901890
  32826/300000: episode: 338, duration: 0.520s, episode steps:  77, steps per second: 148, episode reward: -104.291, mean reward: -1.354 [-100.000, 10.269], mean action: 1.416 [0.000, 3.000],  loss: 78.982677, mae: 150.542690, mean_q: 190.941671, mean_eps: 0.901639
  32942/300000: episode: 339, duration: 0.766s, episode steps: 116, steps per second: 151, episode reward: -204.384, mean reward: -1.762 [-100.000, 123.587], mean action: 1.759 [0.000, 3.000],  loss: 65.668067, mae: 155.923999, mean_q: 198.359835, mean_eps: 0.901349
  33008/300000: episode: 340, duration: 0.443s, episode steps:  66, steps per second: 149, episode reward: -170.123, mean reward: -2.578 [-100.000, 32.018], mean action: 1.439 [0.000, 3.000],  loss: 88.539974, mae: 156.215811, mean_q: 200.533564, mean_eps: 0.901077
  33098/300000: episode: 341, duration: 0.575s, episode steps:  90, steps per second: 157, episode reward: -404.649, mean reward: -4.496 [-100.000,  4.233], mean action: 1.722 [0.000, 3.000],  loss: 59.052830, mae: 155.022566, mean_q: 198.013461, mean_eps: 0.900843
  33209/300000: episode: 342, duration: 0.694s, episode steps: 111, steps per second: 160, episode reward: -181.843, mean reward: -1.638 [-100.000,  6.910], mean action: 1.468 [0.000, 3.000],  loss: 72.048581, mae: 159.464254, mean_q: 204.440461, mean_eps: 0.900541
  33280/300000: episode: 343, duration: 0.494s, episode steps:  71, steps per second: 144, episode reward: -155.945, mean reward: -2.196 [-100.000,  5.771], mean action: 1.296 [0.000, 3.000],  loss: 44.718170, mae: 158.531730, mean_q: 202.831355, mean_eps: 0.900268
  33433/300000: episode: 344, duration: 1.194s, episode steps: 153, steps per second: 128, episode reward: -79.342, mean reward: -0.519 [-100.000,  7.644], mean action: 1.562 [0.000, 3.000],  loss: 66.445553, mae: 162.695321, mean_q: 207.966119, mean_eps: 0.899932
  33568/300000: episode: 345, duration: 1.023s, episode steps: 135, steps per second: 132, episode reward: -122.196, mean reward: -0.905 [-100.000, 10.940], mean action: 1.667 [0.000, 3.000],  loss: 60.652140, mae: 166.962255, mean_q: 214.802428, mean_eps: 0.899500
  33631/300000: episode: 346, duration: 0.446s, episode steps:  63, steps per second: 141, episode reward: -132.259, mean reward: -2.099 [-100.000, 23.947], mean action: 1.508 [0.000, 3.000],  loss: 55.518383, mae: 169.622557, mean_q: 216.451350, mean_eps: 0.899203
  33735/300000: episode: 347, duration: 0.690s, episode steps: 104, steps per second: 151, episode reward: -265.175, mean reward: -2.550 [-100.000,  0.756], mean action: 1.596 [0.000, 3.000],  loss: 45.123028, mae: 170.469395, mean_q: 220.003562, mean_eps: 0.898953
  33831/300000: episode: 348, duration: 0.635s, episode steps:  96, steps per second: 151, episode reward: -551.149, mean reward: -5.741 [-100.000,  8.810], mean action: 1.677 [0.000, 3.000],  loss: 72.917819, mae: 169.898540, mean_q: 218.722708, mean_eps: 0.898652
  33921/300000: episode: 349, duration: 0.657s, episode steps:  90, steps per second: 137, episode reward: -294.198, mean reward: -3.269 [-100.000, -0.139], mean action: 1.467 [0.000, 3.000],  loss: 58.007968, mae: 167.292795, mean_q: 213.046208, mean_eps: 0.898373
  34023/300000: episode: 350, duration: 0.658s, episode steps: 102, steps per second: 155, episode reward: -311.534, mean reward: -3.054 [-100.000,  1.069], mean action: 1.500 [0.000, 3.000],  loss: 46.587783, mae: 169.896205, mean_q: 215.499347, mean_eps: 0.898086
  34122/300000: episode: 351, duration: 0.614s, episode steps:  99, steps per second: 161, episode reward: -42.235, mean reward: -0.427 [-100.000, 20.215], mean action: 1.495 [0.000, 3.000],  loss: 58.706899, mae: 174.085221, mean_q: 219.459172, mean_eps: 0.897784
  34252/300000: episode: 352, duration: 0.866s, episode steps: 130, steps per second: 150, episode reward: -134.589, mean reward: -1.035 [-100.000, 13.397], mean action: 1.569 [0.000, 3.000],  loss: 47.890677, mae: 170.348890, mean_q: 213.707511, mean_eps: 0.897440
  34319/300000: episode: 353, duration: 0.436s, episode steps:  67, steps per second: 154, episode reward: -27.144, mean reward: -0.405 [-100.000, 14.448], mean action: 1.522 [0.000, 3.000],  loss: 64.100874, mae: 172.511859, mean_q: 217.391894, mean_eps: 0.897145
  34435/300000: episode: 354, duration: 0.748s, episode steps: 116, steps per second: 155, episode reward: -177.623, mean reward: -1.531 [-100.000,  7.241], mean action: 1.560 [0.000, 3.000],  loss: 55.550601, mae: 172.397130, mean_q: 216.301062, mean_eps: 0.896871
  34522/300000: episode: 355, duration: 0.579s, episode steps:  87, steps per second: 150, episode reward: -113.808, mean reward: -1.308 [-100.000,  6.569], mean action: 1.529 [0.000, 3.000],  loss: 39.744099, mae: 175.560798, mean_q: 223.923506, mean_eps: 0.896566
  34624/300000: episode: 356, duration: 0.669s, episode steps: 102, steps per second: 152, episode reward: -39.863, mean reward: -0.391 [-100.000, 17.012], mean action: 1.686 [0.000, 3.000],  loss: 34.927443, mae: 173.598931, mean_q: 218.753148, mean_eps: 0.896282
  34770/300000: episode: 357, duration: 0.918s, episode steps: 146, steps per second: 159, episode reward: -41.685, mean reward: -0.286 [-100.000, 41.974], mean action: 1.733 [0.000, 3.000],  loss: 41.662417, mae: 171.026098, mean_q: 213.662134, mean_eps: 0.895910
  34835/300000: episode: 358, duration: 0.410s, episode steps:  65, steps per second: 158, episode reward: -49.678, mean reward: -0.764 [-100.000, 12.624], mean action: 1.446 [0.000, 3.000],  loss: 41.198074, mae: 174.438079, mean_q: 220.003687, mean_eps: 0.895594
  34910/300000: episode: 359, duration: 0.556s, episode steps:  75, steps per second: 135, episode reward: -79.046, mean reward: -1.054 [-100.000, 18.138], mean action: 1.520 [0.000, 3.000],  loss: 48.301672, mae: 176.007666, mean_q: 222.082656, mean_eps: 0.895384
  34983/300000: episode: 360, duration: 0.468s, episode steps:  73, steps per second: 156, episode reward: -69.077, mean reward: -0.946 [-100.000, 19.652], mean action: 1.493 [0.000, 3.000],  loss: 41.963016, mae: 177.778055, mean_q: 225.015546, mean_eps: 0.895162
  35095/300000: episode: 361, duration: 0.706s, episode steps: 112, steps per second: 159, episode reward: -74.663, mean reward: -0.667 [-100.000,  9.450], mean action: 1.500 [0.000, 3.000],  loss: 36.293992, mae: 177.485142, mean_q: 225.739982, mean_eps: 0.894885
  35204/300000: episode: 362, duration: 0.732s, episode steps: 109, steps per second: 149, episode reward: -101.807, mean reward: -0.934 [-100.000, 10.540], mean action: 1.477 [0.000, 3.000],  loss: 37.601900, mae: 178.432568, mean_q: 226.802938, mean_eps: 0.894553
  35284/300000: episode: 363, duration: 0.520s, episode steps:  80, steps per second: 154, episode reward: -83.962, mean reward: -1.050 [-100.000, 33.477], mean action: 1.538 [0.000, 3.000],  loss: 56.146213, mae: 180.316936, mean_q: 228.803360, mean_eps: 0.894269
  35392/300000: episode: 364, duration: 0.690s, episode steps: 108, steps per second: 157, episode reward: -125.020, mean reward: -1.158 [-100.000, 13.868], mean action: 1.602 [0.000, 3.000],  loss: 44.205573, mae: 182.676153, mean_q: 232.335171, mean_eps: 0.893987
  35470/300000: episode: 365, duration: 0.504s, episode steps:  78, steps per second: 155, episode reward: -110.509, mean reward: -1.417 [-100.000, 12.174], mean action: 1.295 [0.000, 3.000],  loss: 53.457393, mae: 177.834972, mean_q: 224.172067, mean_eps: 0.893708
  35568/300000: episode: 366, duration: 0.665s, episode steps:  98, steps per second: 147, episode reward: -197.348, mean reward: -2.014 [-100.000, 19.006], mean action: 1.316 [0.000, 3.000],  loss: 40.970570, mae: 183.016415, mean_q: 233.222317, mean_eps: 0.893445
  35657/300000: episode: 367, duration: 0.576s, episode steps:  89, steps per second: 155, episode reward: -155.638, mean reward: -1.749 [-100.000, 16.584], mean action: 1.573 [0.000, 3.000],  loss: 40.192282, mae: 186.758932, mean_q: 239.323958, mean_eps: 0.893164
  35729/300000: episode: 368, duration: 0.463s, episode steps:  72, steps per second: 156, episode reward: -84.006, mean reward: -1.167 [-100.000, 13.636], mean action: 1.444 [0.000, 3.000],  loss: 37.625807, mae: 185.580050, mean_q: 237.417841, mean_eps: 0.892922
  35802/300000: episode: 369, duration: 0.471s, episode steps:  73, steps per second: 155, episode reward: -102.701, mean reward: -1.407 [-100.000, 18.038], mean action: 1.411 [0.000, 3.000],  loss: 37.053348, mae: 183.079709, mean_q: 231.212088, mean_eps: 0.892705
  35897/300000: episode: 370, duration: 0.637s, episode steps:  95, steps per second: 149, episode reward: -105.143, mean reward: -1.107 [-100.000, 12.075], mean action: 1.368 [0.000, 3.000],  loss: 47.384920, mae: 180.022859, mean_q: 227.532895, mean_eps: 0.892453
  35999/300000: episode: 371, duration: 0.656s, episode steps: 102, steps per second: 155, episode reward: -110.144, mean reward: -1.080 [-100.000, 15.634], mean action: 1.363 [0.000, 3.000],  loss: 50.625017, mae: 182.316920, mean_q: 231.421438, mean_eps: 0.892157
  36091/300000: episode: 372, duration: 0.576s, episode steps:  92, steps per second: 160, episode reward: -199.051, mean reward: -2.164 [-100.000, 15.419], mean action: 1.641 [0.000, 3.000],  loss: 38.867981, mae: 177.352430, mean_q: 223.765175, mean_eps: 0.891866
  36176/300000: episode: 373, duration: 0.555s, episode steps:  85, steps per second: 153, episode reward: -98.866, mean reward: -1.163 [-100.000, 14.893], mean action: 1.459 [0.000, 3.000],  loss: 44.720570, mae: 178.293306, mean_q: 225.444643, mean_eps: 0.891601
  36292/300000: episode: 374, duration: 0.773s, episode steps: 116, steps per second: 150, episode reward: -27.345, mean reward: -0.236 [-100.000, 48.269], mean action: 1.509 [0.000, 3.000],  loss: 40.272601, mae: 180.823590, mean_q: 229.197498, mean_eps: 0.891299
  36389/300000: episode: 375, duration: 0.610s, episode steps:  97, steps per second: 159, episode reward: -192.962, mean reward: -1.989 [-100.000,  6.898], mean action: 1.320 [0.000, 3.000],  loss: 32.877807, mae: 180.158361, mean_q: 228.752457, mean_eps: 0.890980
  36477/300000: episode: 376, duration: 0.556s, episode steps:  88, steps per second: 158, episode reward: -77.557, mean reward: -0.881 [-100.000,  7.771], mean action: 1.591 [0.000, 3.000],  loss: 60.322339, mae: 184.356861, mean_q: 236.489167, mean_eps: 0.890703
  36610/300000: episode: 377, duration: 0.888s, episode steps: 133, steps per second: 150, episode reward: -86.240, mean reward: -0.648 [-100.000,  7.620], mean action: 1.504 [0.000, 3.000],  loss: 42.549397, mae: 183.154353, mean_q: 235.114701, mean_eps: 0.890371
  36695/300000: episode: 378, duration: 0.549s, episode steps:  85, steps per second: 155, episode reward: -105.915, mean reward: -1.246 [-100.000,  8.117], mean action: 1.529 [0.000, 3.000],  loss: 35.766204, mae: 184.463079, mean_q: 237.127233, mean_eps: 0.890044
  36786/300000: episode: 379, duration: 0.581s, episode steps:  91, steps per second: 157, episode reward: -130.895, mean reward: -1.438 [-100.000,  7.504], mean action: 1.560 [0.000, 3.000],  loss: 52.495366, mae: 189.012855, mean_q: 242.597999, mean_eps: 0.889780
  36871/300000: episode: 380, duration: 0.579s, episode steps:  85, steps per second: 147, episode reward: -337.722, mean reward: -3.973 [-100.000,  0.298], mean action: 1.412 [0.000, 3.000],  loss: 35.507390, mae: 182.368711, mean_q: 232.268738, mean_eps: 0.889516
  36973/300000: episode: 381, duration: 0.661s, episode steps: 102, steps per second: 154, episode reward: -97.690, mean reward: -0.958 [-100.000,  7.614], mean action: 1.490 [0.000, 3.000],  loss: 30.602698, mae: 189.079277, mean_q: 242.934332, mean_eps: 0.889235
  37086/300000: episode: 382, duration: 0.751s, episode steps: 113, steps per second: 151, episode reward: -221.351, mean reward: -1.959 [-100.000,  1.303], mean action: 1.442 [0.000, 3.000],  loss: 38.662084, mae: 189.949476, mean_q: 244.140450, mean_eps: 0.888913
  37204/300000: episode: 383, duration: 0.927s, episode steps: 118, steps per second: 127, episode reward: -139.154, mean reward: -1.179 [-100.000, 19.238], mean action: 1.441 [0.000, 3.000],  loss: 33.253812, mae: 185.579152, mean_q: 238.239391, mean_eps: 0.888567
  37326/300000: episode: 384, duration: 0.886s, episode steps: 122, steps per second: 138, episode reward: -97.729, mean reward: -0.801 [-100.000,  7.813], mean action: 1.541 [0.000, 3.000],  loss: 29.072404, mae: 185.087759, mean_q: 235.884965, mean_eps: 0.888207
  37465/300000: episode: 385, duration: 1.008s, episode steps: 139, steps per second: 138, episode reward: -148.548, mean reward: -1.069 [-100.000, 15.776], mean action: 1.698 [0.000, 3.000],  loss: 31.072285, mae: 189.296356, mean_q: 242.505785, mean_eps: 0.887815
  37568/300000: episode: 386, duration: 0.738s, episode steps: 103, steps per second: 140, episode reward: -175.430, mean reward: -1.703 [-100.000,  2.567], mean action: 1.534 [0.000, 3.000],  loss: 39.852391, mae: 188.346227, mean_q: 241.153970, mean_eps: 0.887452
  37635/300000: episode: 387, duration: 0.470s, episode steps:  67, steps per second: 142, episode reward: -93.152, mean reward: -1.390 [-100.000, 16.210], mean action: 1.507 [0.000, 3.000],  loss: 33.166315, mae: 189.246661, mean_q: 242.715431, mean_eps: 0.887197
  37716/300000: episode: 388, duration: 0.548s, episode steps:  81, steps per second: 148, episode reward: -110.314, mean reward: -1.362 [-100.000,  8.005], mean action: 1.543 [0.000, 3.000],  loss: 39.919074, mae: 191.123101, mean_q: 245.427772, mean_eps: 0.886975
  37866/300000: episode: 389, duration: 1.026s, episode steps: 150, steps per second: 146, episode reward: -169.428, mean reward: -1.130 [-100.000,  6.754], mean action: 1.673 [0.000, 3.000],  loss: 48.988404, mae: 191.128881, mean_q: 244.104791, mean_eps: 0.886628
  37960/300000: episode: 390, duration: 0.595s, episode steps:  94, steps per second: 158, episode reward: -92.065, mean reward: -0.979 [-100.000, 12.337], mean action: 1.489 [0.000, 3.000],  loss: 29.115375, mae: 187.792348, mean_q: 238.553224, mean_eps: 0.886263
  38060/300000: episode: 391, duration: 0.636s, episode steps: 100, steps per second: 157, episode reward: -175.997, mean reward: -1.760 [-100.000, 76.903], mean action: 1.490 [0.000, 3.000],  loss: 40.790812, mae: 193.208310, mean_q: 247.604005, mean_eps: 0.885972
  38167/300000: episode: 392, duration: 0.718s, episode steps: 107, steps per second: 149, episode reward: -80.845, mean reward: -0.756 [-100.000, 13.390], mean action: 1.570 [0.000, 3.000],  loss: 29.605521, mae: 187.873514, mean_q: 239.503216, mean_eps: 0.885661
  38255/300000: episode: 393, duration: 0.567s, episode steps:  88, steps per second: 155, episode reward: -106.648, mean reward: -1.212 [-100.000, 12.688], mean action: 1.523 [0.000, 3.000],  loss: 28.825038, mae: 189.269475, mean_q: 241.115969, mean_eps: 0.885369
  38328/300000: episode: 394, duration: 0.457s, episode steps:  73, steps per second: 160, episode reward: -69.085, mean reward: -0.946 [-100.000,  7.994], mean action: 1.479 [0.000, 3.000],  loss: 26.913321, mae: 192.708033, mean_q: 248.686724, mean_eps: 0.885127
  38385/300000: episode: 395, duration: 0.366s, episode steps:  57, steps per second: 156, episode reward: -81.756, mean reward: -1.434 [-100.000, 16.119], mean action: 1.614 [0.000, 3.000],  loss: 37.298481, mae: 192.254625, mean_q: 246.859328, mean_eps: 0.884932
  38486/300000: episode: 396, duration: 0.682s, episode steps: 101, steps per second: 148, episode reward: -208.515, mean reward: -2.065 [-100.000,  8.565], mean action: 1.416 [0.000, 3.000],  loss: 32.086912, mae: 192.639404, mean_q: 246.025236, mean_eps: 0.884695
  38598/300000: episode: 397, duration: 0.734s, episode steps: 112, steps per second: 153, episode reward: -148.587, mean reward: -1.327 [-100.000, 35.463], mean action: 1.554 [0.000, 3.000],  loss: 34.503560, mae: 190.661740, mean_q: 242.824350, mean_eps: 0.884375
  38702/300000: episode: 398, duration: 0.655s, episode steps: 104, steps per second: 159, episode reward: -150.739, mean reward: -1.449 [-100.000,  5.608], mean action: 1.558 [0.000, 3.000],  loss: 28.834231, mae: 193.691166, mean_q: 247.668861, mean_eps: 0.884051
  38788/300000: episode: 399, duration: 0.576s, episode steps:  86, steps per second: 149, episode reward: -85.662, mean reward: -0.996 [-100.000, 11.755], mean action: 1.616 [0.000, 3.000],  loss: 24.059628, mae: 191.983702, mean_q: 244.134240, mean_eps: 0.883766
  38879/300000: episode: 400, duration: 0.598s, episode steps:  91, steps per second: 152, episode reward: -106.208, mean reward: -1.167 [-100.000, 14.786], mean action: 1.396 [0.000, 3.000],  loss: 27.118972, mae: 191.301854, mean_q: 243.590478, mean_eps: 0.883501
  38985/300000: episode: 401, duration: 0.686s, episode steps: 106, steps per second: 154, episode reward: -159.122, mean reward: -1.501 [-100.000, 15.227], mean action: 1.311 [0.000, 3.000],  loss: 38.838139, mae: 189.109971, mean_q: 239.911732, mean_eps: 0.883205
  39123/300000: episode: 402, duration: 0.905s, episode steps: 138, steps per second: 152, episode reward: -87.944, mean reward: -0.637 [-100.000, 18.478], mean action: 1.616 [0.000, 3.000],  loss: 41.109513, mae: 191.167080, mean_q: 244.326802, mean_eps: 0.882839
  39217/300000: episode: 403, duration: 0.623s, episode steps:  94, steps per second: 151, episode reward: -277.574, mean reward: -2.953 [-100.000,  9.384], mean action: 1.628 [0.000, 3.000],  loss: 27.625069, mae: 192.651301, mean_q: 244.545783, mean_eps: 0.882491
  39330/300000: episode: 404, duration: 0.713s, episode steps: 113, steps per second: 159, episode reward: -129.429, mean reward: -1.145 [-100.000, 12.505], mean action: 1.398 [0.000, 3.000],  loss: 34.509210, mae: 189.807815, mean_q: 242.029100, mean_eps: 0.882181
  39401/300000: episode: 405, duration: 0.451s, episode steps:  71, steps per second: 157, episode reward: -104.238, mean reward: -1.468 [-100.000, 11.535], mean action: 1.437 [0.000, 3.000],  loss: 41.782488, mae: 193.256866, mean_q: 246.886019, mean_eps: 0.881905
  39472/300000: episode: 406, duration: 0.498s, episode steps:  71, steps per second: 143, episode reward: -79.353, mean reward: -1.118 [-100.000,  6.277], mean action: 1.648 [0.000, 3.000],  loss: 30.005693, mae: 197.063247, mean_q: 251.706191, mean_eps: 0.881692
  39572/300000: episode: 407, duration: 0.644s, episode steps: 100, steps per second: 155, episode reward: -241.775, mean reward: -2.418 [-100.000,  8.496], mean action: 1.610 [0.000, 3.000],  loss: 28.603397, mae: 197.985579, mean_q: 252.561874, mean_eps: 0.881436
  39683/300000: episode: 408, duration: 0.695s, episode steps: 111, steps per second: 160, episode reward: -137.509, mean reward: -1.239 [-100.000,  3.568], mean action: 1.514 [0.000, 3.000],  loss: 32.403216, mae: 197.199671, mean_q: 249.918464, mean_eps: 0.881119
  39774/300000: episode: 409, duration: 0.606s, episode steps:  91, steps per second: 150, episode reward: -118.260, mean reward: -1.300 [-100.000, 16.270], mean action: 1.670 [0.000, 3.000],  loss: 37.623636, mae: 193.912618, mean_q: 245.528364, mean_eps: 0.880816
  39882/300000: episode: 410, duration: 0.711s, episode steps: 108, steps per second: 152, episode reward: -90.289, mean reward: -0.836 [-100.000, 11.292], mean action: 1.519 [0.000, 3.000],  loss: 39.924794, mae: 197.529815, mean_q: 251.660519, mean_eps: 0.880517
  39965/300000: episode: 411, duration: 0.522s, episode steps:  83, steps per second: 159, episode reward: -256.629, mean reward: -3.092 [-100.000,  3.966], mean action: 1.554 [0.000, 3.000],  loss: 32.905947, mae: 194.766149, mean_q: 246.625609, mean_eps: 0.880231
  40070/300000: episode: 412, duration: 0.661s, episode steps: 105, steps per second: 159, episode reward: -122.627, mean reward: -1.168 [-100.000, 20.016], mean action: 1.467 [0.000, 3.000],  loss: 30.037510, mae: 195.489362, mean_q: 246.277835, mean_eps: 0.879949
  40183/300000: episode: 413, duration: 0.754s, episode steps: 113, steps per second: 150, episode reward: -149.230, mean reward: -1.321 [-100.000,  7.070], mean action: 1.487 [0.000, 3.000],  loss: 26.178138, mae: 197.903337, mean_q: 251.797846, mean_eps: 0.879622
  40315/300000: episode: 414, duration: 0.836s, episode steps: 132, steps per second: 158, episode reward: -131.326, mean reward: -0.995 [-100.000,  3.881], mean action: 1.674 [0.000, 3.000],  loss: 30.915664, mae: 196.603389, mean_q: 249.111474, mean_eps: 0.879255
  40403/300000: episode: 415, duration: 0.568s, episode steps:  88, steps per second: 155, episode reward: -164.141, mean reward: -1.865 [-100.000, 18.661], mean action: 1.659 [0.000, 3.000],  loss: 35.296980, mae: 195.370794, mean_q: 247.214570, mean_eps: 0.878925
  40545/300000: episode: 416, duration: 0.950s, episode steps: 142, steps per second: 150, episode reward: -214.831, mean reward: -1.513 [-100.000,  5.404], mean action: 1.479 [0.000, 3.000],  loss: 32.962509, mae: 198.955635, mean_q: 254.860602, mean_eps: 0.878580
  40625/300000: episode: 417, duration: 0.501s, episode steps:  80, steps per second: 160, episode reward: -54.937, mean reward: -0.687 [-100.000, 10.882], mean action: 1.613 [0.000, 3.000],  loss: 31.712294, mae: 196.794937, mean_q: 253.128037, mean_eps: 0.878246
  40718/300000: episode: 418, duration: 0.597s, episode steps:  93, steps per second: 156, episode reward: -155.857, mean reward: -1.676 [-100.000,  6.998], mean action: 1.419 [0.000, 3.000],  loss: 41.315946, mae: 198.008931, mean_q: 254.107707, mean_eps: 0.877987
  40823/300000: episode: 419, duration: 0.707s, episode steps: 105, steps per second: 149, episode reward: -205.056, mean reward: -1.953 [-100.000,  9.707], mean action: 1.543 [0.000, 3.000],  loss: 43.197943, mae: 194.732426, mean_q: 247.845774, mean_eps: 0.877690
  40935/300000: episode: 420, duration: 0.719s, episode steps: 112, steps per second: 156, episode reward: -249.284, mean reward: -2.226 [-100.000,  0.936], mean action: 1.705 [0.000, 3.000],  loss: 28.918294, mae: 196.877985, mean_q: 252.040262, mean_eps: 0.877364
  41040/300000: episode: 421, duration: 0.658s, episode steps: 105, steps per second: 160, episode reward: -77.013, mean reward: -0.733 [-100.000, 11.311], mean action: 1.629 [0.000, 3.000],  loss: 38.286713, mae: 195.851134, mean_q: 249.169414, mean_eps: 0.877039
  41110/300000: episode: 422, duration: 0.460s, episode steps:  70, steps per second: 152, episode reward: -83.441, mean reward: -1.192 [-100.000, 11.064], mean action: 1.771 [0.000, 3.000],  loss: 32.856157, mae: 197.417924, mean_q: 253.124667, mean_eps: 0.876777
  41221/300000: episode: 423, duration: 0.722s, episode steps: 111, steps per second: 154, episode reward: -81.075, mean reward: -0.730 [-100.000, 11.250], mean action: 1.550 [0.000, 3.000],  loss: 23.837706, mae: 194.155966, mean_q: 248.003570, mean_eps: 0.876505
  41302/300000: episode: 424, duration: 0.525s, episode steps:  81, steps per second: 154, episode reward: -366.624, mean reward: -4.526 [-100.000,  3.676], mean action: 1.494 [0.000, 3.000],  loss: 38.166143, mae: 195.450617, mean_q: 249.659384, mean_eps: 0.876217
  41412/300000: episode: 425, duration: 0.691s, episode steps: 110, steps per second: 159, episode reward: -258.637, mean reward: -2.351 [-100.000,  1.193], mean action: 1.545 [0.000, 3.000],  loss: 21.883696, mae: 194.849603, mean_q: 248.416148, mean_eps: 0.875930
  41511/300000: episode: 426, duration: 0.688s, episode steps:  99, steps per second: 144, episode reward: -50.053, mean reward: -0.506 [-100.000, 57.967], mean action: 1.515 [0.000, 3.000],  loss: 22.334102, mae: 192.602278, mean_q: 246.548968, mean_eps: 0.875617
  41598/300000: episode: 427, duration: 0.553s, episode steps:  87, steps per second: 157, episode reward: -124.830, mean reward: -1.435 [-100.000, 11.317], mean action: 1.402 [0.000, 3.000],  loss: 27.413581, mae: 195.466850, mean_q: 249.631890, mean_eps: 0.875338
  41721/300000: episode: 428, duration: 0.772s, episode steps: 123, steps per second: 159, episode reward: -128.250, mean reward: -1.043 [-100.000,  6.306], mean action: 1.398 [0.000, 3.000],  loss: 22.279660, mae: 194.047957, mean_q: 247.870496, mean_eps: 0.875023
  41794/300000: episode: 429, duration: 0.496s, episode steps:  73, steps per second: 147, episode reward: -104.089, mean reward: -1.426 [-100.000, 12.390], mean action: 1.548 [0.000, 3.000],  loss: 36.947597, mae: 192.551530, mean_q: 245.629768, mean_eps: 0.874729
  41864/300000: episode: 430, duration: 0.452s, episode steps:  70, steps per second: 155, episode reward: -88.421, mean reward: -1.263 [-100.000,  7.655], mean action: 1.557 [0.000, 3.000],  loss: 30.840723, mae: 192.393538, mean_q: 244.159035, mean_eps: 0.874515
  41938/300000: episode: 431, duration: 0.473s, episode steps:  74, steps per second: 156, episode reward: -111.353, mean reward: -1.505 [-100.000,  8.285], mean action: 1.459 [0.000, 3.000],  loss: 31.542696, mae: 192.814330, mean_q: 243.666935, mean_eps: 0.874298
  42041/300000: episode: 432, duration: 0.643s, episode steps: 103, steps per second: 160, episode reward: -75.419, mean reward: -0.732 [-100.000, 15.867], mean action: 1.544 [0.000, 3.000],  loss: 29.380805, mae: 198.494649, mean_q: 252.231677, mean_eps: 0.874033
  42145/300000: episode: 433, duration: 0.702s, episode steps: 104, steps per second: 148, episode reward: -48.767, mean reward: -0.469 [-100.000, 68.946], mean action: 1.394 [0.000, 3.000],  loss: 27.970734, mae: 190.929387, mean_q: 244.314818, mean_eps: 0.873723
  42253/300000: episode: 434, duration: 0.690s, episode steps: 108, steps per second: 157, episode reward: -186.023, mean reward: -1.722 [-100.000, 13.467], mean action: 1.657 [0.000, 3.000],  loss: 35.689986, mae: 192.035159, mean_q: 244.858869, mean_eps: 0.873405
  42349/300000: episode: 435, duration: 0.607s, episode steps:  96, steps per second: 158, episode reward: -95.991, mean reward: -1.000 [-100.000, 12.539], mean action: 1.438 [0.000, 3.000],  loss: 28.680329, mae: 192.600317, mean_q: 244.987363, mean_eps: 0.873098
  42410/300000: episode: 436, duration: 0.388s, episode steps:  61, steps per second: 157, episode reward: -96.991, mean reward: -1.590 [-100.000, 16.599], mean action: 1.475 [0.000, 3.000],  loss: 27.457847, mae: 191.317197, mean_q: 245.903576, mean_eps: 0.872863
  42495/300000: episode: 437, duration: 0.589s, episode steps:  85, steps per second: 144, episode reward: -124.113, mean reward: -1.460 [-100.000,  8.643], mean action: 1.565 [0.000, 3.000],  loss: 33.315819, mae: 190.209843, mean_q: 241.668335, mean_eps: 0.872644
  42559/300000: episode: 438, duration: 0.409s, episode steps:  64, steps per second: 157, episode reward: -132.591, mean reward: -2.072 [-100.000, 11.081], mean action: 1.422 [0.000, 3.000],  loss: 28.093956, mae: 188.070508, mean_q: 240.905622, mean_eps: 0.872421
  42640/300000: episode: 439, duration: 0.504s, episode steps:  81, steps per second: 161, episode reward: -128.969, mean reward: -1.592 [-100.000,  7.474], mean action: 1.346 [0.000, 3.000],  loss: 24.246323, mae: 191.623034, mean_q: 247.697327, mean_eps: 0.872203
  42716/300000: episode: 440, duration: 0.484s, episode steps:  76, steps per second: 157, episode reward: -142.707, mean reward: -1.878 [-100.000, 10.537], mean action: 1.408 [0.000, 3.000],  loss: 49.182401, mae: 190.778063, mean_q: 245.685566, mean_eps: 0.871968
  42840/300000: episode: 441, duration: 0.823s, episode steps: 124, steps per second: 151, episode reward: -281.001, mean reward: -2.266 [-100.000, 66.142], mean action: 1.492 [0.000, 3.000],  loss: 30.578444, mae: 192.224776, mean_q: 247.275845, mean_eps: 0.871668
  42976/300000: episode: 442, duration: 0.854s, episode steps: 136, steps per second: 159, episode reward: -269.577, mean reward: -1.982 [-100.000, 106.066], mean action: 1.596 [0.000, 3.000],  loss: 43.540397, mae: 188.632120, mean_q: 242.555888, mean_eps: 0.871278
  43051/300000: episode: 443, duration: 0.470s, episode steps:  75, steps per second: 160, episode reward: -59.273, mean reward: -0.790 [-100.000,  6.112], mean action: 1.640 [0.000, 3.000],  loss: 31.188575, mae: 190.633552, mean_q: 246.056583, mean_eps: 0.870961
  43163/300000: episode: 444, duration: 0.771s, episode steps: 112, steps per second: 145, episode reward: -83.725, mean reward: -0.748 [-100.000, 11.813], mean action: 1.554 [0.000, 3.000],  loss: 23.981856, mae: 188.162685, mean_q: 241.095558, mean_eps: 0.870680
  43272/300000: episode: 445, duration: 0.693s, episode steps: 109, steps per second: 157, episode reward: -145.632, mean reward: -1.336 [-100.000,  9.567], mean action: 1.826 [0.000, 3.000],  loss: 30.898364, mae: 189.257247, mean_q: 241.840025, mean_eps: 0.870349
  43345/300000: episode: 446, duration: 0.462s, episode steps:  73, steps per second: 158, episode reward: -120.456, mean reward: -1.650 [-100.000,  6.762], mean action: 1.521 [0.000, 3.000],  loss: 35.785161, mae: 188.346975, mean_q: 241.663693, mean_eps: 0.870076
  43462/300000: episode: 447, duration: 0.857s, episode steps: 117, steps per second: 137, episode reward: -101.683, mean reward: -0.869 [-100.000, 13.227], mean action: 1.521 [0.000, 3.000],  loss: 42.677946, mae: 186.021749, mean_q: 238.344544, mean_eps: 0.869791
  43581/300000: episode: 448, duration: 0.841s, episode steps: 119, steps per second: 141, episode reward: -203.395, mean reward: -1.709 [-100.000, 72.681], mean action: 1.504 [0.000, 3.000],  loss: 31.449352, mae: 188.965296, mean_q: 242.513467, mean_eps: 0.869437
  43677/300000: episode: 449, duration: 0.670s, episode steps:  96, steps per second: 143, episode reward: -29.852, mean reward: -0.311 [-100.000, 90.295], mean action: 1.521 [0.000, 3.000],  loss: 37.555201, mae: 189.407416, mean_q: 244.128426, mean_eps: 0.869114
  43761/300000: episode: 450, duration: 0.615s, episode steps:  84, steps per second: 137, episode reward: -96.516, mean reward: -1.149 [-100.000,  9.426], mean action: 1.571 [0.000, 3.000],  loss: 44.839912, mae: 188.305598, mean_q: 239.167365, mean_eps: 0.868844
  43876/300000: episode: 451, duration: 0.832s, episode steps: 115, steps per second: 138, episode reward: -177.827, mean reward: -1.546 [-100.000,  4.142], mean action: 1.496 [0.000, 3.000],  loss: 40.707958, mae: 184.341753, mean_q: 235.256516, mean_eps: 0.868546
  43959/300000: episode: 452, duration: 0.572s, episode steps:  83, steps per second: 145, episode reward: -103.163, mean reward: -1.243 [-100.000, 17.260], mean action: 1.325 [0.000, 3.000],  loss: 24.678608, mae: 187.975786, mean_q: 239.860777, mean_eps: 0.868249
  44049/300000: episode: 453, duration: 0.613s, episode steps:  90, steps per second: 147, episode reward: -176.567, mean reward: -1.962 [-100.000, 30.408], mean action: 1.467 [0.000, 3.000],  loss: 32.986950, mae: 185.641190, mean_q: 236.493851, mean_eps: 0.867990
  44119/300000: episode: 454, duration: 0.458s, episode steps:  70, steps per second: 153, episode reward: -117.257, mean reward: -1.675 [-100.000, 38.630], mean action: 1.429 [0.000, 3.000],  loss: 39.283562, mae: 182.022891, mean_q: 229.650934, mean_eps: 0.867749
  44235/300000: episode: 455, duration: 0.735s, episode steps: 116, steps per second: 158, episode reward: -81.784, mean reward: -0.705 [-100.000,  7.285], mean action: 1.638 [0.000, 3.000],  loss: 25.389561, mae: 181.053951, mean_q: 229.669064, mean_eps: 0.867470
  44356/300000: episode: 456, duration: 0.761s, episode steps: 121, steps per second: 159, episode reward: -112.444, mean reward: -0.929 [-100.000, 16.837], mean action: 1.455 [0.000, 3.000],  loss: 31.478101, mae: 183.010083, mean_q: 232.740414, mean_eps: 0.867115
  44488/300000: episode: 457, duration: 0.894s, episode steps: 132, steps per second: 148, episode reward: -93.263, mean reward: -0.707 [-100.000, 37.172], mean action: 1.553 [0.000, 3.000],  loss: 34.245690, mae: 186.270645, mean_q: 237.357160, mean_eps: 0.866735
  44597/300000: episode: 458, duration: 0.696s, episode steps: 109, steps per second: 157, episode reward: -93.961, mean reward: -0.862 [-100.000,  7.150], mean action: 1.495 [0.000, 3.000],  loss: 44.222262, mae: 179.323269, mean_q: 226.645249, mean_eps: 0.866374
  44717/300000: episode: 459, duration: 0.777s, episode steps: 120, steps per second: 154, episode reward: -44.977, mean reward: -0.375 [-100.000, 45.429], mean action: 1.617 [0.000, 3.000],  loss: 42.742026, mae: 179.279743, mean_q: 228.071088, mean_eps: 0.866031
  44874/300000: episode: 460, duration: 1.002s, episode steps: 157, steps per second: 157, episode reward:  7.342, mean reward:  0.047 [-100.000, 110.990], mean action: 1.548 [0.000, 3.000],  loss: 28.904742, mae: 181.813523, mean_q: 230.647067, mean_eps: 0.865615
  44952/300000: episode: 461, duration: 0.490s, episode steps:  78, steps per second: 159, episode reward: -83.144, mean reward: -1.066 [-100.000,  6.321], mean action: 1.538 [0.000, 3.000],  loss: 44.142901, mae: 177.857600, mean_q: 224.136604, mean_eps: 0.865263
  45073/300000: episode: 462, duration: 0.817s, episode steps: 121, steps per second: 148, episode reward: -144.348, mean reward: -1.193 [-100.000,  7.924], mean action: 1.719 [0.000, 3.000],  loss: 59.339187, mae: 177.470492, mean_q: 225.593494, mean_eps: 0.864964
  45213/300000: episode: 463, duration: 0.903s, episode steps: 140, steps per second: 155, episode reward: -78.262, mean reward: -0.559 [-100.000, 13.952], mean action: 1.586 [0.000, 3.000],  loss: 36.541592, mae: 175.657095, mean_q: 222.262539, mean_eps: 0.864572
  45296/300000: episode: 464, duration: 0.512s, episode steps:  83, steps per second: 162, episode reward: -130.583, mean reward: -1.573 [-100.000, 26.174], mean action: 1.325 [0.000, 3.000],  loss: 29.362618, mae: 173.540378, mean_q: 218.611924, mean_eps: 0.864238
  45364/300000: episode: 465, duration: 0.434s, episode steps:  68, steps per second: 157, episode reward: -122.902, mean reward: -1.807 [-100.000,  8.922], mean action: 1.324 [0.000, 3.000],  loss: 32.486460, mae: 171.963323, mean_q: 215.553686, mean_eps: 0.864012
  45429/300000: episode: 466, duration: 0.440s, episode steps:  65, steps per second: 148, episode reward: -53.163, mean reward: -0.818 [-100.000, 17.336], mean action: 1.538 [0.000, 3.000],  loss: 28.364731, mae: 171.495922, mean_q: 217.581210, mean_eps: 0.863812
  45503/300000: episode: 467, duration: 0.486s, episode steps:  74, steps per second: 152, episode reward: -120.054, mean reward: -1.622 [-100.000, 10.415], mean action: 1.514 [0.000, 3.000],  loss: 33.315091, mae: 173.577173, mean_q: 219.900636, mean_eps: 0.863604
  45596/300000: episode: 468, duration: 0.584s, episode steps:  93, steps per second: 159, episode reward: -69.781, mean reward: -0.750 [-100.000, 12.617], mean action: 1.581 [0.000, 3.000],  loss: 35.380661, mae: 173.960512, mean_q: 221.551992, mean_eps: 0.863353
  45671/300000: episode: 469, duration: 0.461s, episode steps:  75, steps per second: 163, episode reward: -106.687, mean reward: -1.422 [-100.000, 19.351], mean action: 1.587 [0.000, 3.000],  loss: 39.856770, mae: 176.324843, mean_q: 222.768852, mean_eps: 0.863101
  45792/300000: episode: 470, duration: 0.810s, episode steps: 121, steps per second: 149, episode reward: -92.677, mean reward: -0.766 [-100.000,  8.391], mean action: 1.529 [0.000, 3.000],  loss: 42.590436, mae: 173.406021, mean_q: 219.913838, mean_eps: 0.862807
  45865/300000: episode: 471, duration: 0.467s, episode steps:  73, steps per second: 156, episode reward: -138.851, mean reward: -1.902 [-100.000,  9.682], mean action: 1.507 [0.000, 3.000],  loss: 45.291911, mae: 171.664740, mean_q: 219.427242, mean_eps: 0.862516
  45935/300000: episode: 472, duration: 0.443s, episode steps:  70, steps per second: 158, episode reward: -79.528, mean reward: -1.136 [-100.000, 10.084], mean action: 1.386 [0.000, 3.000],  loss: 37.085538, mae: 176.148098, mean_q: 224.525180, mean_eps: 0.862301
  46030/300000: episode: 473, duration: 0.605s, episode steps:  95, steps per second: 157, episode reward: -246.857, mean reward: -2.598 [-100.000,  0.860], mean action: 1.705 [0.000, 3.000],  loss: 27.357288, mae: 176.473458, mean_q: 225.648287, mean_eps: 0.862054
  46095/300000: episode: 474, duration: 0.439s, episode steps:  65, steps per second: 148, episode reward: -53.178, mean reward: -0.818 [-100.000,  7.638], mean action: 1.662 [0.000, 3.000],  loss: 25.832513, mae: 176.320253, mean_q: 225.086064, mean_eps: 0.861814
  46180/300000: episode: 475, duration: 0.546s, episode steps:  85, steps per second: 156, episode reward: -130.155, mean reward: -1.531 [-100.000,  9.806], mean action: 1.788 [0.000, 3.000],  loss: 33.979009, mae: 174.825840, mean_q: 223.536759, mean_eps: 0.861589
  46301/300000: episode: 476, duration: 0.881s, episode steps: 121, steps per second: 137, episode reward: -136.051, mean reward: -1.124 [-100.000,  6.924], mean action: 1.760 [0.000, 3.000],  loss: 25.994466, mae: 175.153628, mean_q: 224.668686, mean_eps: 0.861280
  46396/300000: episode: 477, duration: 0.645s, episode steps:  95, steps per second: 147, episode reward: -97.404, mean reward: -1.025 [-100.000,  8.393], mean action: 1.568 [0.000, 3.000],  loss: 34.809154, mae: 172.563744, mean_q: 220.744585, mean_eps: 0.860956
  46480/300000: episode: 478, duration: 0.535s, episode steps:  84, steps per second: 157, episode reward: -215.961, mean reward: -2.571 [-100.000, 19.089], mean action: 1.619 [0.000, 3.000],  loss: 38.626175, mae: 172.993081, mean_q: 221.543915, mean_eps: 0.860688
  46579/300000: episode: 479, duration: 0.621s, episode steps:  99, steps per second: 159, episode reward: -114.353, mean reward: -1.155 [-100.000,  9.116], mean action: 1.626 [0.000, 3.000],  loss: 23.229662, mae: 172.615754, mean_q: 221.593935, mean_eps: 0.860413
  46710/300000: episode: 480, duration: 0.848s, episode steps: 131, steps per second: 155, episode reward: -189.236, mean reward: -1.445 [-100.000,  6.443], mean action: 1.550 [0.000, 3.000],  loss: 31.406076, mae: 173.598455, mean_q: 223.220290, mean_eps: 0.860068
  46835/300000: episode: 481, duration: 0.811s, episode steps: 125, steps per second: 154, episode reward: -63.405, mean reward: -0.507 [-100.000,  7.764], mean action: 1.512 [0.000, 3.000],  loss: 26.432033, mae: 175.315367, mean_q: 226.012871, mean_eps: 0.859684
  46926/300000: episode: 482, duration: 0.612s, episode steps:  91, steps per second: 149, episode reward: 22.280, mean reward:  0.245 [-100.000, 104.106], mean action: 1.769 [0.000, 3.000],  loss: 37.930663, mae: 165.661545, mean_q: 211.113289, mean_eps: 0.859360
  47019/300000: episode: 483, duration: 0.629s, episode steps:  93, steps per second: 148, episode reward: -137.878, mean reward: -1.483 [-100.000,  5.870], mean action: 1.516 [0.000, 3.000],  loss: 36.028105, mae: 166.143885, mean_q: 211.774523, mean_eps: 0.859084
  47167/300000: episode: 484, duration: 1.116s, episode steps: 148, steps per second: 133, episode reward: -105.505, mean reward: -0.713 [-100.000, 30.586], mean action: 1.622 [0.000, 3.000],  loss: 47.570207, mae: 166.216615, mean_q: 212.554696, mean_eps: 0.858723
  47253/300000: episode: 485, duration: 0.646s, episode steps:  86, steps per second: 133, episode reward: -92.372, mean reward: -1.074 [-100.000,  7.997], mean action: 1.547 [0.000, 3.000],  loss: 43.599918, mae: 163.893838, mean_q: 208.836213, mean_eps: 0.858372
  47358/300000: episode: 486, duration: 0.792s, episode steps: 105, steps per second: 133, episode reward: -37.103, mean reward: -0.353 [-100.000, 22.002], mean action: 1.476 [0.000, 3.000],  loss: 32.709020, mae: 165.679042, mean_q: 212.355318, mean_eps: 0.858085
  47478/300000: episode: 487, duration: 0.829s, episode steps: 120, steps per second: 145, episode reward: -130.038, mean reward: -1.084 [-100.000, 15.681], mean action: 1.533 [0.000, 3.000],  loss: 37.481279, mae: 164.819951, mean_q: 210.899348, mean_eps: 0.857747
  47567/300000: episode: 488, duration: 0.613s, episode steps:  89, steps per second: 145, episode reward: -96.162, mean reward: -1.080 [-100.000,  5.903], mean action: 1.820 [0.000, 3.000],  loss: 40.704335, mae: 165.571532, mean_q: 209.839454, mean_eps: 0.857434
  47686/300000: episode: 489, duration: 0.855s, episode steps: 119, steps per second: 139, episode reward: -85.158, mean reward: -0.716 [-100.000, 11.439], mean action: 1.613 [0.000, 3.000],  loss: 45.306018, mae: 164.933897, mean_q: 209.422184, mean_eps: 0.857122
  47746/300000: episode: 490, duration: 0.399s, episode steps:  60, steps per second: 151, episode reward: -78.156, mean reward: -1.303 [-100.000,  5.767], mean action: 1.217 [0.000, 3.000],  loss: 31.464137, mae: 164.534746, mean_q: 208.789820, mean_eps: 0.856854
  47857/300000: episode: 491, duration: 0.692s, episode steps: 111, steps per second: 160, episode reward: -70.923, mean reward: -0.639 [-100.000, 16.871], mean action: 1.405 [0.000, 3.000],  loss: 50.323174, mae: 165.015871, mean_q: 210.043739, mean_eps: 0.856597
  47923/300000: episode: 492, duration: 0.411s, episode steps:  66, steps per second: 161, episode reward: -70.672, mean reward: -1.071 [-100.000, 12.303], mean action: 1.500 [0.000, 3.000],  loss: 60.553062, mae: 161.063541, mean_q: 207.287782, mean_eps: 0.856332
  48009/300000: episode: 493, duration: 0.590s, episode steps:  86, steps per second: 146, episode reward: -99.572, mean reward: -1.158 [-100.000,  7.729], mean action: 1.442 [0.000, 3.000],  loss: 44.360301, mae: 159.812237, mean_q: 204.372845, mean_eps: 0.856103
  48143/300000: episode: 494, duration: 0.839s, episode steps: 134, steps per second: 160, episode reward: -113.400, mean reward: -0.846 [-100.000, 13.010], mean action: 1.537 [0.000, 3.000],  loss: 54.650681, mae: 162.407775, mean_q: 208.924128, mean_eps: 0.855774
  48210/300000: episode: 495, duration: 0.444s, episode steps:  67, steps per second: 151, episode reward: -100.450, mean reward: -1.499 [-100.000,  7.297], mean action: 1.418 [0.000, 3.000],  loss: 30.448102, mae: 164.642671, mean_q: 213.130097, mean_eps: 0.855472
  48320/300000: episode: 496, duration: 0.746s, episode steps: 110, steps per second: 147, episode reward: -114.510, mean reward: -1.041 [-100.000, 13.478], mean action: 1.536 [0.000, 3.000],  loss: 48.653259, mae: 164.084782, mean_q: 210.781156, mean_eps: 0.855206
  48382/300000: episode: 497, duration: 0.405s, episode steps:  62, steps per second: 153, episode reward: -160.325, mean reward: -2.586 [-100.000,  8.271], mean action: 1.419 [0.000, 3.000],  loss: 37.641047, mae: 159.527187, mean_q: 205.207713, mean_eps: 0.854949
  48448/300000: episode: 498, duration: 0.428s, episode steps:  66, steps per second: 154, episode reward: -102.627, mean reward: -1.555 [-100.000,  8.571], mean action: 1.545 [0.000, 3.000],  loss: 31.285646, mae: 163.887828, mean_q: 210.820739, mean_eps: 0.854756
  48562/300000: episode: 499, duration: 0.731s, episode steps: 114, steps per second: 156, episode reward: -112.005, mean reward: -0.982 [-100.000, 10.186], mean action: 1.588 [0.000, 3.000],  loss: 35.306504, mae: 161.536607, mean_q: 207.360519, mean_eps: 0.854486
  48629/300000: episode: 500, duration: 0.449s, episode steps:  67, steps per second: 149, episode reward: -52.160, mean reward: -0.779 [-100.000,  6.807], mean action: 1.582 [0.000, 3.000],  loss: 33.534065, mae: 156.917786, mean_q: 200.880528, mean_eps: 0.854215
  48756/300000: episode: 501, duration: 0.823s, episode steps: 127, steps per second: 154, episode reward: -54.885, mean reward: -0.432 [-100.000, 12.395], mean action: 1.622 [0.000, 3.000],  loss: 31.698444, mae: 159.906386, mean_q: 205.217608, mean_eps: 0.853924
  48882/300000: episode: 502, duration: 0.787s, episode steps: 126, steps per second: 160, episode reward: -45.867, mean reward: -0.364 [-100.000, 12.459], mean action: 1.667 [0.000, 3.000],  loss: 27.796050, mae: 159.141889, mean_q: 204.396893, mean_eps: 0.853544
  48948/300000: episode: 503, duration: 0.456s, episode steps:  66, steps per second: 145, episode reward: -76.533, mean reward: -1.160 [-100.000,  7.375], mean action: 1.379 [0.000, 3.000],  loss: 30.404324, mae: 159.046211, mean_q: 202.998014, mean_eps: 0.853256
  49021/300000: episode: 504, duration: 0.485s, episode steps:  73, steps per second: 150, episode reward: -118.088, mean reward: -1.618 [-100.000,  9.101], mean action: 1.630 [0.000, 3.000],  loss: 37.741155, mae: 153.521874, mean_q: 196.791302, mean_eps: 0.853048
  49124/300000: episode: 505, duration: 0.661s, episode steps: 103, steps per second: 156, episode reward: -148.515, mean reward: -1.442 [-100.000,  5.310], mean action: 1.553 [0.000, 3.000],  loss: 34.989222, mae: 158.183815, mean_q: 202.280925, mean_eps: 0.852784
  49204/300000: episode: 506, duration: 0.502s, episode steps:  80, steps per second: 159, episode reward: -79.530, mean reward: -0.994 [-100.000,  7.707], mean action: 1.475 [0.000, 3.000],  loss: 31.226673, mae: 159.273870, mean_q: 205.512111, mean_eps: 0.852510
  49337/300000: episode: 507, duration: 0.882s, episode steps: 133, steps per second: 151, episode reward: -27.005, mean reward: -0.203 [-100.000, 18.763], mean action: 1.774 [0.000, 3.000],  loss: 49.123528, mae: 157.630775, mean_q: 202.783785, mean_eps: 0.852190
  49416/300000: episode: 508, duration: 0.500s, episode steps:  79, steps per second: 158, episode reward: -60.693, mean reward: -0.768 [-100.000,  8.543], mean action: 1.633 [0.000, 3.000],  loss: 43.752476, mae: 155.064952, mean_q: 199.365060, mean_eps: 0.851872
  49522/300000: episode: 509, duration: 0.665s, episode steps: 106, steps per second: 159, episode reward: -111.938, mean reward: -1.056 [-100.000, 28.323], mean action: 1.500 [0.000, 3.000],  loss: 53.397538, mae: 158.246302, mean_q: 205.790233, mean_eps: 0.851595
  49594/300000: episode: 510, duration: 0.461s, episode steps:  72, steps per second: 156, episode reward: -111.211, mean reward: -1.545 [-100.000,  5.395], mean action: 1.764 [0.000, 3.000],  loss: 42.451268, mae: 152.863590, mean_q: 198.267210, mean_eps: 0.851328
  49709/300000: episode: 511, duration: 0.754s, episode steps: 115, steps per second: 152, episode reward: -154.069, mean reward: -1.340 [-100.000,  5.675], mean action: 1.374 [0.000, 3.000],  loss: 50.614906, mae: 157.696580, mean_q: 205.074372, mean_eps: 0.851047
  49783/300000: episode: 512, duration: 0.476s, episode steps:  74, steps per second: 155, episode reward: -107.977, mean reward: -1.459 [-100.000, 10.014], mean action: 1.486 [0.000, 3.000],  loss: 31.331246, mae: 155.946865, mean_q: 203.795662, mean_eps: 0.850764
  49918/300000: episode: 513, duration: 0.842s, episode steps: 135, steps per second: 160, episode reward: -79.252, mean reward: -0.587 [-100.000, 25.328], mean action: 1.600 [0.000, 3.000],  loss: 49.374931, mae: 155.138665, mean_q: 202.624019, mean_eps: 0.850450
  49998/300000: episode: 514, duration: 0.549s, episode steps:  80, steps per second: 146, episode reward: -73.902, mean reward: -0.924 [-100.000, 10.027], mean action: 1.462 [0.000, 3.000],  loss: 42.506076, mae: 159.016546, mean_q: 208.178923, mean_eps: 0.850127
  50085/300000: episode: 515, duration: 0.563s, episode steps:  87, steps per second: 155, episode reward: -98.498, mean reward: -1.132 [-100.000, 11.297], mean action: 1.586 [0.000, 3.000],  loss: 33.977270, mae: 157.110975, mean_q: 205.033632, mean_eps: 0.849877
  50202/300000: episode: 516, duration: 0.729s, episode steps: 117, steps per second: 160, episode reward: -101.681, mean reward: -0.869 [-100.000, 16.616], mean action: 1.718 [0.000, 3.000],  loss: 49.148246, mae: 159.867345, mean_q: 209.689917, mean_eps: 0.849571
  50278/300000: episode: 517, duration: 0.490s, episode steps:  76, steps per second: 155, episode reward: -68.146, mean reward: -0.897 [-100.000,  6.501], mean action: 1.382 [0.000, 3.000],  loss: 48.928900, mae: 157.129371, mean_q: 205.960129, mean_eps: 0.849282
  50372/300000: episode: 518, duration: 0.631s, episode steps:  94, steps per second: 149, episode reward: -66.859, mean reward: -0.711 [-100.000, 72.700], mean action: 1.713 [0.000, 3.000],  loss: 41.629600, mae: 157.157600, mean_q: 205.536020, mean_eps: 0.849027
  50442/300000: episode: 519, duration: 0.447s, episode steps:  70, steps per second: 157, episode reward: -130.649, mean reward: -1.866 [-100.000, 20.490], mean action: 1.600 [0.000, 3.000],  loss: 49.078952, mae: 155.626137, mean_q: 202.059442, mean_eps: 0.848781
  50548/300000: episode: 520, duration: 0.674s, episode steps: 106, steps per second: 157, episode reward: -81.318, mean reward: -0.767 [-100.000, 12.666], mean action: 1.566 [0.000, 3.000],  loss: 38.851078, mae: 158.761592, mean_q: 207.529698, mean_eps: 0.848516
  50615/300000: episode: 521, duration: 0.440s, episode steps:  67, steps per second: 152, episode reward: -83.184, mean reward: -1.242 [-100.000,  7.472], mean action: 1.463 [0.000, 3.000],  loss: 66.854210, mae: 159.140906, mean_q: 207.983288, mean_eps: 0.848257
  50692/300000: episode: 522, duration: 0.530s, episode steps:  77, steps per second: 145, episode reward: -79.507, mean reward: -1.033 [-100.000,  7.573], mean action: 1.597 [0.000, 3.000],  loss: 58.939112, mae: 154.626786, mean_q: 201.946031, mean_eps: 0.848041
  50810/300000: episode: 523, duration: 0.742s, episode steps: 118, steps per second: 159, episode reward: -86.437, mean reward: -0.733 [-100.000, 22.478], mean action: 1.619 [0.000, 3.000],  loss: 32.664510, mae: 156.299598, mean_q: 204.538965, mean_eps: 0.847748
  50887/300000: episode: 524, duration: 0.484s, episode steps:  77, steps per second: 159, episode reward: -126.752, mean reward: -1.646 [-100.000, 12.987], mean action: 1.377 [0.000, 3.000],  loss: 52.803250, mae: 155.741445, mean_q: 202.057525, mean_eps: 0.847456
  51029/300000: episode: 525, duration: 0.947s, episode steps: 142, steps per second: 150, episode reward: -82.288, mean reward: -0.579 [-100.000, 16.819], mean action: 1.507 [0.000, 3.000],  loss: 32.696370, mae: 156.473297, mean_q: 203.714793, mean_eps: 0.847127
  51103/300000: episode: 526, duration: 0.472s, episode steps:  74, steps per second: 157, episode reward: -233.821, mean reward: -3.160 [-100.000,  5.531], mean action: 1.554 [0.000, 3.000],  loss: 45.591197, mae: 152.851045, mean_q: 197.794269, mean_eps: 0.846803
  51175/300000: episode: 527, duration: 0.452s, episode steps:  72, steps per second: 159, episode reward: -144.293, mean reward: -2.004 [-100.000, 10.384], mean action: 1.500 [0.000, 3.000],  loss: 61.295371, mae: 153.994326, mean_q: 199.366111, mean_eps: 0.846584
  51266/300000: episode: 528, duration: 0.575s, episode steps:  91, steps per second: 158, episode reward: -93.133, mean reward: -1.023 [-100.000,  7.980], mean action: 1.527 [0.000, 3.000],  loss: 47.012365, mae: 154.953919, mean_q: 200.865380, mean_eps: 0.846340
  51340/300000: episode: 529, duration: 0.501s, episode steps:  74, steps per second: 148, episode reward: -74.590, mean reward: -1.008 [-100.000,  8.479], mean action: 1.608 [0.000, 3.000],  loss: 38.551773, mae: 156.714093, mean_q: 202.903106, mean_eps: 0.846092
  51451/300000: episode: 530, duration: 0.717s, episode steps: 111, steps per second: 155, episode reward: -163.739, mean reward: -1.475 [-100.000,  8.524], mean action: 1.658 [0.000, 3.000],  loss: 40.540438, mae: 156.494151, mean_q: 201.944857, mean_eps: 0.845815
  51542/300000: episode: 531, duration: 0.570s, episode steps:  91, steps per second: 160, episode reward: -129.159, mean reward: -1.419 [-100.000, 13.473], mean action: 1.516 [0.000, 3.000],  loss: 34.461454, mae: 157.482947, mean_q: 202.441768, mean_eps: 0.845512
  51607/300000: episode: 532, duration: 0.421s, episode steps:  65, steps per second: 154, episode reward: -120.204, mean reward: -1.849 [-100.000,  9.415], mean action: 1.723 [0.000, 3.000],  loss: 28.875029, mae: 161.806839, mean_q: 209.983038, mean_eps: 0.845278
  51767/300000: episode: 533, duration: 1.039s, episode steps: 160, steps per second: 154, episode reward: -7.490, mean reward: -0.047 [-100.000, 77.457], mean action: 1.556 [0.000, 3.000],  loss: 41.264623, mae: 155.439433, mean_q: 200.609236, mean_eps: 0.844940
  51904/300000: episode: 534, duration: 0.859s, episode steps: 137, steps per second: 159, episode reward: -83.460, mean reward: -0.609 [-100.000, 11.605], mean action: 1.642 [0.000, 3.000],  loss: 29.482349, mae: 157.375212, mean_q: 203.819392, mean_eps: 0.844495
  52001/300000: episode: 535, duration: 0.670s, episode steps:  97, steps per second: 145, episode reward: -94.307, mean reward: -0.972 [-100.000, 10.574], mean action: 1.474 [0.000, 3.000],  loss: 34.151256, mae: 154.968051, mean_q: 200.484718, mean_eps: 0.844144
  52081/300000: episode: 536, duration: 0.518s, episode steps:  80, steps per second: 154, episode reward: -65.078, mean reward: -0.813 [-100.000, 17.484], mean action: 1.600 [0.000, 3.000],  loss: 54.642838, mae: 153.773825, mean_q: 198.863484, mean_eps: 0.843878
  52167/300000: episode: 537, duration: 0.544s, episode steps:  86, steps per second: 158, episode reward: -174.991, mean reward: -2.035 [-100.000,  2.092], mean action: 1.605 [0.000, 3.000],  loss: 40.187233, mae: 152.495938, mean_q: 195.401021, mean_eps: 0.843630
  52271/300000: episode: 538, duration: 0.664s, episode steps: 104, steps per second: 157, episode reward: -119.270, mean reward: -1.147 [-100.000, 11.238], mean action: 1.615 [0.000, 3.000],  loss: 34.918219, mae: 153.943531, mean_q: 196.581088, mean_eps: 0.843344
  52368/300000: episode: 539, duration: 0.655s, episode steps:  97, steps per second: 148, episode reward: -182.092, mean reward: -1.877 [-100.000,  6.868], mean action: 1.773 [0.000, 3.000],  loss: 34.306750, mae: 155.969632, mean_q: 200.338208, mean_eps: 0.843043
  52480/300000: episode: 540, duration: 0.710s, episode steps: 112, steps per second: 158, episode reward: -49.174, mean reward: -0.439 [-100.000, 22.208], mean action: 1.643 [0.000, 3.000],  loss: 40.141945, mae: 153.518949, mean_q: 196.850983, mean_eps: 0.842730
  52597/300000: episode: 541, duration: 0.729s, episode steps: 117, steps per second: 161, episode reward: -139.273, mean reward: -1.190 [-100.000,  5.850], mean action: 1.564 [0.000, 3.000],  loss: 29.983589, mae: 153.070188, mean_q: 195.653419, mean_eps: 0.842386
  52738/300000: episode: 542, duration: 0.936s, episode steps: 141, steps per second: 151, episode reward: -72.487, mean reward: -0.514 [-100.000,  9.727], mean action: 1.560 [0.000, 3.000],  loss: 41.179393, mae: 154.345206, mean_q: 196.981957, mean_eps: 0.841999
  52811/300000: episode: 543, duration: 0.461s, episode steps:  73, steps per second: 159, episode reward: -60.679, mean reward: -0.831 [-100.000, 14.691], mean action: 1.589 [0.000, 3.000],  loss: 49.698243, mae: 155.290157, mean_q: 199.476467, mean_eps: 0.841678
  52955/300000: episode: 544, duration: 0.945s, episode steps: 144, steps per second: 152, episode reward: -8.058, mean reward: -0.056 [-100.000, 77.266], mean action: 1.535 [0.000, 3.000],  loss: 51.248423, mae: 157.363413, mean_q: 203.644512, mean_eps: 0.841352
  53022/300000: episode: 545, duration: 0.456s, episode steps:  67, steps per second: 147, episode reward: -63.808, mean reward: -0.952 [-100.000,  7.322], mean action: 1.597 [0.000, 3.000],  loss: 39.494603, mae: 159.060746, mean_q: 206.782633, mean_eps: 0.841036
  53137/300000: episode: 546, duration: 0.751s, episode steps: 115, steps per second: 153, episode reward: -90.447, mean reward: -0.786 [-100.000, 10.237], mean action: 1.757 [0.000, 3.000],  loss: 38.188316, mae: 155.725857, mean_q: 201.176099, mean_eps: 0.840763
  53209/300000: episode: 547, duration: 0.453s, episode steps:  72, steps per second: 159, episode reward: -85.181, mean reward: -1.183 [-100.000, 22.391], mean action: 1.458 [0.000, 3.000],  loss: 35.665538, mae: 156.275789, mean_q: 202.152684, mean_eps: 0.840483
  53302/300000: episode: 548, duration: 0.618s, episode steps:  93, steps per second: 150, episode reward: -400.731, mean reward: -4.309 [-100.000,  1.014], mean action: 1.624 [0.000, 3.000],  loss: 31.195425, mae: 160.124527, mean_q: 207.998323, mean_eps: 0.840235
  53369/300000: episode: 549, duration: 0.469s, episode steps:  67, steps per second: 143, episode reward: -85.195, mean reward: -1.272 [-100.000,  8.318], mean action: 1.746 [0.000, 3.000],  loss: 43.840208, mae: 156.322879, mean_q: 202.259044, mean_eps: 0.839995
  53461/300000: episode: 550, duration: 0.663s, episode steps:  92, steps per second: 139, episode reward: -85.921, mean reward: -0.934 [-100.000, 11.780], mean action: 1.609 [0.000, 3.000],  loss: 42.917603, mae: 159.032502, mean_q: 205.899542, mean_eps: 0.839757
  53578/300000: episode: 551, duration: 0.792s, episode steps: 117, steps per second: 148, episode reward: -102.688, mean reward: -0.878 [-100.000, 12.417], mean action: 1.564 [0.000, 3.000],  loss: 42.078003, mae: 159.472176, mean_q: 206.177555, mean_eps: 0.839443
  53653/300000: episode: 552, duration: 0.560s, episode steps:  75, steps per second: 134, episode reward: -50.843, mean reward: -0.678 [-100.000, 16.755], mean action: 1.467 [0.000, 3.000],  loss: 55.808400, mae: 160.901143, mean_q: 208.032272, mean_eps: 0.839155
  53787/300000: episode: 553, duration: 1.074s, episode steps: 134, steps per second: 125, episode reward: -148.707, mean reward: -1.110 [-100.000, 10.123], mean action: 1.522 [0.000, 3.000],  loss: 36.772946, mae: 161.963882, mean_q: 209.195109, mean_eps: 0.838842
  53889/300000: episode: 554, duration: 0.864s, episode steps: 102, steps per second: 118, episode reward: -39.682, mean reward: -0.389 [-100.000, 78.944], mean action: 1.510 [0.000, 3.000],  loss: 58.609970, mae: 161.430122, mean_q: 209.328338, mean_eps: 0.838488
  54031/300000: episode: 555, duration: 1.042s, episode steps: 142, steps per second: 136, episode reward: -252.025, mean reward: -1.775 [-100.000, 89.936], mean action: 1.465 [0.000, 3.000],  loss: 42.243658, mae: 162.557799, mean_q: 210.401647, mean_eps: 0.838121
  54167/300000: episode: 556, duration: 0.908s, episode steps: 136, steps per second: 150, episode reward: -55.242, mean reward: -0.406 [-100.000, 20.475], mean action: 1.522 [0.000, 3.000],  loss: 57.067530, mae: 162.114842, mean_q: 208.769894, mean_eps: 0.837704
  54242/300000: episode: 557, duration: 0.572s, episode steps:  75, steps per second: 131, episode reward: -64.307, mean reward: -0.857 [-100.000,  9.720], mean action: 1.480 [0.000, 3.000],  loss: 53.548482, mae: 160.935615, mean_q: 206.825268, mean_eps: 0.837388
  54360/300000: episode: 558, duration: 0.772s, episode steps: 118, steps per second: 153, episode reward: -65.298, mean reward: -0.553 [-100.000, 14.487], mean action: 1.517 [0.000, 3.000],  loss: 71.111277, mae: 156.610299, mean_q: 201.681680, mean_eps: 0.837099
  54493/300000: episode: 559, duration: 0.879s, episode steps: 133, steps per second: 151, episode reward: -89.365, mean reward: -0.672 [-100.000, 11.975], mean action: 1.602 [0.000, 3.000],  loss: 62.708697, mae: 159.646268, mean_q: 205.272745, mean_eps: 0.836722
  54588/300000: episode: 560, duration: 0.661s, episode steps:  95, steps per second: 144, episode reward: -119.689, mean reward: -1.260 [-100.000,  6.415], mean action: 1.453 [0.000, 3.000],  loss: 50.874475, mae: 156.851015, mean_q: 200.789125, mean_eps: 0.836380
  54674/300000: episode: 561, duration: 0.570s, episode steps:  86, steps per second: 151, episode reward: -116.415, mean reward: -1.354 [-100.000,  9.702], mean action: 1.523 [0.000, 3.000],  loss: 36.304602, mae: 156.785620, mean_q: 201.885970, mean_eps: 0.836108
  54738/300000: episode: 562, duration: 0.409s, episode steps:  64, steps per second: 156, episode reward: -128.522, mean reward: -2.008 [-100.000,  8.110], mean action: 1.516 [0.000, 3.000],  loss: 60.664328, mae: 158.961279, mean_q: 203.733270, mean_eps: 0.835884
  54865/300000: episode: 563, duration: 0.862s, episode steps: 127, steps per second: 147, episode reward: -195.799, mean reward: -1.542 [-100.000, 11.473], mean action: 1.764 [0.000, 3.000],  loss: 36.956454, mae: 159.564609, mean_q: 205.147188, mean_eps: 0.835597
  54986/300000: episode: 564, duration: 0.782s, episode steps: 121, steps per second: 155, episode reward:  5.828, mean reward:  0.048 [-100.000, 88.538], mean action: 1.537 [0.000, 3.000],  loss: 54.471722, mae: 155.298031, mean_q: 199.185662, mean_eps: 0.835225
  55048/300000: episode: 565, duration: 0.408s, episode steps:  62, steps per second: 152, episode reward: -149.075, mean reward: -2.404 [-100.000, 38.263], mean action: 1.855 [0.000, 3.000],  loss: 65.706920, mae: 159.353795, mean_q: 206.556592, mean_eps: 0.834951
  55205/300000: episode: 566, duration: 1.076s, episode steps: 157, steps per second: 146, episode reward: -121.685, mean reward: -0.775 [-100.000, 20.190], mean action: 1.662 [0.000, 3.000],  loss: 93.871805, mae: 157.589905, mean_q: 202.998318, mean_eps: 0.834622
  55309/300000: episode: 567, duration: 0.674s, episode steps: 104, steps per second: 154, episode reward: -107.635, mean reward: -1.035 [-100.000, 16.102], mean action: 1.529 [0.000, 3.000],  loss: 74.777616, mae: 158.023102, mean_q: 204.064130, mean_eps: 0.834231
  55378/300000: episode: 568, duration: 0.432s, episode steps:  69, steps per second: 160, episode reward: -92.301, mean reward: -1.338 [-100.000,  8.644], mean action: 1.594 [0.000, 3.000],  loss: 50.676084, mae: 159.753670, mean_q: 207.660973, mean_eps: 0.833971
  55465/300000: episode: 569, duration: 0.574s, episode steps:  87, steps per second: 152, episode reward: -77.566, mean reward: -0.892 [-100.000, 19.958], mean action: 1.529 [0.000, 3.000],  loss: 42.601420, mae: 155.758573, mean_q: 200.725924, mean_eps: 0.833737
  55564/300000: episode: 570, duration: 0.667s, episode steps:  99, steps per second: 148, episode reward: -256.980, mean reward: -2.596 [-100.000,  5.999], mean action: 1.505 [0.000, 3.000],  loss: 54.825871, mae: 157.676791, mean_q: 202.647282, mean_eps: 0.833458
  55674/300000: episode: 571, duration: 0.703s, episode steps: 110, steps per second: 157, episode reward: -76.324, mean reward: -0.694 [-100.000,  6.607], mean action: 1.555 [0.000, 3.000],  loss: 40.479629, mae: 158.237943, mean_q: 202.393599, mean_eps: 0.833144
  55786/300000: episode: 572, duration: 0.756s, episode steps: 112, steps per second: 148, episode reward: -343.874, mean reward: -3.070 [-100.000, 65.712], mean action: 1.696 [0.000, 3.000],  loss: 46.032080, mae: 154.793218, mean_q: 199.079362, mean_eps: 0.832812
  55892/300000: episode: 573, duration: 0.717s, episode steps: 106, steps per second: 148, episode reward: -154.926, mean reward: -1.462 [-100.000,  2.207], mean action: 1.811 [0.000, 3.000],  loss: 40.513047, mae: 154.805668, mean_q: 198.803859, mean_eps: 0.832485
  56023/300000: episode: 574, duration: 0.839s, episode steps: 131, steps per second: 156, episode reward: -106.506, mean reward: -0.813 [-100.000, 12.852], mean action: 1.458 [0.000, 3.000],  loss: 60.794834, mae: 154.817554, mean_q: 198.226761, mean_eps: 0.832129
  56096/300000: episode: 575, duration: 0.470s, episode steps:  73, steps per second: 155, episode reward: -95.305, mean reward: -1.306 [-100.000,  4.403], mean action: 1.438 [0.000, 3.000],  loss: 38.732186, mae: 154.995332, mean_q: 199.060008, mean_eps: 0.831823
  56180/300000: episode: 576, duration: 0.572s, episode steps:  84, steps per second: 147, episode reward: -147.004, mean reward: -1.750 [-100.000,  9.378], mean action: 1.440 [0.000, 3.000],  loss: 33.622784, mae: 151.193372, mean_q: 193.559925, mean_eps: 0.831588
  56317/300000: episode: 577, duration: 0.885s, episode steps: 137, steps per second: 155, episode reward: -366.143, mean reward: -2.673 [-100.000, 36.360], mean action: 1.591 [0.000, 3.000],  loss: 52.875958, mae: 154.949822, mean_q: 199.799591, mean_eps: 0.831256
  56387/300000: episode: 578, duration: 0.466s, episode steps:  70, steps per second: 150, episode reward: -130.173, mean reward: -1.860 [-100.000,  5.591], mean action: 1.657 [0.000, 3.000],  loss: 58.073662, mae: 153.895457, mean_q: 198.140935, mean_eps: 0.830946
  56473/300000: episode: 579, duration: 0.652s, episode steps:  86, steps per second: 132, episode reward: -102.534, mean reward: -1.192 [-100.000, 11.905], mean action: 1.709 [0.000, 3.000],  loss: 64.438186, mae: 150.932220, mean_q: 193.585559, mean_eps: 0.830711
  56568/300000: episode: 580, duration: 0.627s, episode steps:  95, steps per second: 151, episode reward: -51.115, mean reward: -0.538 [-100.000, 62.632], mean action: 1.537 [0.000, 3.000],  loss: 46.004338, mae: 155.994628, mean_q: 201.155218, mean_eps: 0.830440
  56664/300000: episode: 581, duration: 0.617s, episode steps:  96, steps per second: 155, episode reward: -130.864, mean reward: -1.363 [-100.000,  7.444], mean action: 1.594 [0.000, 3.000],  loss: 48.094900, mae: 153.579698, mean_q: 199.257188, mean_eps: 0.830154
  56802/300000: episode: 582, duration: 0.921s, episode steps: 138, steps per second: 150, episode reward:  3.037, mean reward:  0.022 [-100.000, 64.529], mean action: 1.370 [0.000, 3.000],  loss: 46.631835, mae: 157.781828, mean_q: 205.042716, mean_eps: 0.829802
  56900/300000: episode: 583, duration: 0.683s, episode steps:  98, steps per second: 144, episode reward: -92.881, mean reward: -0.948 [-100.000,  5.926], mean action: 1.571 [0.000, 3.000],  loss: 33.623031, mae: 158.708274, mean_q: 206.243910, mean_eps: 0.829448
  57018/300000: episode: 584, duration: 0.924s, episode steps: 118, steps per second: 128, episode reward: -135.526, mean reward: -1.149 [-100.000,  9.362], mean action: 1.593 [0.000, 3.000],  loss: 63.609493, mae: 157.552451, mean_q: 204.748618, mean_eps: 0.829125
  57122/300000: episode: 585, duration: 0.834s, episode steps: 104, steps per second: 125, episode reward: -71.395, mean reward: -0.686 [-100.000, 18.087], mean action: 1.567 [0.000, 3.000],  loss: 66.350110, mae: 157.071787, mean_q: 203.610891, mean_eps: 0.828792
  57210/300000: episode: 586, duration: 0.641s, episode steps:  88, steps per second: 137, episode reward: -42.330, mean reward: -0.481 [-100.000, 12.155], mean action: 1.693 [0.000, 3.000],  loss: 58.011607, mae: 157.650348, mean_q: 205.492202, mean_eps: 0.828504
  57341/300000: episode: 587, duration: 1.066s, episode steps: 131, steps per second: 123, episode reward: -78.489, mean reward: -0.599 [-100.000, 17.258], mean action: 1.527 [0.000, 3.000],  loss: 53.641077, mae: 155.502595, mean_q: 201.882495, mean_eps: 0.828175
  57445/300000: episode: 588, duration: 0.807s, episode steps: 104, steps per second: 129, episode reward: -185.650, mean reward: -1.785 [-100.000,  6.588], mean action: 1.510 [0.000, 3.000],  loss: 76.348751, mae: 154.904795, mean_q: 200.120543, mean_eps: 0.827822
  57544/300000: episode: 589, duration: 0.719s, episode steps:  99, steps per second: 138, episode reward: -171.360, mean reward: -1.731 [-100.000, 24.089], mean action: 1.667 [0.000, 3.000],  loss: 56.091031, mae: 154.502836, mean_q: 199.059119, mean_eps: 0.827518
  57618/300000: episode: 590, duration: 0.492s, episode steps:  74, steps per second: 150, episode reward: -101.106, mean reward: -1.366 [-100.000,  6.699], mean action: 1.514 [0.000, 3.000],  loss: 40.585908, mae: 158.600069, mean_q: 205.164871, mean_eps: 0.827258
  57727/300000: episode: 591, duration: 0.792s, episode steps: 109, steps per second: 138, episode reward: -148.933, mean reward: -1.366 [-100.000, 17.471], mean action: 1.587 [0.000, 3.000],  loss: 52.462506, mae: 157.792654, mean_q: 203.776316, mean_eps: 0.826984
  57851/300000: episode: 592, duration: 0.878s, episode steps: 124, steps per second: 141, episode reward: -15.737, mean reward: -0.127 [-100.000, 38.225], mean action: 1.452 [0.000, 3.000],  loss: 59.824285, mae: 157.409260, mean_q: 203.640031, mean_eps: 0.826634
  57973/300000: episode: 593, duration: 0.875s, episode steps: 122, steps per second: 139, episode reward: -78.282, mean reward: -0.642 [-100.000, 11.401], mean action: 1.607 [0.000, 3.000],  loss: 57.478899, mae: 159.097305, mean_q: 207.087524, mean_eps: 0.826265
  58043/300000: episode: 594, duration: 0.462s, episode steps:  70, steps per second: 151, episode reward: -183.345, mean reward: -2.619 [-100.000,  5.488], mean action: 1.286 [0.000, 3.000],  loss: 50.733165, mae: 158.239562, mean_q: 206.330092, mean_eps: 0.825977
  58119/300000: episode: 595, duration: 0.485s, episode steps:  76, steps per second: 157, episode reward: -49.145, mean reward: -0.647 [-100.000,  7.666], mean action: 1.618 [0.000, 3.000],  loss: 36.759137, mae: 162.483364, mean_q: 211.279187, mean_eps: 0.825758
  58225/300000: episode: 596, duration: 0.662s, episode steps: 106, steps per second: 160, episode reward: -151.414, mean reward: -1.428 [-100.000,  4.740], mean action: 1.509 [0.000, 3.000],  loss: 60.585101, mae: 156.968067, mean_q: 203.025006, mean_eps: 0.825485
  58372/300000: episode: 597, duration: 0.981s, episode steps: 147, steps per second: 150, episode reward: -361.845, mean reward: -2.462 [-100.000, 94.819], mean action: 1.605 [0.000, 3.000],  loss: 63.095976, mae: 156.883409, mean_q: 202.012647, mean_eps: 0.825106
  58433/300000: episode: 598, duration: 0.400s, episode steps:  61, steps per second: 152, episode reward: -43.891, mean reward: -0.720 [-100.000, 22.156], mean action: 1.738 [0.000, 3.000],  loss: 49.375878, mae: 158.271545, mean_q: 204.655628, mean_eps: 0.824794
  58500/300000: episode: 599, duration: 0.444s, episode steps:  67, steps per second: 151, episode reward: -124.462, mean reward: -1.858 [-100.000, 16.466], mean action: 1.806 [0.000, 3.000],  loss: 66.542816, mae: 157.152596, mean_q: 201.764860, mean_eps: 0.824602
  58605/300000: episode: 600, duration: 0.719s, episode steps: 105, steps per second: 146, episode reward: -107.417, mean reward: -1.023 [-100.000,  7.475], mean action: 1.476 [0.000, 3.000],  loss: 39.508307, mae: 158.271419, mean_q: 204.557815, mean_eps: 0.824344
  58706/300000: episode: 601, duration: 0.688s, episode steps: 101, steps per second: 147, episode reward: -234.120, mean reward: -2.318 [-100.000,  1.007], mean action: 1.693 [0.000, 3.000],  loss: 59.151137, mae: 155.655681, mean_q: 200.953395, mean_eps: 0.824035
  58808/300000: episode: 602, duration: 0.673s, episode steps: 102, steps per second: 152, episode reward: -84.451, mean reward: -0.828 [-100.000,  8.384], mean action: 1.706 [0.000, 3.000],  loss: 51.551506, mae: 158.486302, mean_q: 206.121506, mean_eps: 0.823730
  58918/300000: episode: 603, duration: 0.745s, episode steps: 110, steps per second: 148, episode reward: -83.432, mean reward: -0.758 [-100.000, 18.095], mean action: 1.591 [0.000, 3.000],  loss: 63.832044, mae: 156.167792, mean_q: 203.326457, mean_eps: 0.823412
  59016/300000: episode: 604, duration: 0.669s, episode steps:  98, steps per second: 147, episode reward: -131.080, mean reward: -1.338 [-100.000,  6.216], mean action: 1.561 [0.000, 3.000],  loss: 41.701532, mae: 160.098869, mean_q: 210.469187, mean_eps: 0.823100
  59126/300000: episode: 605, duration: 0.738s, episode steps: 110, steps per second: 149, episode reward: -155.179, mean reward: -1.411 [-100.000,  3.830], mean action: 1.727 [0.000, 3.000],  loss: 48.155436, mae: 160.276483, mean_q: 210.261225, mean_eps: 0.822789
  59204/300000: episode: 606, duration: 0.587s, episode steps:  78, steps per second: 133, episode reward: -80.742, mean reward: -1.035 [-100.000, 11.386], mean action: 1.628 [0.000, 3.000],  loss: 80.224104, mae: 161.790091, mean_q: 212.286672, mean_eps: 0.822507
  59285/300000: episode: 607, duration: 0.552s, episode steps:  81, steps per second: 147, episode reward: -54.407, mean reward: -0.672 [-100.000, 20.301], mean action: 1.790 [0.000, 3.000],  loss: 55.989663, mae: 164.359038, mean_q: 216.548584, mean_eps: 0.822268
  59381/300000: episode: 608, duration: 0.679s, episode steps:  96, steps per second: 141, episode reward: -96.876, mean reward: -1.009 [-100.000,  7.356], mean action: 1.469 [0.000, 3.000],  loss: 88.124347, mae: 163.597029, mean_q: 215.224662, mean_eps: 0.822002
  59491/300000: episode: 609, duration: 0.945s, episode steps: 110, steps per second: 116, episode reward: -59.923, mean reward: -0.545 [-100.000, 11.740], mean action: 1.555 [0.000, 3.000],  loss: 54.720661, mae: 157.909614, mean_q: 206.454176, mean_eps: 0.821693
  59571/300000: episode: 610, duration: 0.645s, episode steps:  80, steps per second: 124, episode reward: -69.649, mean reward: -0.871 [-100.000, 18.596], mean action: 1.550 [0.000, 3.000],  loss: 61.224771, mae: 158.487852, mean_q: 208.273268, mean_eps: 0.821409
  59671/300000: episode: 611, duration: 0.672s, episode steps: 100, steps per second: 149, episode reward: -97.107, mean reward: -0.971 [-100.000, 13.077], mean action: 1.620 [0.000, 3.000],  loss: 37.674102, mae: 161.770235, mean_q: 212.489980, mean_eps: 0.821138
  59757/300000: episode: 612, duration: 0.578s, episode steps:  86, steps per second: 149, episode reward: -92.462, mean reward: -1.075 [-100.000, 51.359], mean action: 1.616 [0.000, 3.000],  loss: 67.286542, mae: 159.075295, mean_q: 207.942972, mean_eps: 0.820860
  59867/300000: episode: 613, duration: 0.802s, episode steps: 110, steps per second: 137, episode reward: -108.657, mean reward: -0.988 [-100.000, 20.257], mean action: 1.373 [0.000, 3.000],  loss: 69.282410, mae: 163.932052, mean_q: 215.747809, mean_eps: 0.820566
  59976/300000: episode: 614, duration: 0.720s, episode steps: 109, steps per second: 151, episode reward: -315.958, mean reward: -2.899 [-100.000, 95.175], mean action: 1.578 [0.000, 3.000],  loss: 48.194549, mae: 162.624195, mean_q: 212.668534, mean_eps: 0.820237
  60070/300000: episode: 615, duration: 0.695s, episode steps:  94, steps per second: 135, episode reward: -184.906, mean reward: -1.967 [-100.000,  4.795], mean action: 1.489 [0.000, 3.000],  loss: 70.689352, mae: 163.492142, mean_q: 214.374666, mean_eps: 0.819932
  60141/300000: episode: 616, duration: 0.621s, episode steps:  71, steps per second: 114, episode reward: -79.207, mean reward: -1.116 [-100.000, 14.368], mean action: 1.592 [0.000, 3.000],  loss: 54.941431, mae: 157.601680, mean_q: 206.212184, mean_eps: 0.819685
  60208/300000: episode: 617, duration: 0.547s, episode steps:  67, steps per second: 123, episode reward: -72.539, mean reward: -1.083 [-100.000, 18.634], mean action: 1.761 [0.000, 3.000],  loss: 30.108539, mae: 158.198834, mean_q: 206.791126, mean_eps: 0.819478
  60292/300000: episode: 618, duration: 0.918s, episode steps:  84, steps per second:  92, episode reward: -106.924, mean reward: -1.273 [-100.000,  5.896], mean action: 1.512 [0.000, 3.000],  loss: 58.606214, mae: 159.737331, mean_q: 208.392341, mean_eps: 0.819251
  60406/300000: episode: 619, duration: 0.934s, episode steps: 114, steps per second: 122, episode reward: -111.851, mean reward: -0.981 [-100.000, 11.559], mean action: 1.649 [0.000, 3.000],  loss: 51.269789, mae: 162.247125, mean_q: 212.453323, mean_eps: 0.818955
  60505/300000: episode: 620, duration: 0.753s, episode steps:  99, steps per second: 131, episode reward: -172.178, mean reward: -1.739 [-100.000, 13.761], mean action: 1.566 [0.000, 3.000],  loss: 62.826101, mae: 160.334055, mean_q: 208.984508, mean_eps: 0.818635
  60568/300000: episode: 621, duration: 0.510s, episode steps:  63, steps per second: 124, episode reward: -102.543, mean reward: -1.628 [-100.000,  6.107], mean action: 1.540 [0.000, 3.000],  loss: 48.192546, mae: 159.636906, mean_q: 207.371531, mean_eps: 0.818392
  60679/300000: episode: 622, duration: 1.079s, episode steps: 111, steps per second: 103, episode reward: -95.980, mean reward: -0.865 [-100.000, 16.051], mean action: 1.856 [0.000, 3.000],  loss: 46.250814, mae: 159.749384, mean_q: 207.100863, mean_eps: 0.818131
  60762/300000: episode: 623, duration: 0.546s, episode steps:  83, steps per second: 152, episode reward: -64.407, mean reward: -0.776 [-100.000, 17.376], mean action: 1.482 [0.000, 3.000],  loss: 34.958540, mae: 157.739829, mean_q: 203.674432, mean_eps: 0.817840
  60822/300000: episode: 624, duration: 0.382s, episode steps:  60, steps per second: 157, episode reward: -114.460, mean reward: -1.908 [-100.000, 19.107], mean action: 1.250 [0.000, 3.000],  loss: 35.649158, mae: 161.600427, mean_q: 209.544780, mean_eps: 0.817626
  60925/300000: episode: 625, duration: 0.706s, episode steps: 103, steps per second: 146, episode reward: -127.679, mean reward: -1.240 [-100.000, 10.555], mean action: 1.583 [0.000, 3.000],  loss: 70.198956, mae: 159.437861, mean_q: 205.661736, mean_eps: 0.817381
  61032/300000: episode: 626, duration: 0.714s, episode steps: 107, steps per second: 150, episode reward: -162.433, mean reward: -1.518 [-100.000, 44.811], mean action: 1.551 [0.000, 3.000],  loss: 38.877589, mae: 157.530699, mean_q: 202.877724, mean_eps: 0.817066
  61137/300000: episode: 627, duration: 0.680s, episode steps: 105, steps per second: 154, episode reward: -84.018, mean reward: -0.800 [-100.000,  8.796], mean action: 1.571 [0.000, 3.000],  loss: 52.721676, mae: 160.383215, mean_q: 207.191032, mean_eps: 0.816748
  61219/300000: episode: 628, duration: 0.635s, episode steps:  82, steps per second: 129, episode reward: -119.530, mean reward: -1.458 [-100.000,  8.587], mean action: 1.671 [0.000, 3.000],  loss: 52.889855, mae: 155.659079, mean_q: 200.779820, mean_eps: 0.816468
  61324/300000: episode: 629, duration: 0.765s, episode steps: 105, steps per second: 137, episode reward: -194.235, mean reward: -1.850 [-100.000, 61.585], mean action: 1.752 [0.000, 3.000],  loss: 64.961392, mae: 155.404803, mean_q: 199.575005, mean_eps: 0.816187
  61412/300000: episode: 630, duration: 0.569s, episode steps:  88, steps per second: 155, episode reward: -68.921, mean reward: -0.783 [-100.000, 22.573], mean action: 1.682 [0.000, 3.000],  loss: 35.931295, mae: 153.315245, mean_q: 197.099751, mean_eps: 0.815898
  61496/300000: episode: 631, duration: 0.544s, episode steps:  84, steps per second: 154, episode reward: -115.167, mean reward: -1.371 [-100.000,  7.526], mean action: 1.548 [0.000, 3.000],  loss: 43.036982, mae: 155.940275, mean_q: 202.451403, mean_eps: 0.815640
  61637/300000: episode: 632, duration: 0.952s, episode steps: 141, steps per second: 148, episode reward: -241.212, mean reward: -1.711 [-100.000,  3.871], mean action: 1.532 [0.000, 3.000],  loss: 40.069259, mae: 156.073120, mean_q: 201.963603, mean_eps: 0.815302
  61753/300000: episode: 633, duration: 0.747s, episode steps: 116, steps per second: 155, episode reward: -115.598, mean reward: -0.997 [-100.000, 10.942], mean action: 1.681 [0.000, 3.000],  loss: 44.477179, mae: 155.075192, mean_q: 201.728282, mean_eps: 0.814917
  61852/300000: episode: 634, duration: 0.625s, episode steps:  99, steps per second: 158, episode reward: -101.620, mean reward: -1.026 [-100.000,  7.791], mean action: 1.636 [0.000, 3.000],  loss: 75.596978, mae: 154.965507, mean_q: 200.664457, mean_eps: 0.814594
  61960/300000: episode: 635, duration: 0.745s, episode steps: 108, steps per second: 145, episode reward: -70.647, mean reward: -0.654 [-100.000, 14.054], mean action: 1.620 [0.000, 3.000],  loss: 55.890316, mae: 153.968471, mean_q: 200.187255, mean_eps: 0.814283
  62071/300000: episode: 636, duration: 0.701s, episode steps: 111, steps per second: 158, episode reward: -279.417, mean reward: -2.517 [-100.000,  0.644], mean action: 1.604 [0.000, 3.000],  loss: 40.857574, mae: 154.293860, mean_q: 201.618124, mean_eps: 0.813955
  62176/300000: episode: 637, duration: 0.665s, episode steps: 105, steps per second: 158, episode reward: -92.184, mean reward: -0.878 [-100.000, 10.245], mean action: 1.752 [0.000, 3.000],  loss: 73.172828, mae: 155.990302, mean_q: 203.948953, mean_eps: 0.813631
  62253/300000: episode: 638, duration: 0.524s, episode steps:  77, steps per second: 147, episode reward: -93.779, mean reward: -1.218 [-100.000, 13.983], mean action: 1.442 [0.000, 3.000],  loss: 53.088432, mae: 156.815454, mean_q: 204.735155, mean_eps: 0.813358
  62349/300000: episode: 639, duration: 0.615s, episode steps:  96, steps per second: 156, episode reward: -102.264, mean reward: -1.065 [-100.000,  7.157], mean action: 1.677 [0.000, 3.000],  loss: 48.759486, mae: 157.473938, mean_q: 206.452615, mean_eps: 0.813099
  62444/300000: episode: 640, duration: 0.614s, episode steps:  95, steps per second: 155, episode reward: -262.805, mean reward: -2.766 [-100.000, 25.124], mean action: 1.747 [0.000, 3.000],  loss: 58.945192, mae: 156.025916, mean_q: 203.316645, mean_eps: 0.812812
  62554/300000: episode: 641, duration: 0.751s, episode steps: 110, steps per second: 147, episode reward: -141.844, mean reward: -1.289 [-100.000,  8.268], mean action: 1.755 [0.000, 3.000],  loss: 61.335720, mae: 156.068454, mean_q: 203.674899, mean_eps: 0.812504
  62619/300000: episode: 642, duration: 0.433s, episode steps:  65, steps per second: 150, episode reward: -65.953, mean reward: -1.015 [-100.000,  6.424], mean action: 1.615 [0.000, 3.000],  loss: 48.768437, mae: 153.946188, mean_q: 201.187573, mean_eps: 0.812242
  62730/300000: episode: 643, duration: 0.748s, episode steps: 111, steps per second: 148, episode reward: -63.223, mean reward: -0.570 [-100.000, 111.835], mean action: 1.658 [0.000, 3.000],  loss: 52.089901, mae: 154.925686, mean_q: 202.671905, mean_eps: 0.811978
  62804/300000: episode: 644, duration: 0.521s, episode steps:  74, steps per second: 142, episode reward: -102.549, mean reward: -1.386 [-100.000, 11.345], mean action: 1.473 [0.000, 3.000],  loss: 57.791313, mae: 156.099212, mean_q: 203.489001, mean_eps: 0.811700
  62873/300000: episode: 645, duration: 0.529s, episode steps:  69, steps per second: 131, episode reward: -69.133, mean reward: -1.002 [-100.000,  6.304], mean action: 1.391 [0.000, 3.000],  loss: 83.818465, mae: 153.886188, mean_q: 200.911800, mean_eps: 0.811486
  62940/300000: episode: 646, duration: 0.463s, episode steps:  67, steps per second: 145, episode reward: -71.401, mean reward: -1.066 [-100.000, 17.625], mean action: 1.493 [0.000, 3.000],  loss: 61.238989, mae: 156.686524, mean_q: 205.995644, mean_eps: 0.811282
  63028/300000: episode: 647, duration: 0.587s, episode steps:  88, steps per second: 150, episode reward: -122.149, mean reward: -1.388 [-100.000,  5.462], mean action: 1.545 [0.000, 3.000],  loss: 64.761146, mae: 155.503855, mean_q: 203.260612, mean_eps: 0.811049
  63105/300000: episode: 648, duration: 0.538s, episode steps:  77, steps per second: 143, episode reward: -128.492, mean reward: -1.669 [-100.000, 18.373], mean action: 1.792 [0.000, 3.000],  loss: 48.434427, mae: 155.147728, mean_q: 203.752414, mean_eps: 0.810802
  63222/300000: episode: 649, duration: 0.817s, episode steps: 117, steps per second: 143, episode reward: -115.502, mean reward: -0.987 [-100.000,  7.144], mean action: 1.641 [0.000, 3.000],  loss: 35.381087, mae: 157.872898, mean_q: 206.724266, mean_eps: 0.810511
  63323/300000: episode: 650, duration: 0.680s, episode steps: 101, steps per second: 148, episode reward: -161.685, mean reward: -1.601 [-100.000,  6.259], mean action: 1.475 [0.000, 3.000],  loss: 49.952886, mae: 154.549037, mean_q: 201.827111, mean_eps: 0.810184
  63432/300000: episode: 651, duration: 0.706s, episode steps: 109, steps per second: 154, episode reward: -355.879, mean reward: -3.265 [-100.000, 59.360], mean action: 1.560 [0.000, 3.000],  loss: 47.817505, mae: 157.002452, mean_q: 205.452956, mean_eps: 0.809869
  63577/300000: episode: 652, duration: 0.973s, episode steps: 145, steps per second: 149, episode reward: -320.566, mean reward: -2.211 [-100.000, 60.846], mean action: 1.579 [0.000, 3.000],  loss: 34.894145, mae: 156.449160, mean_q: 204.610191, mean_eps: 0.809488
  63716/300000: episode: 653, duration: 0.889s, episode steps: 139, steps per second: 156, episode reward: -291.000, mean reward: -2.094 [-100.000, 65.792], mean action: 1.568 [0.000, 3.000],  loss: 47.531435, mae: 155.500562, mean_q: 202.182189, mean_eps: 0.809062
  63837/300000: episode: 654, duration: 0.788s, episode steps: 121, steps per second: 154, episode reward: -190.929, mean reward: -1.578 [-100.000, 30.038], mean action: 1.612 [0.000, 3.000],  loss: 75.508429, mae: 153.964178, mean_q: 200.277238, mean_eps: 0.808672
  63898/300000: episode: 655, duration: 0.404s, episode steps:  61, steps per second: 151, episode reward: -84.987, mean reward: -1.393 [-100.000,  7.839], mean action: 1.426 [0.000, 3.000],  loss: 42.114186, mae: 150.648921, mean_q: 193.142647, mean_eps: 0.808399
  63993/300000: episode: 656, duration: 0.598s, episode steps:  95, steps per second: 159, episode reward: -53.320, mean reward: -0.561 [-100.000, 13.388], mean action: 1.611 [0.000, 3.000],  loss: 37.997417, mae: 154.429132, mean_q: 199.979751, mean_eps: 0.808165
  64058/300000: episode: 657, duration: 0.418s, episode steps:  65, steps per second: 155, episode reward: -89.380, mean reward: -1.375 [-100.000,  8.288], mean action: 1.569 [0.000, 3.000],  loss: 61.304540, mae: 156.793912, mean_q: 204.280063, mean_eps: 0.807925
  64168/300000: episode: 658, duration: 0.723s, episode steps: 110, steps per second: 152, episode reward: -139.406, mean reward: -1.267 [-100.000,  3.790], mean action: 1.627 [0.000, 3.000],  loss: 32.801405, mae: 153.399504, mean_q: 198.308333, mean_eps: 0.807663
  64251/300000: episode: 659, duration: 0.551s, episode steps:  83, steps per second: 151, episode reward: -440.253, mean reward: -5.304 [-100.000, -0.700], mean action: 1.663 [0.000, 3.000],  loss: 31.436763, mae: 150.300524, mean_q: 195.101371, mean_eps: 0.807373
  64344/300000: episode: 660, duration: 0.598s, episode steps:  93, steps per second: 155, episode reward: -80.597, mean reward: -0.867 [-100.000,  8.722], mean action: 1.667 [0.000, 3.000],  loss: 63.060645, mae: 154.321665, mean_q: 199.728025, mean_eps: 0.807109
  64432/300000: episode: 661, duration: 0.548s, episode steps:  88, steps per second: 161, episode reward: -181.042, mean reward: -2.057 [-100.000,  7.920], mean action: 1.295 [0.000, 3.000],  loss: 52.235739, mae: 153.439733, mean_q: 198.979920, mean_eps: 0.806837
  64508/300000: episode: 662, duration: 0.514s, episode steps:  76, steps per second: 148, episode reward: -106.176, mean reward: -1.397 [-100.000,  6.514], mean action: 1.368 [0.000, 3.000],  loss: 43.718581, mae: 152.316587, mean_q: 195.915050, mean_eps: 0.806592
  64605/300000: episode: 663, duration: 0.635s, episode steps:  97, steps per second: 153, episode reward: -21.011, mean reward: -0.217 [-100.000, 51.008], mean action: 1.412 [0.000, 3.000],  loss: 38.553213, mae: 153.308194, mean_q: 198.039139, mean_eps: 0.806332
  64730/300000: episode: 664, duration: 0.801s, episode steps: 125, steps per second: 156, episode reward: -259.183, mean reward: -2.073 [-100.000,  1.472], mean action: 1.560 [0.000, 3.000],  loss: 49.976439, mae: 153.322511, mean_q: 197.417847, mean_eps: 0.805999
  64840/300000: episode: 665, duration: 0.733s, episode steps: 110, steps per second: 150, episode reward: -233.467, mean reward: -2.122 [-100.000,  6.367], mean action: 1.627 [0.000, 3.000],  loss: 74.978499, mae: 154.908103, mean_q: 199.821274, mean_eps: 0.805646
  64921/300000: episode: 666, duration: 0.526s, episode steps:  81, steps per second: 154, episode reward: -63.948, mean reward: -0.789 [-100.000,  9.365], mean action: 1.457 [0.000, 3.000],  loss: 60.284131, mae: 155.300472, mean_q: 200.728880, mean_eps: 0.805360
  64985/300000: episode: 667, duration: 0.411s, episode steps:  64, steps per second: 156, episode reward: -78.760, mean reward: -1.231 [-100.000, 10.105], mean action: 1.609 [0.000, 3.000],  loss: 43.403683, mae: 154.650234, mean_q: 199.860809, mean_eps: 0.805142
  65084/300000: episode: 668, duration: 0.613s, episode steps:  99, steps per second: 161, episode reward: -61.322, mean reward: -0.619 [-100.000, 21.731], mean action: 1.576 [0.000, 3.000],  loss: 43.102146, mae: 155.461232, mean_q: 200.581210, mean_eps: 0.804898
  65149/300000: episode: 669, duration: 0.439s, episode steps:  65, steps per second: 148, episode reward: -99.036, mean reward: -1.524 [-100.000,  8.154], mean action: 1.538 [0.000, 3.000],  loss: 41.871260, mae: 155.029433, mean_q: 200.171530, mean_eps: 0.804652
  65275/300000: episode: 670, duration: 0.828s, episode steps: 126, steps per second: 152, episode reward: -106.785, mean reward: -0.848 [-100.000, 10.550], mean action: 1.532 [0.000, 3.000],  loss: 66.756318, mae: 156.649497, mean_q: 201.088970, mean_eps: 0.804366
  65388/300000: episode: 671, duration: 0.708s, episode steps: 113, steps per second: 160, episode reward: -129.473, mean reward: -1.146 [-100.000,  8.570], mean action: 1.522 [0.000, 3.000],  loss: 44.360415, mae: 157.765199, mean_q: 202.610049, mean_eps: 0.804007
  65525/300000: episode: 672, duration: 0.914s, episode steps: 137, steps per second: 150, episode reward: -108.617, mean reward: -0.793 [-100.000,  8.225], mean action: 1.547 [0.000, 3.000],  loss: 36.125533, mae: 157.955770, mean_q: 202.716945, mean_eps: 0.803632
  65640/300000: episode: 673, duration: 0.738s, episode steps: 115, steps per second: 156, episode reward: -113.696, mean reward: -0.989 [-100.000, 13.683], mean action: 1.617 [0.000, 3.000],  loss: 35.530293, mae: 156.691988, mean_q: 200.521243, mean_eps: 0.803254
  65739/300000: episode: 674, duration: 0.630s, episode steps:  99, steps per second: 157, episode reward: -92.228, mean reward: -0.932 [-100.000, 15.099], mean action: 1.657 [0.000, 3.000],  loss: 38.488403, mae: 158.954071, mean_q: 203.980279, mean_eps: 0.802933
  65820/300000: episode: 675, duration: 0.530s, episode steps:  81, steps per second: 153, episode reward: -100.562, mean reward: -1.242 [-100.000,  8.120], mean action: 1.407 [0.000, 3.000],  loss: 53.425056, mae: 161.435436, mean_q: 207.702311, mean_eps: 0.802663
  65948/300000: episode: 676, duration: 0.837s, episode steps: 128, steps per second: 153, episode reward: -176.998, mean reward: -1.383 [-100.000,  7.673], mean action: 1.672 [0.000, 3.000],  loss: 41.323063, mae: 159.505402, mean_q: 205.172440, mean_eps: 0.802350
  66040/300000: episode: 677, duration: 0.582s, episode steps:  92, steps per second: 158, episode reward: -81.756, mean reward: -0.889 [-100.000, 42.555], mean action: 1.533 [0.000, 3.000],  loss: 44.103695, mae: 159.276310, mean_q: 205.163710, mean_eps: 0.802020
  66136/300000: episode: 678, duration: 0.636s, episode steps:  96, steps per second: 151, episode reward: -181.512, mean reward: -1.891 [-100.000,  8.352], mean action: 1.646 [0.000, 3.000],  loss: 37.539703, mae: 160.439316, mean_q: 206.580521, mean_eps: 0.801737
  66202/300000: episode: 679, duration: 0.463s, episode steps:  66, steps per second: 143, episode reward: -89.419, mean reward: -1.355 [-100.000, 12.002], mean action: 1.591 [0.000, 3.000],  loss: 32.791101, mae: 158.194864, mean_q: 203.156338, mean_eps: 0.801494
  66277/300000: episode: 680, duration: 0.478s, episode steps:  75, steps per second: 157, episode reward: -113.325, mean reward: -1.511 [-100.000, 14.198], mean action: 1.760 [0.000, 3.000],  loss: 31.561116, mae: 160.011248, mean_q: 206.986266, mean_eps: 0.801283
  66357/300000: episode: 681, duration: 0.507s, episode steps:  80, steps per second: 158, episode reward: -104.882, mean reward: -1.311 [-100.000, 26.779], mean action: 1.575 [0.000, 3.000],  loss: 34.072921, mae: 158.521283, mean_q: 204.231096, mean_eps: 0.801050
  66478/300000: episode: 682, duration: 0.958s, episode steps: 121, steps per second: 126, episode reward: -108.427, mean reward: -0.896 [-100.000,  7.778], mean action: 1.612 [0.000, 3.000],  loss: 38.246023, mae: 157.835464, mean_q: 202.924261, mean_eps: 0.800749
  66556/300000: episode: 683, duration: 0.608s, episode steps:  78, steps per second: 128, episode reward: -105.501, mean reward: -1.353 [-100.000,  6.415], mean action: 1.846 [0.000, 3.000],  loss: 39.825324, mae: 158.764853, mean_q: 205.407119, mean_eps: 0.800450
  66632/300000: episode: 684, duration: 0.542s, episode steps:  76, steps per second: 140, episode reward: -113.124, mean reward: -1.488 [-100.000, 10.227], mean action: 1.763 [0.000, 3.000],  loss: 50.928406, mae: 159.390112, mean_q: 207.101296, mean_eps: 0.800219
  66724/300000: episode: 685, duration: 0.647s, episode steps:  92, steps per second: 142, episode reward: -74.826, mean reward: -0.813 [-100.000,  7.282], mean action: 1.717 [0.000, 3.000],  loss: 39.994554, mae: 158.717144, mean_q: 205.202508, mean_eps: 0.799967
  66821/300000: episode: 686, duration: 0.704s, episode steps:  97, steps per second: 138, episode reward: -58.886, mean reward: -0.607 [-100.000, 10.055], mean action: 1.608 [0.000, 3.000],  loss: 44.490887, mae: 160.344351, mean_q: 207.891863, mean_eps: 0.799684
  66962/300000: episode: 687, duration: 0.996s, episode steps: 141, steps per second: 142, episode reward: -224.506, mean reward: -1.592 [-100.000,  6.453], mean action: 1.624 [0.000, 3.000],  loss: 39.967164, mae: 160.726415, mean_q: 209.372382, mean_eps: 0.799327
  67067/300000: episode: 688, duration: 0.688s, episode steps: 105, steps per second: 153, episode reward: -161.187, mean reward: -1.535 [-100.000,  2.428], mean action: 1.657 [0.000, 3.000],  loss: 31.192328, mae: 159.298326, mean_q: 206.833786, mean_eps: 0.798958
  67192/300000: episode: 689, duration: 0.832s, episode steps: 125, steps per second: 150, episode reward: -127.146, mean reward: -1.017 [-100.000,  9.291], mean action: 1.512 [0.000, 3.000],  loss: 42.645377, mae: 161.402469, mean_q: 210.598073, mean_eps: 0.798613
  67334/300000: episode: 690, duration: 0.912s, episode steps: 142, steps per second: 156, episode reward: -127.947, mean reward: -0.901 [-100.000,  5.395], mean action: 1.535 [0.000, 3.000],  loss: 36.638955, mae: 163.278578, mean_q: 214.683712, mean_eps: 0.798212
  67450/300000: episode: 691, duration: 0.790s, episode steps: 116, steps per second: 147, episode reward: -110.211, mean reward: -0.950 [-100.000, 10.514], mean action: 1.517 [0.000, 3.000],  loss: 32.534344, mae: 161.084752, mean_q: 209.903963, mean_eps: 0.797825
  67571/300000: episode: 692, duration: 0.777s, episode steps: 121, steps per second: 156, episode reward: -175.523, mean reward: -1.451 [-100.000,  8.225], mean action: 1.678 [0.000, 3.000],  loss: 29.492006, mae: 161.316343, mean_q: 209.781670, mean_eps: 0.797470
  67661/300000: episode: 693, duration: 0.569s, episode steps:  90, steps per second: 158, episode reward: -102.050, mean reward: -1.134 [-100.000,  9.560], mean action: 1.656 [0.000, 3.000],  loss: 26.570539, mae: 163.392719, mean_q: 212.702078, mean_eps: 0.797154
  67745/300000: episode: 694, duration: 0.566s, episode steps:  84, steps per second: 148, episode reward: -114.382, mean reward: -1.362 [-100.000,  6.559], mean action: 1.512 [0.000, 3.000],  loss: 29.873288, mae: 161.099261, mean_q: 208.254618, mean_eps: 0.796893
  67917/300000: episode: 695, duration: 1.132s, episode steps: 172, steps per second: 152, episode reward: -363.061, mean reward: -2.111 [-100.000,  4.526], mean action: 1.616 [0.000, 3.000],  loss: 30.610275, mae: 164.306245, mean_q: 213.890296, mean_eps: 0.796508
  68021/300000: episode: 696, duration: 0.651s, episode steps: 104, steps per second: 160, episode reward: -124.598, mean reward: -1.198 [-100.000,  6.720], mean action: 1.548 [0.000, 3.000],  loss: 34.406512, mae: 163.362449, mean_q: 211.678115, mean_eps: 0.796095
  68107/300000: episode: 697, duration: 0.598s, episode steps:  86, steps per second: 144, episode reward: -29.723, mean reward: -0.346 [-100.000, 11.489], mean action: 1.616 [0.000, 3.000],  loss: 37.510583, mae: 165.319352, mean_q: 213.478910, mean_eps: 0.795810
  68255/300000: episode: 698, duration: 0.950s, episode steps: 148, steps per second: 156, episode reward: -126.357, mean reward: -0.854 [-100.000,  7.770], mean action: 1.716 [0.000, 3.000],  loss: 34.702882, mae: 163.853491, mean_q: 211.230400, mean_eps: 0.795458
  68344/300000: episode: 699, duration: 0.564s, episode steps:  89, steps per second: 158, episode reward: -108.798, mean reward: -1.222 [-100.000,  6.440], mean action: 1.596 [0.000, 3.000],  loss: 22.598429, mae: 163.765817, mean_q: 212.379912, mean_eps: 0.795103
  68475/300000: episode: 700, duration: 0.869s, episode steps: 131, steps per second: 151, episode reward: -196.774, mean reward: -1.502 [-100.000,  6.734], mean action: 1.573 [0.000, 3.000],  loss: 33.730841, mae: 162.933306, mean_q: 209.528601, mean_eps: 0.794773
  68550/300000: episode: 701, duration: 0.496s, episode steps:  75, steps per second: 151, episode reward: -44.905, mean reward: -0.599 [-100.000,  9.068], mean action: 1.520 [0.000, 3.000],  loss: 77.373749, mae: 161.632315, mean_q: 207.268830, mean_eps: 0.794464
  68662/300000: episode: 702, duration: 0.727s, episode steps: 112, steps per second: 154, episode reward: -104.140, mean reward: -0.930 [-100.000,  7.998], mean action: 1.750 [0.000, 3.000],  loss: 36.667887, mae: 161.633153, mean_q: 206.576188, mean_eps: 0.794184
  68783/300000: episode: 703, duration: 0.821s, episode steps: 121, steps per second: 147, episode reward: -66.101, mean reward: -0.546 [-100.000, 14.514], mean action: 1.479 [0.000, 3.000],  loss: 41.369760, mae: 162.442700, mean_q: 207.704348, mean_eps: 0.793834
  68863/300000: episode: 704, duration: 0.536s, episode steps:  80, steps per second: 149, episode reward: -49.414, mean reward: -0.618 [-100.000, 11.826], mean action: 1.775 [0.000, 3.000],  loss: 44.487598, mae: 163.504466, mean_q: 209.563269, mean_eps: 0.793532
  68958/300000: episode: 705, duration: 0.600s, episode steps:  95, steps per second: 158, episode reward: -96.573, mean reward: -1.017 [-100.000,  6.879], mean action: 1.726 [0.000, 3.000],  loss: 36.787920, mae: 164.424935, mean_q: 211.712099, mean_eps: 0.793270
  69079/300000: episode: 706, duration: 0.797s, episode steps: 121, steps per second: 152, episode reward: -68.019, mean reward: -0.562 [-100.000, 17.746], mean action: 1.653 [0.000, 3.000],  loss: 46.052025, mae: 164.733601, mean_q: 210.773125, mean_eps: 0.792946
  69198/300000: episode: 707, duration: 0.773s, episode steps: 119, steps per second: 154, episode reward: -132.541, mean reward: -1.114 [-100.000,  8.317], mean action: 1.513 [0.000, 3.000],  loss: 25.903491, mae: 162.473957, mean_q: 207.240020, mean_eps: 0.792586
  69327/300000: episode: 708, duration: 0.860s, episode steps: 129, steps per second: 150, episode reward: -134.272, mean reward: -1.041 [-100.000, 19.704], mean action: 1.512 [0.000, 3.000],  loss: 23.314884, mae: 165.196304, mean_q: 211.122496, mean_eps: 0.792214
  69433/300000: episode: 709, duration: 0.712s, episode steps: 106, steps per second: 149, episode reward: -127.227, mean reward: -1.200 [-100.000, 12.248], mean action: 1.708 [0.000, 3.000],  loss: 27.017799, mae: 165.590974, mean_q: 212.371718, mean_eps: 0.791861
  69614/300000: episode: 710, duration: 1.149s, episode steps: 181, steps per second: 158, episode reward: -292.661, mean reward: -1.617 [-100.000,  5.897], mean action: 1.718 [0.000, 3.000],  loss: 34.041820, mae: 165.118217, mean_q: 211.659940, mean_eps: 0.791431
  69691/300000: episode: 711, duration: 0.481s, episode steps:  77, steps per second: 160, episode reward: -90.975, mean reward: -1.181 [-100.000, 11.460], mean action: 1.442 [0.000, 3.000],  loss: 44.011860, mae: 163.750992, mean_q: 209.002872, mean_eps: 0.791044
  69769/300000: episode: 712, duration: 0.534s, episode steps:  78, steps per second: 146, episode reward: -106.376, mean reward: -1.364 [-100.000, 16.504], mean action: 1.641 [0.000, 3.000],  loss: 41.673150, mae: 165.267483, mean_q: 211.338457, mean_eps: 0.790812
  69873/300000: episode: 713, duration: 0.661s, episode steps: 104, steps per second: 157, episode reward: -148.126, mean reward: -1.424 [-100.000, 59.272], mean action: 1.606 [0.000, 3.000],  loss: 34.703250, mae: 167.925008, mean_q: 216.596606, mean_eps: 0.790539
  70048/300000: episode: 714, duration: 1.154s, episode steps: 175, steps per second: 152, episode reward: -212.289, mean reward: -1.213 [-100.000, 14.634], mean action: 1.640 [0.000, 3.000],  loss: 38.277068, mae: 165.660401, mean_q: 213.301761, mean_eps: 0.790120
  70119/300000: episode: 715, duration: 0.483s, episode steps:  71, steps per second: 147, episode reward: -95.144, mean reward: -1.340 [-100.000, 42.330], mean action: 1.746 [0.000, 3.000],  loss: 23.922482, mae: 166.384614, mean_q: 214.451798, mean_eps: 0.789751
  70201/300000: episode: 716, duration: 0.539s, episode steps:  82, steps per second: 152, episode reward: -120.908, mean reward: -1.474 [-100.000, 10.518], mean action: 1.744 [0.000, 3.000],  loss: 29.318998, mae: 164.679647, mean_q: 212.672598, mean_eps: 0.789521
  70318/300000: episode: 717, duration: 0.729s, episode steps: 117, steps per second: 161, episode reward: -123.507, mean reward: -1.056 [-100.000,  3.642], mean action: 1.470 [0.000, 3.000],  loss: 31.112891, mae: 165.397643, mean_q: 213.622055, mean_eps: 0.789223
  70413/300000: episode: 718, duration: 0.642s, episode steps:  95, steps per second: 148, episode reward: -7.767, mean reward: -0.082 [-100.000, 95.564], mean action: 1.453 [0.000, 3.000],  loss: 38.043198, mae: 166.780121, mean_q: 215.635144, mean_eps: 0.788905
  70492/300000: episode: 719, duration: 0.504s, episode steps:  79, steps per second: 157, episode reward: -146.349, mean reward: -1.853 [-100.000, 14.602], mean action: 1.506 [0.000, 3.000],  loss: 38.668053, mae: 167.213837, mean_q: 215.245182, mean_eps: 0.788644
  70634/300000: episode: 720, duration: 0.902s, episode steps: 142, steps per second: 157, episode reward: -186.150, mean reward: -1.311 [-100.000, 13.334], mean action: 1.549 [0.000, 3.000],  loss: 33.531216, mae: 165.360220, mean_q: 212.428385, mean_eps: 0.788312
  70719/300000: episode: 721, duration: 0.584s, episode steps:  85, steps per second: 145, episode reward: -48.712, mean reward: -0.573 [-100.000, 13.368], mean action: 1.553 [0.000, 3.000],  loss: 24.278409, mae: 168.748989, mean_q: 217.837740, mean_eps: 0.787972
  70804/300000: episode: 722, duration: 0.561s, episode steps:  85, steps per second: 152, episode reward: -141.154, mean reward: -1.661 [-100.000, 15.057], mean action: 1.412 [0.000, 3.000],  loss: 33.824396, mae: 168.144052, mean_q: 215.104452, mean_eps: 0.787717
  70870/300000: episode: 723, duration: 0.426s, episode steps:  66, steps per second: 155, episode reward: -149.912, mean reward: -2.271 [-100.000,  7.842], mean action: 1.576 [0.000, 3.000],  loss: 49.328378, mae: 166.617983, mean_q: 212.846254, mean_eps: 0.787491
  70948/300000: episode: 724, duration: 0.489s, episode steps:  78, steps per second: 159, episode reward: -96.496, mean reward: -1.237 [-100.000, 10.201], mean action: 1.590 [0.000, 3.000],  loss: 44.586024, mae: 166.825182, mean_q: 214.026823, mean_eps: 0.787274
  71099/300000: episode: 725, duration: 1.028s, episode steps: 151, steps per second: 147, episode reward: -110.200, mean reward: -0.730 [-100.000,  5.938], mean action: 1.563 [0.000, 3.000],  loss: 34.195947, mae: 167.900209, mean_q: 215.366768, mean_eps: 0.786931
  71222/300000: episode: 726, duration: 0.797s, episode steps: 123, steps per second: 154, episode reward: -104.152, mean reward: -0.847 [-100.000, 13.574], mean action: 1.756 [0.000, 3.000],  loss: 32.079178, mae: 169.116207, mean_q: 217.954832, mean_eps: 0.786520
  71365/300000: episode: 727, duration: 0.943s, episode steps: 143, steps per second: 152, episode reward: -147.966, mean reward: -1.035 [-100.000, 13.827], mean action: 1.573 [0.000, 3.000],  loss: 37.096915, mae: 168.734687, mean_q: 217.000756, mean_eps: 0.786121
  71521/300000: episode: 728, duration: 1.024s, episode steps: 156, steps per second: 152, episode reward: -209.730, mean reward: -1.344 [-100.000,  1.745], mean action: 1.506 [0.000, 3.000],  loss: 30.827469, mae: 167.268870, mean_q: 214.585052, mean_eps: 0.785672
  71644/300000: episode: 729, duration: 0.788s, episode steps: 123, steps per second: 156, episode reward: -83.091, mean reward: -0.676 [-100.000, 19.697], mean action: 1.593 [0.000, 3.000],  loss: 34.746332, mae: 169.876388, mean_q: 217.336102, mean_eps: 0.785254
  71792/300000: episode: 730, duration: 0.989s, episode steps: 148, steps per second: 150, episode reward: -301.231, mean reward: -2.035 [-100.000, 130.724], mean action: 1.547 [0.000, 3.000],  loss: 32.124281, mae: 168.041543, mean_q: 214.843626, mean_eps: 0.784848
  71884/300000: episode: 731, duration: 0.580s, episode steps:  92, steps per second: 159, episode reward: -87.537, mean reward: -0.951 [-100.000,  6.422], mean action: 1.620 [0.000, 3.000],  loss: 36.443953, mae: 166.790960, mean_q: 212.091086, mean_eps: 0.784488
  72005/300000: episode: 732, duration: 0.753s, episode steps: 121, steps per second: 161, episode reward: -194.429, mean reward: -1.607 [-100.000, 10.681], mean action: 1.603 [0.000, 3.000],  loss: 40.068602, mae: 164.436861, mean_q: 210.545870, mean_eps: 0.784168
  72111/300000: episode: 733, duration: 0.714s, episode steps: 106, steps per second: 148, episode reward: -30.524, mean reward: -0.288 [-100.000, 10.713], mean action: 1.698 [0.000, 3.000],  loss: 29.600314, mae: 163.953629, mean_q: 209.366702, mean_eps: 0.783827
  72224/300000: episode: 734, duration: 0.719s, episode steps: 113, steps per second: 157, episode reward: -64.440, mean reward: -0.570 [-100.000,  6.791], mean action: 1.504 [0.000, 3.000],  loss: 43.914815, mae: 164.074428, mean_q: 207.884141, mean_eps: 0.783499
  72325/300000: episode: 735, duration: 0.629s, episode steps: 101, steps per second: 161, episode reward: -108.769, mean reward: -1.077 [-100.000,  7.602], mean action: 1.673 [0.000, 3.000],  loss: 32.863965, mae: 163.119021, mean_q: 208.966970, mean_eps: 0.783178
  72419/300000: episode: 736, duration: 0.651s, episode steps:  94, steps per second: 144, episode reward: -91.837, mean reward: -0.977 [-100.000, 11.187], mean action: 1.681 [0.000, 3.000],  loss: 43.019863, mae: 163.588357, mean_q: 207.681676, mean_eps: 0.782885
  72514/300000: episode: 737, duration: 0.623s, episode steps:  95, steps per second: 152, episode reward: -52.999, mean reward: -0.558 [-100.000, 12.411], mean action: 1.474 [0.000, 3.000],  loss: 40.285443, mae: 163.984051, mean_q: 210.186356, mean_eps: 0.782602
  72627/300000: episode: 738, duration: 0.745s, episode steps: 113, steps per second: 152, episode reward: -90.269, mean reward: -0.799 [-100.000, 21.807], mean action: 1.593 [0.000, 3.000],  loss: 51.899317, mae: 163.476028, mean_q: 209.062327, mean_eps: 0.782290
  72758/300000: episode: 739, duration: 1.011s, episode steps: 131, steps per second: 130, episode reward: -131.741, mean reward: -1.006 [-100.000,  7.127], mean action: 1.573 [0.000, 3.000],  loss: 45.306314, mae: 166.064398, mean_q: 213.054978, mean_eps: 0.781924
  72830/300000: episode: 740, duration: 0.519s, episode steps:  72, steps per second: 139, episode reward: -166.125, mean reward: -2.307 [-100.000,  7.414], mean action: 1.542 [0.000, 3.000],  loss: 56.921436, mae: 168.527150, mean_q: 215.539835, mean_eps: 0.781619
  72937/300000: episode: 741, duration: 0.739s, episode steps: 107, steps per second: 145, episode reward: -177.540, mean reward: -1.659 [-100.000,  2.368], mean action: 1.813 [0.000, 3.000],  loss: 44.253346, mae: 166.418056, mean_q: 212.074730, mean_eps: 0.781351
  73029/300000: episode: 742, duration: 0.665s, episode steps:  92, steps per second: 138, episode reward: -369.478, mean reward: -4.016 [-100.000,  0.529], mean action: 1.641 [0.000, 3.000],  loss: 40.272224, mae: 167.328286, mean_q: 213.937258, mean_eps: 0.781053
  73149/300000: episode: 743, duration: 0.822s, episode steps: 120, steps per second: 146, episode reward: -213.504, mean reward: -1.779 [-100.000,  0.949], mean action: 1.633 [0.000, 3.000],  loss: 43.003010, mae: 170.357302, mean_q: 219.038234, mean_eps: 0.780734
  73288/300000: episode: 744, duration: 0.907s, episode steps: 139, steps per second: 153, episode reward: -247.173, mean reward: -1.778 [-100.000, 18.355], mean action: 1.719 [0.000, 3.000],  loss: 55.748793, mae: 174.879932, mean_q: 227.086066, mean_eps: 0.780346
  73381/300000: episode: 745, duration: 0.643s, episode steps:  93, steps per second: 145, episode reward: -82.017, mean reward: -0.882 [-100.000, 10.522], mean action: 1.409 [0.000, 3.000],  loss: 53.466342, mae: 173.365061, mean_q: 225.159842, mean_eps: 0.779998
  73472/300000: episode: 746, duration: 0.578s, episode steps:  91, steps per second: 157, episode reward: -175.615, mean reward: -1.930 [-100.000, 25.677], mean action: 1.670 [0.000, 3.000],  loss: 48.875555, mae: 175.656176, mean_q: 227.057541, mean_eps: 0.779722
  73607/300000: episode: 747, duration: 0.851s, episode steps: 135, steps per second: 159, episode reward: -145.544, mean reward: -1.078 [-100.000, 17.368], mean action: 1.637 [0.000, 3.000],  loss: 44.339498, mae: 176.033377, mean_q: 228.409372, mean_eps: 0.779383
  73705/300000: episode: 748, duration: 0.674s, episode steps:  98, steps per second: 145, episode reward: -367.810, mean reward: -3.753 [-100.000,  1.087], mean action: 1.520 [0.000, 3.000],  loss: 51.087185, mae: 176.965217, mean_q: 230.377515, mean_eps: 0.779033
  73887/300000: episode: 749, duration: 1.156s, episode steps: 182, steps per second: 157, episode reward: -53.439, mean reward: -0.294 [-100.000, 17.465], mean action: 1.555 [0.000, 3.000],  loss: 65.471433, mae: 181.666180, mean_q: 236.808562, mean_eps: 0.778613
  74036/300000: episode: 750, duration: 1.005s, episode steps: 149, steps per second: 148, episode reward: -145.251, mean reward: -0.975 [-100.000, 14.990], mean action: 1.523 [0.000, 3.000],  loss: 46.168179, mae: 186.119617, mean_q: 245.576691, mean_eps: 0.778117
  74156/300000: episode: 751, duration: 0.756s, episode steps: 120, steps per second: 159, episode reward: -147.399, mean reward: -1.228 [-100.000,  3.748], mean action: 1.475 [0.000, 3.000],  loss: 46.646447, mae: 189.563262, mean_q: 248.074052, mean_eps: 0.777714
  74313/300000: episode: 752, duration: 1.019s, episode steps: 157, steps per second: 154, episode reward: -253.439, mean reward: -1.614 [-100.000,  4.443], mean action: 1.529 [0.000, 3.000],  loss: 45.632128, mae: 190.372386, mean_q: 249.739112, mean_eps: 0.777298
  74435/300000: episode: 753, duration: 0.790s, episode steps: 122, steps per second: 154, episode reward: -70.561, mean reward: -0.578 [-100.000, 17.490], mean action: 1.557 [0.000, 3.000],  loss: 45.443299, mae: 188.690300, mean_q: 245.934492, mean_eps: 0.776879
  74551/300000: episode: 754, duration: 0.723s, episode steps: 116, steps per second: 160, episode reward: -140.845, mean reward: -1.214 [-100.000,  5.017], mean action: 1.552 [0.000, 3.000],  loss: 57.557718, mae: 189.857278, mean_q: 249.211653, mean_eps: 0.776523
  74655/300000: episode: 755, duration: 0.699s, episode steps: 104, steps per second: 149, episode reward: -173.549, mean reward: -1.669 [-100.000,  4.455], mean action: 1.817 [0.000, 3.000],  loss: 53.344930, mae: 195.283819, mean_q: 255.928162, mean_eps: 0.776192
  74799/300000: episode: 756, duration: 0.936s, episode steps: 144, steps per second: 154, episode reward: -218.248, mean reward: -1.516 [-100.000, 32.872], mean action: 1.292 [0.000, 3.000],  loss: 58.167553, mae: 197.115146, mean_q: 258.273569, mean_eps: 0.775820
  74939/300000: episode: 757, duration: 0.880s, episode steps: 140, steps per second: 159, episode reward: -265.664, mean reward: -1.898 [-100.000,  1.647], mean action: 1.764 [0.000, 3.000],  loss: 53.655891, mae: 207.179557, mean_q: 273.783744, mean_eps: 0.775394
  75016/300000: episode: 758, duration: 0.528s, episode steps:  77, steps per second: 146, episode reward: -55.096, mean reward: -0.716 [-100.000,  7.954], mean action: 1.636 [0.000, 3.000],  loss: 272.288654, mae: 207.848321, mean_q: 272.682607, mean_eps: 0.775069
  75096/300000: episode: 759, duration: 0.511s, episode steps:  80, steps per second: 157, episode reward: -71.522, mean reward: -0.894 [-100.000, 25.995], mean action: 1.562 [0.000, 3.000],  loss: 54.905718, mae: 210.613466, mean_q: 278.028854, mean_eps: 0.774834
  75178/300000: episode: 760, duration: 0.516s, episode steps:  82, steps per second: 159, episode reward: -201.793, mean reward: -2.461 [-100.000,  8.660], mean action: 1.671 [0.000, 3.000],  loss: 53.695007, mae: 211.505433, mean_q: 279.316553, mean_eps: 0.774590
  75321/300000: episode: 761, duration: 0.949s, episode steps: 143, steps per second: 151, episode reward: -45.913, mean reward: -0.321 [-100.000, 15.549], mean action: 1.657 [0.000, 3.000],  loss: 64.645822, mae: 214.544947, mean_q: 285.856767, mean_eps: 0.774253
  75409/300000: episode: 762, duration: 0.577s, episode steps:  88, steps per second: 152, episode reward: -98.522, mean reward: -1.120 [-100.000, 11.546], mean action: 1.625 [0.000, 3.000],  loss: 60.222919, mae: 218.649313, mean_q: 293.025134, mean_eps: 0.773906
  75544/300000: episode: 763, duration: 0.853s, episode steps: 135, steps per second: 158, episode reward: -61.111, mean reward: -0.453 [-100.000,  8.685], mean action: 1.496 [0.000, 3.000],  loss: 268.209285, mae: 224.919353, mean_q: 300.590620, mean_eps: 0.773572
  75750/300000: episode: 764, duration: 1.373s, episode steps: 206, steps per second: 150, episode reward: -130.217, mean reward: -0.632 [-100.000, 32.345], mean action: 1.607 [0.000, 3.000],  loss: 70.886578, mae: 228.649208, mean_q: 306.582962, mean_eps: 0.773060
  75850/300000: episode: 765, duration: 0.633s, episode steps: 100, steps per second: 158, episode reward: -76.047, mean reward: -0.760 [-100.000, 11.116], mean action: 1.500 [0.000, 3.000],  loss: 57.910558, mae: 225.788697, mean_q: 301.930574, mean_eps: 0.772602
  76009/300000: episode: 766, duration: 1.095s, episode steps: 159, steps per second: 145, episode reward: -285.564, mean reward: -1.796 [-100.000,  1.790], mean action: 1.572 [0.000, 3.000],  loss: 152.736168, mae: 236.874832, mean_q: 317.071979, mean_eps: 0.772213
  76167/300000: episode: 767, duration: 1.201s, episode steps: 158, steps per second: 132, episode reward: -245.689, mean reward: -1.555 [-100.000, 31.771], mean action: 1.563 [0.000, 3.000],  loss: 149.579146, mae: 238.260296, mean_q: 320.454380, mean_eps: 0.771738
  76300/300000: episode: 768, duration: 1.006s, episode steps: 133, steps per second: 132, episode reward: -290.941, mean reward: -2.188 [-100.000,  1.991], mean action: 1.579 [0.000, 3.000],  loss: 164.493984, mae: 248.402831, mean_q: 334.764503, mean_eps: 0.771301
  76399/300000: episode: 769, duration: 0.769s, episode steps:  99, steps per second: 129, episode reward: -271.482, mean reward: -2.742 [-100.000,  0.493], mean action: 1.747 [0.000, 3.000],  loss: 84.798947, mae: 254.647584, mean_q: 342.971655, mean_eps: 0.770953
  76563/300000: episode: 770, duration: 1.255s, episode steps: 164, steps per second: 131, episode reward: -333.853, mean reward: -2.036 [-100.000, 108.460], mean action: 1.677 [0.000, 3.000],  loss: 77.198514, mae: 259.324378, mean_q: 348.718259, mean_eps: 0.770558
  76654/300000: episode: 771, duration: 0.667s, episode steps:  91, steps per second: 136, episode reward: -143.189, mean reward: -1.574 [-100.000,  9.296], mean action: 1.538 [0.000, 3.000],  loss: 189.107102, mae: 251.100584, mean_q: 336.311540, mean_eps: 0.770176
  76867/300000: episode: 772, duration: 1.543s, episode steps: 213, steps per second: 138, episode reward: -142.390, mean reward: -0.668 [-100.000,  9.810], mean action: 1.662 [0.000, 3.000],  loss: 117.273538, mae: 260.823187, mean_q: 349.440461, mean_eps: 0.769720
  76987/300000: episode: 773, duration: 0.802s, episode steps: 120, steps per second: 150, episode reward: -79.413, mean reward: -0.662 [-100.000,  8.513], mean action: 1.575 [0.000, 3.000],  loss: 151.086039, mae: 270.193853, mean_q: 363.001167, mean_eps: 0.769221
  77055/300000: episode: 774, duration: 0.431s, episode steps:  68, steps per second: 158, episode reward: -53.901, mean reward: -0.793 [-100.000, 11.178], mean action: 1.588 [0.000, 3.000],  loss: 83.032871, mae: 268.818204, mean_q: 360.204123, mean_eps: 0.768939
  77174/300000: episode: 775, duration: 0.794s, episode steps: 119, steps per second: 150, episode reward: -354.786, mean reward: -2.981 [-100.000,  1.686], mean action: 1.731 [0.000, 3.000],  loss: 155.732246, mae: 274.037753, mean_q: 367.639618, mean_eps: 0.768658
  77248/300000: episode: 776, duration: 0.487s, episode steps:  74, steps per second: 152, episode reward: -98.479, mean reward: -1.331 [-100.000, 10.119], mean action: 1.324 [0.000, 3.000],  loss: 854.720393, mae: 288.779513, mean_q: 387.792105, mean_eps: 0.768369
  77326/300000: episode: 777, duration: 0.494s, episode steps:  78, steps per second: 158, episode reward: -33.212, mean reward: -0.426 [-100.000,  8.666], mean action: 1.462 [0.000, 3.000],  loss: 128.939433, mae: 288.856015, mean_q: 386.626663, mean_eps: 0.768141
  77520/300000: episode: 778, duration: 1.285s, episode steps: 194, steps per second: 151, episode reward: -117.787, mean reward: -0.607 [-100.000,  6.379], mean action: 1.541 [0.000, 3.000],  loss: 666.007430, mae: 295.773404, mean_q: 396.026558, mean_eps: 0.767733
  77600/300000: episode: 779, duration: 0.522s, episode steps:  80, steps per second: 153, episode reward: -115.825, mean reward: -1.448 [-100.000,  8.744], mean action: 1.688 [0.000, 3.000],  loss: 156.573691, mae: 297.945610, mean_q: 400.696074, mean_eps: 0.767321
  77701/300000: episode: 780, duration: 0.655s, episode steps: 101, steps per second: 154, episode reward: -194.410, mean reward: -1.925 [-100.000, 24.996], mean action: 1.366 [0.000, 3.000],  loss: 148.348508, mae: 297.482276, mean_q: 399.645118, mean_eps: 0.767050
  77812/300000: episode: 781, duration: 0.723s, episode steps: 111, steps per second: 153, episode reward: -97.544, mean reward: -0.879 [-100.000,  7.001], mean action: 1.577 [0.000, 3.000],  loss: 71.759257, mae: 303.933623, mean_q: 409.540498, mean_eps: 0.766732
  77948/300000: episode: 782, duration: 0.905s, episode steps: 136, steps per second: 150, episode reward: -87.661, mean reward: -0.645 [-100.000, 11.567], mean action: 1.662 [0.000, 3.000],  loss: 92.545441, mae: 305.789887, mean_q: 409.420437, mean_eps: 0.766361
  78050/300000: episode: 783, duration: 0.643s, episode steps: 102, steps per second: 159, episode reward: -248.403, mean reward: -2.435 [-100.000,  1.034], mean action: 1.667 [0.000, 3.000],  loss: 143.459422, mae: 307.153804, mean_q: 411.650495, mean_eps: 0.766005
  78150/300000: episode: 784, duration: 0.709s, episode steps: 100, steps per second: 141, episode reward: -110.238, mean reward: -1.102 [-100.000, 20.134], mean action: 1.610 [0.000, 3.000],  loss: 570.654534, mae: 312.999152, mean_q: 418.728532, mean_eps: 0.765702
  78215/300000: episode: 785, duration: 0.440s, episode steps:  65, steps per second: 148, episode reward: -92.178, mean reward: -1.418 [-100.000, 12.538], mean action: 1.523 [0.000, 3.000],  loss: 860.674922, mae: 320.609854, mean_q: 429.106167, mean_eps: 0.765454
  78334/300000: episode: 786, duration: 0.925s, episode steps: 119, steps per second: 129, episode reward: -198.873, mean reward: -1.671 [-100.000, 14.542], mean action: 1.563 [0.000, 3.000],  loss: 86.352157, mae: 324.742240, mean_q: 440.171909, mean_eps: 0.765178
  78497/300000: episode: 787, duration: 1.209s, episode steps: 163, steps per second: 135, episode reward: -118.511, mean reward: -0.727 [-100.000,  9.752], mean action: 1.730 [0.000, 3.000],  loss: 119.103382, mae: 326.859953, mean_q: 443.593268, mean_eps: 0.764755
  78606/300000: episode: 788, duration: 0.700s, episode steps: 109, steps per second: 156, episode reward: -74.979, mean reward: -0.688 [-100.000, 12.927], mean action: 1.477 [0.000, 3.000],  loss: 123.419971, mae: 339.652509, mean_q: 462.235680, mean_eps: 0.764347
  78707/300000: episode: 789, duration: 0.660s, episode steps: 101, steps per second: 153, episode reward: -298.584, mean reward: -2.956 [-100.000,  1.097], mean action: 1.792 [0.000, 3.000],  loss: 456.347445, mae: 341.013390, mean_q: 461.229568, mean_eps: 0.764032
  78775/300000: episode: 790, duration: 0.469s, episode steps:  68, steps per second: 145, episode reward: -116.945, mean reward: -1.720 [-100.000,  8.215], mean action: 1.691 [0.000, 3.000],  loss: 104.709939, mae: 349.320318, mean_q: 473.775471, mean_eps: 0.763778
  78879/300000: episode: 791, duration: 0.681s, episode steps: 104, steps per second: 153, episode reward: -204.998, mean reward: -1.971 [-100.000,  3.095], mean action: 1.702 [0.000, 3.000],  loss: 409.464156, mae: 351.155287, mean_q: 476.830541, mean_eps: 0.763521
  79016/300000: episode: 792, duration: 0.871s, episode steps: 137, steps per second: 157, episode reward: -30.916, mean reward: -0.226 [-100.000, 13.339], mean action: 1.591 [0.000, 3.000],  loss: 467.078193, mae: 351.526205, mean_q: 478.120709, mean_eps: 0.763159
  79152/300000: episode: 793, duration: 0.930s, episode steps: 136, steps per second: 146, episode reward: -295.242, mean reward: -2.171 [-100.000,  1.107], mean action: 1.684 [0.000, 3.000],  loss: 217.215818, mae: 354.354077, mean_q: 481.390236, mean_eps: 0.762749
  79293/300000: episode: 794, duration: 0.910s, episode steps: 141, steps per second: 155, episode reward: -76.217, mean reward: -0.541 [-100.000,  9.186], mean action: 1.652 [0.000, 3.000],  loss: 349.862475, mae: 357.145192, mean_q: 485.734781, mean_eps: 0.762334
  79409/300000: episode: 795, duration: 0.754s, episode steps: 116, steps per second: 154, episode reward: -68.535, mean reward: -0.591 [-100.000,  9.416], mean action: 1.552 [0.000, 3.000],  loss: 85.179393, mae: 365.464045, mean_q: 497.545251, mean_eps: 0.761949
  79481/300000: episode: 796, duration: 0.489s, episode steps:  72, steps per second: 147, episode reward: -211.147, mean reward: -2.933 [-100.000,  7.624], mean action: 1.431 [0.000, 3.000],  loss: 86.730783, mae: 371.690573, mean_q: 507.042206, mean_eps: 0.761667
  79612/300000: episode: 797, duration: 0.843s, episode steps: 131, steps per second: 155, episode reward: -110.383, mean reward: -0.843 [-100.000, 10.320], mean action: 1.489 [0.000, 3.000],  loss: 83.782764, mae: 362.927363, mean_q: 492.846241, mean_eps: 0.761362
  79710/300000: episode: 798, duration: 0.618s, episode steps:  98, steps per second: 159, episode reward: -254.574, mean reward: -2.598 [-100.000, 73.793], mean action: 1.633 [0.000, 3.000],  loss: 77.925529, mae: 371.635956, mean_q: 505.529634, mean_eps: 0.761019
  79848/300000: episode: 799, duration: 0.919s, episode steps: 138, steps per second: 150, episode reward: -141.107, mean reward: -1.023 [-100.000,  6.554], mean action: 1.696 [0.000, 3.000],  loss: 104.902301, mae: 374.169512, mean_q: 509.627673, mean_eps: 0.760664
  79962/300000: episode: 800, duration: 0.728s, episode steps: 114, steps per second: 157, episode reward: -179.600, mean reward: -1.575 [-100.000,  3.201], mean action: 1.667 [0.000, 3.000],  loss: 107.228020, mae: 374.912006, mean_q: 508.226275, mean_eps: 0.760286
  80077/300000: episode: 801, duration: 0.761s, episode steps: 115, steps per second: 151, episode reward: -240.307, mean reward: -2.090 [-100.000,  4.787], mean action: 1.583 [0.000, 3.000],  loss: 231.447128, mae: 387.186846, mean_q: 527.102140, mean_eps: 0.759943
  80196/300000: episode: 802, duration: 0.782s, episode steps: 119, steps per second: 152, episode reward: -289.666, mean reward: -2.434 [-100.000, 63.187], mean action: 1.513 [0.000, 3.000],  loss: 300.447669, mae: 383.255047, mean_q: 518.903712, mean_eps: 0.759592
  80347/300000: episode: 803, duration: 0.955s, episode steps: 151, steps per second: 158, episode reward: -400.307, mean reward: -2.651 [-100.000,  1.890], mean action: 1.709 [0.000, 3.000],  loss: 208.124731, mae: 393.097079, mean_q: 532.247015, mean_eps: 0.759187
  80463/300000: episode: 804, duration: 0.781s, episode steps: 116, steps per second: 149, episode reward: -94.961, mean reward: -0.819 [-100.000,  7.491], mean action: 1.759 [0.000, 3.000],  loss: 167.610568, mae: 396.863639, mean_q: 537.538757, mean_eps: 0.758787
  80619/300000: episode: 805, duration: 1.002s, episode steps: 156, steps per second: 156, episode reward: -542.481, mean reward: -3.477 [-100.000, 100.705], mean action: 1.635 [0.000, 3.000],  loss: 144.534962, mae: 395.081045, mean_q: 534.518363, mean_eps: 0.758379
  80705/300000: episode: 806, duration: 0.562s, episode steps:  86, steps per second: 153, episode reward: -85.587, mean reward: -0.995 [-100.000, 11.734], mean action: 1.570 [0.000, 3.000],  loss: 86.093101, mae: 400.919687, mean_q: 541.956863, mean_eps: 0.758015
  80787/300000: episode: 807, duration: 0.564s, episode steps:  82, steps per second: 145, episode reward: -73.078, mean reward: -0.891 [-100.000,  7.191], mean action: 1.463 [0.000, 3.000],  loss: 88.940166, mae: 404.338211, mean_q: 547.303791, mean_eps: 0.757763
  80997/300000: episode: 808, duration: 1.339s, episode steps: 210, steps per second: 157, episode reward: -88.898, mean reward: -0.423 [-100.000,  6.606], mean action: 1.686 [0.000, 3.000],  loss: 163.791116, mae: 404.273480, mean_q: 545.655052, mean_eps: 0.757325
  81117/300000: episode: 809, duration: 0.792s, episode steps: 120, steps per second: 152, episode reward: -252.138, mean reward: -2.101 [-100.000,  1.677], mean action: 1.542 [0.000, 3.000],  loss: 144.595426, mae: 416.429560, mean_q: 562.917096, mean_eps: 0.756830
  81185/300000: episode: 810, duration: 0.448s, episode steps:  68, steps per second: 152, episode reward: -90.122, mean reward: -1.325 [-100.000,  7.026], mean action: 1.735 [0.000, 3.000],  loss: 106.836994, mae: 411.307047, mean_q: 556.352254, mean_eps: 0.756548
  81287/300000: episode: 811, duration: 0.642s, episode steps: 102, steps per second: 159, episode reward: -194.106, mean reward: -1.903 [-100.000,  2.065], mean action: 1.510 [0.000, 3.000],  loss: 85.855602, mae: 420.921138, mean_q: 568.397616, mean_eps: 0.756293
  81388/300000: episode: 812, duration: 0.637s, episode steps: 101, steps per second: 159, episode reward: -140.492, mean reward: -1.391 [-100.000,  3.279], mean action: 1.564 [0.000, 3.000],  loss: 74.072254, mae: 423.187397, mean_q: 573.043906, mean_eps: 0.755989
  81467/300000: episode: 813, duration: 0.551s, episode steps:  79, steps per second: 143, episode reward: -44.168, mean reward: -0.559 [-100.000,  8.441], mean action: 1.608 [0.000, 3.000],  loss: 83.654412, mae: 430.160763, mean_q: 580.902778, mean_eps: 0.755719
  81578/300000: episode: 814, duration: 0.703s, episode steps: 111, steps per second: 158, episode reward: -192.160, mean reward: -1.731 [-100.000,  8.792], mean action: 1.486 [0.000, 3.000],  loss: 83.423265, mae: 429.186486, mean_q: 579.046053, mean_eps: 0.755434
  81710/300000: episode: 815, duration: 0.837s, episode steps: 132, steps per second: 158, episode reward: -237.017, mean reward: -1.796 [-100.000,  2.188], mean action: 1.659 [0.000, 3.000],  loss: 78.982340, mae: 426.049427, mean_q: 574.889950, mean_eps: 0.755069
  81792/300000: episode: 816, duration: 0.574s, episode steps:  82, steps per second: 143, episode reward: -82.507, mean reward: -1.006 [-100.000, 86.882], mean action: 1.671 [0.000, 3.000],  loss: 134.806415, mae: 429.892230, mean_q: 580.110274, mean_eps: 0.754748
  81889/300000: episode: 817, duration: 0.616s, episode steps:  97, steps per second: 157, episode reward: -37.253, mean reward: -0.384 [-100.000, 10.930], mean action: 1.495 [0.000, 3.000],  loss: 78.834778, mae: 429.539123, mean_q: 580.830110, mean_eps: 0.754480
  81983/300000: episode: 818, duration: 0.593s, episode steps:  94, steps per second: 159, episode reward: -340.872, mean reward: -3.626 [-100.000, 14.488], mean action: 1.585 [0.000, 3.000],  loss: 108.004660, mae: 428.746712, mean_q: 577.503996, mean_eps: 0.754193
  82113/300000: episode: 819, duration: 0.891s, episode steps: 130, steps per second: 146, episode reward: -122.127, mean reward: -0.939 [-100.000, 12.100], mean action: 1.662 [0.000, 3.000],  loss: 92.298273, mae: 434.701408, mean_q: 586.318050, mean_eps: 0.753857
  82311/300000: episode: 820, duration: 1.264s, episode steps: 198, steps per second: 157, episode reward: -36.977, mean reward: -0.187 [-100.000, 97.868], mean action: 1.566 [0.000, 3.000],  loss: 108.888582, mae: 440.764009, mean_q: 595.427352, mean_eps: 0.753365
  82377/300000: episode: 821, duration: 0.426s, episode steps:  66, steps per second: 155, episode reward: -109.106, mean reward: -1.653 [-100.000,  6.815], mean action: 1.576 [0.000, 3.000],  loss: 85.928282, mae: 443.267302, mean_q: 597.255257, mean_eps: 0.752970
  82445/300000: episode: 822, duration: 0.487s, episode steps:  68, steps per second: 140, episode reward: -82.370, mean reward: -1.211 [-100.000, 15.699], mean action: 1.500 [0.000, 3.000],  loss: 104.325590, mae: 427.350533, mean_q: 576.499239, mean_eps: 0.752768
  82508/300000: episode: 823, duration: 0.472s, episode steps:  63, steps per second: 134, episode reward: -35.246, mean reward: -0.559 [-100.000, 12.514], mean action: 1.683 [0.000, 3.000],  loss: 119.064524, mae: 438.652615, mean_q: 591.628710, mean_eps: 0.752572
  82578/300000: episode: 824, duration: 0.501s, episode steps:  70, steps per second: 140, episode reward: -141.473, mean reward: -2.021 [-100.000, 16.406], mean action: 1.529 [0.000, 3.000],  loss: 99.624500, mae: 444.785294, mean_q: 598.942065, mean_eps: 0.752372
  82692/300000: episode: 825, duration: 0.805s, episode steps: 114, steps per second: 142, episode reward: -161.239, mean reward: -1.414 [-100.000,  2.278], mean action: 1.632 [0.000, 3.000],  loss: 124.060482, mae: 445.283412, mean_q: 601.751780, mean_eps: 0.752096
  82857/300000: episode: 826, duration: 1.154s, episode steps: 165, steps per second: 143, episode reward: -177.125, mean reward: -1.073 [-100.000,  9.170], mean action: 1.709 [0.000, 3.000],  loss: 85.432540, mae: 442.456000, mean_q: 596.450873, mean_eps: 0.751678
  83016/300000: episode: 827, duration: 1.097s, episode steps: 159, steps per second: 145, episode reward: -117.720, mean reward: -0.740 [-100.000,  9.146], mean action: 1.623 [0.000, 3.000],  loss: 97.475802, mae: 446.595545, mean_q: 603.303713, mean_eps: 0.751192
  83110/300000: episode: 828, duration: 0.630s, episode steps:  94, steps per second: 149, episode reward: -50.278, mean reward: -0.535 [-100.000,  8.069], mean action: 1.553 [0.000, 3.000],  loss: 90.577751, mae: 443.962730, mean_q: 599.122248, mean_eps: 0.750813
  83252/300000: episode: 829, duration: 0.899s, episode steps: 142, steps per second: 158, episode reward: -242.825, mean reward: -1.710 [-100.000,  1.432], mean action: 1.599 [0.000, 3.000],  loss: 95.536655, mae: 456.498489, mean_q: 616.353485, mean_eps: 0.750459
  83373/300000: episode: 830, duration: 0.805s, episode steps: 121, steps per second: 150, episode reward: 36.484, mean reward:  0.302 [-100.000, 17.898], mean action: 1.653 [0.000, 3.000],  loss: 75.401134, mae: 453.664231, mean_q: 611.440069, mean_eps: 0.750064
  83468/300000: episode: 831, duration: 0.623s, episode steps:  95, steps per second: 153, episode reward: -215.611, mean reward: -2.270 [-100.000,  7.197], mean action: 1.474 [0.000, 3.000],  loss: 76.445329, mae: 460.546938, mean_q: 622.238875, mean_eps: 0.749740
  83561/300000: episode: 832, duration: 0.592s, episode steps:  93, steps per second: 157, episode reward: -182.386, mean reward: -1.961 [-100.000, 33.187], mean action: 1.548 [0.000, 3.000],  loss: 98.818126, mae: 470.269915, mean_q: 633.867440, mean_eps: 0.749458
  83686/300000: episode: 833, duration: 0.810s, episode steps: 125, steps per second: 154, episode reward: -158.234, mean reward: -1.266 [-100.000,  3.140], mean action: 1.792 [0.000, 3.000],  loss: 79.347905, mae: 458.538371, mean_q: 617.697168, mean_eps: 0.749131
  83828/300000: episode: 834, duration: 0.934s, episode steps: 142, steps per second: 152, episode reward: -98.321, mean reward: -0.692 [-100.000,  5.623], mean action: 1.697 [0.000, 3.000],  loss: 94.997531, mae: 466.824374, mean_q: 629.447100, mean_eps: 0.748731
  83914/300000: episode: 835, duration: 0.551s, episode steps:  86, steps per second: 156, episode reward: -65.179, mean reward: -0.758 [-100.000, 21.849], mean action: 1.605 [0.000, 3.000],  loss: 81.612002, mae: 458.086496, mean_q: 617.744116, mean_eps: 0.748388
  83998/300000: episode: 836, duration: 0.533s, episode steps:  84, steps per second: 157, episode reward: -88.448, mean reward: -1.053 [-100.000,  6.390], mean action: 1.786 [0.000, 3.000],  loss: 74.087445, mae: 469.177624, mean_q: 635.403163, mean_eps: 0.748134
  84095/300000: episode: 837, duration: 0.657s, episode steps:  97, steps per second: 148, episode reward: -12.363, mean reward: -0.127 [-100.000, 46.986], mean action: 1.433 [0.000, 3.000],  loss: 93.484774, mae: 463.984032, mean_q: 626.610967, mean_eps: 0.747862
  84236/300000: episode: 838, duration: 0.892s, episode steps: 141, steps per second: 158, episode reward: -279.698, mean reward: -1.984 [-100.000, 86.914], mean action: 1.553 [0.000, 3.000],  loss: 98.176423, mae: 457.854373, mean_q: 618.886131, mean_eps: 0.747505
  84343/300000: episode: 839, duration: 0.708s, episode steps: 107, steps per second: 151, episode reward: -88.713, mean reward: -0.829 [-100.000,  5.756], mean action: 1.486 [0.000, 3.000],  loss: 83.971745, mae: 463.414335, mean_q: 625.790040, mean_eps: 0.747133
  84504/300000: episode: 840, duration: 1.060s, episode steps: 161, steps per second: 152, episode reward: -235.742, mean reward: -1.464 [-100.000,  6.375], mean action: 1.652 [0.000, 3.000],  loss: 86.310944, mae: 463.997212, mean_q: 627.008096, mean_eps: 0.746731
  84579/300000: episode: 841, duration: 0.467s, episode steps:  75, steps per second: 160, episode reward: -108.146, mean reward: -1.442 [-100.000,  9.556], mean action: 1.693 [0.000, 3.000],  loss: 80.985942, mae: 459.691178, mean_q: 621.740043, mean_eps: 0.746377
  84714/300000: episode: 842, duration: 0.908s, episode steps: 135, steps per second: 149, episode reward: -11.056, mean reward: -0.082 [-100.000, 38.514], mean action: 1.696 [0.000, 3.000],  loss: 93.023289, mae: 469.887597, mean_q: 636.314458, mean_eps: 0.746062
  84806/300000: episode: 843, duration: 0.602s, episode steps:  92, steps per second: 153, episode reward: -232.859, mean reward: -2.531 [-100.000, 102.439], mean action: 1.685 [0.000, 3.000],  loss: 82.925252, mae: 460.298982, mean_q: 623.235752, mean_eps: 0.745722
  84932/300000: episode: 844, duration: 0.797s, episode steps: 126, steps per second: 158, episode reward: -94.771, mean reward: -0.752 [-100.000, 13.540], mean action: 1.571 [0.000, 3.000],  loss: 84.279885, mae: 470.483754, mean_q: 636.636419, mean_eps: 0.745395
  85139/300000: episode: 845, duration: 1.366s, episode steps: 207, steps per second: 152, episode reward: -171.172, mean reward: -0.827 [-100.000,  6.017], mean action: 1.686 [0.000, 3.000],  loss: 101.749629, mae: 479.496736, mean_q: 649.477295, mean_eps: 0.744895
  85245/300000: episode: 846, duration: 0.679s, episode steps: 106, steps per second: 156, episode reward: -141.005, mean reward: -1.330 [-100.000, 10.484], mean action: 1.604 [0.000, 3.000],  loss: 87.385465, mae: 477.745812, mean_q: 648.035527, mean_eps: 0.744426
  85325/300000: episode: 847, duration: 0.515s, episode steps:  80, steps per second: 155, episode reward: -41.655, mean reward: -0.521 [-100.000, 11.819], mean action: 1.538 [0.000, 3.000],  loss: 87.858068, mae: 486.205551, mean_q: 657.770564, mean_eps: 0.744147
  85421/300000: episode: 848, duration: 0.649s, episode steps:  96, steps per second: 148, episode reward: -437.329, mean reward: -4.556 [-100.000, 80.255], mean action: 1.323 [0.000, 3.000],  loss: 86.156585, mae: 476.185857, mean_q: 644.254534, mean_eps: 0.743882
  85616/300000: episode: 849, duration: 1.234s, episode steps: 195, steps per second: 158, episode reward: -74.813, mean reward: -0.384 [-100.000,  9.536], mean action: 1.651 [0.000, 3.000],  loss: 82.555460, mae: 482.822311, mean_q: 652.027965, mean_eps: 0.743446
  85731/300000: episode: 850, duration: 0.788s, episode steps: 115, steps per second: 146, episode reward: -170.898, mean reward: -1.486 [-100.000, 29.781], mean action: 1.635 [0.000, 3.000],  loss: 84.547720, mae: 488.953467, mean_q: 659.972304, mean_eps: 0.742981
  85831/300000: episode: 851, duration: 0.632s, episode steps: 100, steps per second: 158, episode reward: -429.916, mean reward: -4.299 [-100.000, 59.508], mean action: 1.430 [0.000, 3.000],  loss: 82.218398, mae: 472.009586, mean_q: 636.078678, mean_eps: 0.742658
  85934/300000: episode: 852, duration: 0.653s, episode steps: 103, steps per second: 158, episode reward: -132.129, mean reward: -1.283 [-100.000,  9.049], mean action: 1.573 [0.000, 3.000],  loss: 85.540164, mae: 480.924448, mean_q: 647.033019, mean_eps: 0.742354
  86037/300000: episode: 853, duration: 0.676s, episode steps: 103, steps per second: 152, episode reward: -268.531, mean reward: -2.607 [-100.000, 86.639], mean action: 1.767 [0.000, 3.000],  loss: 84.849783, mae: 486.995639, mean_q: 656.597421, mean_eps: 0.742045
  86248/300000: episode: 854, duration: 1.514s, episode steps: 211, steps per second: 139, episode reward: -103.903, mean reward: -0.492 [-100.000, 31.726], mean action: 1.578 [0.000, 3.000],  loss: 86.486995, mae: 482.017575, mean_q: 648.914138, mean_eps: 0.741574
  86347/300000: episode: 855, duration: 0.779s, episode steps:  99, steps per second: 127, episode reward:  4.899, mean reward:  0.049 [-100.000, 22.082], mean action: 1.606 [0.000, 3.000],  loss: 86.409968, mae: 484.609754, mean_q: 653.551529, mean_eps: 0.741109
  86428/300000: episode: 856, duration: 0.589s, episode steps:  81, steps per second: 138, episode reward: -164.986, mean reward: -2.037 [-100.000, 28.932], mean action: 1.469 [0.000, 3.000],  loss: 76.620645, mae: 487.391469, mean_q: 657.012246, mean_eps: 0.740839
  86598/300000: episode: 857, duration: 1.201s, episode steps: 170, steps per second: 142, episode reward: -82.319, mean reward: -0.484 [-100.000,  8.616], mean action: 1.629 [0.000, 3.000],  loss: 78.195134, mae: 478.767722, mean_q: 645.209700, mean_eps: 0.740463
  86704/300000: episode: 858, duration: 0.778s, episode steps: 106, steps per second: 136, episode reward: -113.537, mean reward: -1.071 [-100.000, 11.745], mean action: 1.453 [0.000, 3.000],  loss: 83.568970, mae: 473.209983, mean_q: 637.998939, mean_eps: 0.740049
  86824/300000: episode: 859, duration: 0.816s, episode steps: 120, steps per second: 147, episode reward: -122.806, mean reward: -1.023 [-100.000, 13.258], mean action: 1.758 [0.000, 3.000],  loss: 77.587621, mae: 473.200351, mean_q: 637.347225, mean_eps: 0.739710
  86962/300000: episode: 860, duration: 0.923s, episode steps: 138, steps per second: 149, episode reward: -155.196, mean reward: -1.125 [-100.000, 28.291], mean action: 1.536 [0.000, 3.000],  loss: 88.143639, mae: 470.070442, mean_q: 632.867465, mean_eps: 0.739322
  87069/300000: episode: 861, duration: 0.794s, episode steps: 107, steps per second: 135, episode reward: -173.474, mean reward: -1.621 [-100.000,  7.364], mean action: 1.551 [0.000, 3.000],  loss: 86.681343, mae: 469.885747, mean_q: 633.026028, mean_eps: 0.738955
  87157/300000: episode: 862, duration: 0.593s, episode steps:  88, steps per second: 149, episode reward: -82.902, mean reward: -0.942 [-100.000, 23.172], mean action: 1.386 [0.000, 3.000],  loss: 82.938782, mae: 481.324847, mean_q: 648.567121, mean_eps: 0.738662
  87270/300000: episode: 863, duration: 0.756s, episode steps: 113, steps per second: 149, episode reward: -93.483, mean reward: -0.827 [-100.000, 81.005], mean action: 1.531 [0.000, 3.000],  loss: 74.926751, mae: 476.914327, mean_q: 641.860633, mean_eps: 0.738361
  87378/300000: episode: 864, duration: 0.699s, episode steps: 108, steps per second: 155, episode reward: -106.663, mean reward: -0.988 [-100.000, 11.068], mean action: 1.704 [0.000, 3.000],  loss: 77.886622, mae: 463.294188, mean_q: 622.538645, mean_eps: 0.738029
  88378/300000: episode: 865, duration: 7.410s, episode steps: 1000, steps per second: 135, episode reward: 74.745, mean reward:  0.075 [-24.784, 26.440], mean action: 1.683 [0.000, 3.000],  loss: 109.759903, mae: 452.608567, mean_q: 608.443814, mean_eps: 0.736367
  88482/300000: episode: 866, duration: 0.700s, episode steps: 104, steps per second: 149, episode reward: -148.531, mean reward: -1.428 [-100.000, 10.636], mean action: 1.827 [0.000, 3.000],  loss: 91.605788, mae: 437.441576, mean_q: 588.467424, mean_eps: 0.734712
  88632/300000: episode: 867, duration: 0.950s, episode steps: 150, steps per second: 158, episode reward: -92.488, mean reward: -0.617 [-100.000,  6.661], mean action: 1.627 [0.000, 3.000],  loss: 114.000955, mae: 437.210814, mean_q: 586.717241, mean_eps: 0.734330
  88715/300000: episode: 868, duration: 0.533s, episode steps:  83, steps per second: 156, episode reward: -58.388, mean reward: -0.703 [-100.000, 21.514], mean action: 1.651 [0.000, 3.000],  loss: 90.613299, mae: 444.106256, mean_q: 597.636907, mean_eps: 0.733981
  88859/300000: episode: 869, duration: 0.962s, episode steps: 144, steps per second: 150, episode reward: -30.307, mean reward: -0.210 [-100.000, 108.940], mean action: 1.632 [0.000, 3.000],  loss: 93.800869, mae: 434.170219, mean_q: 582.740797, mean_eps: 0.733641
  88960/300000: episode: 870, duration: 0.632s, episode steps: 101, steps per second: 160, episode reward: -35.370, mean reward: -0.350 [-100.000, 10.023], mean action: 1.644 [0.000, 3.000],  loss: 93.352415, mae: 436.170186, mean_q: 584.709085, mean_eps: 0.733273
  89058/300000: episode: 871, duration: 0.626s, episode steps:  98, steps per second: 157, episode reward: -141.436, mean reward: -1.443 [-100.000, 31.857], mean action: 1.745 [0.000, 3.000],  loss: 88.771163, mae: 424.293109, mean_q: 568.013458, mean_eps: 0.732974
  89193/300000: episode: 872, duration: 0.918s, episode steps: 135, steps per second: 147, episode reward: -87.572, mean reward: -0.649 [-100.000,  9.034], mean action: 1.533 [0.000, 3.000],  loss: 86.789198, mae: 426.631988, mean_q: 570.475248, mean_eps: 0.732625
  89367/300000: episode: 873, duration: 1.130s, episode steps: 174, steps per second: 154, episode reward: -73.590, mean reward: -0.423 [-100.000, 12.954], mean action: 1.638 [0.000, 3.000],  loss: 93.020492, mae: 430.809495, mean_q: 576.976308, mean_eps: 0.732162
  89475/300000: episode: 874, duration: 0.733s, episode steps: 108, steps per second: 147, episode reward: -93.893, mean reward: -0.869 [-100.000, 32.574], mean action: 1.565 [0.000, 3.000],  loss: 91.439035, mae: 432.247999, mean_q: 581.131429, mean_eps: 0.731739
  89593/300000: episode: 875, duration: 0.755s, episode steps: 118, steps per second: 156, episode reward: -149.354, mean reward: -1.266 [-100.000,  7.347], mean action: 1.602 [0.000, 3.000],  loss: 99.825877, mae: 431.922658, mean_q: 578.186154, mean_eps: 0.731400
  89678/300000: episode: 876, duration: 0.539s, episode steps:  85, steps per second: 158, episode reward: -37.279, mean reward: -0.439 [-100.000, 28.694], mean action: 1.741 [0.000, 3.000],  loss: 111.206463, mae: 429.083822, mean_q: 575.061600, mean_eps: 0.731095
  89760/300000: episode: 877, duration: 0.567s, episode steps:  82, steps per second: 145, episode reward: -74.408, mean reward: -0.907 [-100.000, 24.751], mean action: 1.732 [0.000, 3.000],  loss: 98.799447, mae: 427.276502, mean_q: 573.253302, mean_eps: 0.730844
  89864/300000: episode: 878, duration: 0.678s, episode steps: 104, steps per second: 153, episode reward: -111.631, mean reward: -1.073 [-100.000, 14.632], mean action: 1.731 [0.000, 3.000],  loss: 86.428642, mae: 426.148253, mean_q: 572.359299, mean_eps: 0.730565
  90043/300000: episode: 879, duration: 1.128s, episode steps: 179, steps per second: 159, episode reward: -51.907, mean reward: -0.290 [-100.000,  6.064], mean action: 1.626 [0.000, 3.000],  loss: 99.504665, mae: 427.590399, mean_q: 573.793533, mean_eps: 0.730141
  90114/300000: episode: 880, duration: 0.503s, episode steps:  71, steps per second: 141, episode reward: -55.044, mean reward: -0.775 [-100.000, 28.139], mean action: 1.535 [0.000, 3.000],  loss: 85.519264, mae: 435.913951, mean_q: 585.568122, mean_eps: 0.729766
  90267/300000: episode: 881, duration: 0.969s, episode steps: 153, steps per second: 158, episode reward: -53.728, mean reward: -0.351 [-100.000, 14.459], mean action: 1.634 [0.000, 3.000],  loss: 102.766819, mae: 423.537245, mean_q: 568.602458, mean_eps: 0.729430
  90400/300000: episode: 882, duration: 0.858s, episode steps: 133, steps per second: 155, episode reward: -248.599, mean reward: -1.869 [-100.000, 30.462], mean action: 1.504 [0.000, 3.000],  loss: 103.421359, mae: 422.491939, mean_q: 566.348174, mean_eps: 0.729001
  90524/300000: episode: 883, duration: 0.823s, episode steps: 124, steps per second: 151, episode reward: -14.324, mean reward: -0.116 [-100.000, 13.088], mean action: 1.782 [0.000, 3.000],  loss: 100.916816, mae: 419.314766, mean_q: 563.054547, mean_eps: 0.728615
  90686/300000: episode: 884, duration: 1.031s, episode steps: 162, steps per second: 157, episode reward: -75.895, mean reward: -0.468 [-100.000, 43.254], mean action: 1.549 [0.000, 3.000],  loss: 95.463706, mae: 424.179865, mean_q: 570.452625, mean_eps: 0.728186
  90809/300000: episode: 885, duration: 0.809s, episode steps: 123, steps per second: 152, episode reward: -198.129, mean reward: -1.611 [-100.000,  7.395], mean action: 1.561 [0.000, 3.000],  loss: 99.581942, mae: 434.784556, mean_q: 584.373080, mean_eps: 0.727759
  90939/300000: episode: 886, duration: 0.829s, episode steps: 130, steps per second: 157, episode reward: -33.786, mean reward: -0.260 [-100.000,  7.329], mean action: 1.631 [0.000, 3.000],  loss: 99.982829, mae: 430.601964, mean_q: 578.480553, mean_eps: 0.727380
  91081/300000: episode: 887, duration: 0.943s, episode steps: 142, steps per second: 151, episode reward: -119.141, mean reward: -0.839 [-100.000, 18.738], mean action: 1.669 [0.000, 3.000],  loss: 93.292006, mae: 431.610728, mean_q: 579.221425, mean_eps: 0.726971
  91177/300000: episode: 888, duration: 0.635s, episode steps:  96, steps per second: 151, episode reward: -46.205, mean reward: -0.481 [-100.000,  9.036], mean action: 1.510 [0.000, 3.000],  loss: 89.494773, mae: 422.689212, mean_q: 568.944680, mean_eps: 0.726615
  91255/300000: episode: 889, duration: 0.493s, episode steps:  78, steps per second: 158, episode reward: -153.627, mean reward: -1.970 [-100.000,  8.053], mean action: 1.667 [0.000, 3.000],  loss: 90.008165, mae: 421.751734, mean_q: 566.520939, mean_eps: 0.726354
  91419/300000: episode: 890, duration: 1.085s, episode steps: 164, steps per second: 151, episode reward: -149.283, mean reward: -0.910 [-100.000,  8.524], mean action: 1.659 [0.000, 3.000],  loss: 102.835446, mae: 424.843217, mean_q: 569.535679, mean_eps: 0.725990
  91493/300000: episode: 891, duration: 0.495s, episode steps:  74, steps per second: 150, episode reward: -89.945, mean reward: -1.215 [-100.000, 12.696], mean action: 1.824 [0.000, 3.000],  loss: 107.749440, mae: 428.714360, mean_q: 573.853977, mean_eps: 0.725634
  91620/300000: episode: 892, duration: 0.816s, episode steps: 127, steps per second: 156, episode reward: -210.940, mean reward: -1.661 [-100.000, 21.448], mean action: 1.598 [0.000, 3.000],  loss: 96.587477, mae: 423.583005, mean_q: 565.526244, mean_eps: 0.725332
  91785/300000: episode: 893, duration: 1.088s, episode steps: 165, steps per second: 152, episode reward: -73.252, mean reward: -0.444 [-100.000,  8.604], mean action: 1.679 [0.000, 3.000],  loss: 99.683935, mae: 426.273900, mean_q: 570.223431, mean_eps: 0.724894
  91942/300000: episode: 894, duration: 1.018s, episode steps: 157, steps per second: 154, episode reward: -293.477, mean reward: -1.869 [-100.000, 35.916], mean action: 1.758 [0.000, 3.000],  loss: 107.184870, mae: 415.330419, mean_q: 555.454883, mean_eps: 0.724411
  92050/300000: episode: 895, duration: 0.699s, episode steps: 108, steps per second: 155, episode reward: -176.501, mean reward: -1.634 [-100.000,  5.191], mean action: 1.593 [0.000, 3.000],  loss: 119.761691, mae: 422.766575, mean_q: 566.616774, mean_eps: 0.724014
  92157/300000: episode: 896, duration: 0.706s, episode steps: 107, steps per second: 152, episode reward: -83.193, mean reward: -0.778 [-100.000,  9.321], mean action: 1.757 [0.000, 3.000],  loss: 120.376871, mae: 413.251469, mean_q: 554.407733, mean_eps: 0.723691
  92313/300000: episode: 897, duration: 1.052s, episode steps: 156, steps per second: 148, episode reward: -84.865, mean reward: -0.544 [-100.000, 19.566], mean action: 1.596 [0.000, 3.000],  loss: 95.504455, mae: 418.969301, mean_q: 561.180817, mean_eps: 0.723297
  92402/300000: episode: 898, duration: 0.634s, episode steps:  89, steps per second: 140, episode reward: -77.938, mean reward: -0.876 [-100.000, 36.315], mean action: 1.584 [0.000, 3.000],  loss: 104.372165, mae: 421.475635, mean_q: 567.020871, mean_eps: 0.722929
  92503/300000: episode: 899, duration: 0.737s, episode steps: 101, steps per second: 137, episode reward: -86.225, mean reward: -0.854 [-100.000, 10.519], mean action: 1.545 [0.000, 3.000],  loss: 94.745466, mae: 419.632688, mean_q: 562.866525, mean_eps: 0.722644
  92636/300000: episode: 900, duration: 0.894s, episode steps: 133, steps per second: 149, episode reward: -169.212, mean reward: -1.272 [-100.000, 23.897], mean action: 1.624 [0.000, 3.000],  loss: 109.646360, mae: 422.022759, mean_q: 565.731030, mean_eps: 0.722293
  92732/300000: episode: 901, duration: 0.689s, episode steps:  96, steps per second: 139, episode reward: -122.021, mean reward: -1.271 [-100.000,  6.726], mean action: 1.427 [0.000, 3.000],  loss: 112.736790, mae: 424.725283, mean_q: 568.357173, mean_eps: 0.721950
  92810/300000: episode: 902, duration: 0.527s, episode steps:  78, steps per second: 148, episode reward: -191.678, mean reward: -2.457 [-100.000,  4.444], mean action: 1.462 [0.000, 3.000],  loss: 113.882030, mae: 421.321098, mean_q: 564.134321, mean_eps: 0.721688
  92925/300000: episode: 903, duration: 0.758s, episode steps: 115, steps per second: 152, episode reward: -102.794, mean reward: -0.894 [-100.000,  9.146], mean action: 1.722 [0.000, 3.000],  loss: 99.052340, mae: 421.180299, mean_q: 563.550007, mean_eps: 0.721399
  93049/300000: episode: 904, duration: 0.831s, episode steps: 124, steps per second: 149, episode reward: -61.405, mean reward: -0.495 [-100.000,  8.578], mean action: 1.629 [0.000, 3.000],  loss: 103.258343, mae: 416.613285, mean_q: 556.508153, mean_eps: 0.721041
  93142/300000: episode: 905, duration: 0.598s, episode steps:  93, steps per second: 156, episode reward: -120.903, mean reward: -1.300 [-100.000,  6.154], mean action: 1.720 [0.000, 3.000],  loss: 121.004397, mae: 417.591315, mean_q: 558.545039, mean_eps: 0.720715
  93268/300000: episode: 906, duration: 0.788s, episode steps: 126, steps per second: 160, episode reward: -202.646, mean reward: -1.608 [-100.000,  6.671], mean action: 1.587 [0.000, 3.000],  loss: 120.721942, mae: 418.827336, mean_q: 560.190218, mean_eps: 0.720387
  93404/300000: episode: 907, duration: 0.913s, episode steps: 136, steps per second: 149, episode reward: -80.938, mean reward: -0.595 [-100.000, 27.404], mean action: 1.471 [0.000, 3.000],  loss: 110.535068, mae: 413.378562, mean_q: 554.143134, mean_eps: 0.719994
  93480/300000: episode: 908, duration: 0.490s, episode steps:  76, steps per second: 155, episode reward: -95.369, mean reward: -1.255 [-100.000, 31.877], mean action: 1.632 [0.000, 3.000],  loss: 98.123974, mae: 424.770131, mean_q: 572.636465, mean_eps: 0.719676
  93612/300000: episode: 909, duration: 0.828s, episode steps: 132, steps per second: 159, episode reward: -37.147, mean reward: -0.281 [-100.000, 19.737], mean action: 1.652 [0.000, 3.000],  loss: 101.840204, mae: 418.546171, mean_q: 564.523373, mean_eps: 0.719363
  93730/300000: episode: 910, duration: 0.779s, episode steps: 118, steps per second: 151, episode reward: -64.665, mean reward: -0.548 [-100.000, 63.594], mean action: 1.678 [0.000, 3.000],  loss: 117.289204, mae: 414.125787, mean_q: 559.129742, mean_eps: 0.718989
  93838/300000: episode: 911, duration: 0.699s, episode steps: 108, steps per second: 155, episode reward: -71.827, mean reward: -0.665 [-100.000, 12.025], mean action: 1.620 [0.000, 3.000],  loss: 127.241682, mae: 415.480146, mean_q: 561.031629, mean_eps: 0.718650
  93976/300000: episode: 912, duration: 0.864s, episode steps: 138, steps per second: 160, episode reward: -48.266, mean reward: -0.350 [-100.000, 13.535], mean action: 1.543 [0.000, 3.000],  loss: 118.438508, mae: 416.579354, mean_q: 563.434878, mean_eps: 0.718280
  94084/300000: episode: 913, duration: 0.733s, episode steps: 108, steps per second: 147, episode reward: -61.289, mean reward: -0.567 [-100.000, 12.550], mean action: 1.602 [0.000, 3.000],  loss: 132.134554, mae: 412.710074, mean_q: 557.646083, mean_eps: 0.717912
  94229/300000: episode: 914, duration: 1.031s, episode steps: 145, steps per second: 141, episode reward: -85.168, mean reward: -0.587 [-100.000, 11.818], mean action: 1.697 [0.000, 3.000],  loss: 118.655983, mae: 411.304066, mean_q: 557.035506, mean_eps: 0.717532
  94375/300000: episode: 915, duration: 0.968s, episode steps: 146, steps per second: 151, episode reward: -65.536, mean reward: -0.449 [-100.000, 68.678], mean action: 1.664 [0.000, 3.000],  loss: 108.994601, mae: 417.093356, mean_q: 563.534862, mean_eps: 0.717095
  94491/300000: episode: 916, duration: 0.738s, episode steps: 116, steps per second: 157, episode reward: -66.697, mean reward: -0.575 [-100.000, 16.304], mean action: 1.586 [0.000, 3.000],  loss: 125.835282, mae: 410.128809, mean_q: 554.476860, mean_eps: 0.716703
  94652/300000: episode: 917, duration: 1.026s, episode steps: 161, steps per second: 157, episode reward: -328.688, mean reward: -2.042 [-100.000, 89.691], mean action: 1.584 [0.000, 3.000],  loss: 138.313806, mae: 408.932202, mean_q: 552.892250, mean_eps: 0.716287
  94756/300000: episode: 918, duration: 0.693s, episode steps: 104, steps per second: 150, episode reward: -80.024, mean reward: -0.769 [-100.000,  6.539], mean action: 1.548 [0.000, 3.000],  loss: 154.725014, mae: 403.316085, mean_q: 545.004991, mean_eps: 0.715889
  94860/300000: episode: 919, duration: 0.652s, episode steps: 104, steps per second: 160, episode reward: -115.739, mean reward: -1.113 [-100.000,  6.194], mean action: 1.606 [0.000, 3.000],  loss: 130.685874, mae: 411.414719, mean_q: 556.582639, mean_eps: 0.715578
  94994/300000: episode: 920, duration: 0.851s, episode steps: 134, steps per second: 157, episode reward: -216.681, mean reward: -1.617 [-100.000, 15.330], mean action: 1.537 [0.000, 3.000],  loss: 131.870844, mae: 409.510883, mean_q: 553.384643, mean_eps: 0.715221
  95122/300000: episode: 921, duration: 0.854s, episode steps: 128, steps per second: 150, episode reward: -102.657, mean reward: -0.802 [-100.000,  9.611], mean action: 1.672 [0.000, 3.000],  loss: 172.465652, mae: 406.432293, mean_q: 549.085250, mean_eps: 0.714827
  95232/300000: episode: 922, duration: 0.711s, episode steps: 110, steps per second: 155, episode reward: -107.786, mean reward: -0.980 [-100.000, 11.822], mean action: 1.591 [0.000, 3.000],  loss: 150.389042, mae: 408.130022, mean_q: 551.383772, mean_eps: 0.714471
  95393/300000: episode: 923, duration: 1.063s, episode steps: 161, steps per second: 151, episode reward: -150.013, mean reward: -0.932 [-100.000,  5.470], mean action: 1.665 [0.000, 3.000],  loss: 172.285685, mae: 407.292121, mean_q: 550.943928, mean_eps: 0.714064
  95570/300000: episode: 924, duration: 1.120s, episode steps: 177, steps per second: 158, episode reward: -61.325, mean reward: -0.346 [-100.000,  6.297], mean action: 1.672 [0.000, 3.000],  loss: 125.297244, mae: 405.673947, mean_q: 550.476801, mean_eps: 0.713557
  95651/300000: episode: 925, duration: 0.520s, episode steps:  81, steps per second: 156, episode reward: -85.993, mean reward: -1.062 [-100.000,  8.699], mean action: 1.481 [0.000, 3.000],  loss: 149.221502, mae: 405.407459, mean_q: 550.912126, mean_eps: 0.713170
  95806/300000: episode: 926, duration: 1.027s, episode steps: 155, steps per second: 151, episode reward: -18.471, mean reward: -0.119 [-100.000, 14.527], mean action: 1.665 [0.000, 3.000],  loss: 178.139992, mae: 406.438330, mean_q: 553.552282, mean_eps: 0.712816
  95938/300000: episode: 927, duration: 0.883s, episode steps: 132, steps per second: 149, episode reward: -64.786, mean reward: -0.491 [-100.000,  8.445], mean action: 1.583 [0.000, 3.000],  loss: 140.590546, mae: 405.242941, mean_q: 550.603434, mean_eps: 0.712386
  96050/300000: episode: 928, duration: 0.894s, episode steps: 112, steps per second: 125, episode reward: -133.950, mean reward: -1.196 [-100.000, 41.945], mean action: 1.679 [0.000, 3.000],  loss: 149.968186, mae: 400.982552, mean_q: 544.367756, mean_eps: 0.712020
  96165/300000: episode: 929, duration: 0.836s, episode steps: 115, steps per second: 138, episode reward: -47.117, mean reward: -0.410 [-100.000, 35.414], mean action: 1.661 [0.000, 3.000],  loss: 187.356855, mae: 410.166603, mean_q: 557.590506, mean_eps: 0.711679
  96305/300000: episode: 930, duration: 1.048s, episode steps: 140, steps per second: 134, episode reward: -72.310, mean reward: -0.516 [-100.000, 22.718], mean action: 1.707 [0.000, 3.000],  loss: 175.867570, mae: 401.822141, mean_q: 546.320911, mean_eps: 0.711297
  96404/300000: episode: 931, duration: 0.749s, episode steps:  99, steps per second: 132, episode reward: -272.733, mean reward: -2.755 [-100.000,  2.146], mean action: 1.646 [0.000, 3.000],  loss: 183.923170, mae: 407.986464, mean_q: 554.348723, mean_eps: 0.710938
  96558/300000: episode: 932, duration: 1.065s, episode steps: 154, steps per second: 145, episode reward: -89.629, mean reward: -0.582 [-100.000, 11.927], mean action: 1.571 [0.000, 3.000],  loss: 139.777562, mae: 403.756645, mean_q: 549.757436, mean_eps: 0.710558
  96675/300000: episode: 933, duration: 0.788s, episode steps: 117, steps per second: 149, episode reward: -47.384, mean reward: -0.405 [-100.000, 19.789], mean action: 1.675 [0.000, 3.000],  loss: 166.325691, mae: 414.778342, mean_q: 564.496637, mean_eps: 0.710152
  96806/300000: episode: 934, duration: 0.848s, episode steps: 131, steps per second: 154, episode reward: -125.369, mean reward: -0.957 [-100.000, 13.840], mean action: 1.634 [0.000, 3.000],  loss: 179.578899, mae: 414.344797, mean_q: 564.049951, mean_eps: 0.709780
  96880/300000: episode: 935, duration: 0.465s, episode steps:  74, steps per second: 159, episode reward: -109.683, mean reward: -1.482 [-100.000, 10.026], mean action: 1.635 [0.000, 3.000],  loss: 162.247618, mae: 416.037359, mean_q: 565.050226, mean_eps: 0.709473
  96965/300000: episode: 936, duration: 0.592s, episode steps:  85, steps per second: 143, episode reward: -130.378, mean reward: -1.534 [-100.000, 16.034], mean action: 1.788 [0.000, 3.000],  loss: 133.583480, mae: 420.618808, mean_q: 572.431453, mean_eps: 0.709234
  97082/300000: episode: 937, duration: 0.756s, episode steps: 117, steps per second: 155, episode reward: -111.057, mean reward: -0.949 [-100.000, 27.289], mean action: 1.650 [0.000, 3.000],  loss: 148.604430, mae: 417.121565, mean_q: 567.970281, mean_eps: 0.708931
  97193/300000: episode: 938, duration: 0.702s, episode steps: 111, steps per second: 158, episode reward: -142.185, mean reward: -1.281 [-100.000,  5.714], mean action: 1.514 [0.000, 3.000],  loss: 168.269964, mae: 428.734218, mean_q: 582.719268, mean_eps: 0.708589
  97288/300000: episode: 939, duration: 0.658s, episode steps:  95, steps per second: 144, episode reward: -63.957, mean reward: -0.673 [-100.000, 12.548], mean action: 1.579 [0.000, 3.000],  loss: 189.193797, mae: 418.925422, mean_q: 569.895334, mean_eps: 0.708280
  97361/300000: episode: 940, duration: 0.472s, episode steps:  73, steps per second: 155, episode reward: -54.855, mean reward: -0.751 [-100.000, 19.918], mean action: 1.589 [0.000, 3.000],  loss: 164.110743, mae: 425.255457, mean_q: 577.844277, mean_eps: 0.708028
  97447/300000: episode: 941, duration: 0.565s, episode steps:  86, steps per second: 152, episode reward: -49.269, mean reward: -0.573 [-100.000, 10.749], mean action: 1.733 [0.000, 3.000],  loss: 129.750569, mae: 421.612484, mean_q: 573.351112, mean_eps: 0.707789
  97529/300000: episode: 942, duration: 0.529s, episode steps:  82, steps per second: 155, episode reward: -28.332, mean reward: -0.346 [-100.000, 11.871], mean action: 1.427 [0.000, 3.000],  loss: 161.404788, mae: 424.077246, mean_q: 577.605653, mean_eps: 0.707538
  97665/300000: episode: 943, duration: 0.918s, episode steps: 136, steps per second: 148, episode reward: -73.745, mean reward: -0.542 [-100.000, 20.326], mean action: 1.618 [0.000, 3.000],  loss: 210.868061, mae: 424.854091, mean_q: 577.832986, mean_eps: 0.707210
  97735/300000: episode: 944, duration: 0.447s, episode steps:  70, steps per second: 157, episode reward: -30.767, mean reward: -0.440 [-100.000, 49.571], mean action: 1.500 [0.000, 3.000],  loss: 225.697582, mae: 426.014073, mean_q: 580.293631, mean_eps: 0.706901
  97899/300000: episode: 945, duration: 1.088s, episode steps: 164, steps per second: 151, episode reward: -202.390, mean reward: -1.234 [-100.000,  5.249], mean action: 1.659 [0.000, 3.000],  loss: 208.211390, mae: 425.353800, mean_q: 579.359451, mean_eps: 0.706550
  97984/300000: episode: 946, duration: 0.571s, episode steps:  85, steps per second: 149, episode reward: -274.790, mean reward: -3.233 [-100.000,  4.458], mean action: 1.812 [0.000, 3.000],  loss: 240.571101, mae: 431.528598, mean_q: 588.054360, mean_eps: 0.706177
  98134/300000: episode: 947, duration: 0.963s, episode steps: 150, steps per second: 156, episode reward: -75.035, mean reward: -0.500 [-100.000,  9.844], mean action: 1.573 [0.000, 3.000],  loss: 192.266936, mae: 431.441668, mean_q: 587.701396, mean_eps: 0.705824
  98256/300000: episode: 948, duration: 0.833s, episode steps: 122, steps per second: 146, episode reward: -222.122, mean reward: -1.821 [-100.000, 15.383], mean action: 1.664 [0.000, 3.000],  loss: 198.395358, mae: 426.439276, mean_q: 581.669582, mean_eps: 0.705417
  98378/300000: episode: 949, duration: 0.787s, episode steps: 122, steps per second: 155, episode reward: -59.544, mean reward: -0.488 [-100.000, 12.675], mean action: 1.590 [0.000, 3.000],  loss: 161.416702, mae: 427.149111, mean_q: 582.726030, mean_eps: 0.705050
  98507/300000: episode: 950, duration: 0.806s, episode steps: 129, steps per second: 160, episode reward: -26.044, mean reward: -0.202 [-100.000, 98.467], mean action: 1.558 [0.000, 3.000],  loss: 232.696352, mae: 427.951456, mean_q: 583.386114, mean_eps: 0.704674
  98583/300000: episode: 951, duration: 0.534s, episode steps:  76, steps per second: 142, episode reward: -27.760, mean reward: -0.365 [-100.000, 11.050], mean action: 1.526 [0.000, 3.000],  loss: 336.298732, mae: 434.371082, mean_q: 591.119825, mean_eps: 0.704366
  98668/300000: episode: 952, duration: 0.556s, episode steps:  85, steps per second: 153, episode reward: -119.205, mean reward: -1.402 [-100.000,  6.791], mean action: 1.518 [0.000, 3.000],  loss: 295.637336, mae: 429.188756, mean_q: 585.327581, mean_eps: 0.704125
  98835/300000: episode: 953, duration: 1.072s, episode steps: 167, steps per second: 156, episode reward: -157.651, mean reward: -0.944 [-100.000, 12.601], mean action: 1.677 [0.000, 3.000],  loss: 225.775191, mae: 428.270878, mean_q: 584.114779, mean_eps: 0.703747
  99012/300000: episode: 954, duration: 1.174s, episode steps: 177, steps per second: 151, episode reward: -31.901, mean reward: -0.180 [-100.000, 10.865], mean action: 1.723 [0.000, 3.000],  loss: 164.081881, mae: 427.168364, mean_q: 582.842985, mean_eps: 0.703231
  99139/300000: episode: 955, duration: 0.800s, episode steps: 127, steps per second: 159, episode reward: -175.542, mean reward: -1.382 [-100.000, 11.129], mean action: 1.732 [0.000, 3.000],  loss: 192.163241, mae: 428.944007, mean_q: 585.071535, mean_eps: 0.702775
  99272/300000: episode: 956, duration: 0.888s, episode steps: 133, steps per second: 150, episode reward: -59.723, mean reward: -0.449 [-100.000,  9.775], mean action: 1.519 [0.000, 3.000],  loss: 234.768178, mae: 423.806229, mean_q: 577.590550, mean_eps: 0.702385
  99351/300000: episode: 957, duration: 0.506s, episode steps:  79, steps per second: 156, episode reward: -50.290, mean reward: -0.637 [-100.000, 10.366], mean action: 1.544 [0.000, 3.000],  loss: 167.260589, mae: 425.669081, mean_q: 580.005830, mean_eps: 0.702067
  99483/300000: episode: 958, duration: 0.832s, episode steps: 132, steps per second: 159, episode reward: -74.799, mean reward: -0.567 [-100.000, 18.125], mean action: 1.492 [0.000, 3.000],  loss: 215.236046, mae: 423.046097, mean_q: 576.281522, mean_eps: 0.701751
  99581/300000: episode: 959, duration: 0.664s, episode steps:  98, steps per second: 148, episode reward: -78.667, mean reward: -0.803 [-100.000,  6.679], mean action: 1.643 [0.000, 3.000],  loss: 232.367664, mae: 426.772547, mean_q: 581.624344, mean_eps: 0.701406
  99721/300000: episode: 960, duration: 0.952s, episode steps: 140, steps per second: 147, episode reward: -148.063, mean reward: -1.058 [-100.000,  9.330], mean action: 1.786 [0.000, 3.000],  loss: 216.283086, mae: 427.146315, mean_q: 580.724157, mean_eps: 0.701048
  99848/300000: episode: 961, duration: 0.967s, episode steps: 127, steps per second: 131, episode reward: -83.563, mean reward: -0.658 [-100.000,  9.173], mean action: 1.606 [0.000, 3.000],  loss: 158.281506, mae: 437.570990, mean_q: 594.438689, mean_eps: 0.700648
 100227/300000: episode: 962, duration: 2.739s, episode steps: 379, steps per second: 138, episode reward: -36.981, mean reward: -0.098 [-100.000, 13.427], mean action: 1.776 [0.000, 3.000],  loss: 198.237674, mae: 434.060875, mean_q: 590.426705, mean_eps: 0.699889
 100419/300000: episode: 963, duration: 1.233s, episode steps: 192, steps per second: 156, episode reward: -126.220, mean reward: -0.657 [-100.000,  8.506], mean action: 1.625 [0.000, 3.000],  loss: 215.844110, mae: 441.918905, mean_q: 601.477870, mean_eps: 0.699033
 100531/300000: episode: 964, duration: 0.756s, episode steps: 112, steps per second: 148, episode reward: -102.232, mean reward: -0.913 [-100.000, 16.945], mean action: 1.571 [0.000, 3.000],  loss: 195.391254, mae: 439.544624, mean_q: 598.331213, mean_eps: 0.698576
 100671/300000: episode: 965, duration: 0.892s, episode steps: 140, steps per second: 157, episode reward: -197.515, mean reward: -1.411 [-100.000,  4.153], mean action: 1.550 [0.000, 3.000],  loss: 169.086149, mae: 440.638318, mean_q: 600.243037, mean_eps: 0.698199
 100897/300000: episode: 966, duration: 1.487s, episode steps: 226, steps per second: 152, episode reward: -120.663, mean reward: -0.534 [-100.000, 13.928], mean action: 1.571 [0.000, 3.000],  loss: 244.109828, mae: 437.650536, mean_q: 595.934761, mean_eps: 0.697650
 101000/300000: episode: 967, duration: 0.653s, episode steps: 103, steps per second: 158, episode reward: -50.292, mean reward: -0.488 [-100.000, 13.208], mean action: 1.553 [0.000, 3.000],  loss: 174.677393, mae: 447.927434, mean_q: 610.787787, mean_eps: 0.697156
 101131/300000: episode: 968, duration: 0.852s, episode steps: 131, steps per second: 154, episode reward: -96.546, mean reward: -0.737 [-100.000, 11.114], mean action: 1.504 [0.000, 3.000],  loss: 178.866187, mae: 444.131372, mean_q: 604.880886, mean_eps: 0.696805
 101303/300000: episode: 969, duration: 1.128s, episode steps: 172, steps per second: 152, episode reward: -110.681, mean reward: -0.643 [-100.000,  9.701], mean action: 1.616 [0.000, 3.000],  loss: 245.656818, mae: 444.285854, mean_q: 604.071235, mean_eps: 0.696351
 101432/300000: episode: 970, duration: 0.807s, episode steps: 129, steps per second: 160, episode reward: -87.891, mean reward: -0.681 [-100.000,  9.266], mean action: 1.760 [0.000, 3.000],  loss: 288.139540, mae: 445.532076, mean_q: 605.739723, mean_eps: 0.695899
 101575/300000: episode: 971, duration: 0.962s, episode steps: 143, steps per second: 149, episode reward:  2.381, mean reward:  0.017 [-100.000, 61.193], mean action: 1.734 [0.000, 3.000],  loss: 241.083889, mae: 442.405921, mean_q: 601.284709, mean_eps: 0.695491
 101741/300000: episode: 972, duration: 1.101s, episode steps: 166, steps per second: 151, episode reward: -70.639, mean reward: -0.426 [-100.000,  8.934], mean action: 1.723 [0.000, 3.000],  loss: 230.453689, mae: 442.085860, mean_q: 601.922140, mean_eps: 0.695028
 101837/300000: episode: 973, duration: 0.653s, episode steps:  96, steps per second: 147, episode reward: -66.986, mean reward: -0.698 [-100.000, 14.214], mean action: 1.635 [0.000, 3.000],  loss: 239.726966, mae: 442.017842, mean_q: 601.157593, mean_eps: 0.694634
 101913/300000: episode: 974, duration: 0.494s, episode steps:  76, steps per second: 154, episode reward: -58.287, mean reward: -0.767 [-100.000, 21.097], mean action: 1.750 [0.000, 3.000],  loss: 217.602738, mae: 444.964697, mean_q: 605.183258, mean_eps: 0.694376
 102021/300000: episode: 975, duration: 0.803s, episode steps: 108, steps per second: 134, episode reward: -107.955, mean reward: -1.000 [-100.000, 10.756], mean action: 1.509 [0.000, 3.000],  loss: 248.274551, mae: 435.078062, mean_q: 591.142838, mean_eps: 0.694101
 102188/300000: episode: 976, duration: 1.200s, episode steps: 167, steps per second: 139, episode reward:  8.213, mean reward:  0.049 [-100.000, 84.565], mean action: 1.731 [0.000, 3.000],  loss: 218.710815, mae: 446.884205, mean_q: 608.700813, mean_eps: 0.693688
 102298/300000: episode: 977, duration: 0.742s, episode steps: 110, steps per second: 148, episode reward: -76.017, mean reward: -0.691 [-100.000,  4.842], mean action: 1.500 [0.000, 3.000],  loss: 267.232332, mae: 451.514482, mean_q: 613.572307, mean_eps: 0.693273
 102424/300000: episode: 978, duration: 0.862s, episode steps: 126, steps per second: 146, episode reward: -119.958, mean reward: -0.952 [-100.000,  5.871], mean action: 1.563 [0.000, 3.000],  loss: 259.966886, mae: 455.319179, mean_q: 618.896228, mean_eps: 0.692918
 102539/300000: episode: 979, duration: 0.808s, episode steps: 115, steps per second: 142, episode reward: -55.994, mean reward: -0.487 [-100.000, 17.768], mean action: 1.600 [0.000, 3.000],  loss: 210.028534, mae: 455.030595, mean_q: 618.595884, mean_eps: 0.692557
 102685/300000: episode: 980, duration: 0.973s, episode steps: 146, steps per second: 150, episode reward: -215.423, mean reward: -1.476 [-100.000,  3.032], mean action: 1.678 [0.000, 3.000],  loss: 365.198249, mae: 455.216115, mean_q: 619.612374, mean_eps: 0.692165
 102781/300000: episode: 981, duration: 0.639s, episode steps:  96, steps per second: 150, episode reward: -17.448, mean reward: -0.182 [-100.000, 12.170], mean action: 1.573 [0.000, 3.000],  loss: 259.688161, mae: 455.932925, mean_q: 620.427419, mean_eps: 0.691802
 102870/300000: episode: 982, duration: 0.574s, episode steps:  89, steps per second: 155, episode reward: -98.134, mean reward: -1.103 [-100.000,  6.230], mean action: 1.663 [0.000, 3.000],  loss: 224.747001, mae: 451.283696, mean_q: 615.174111, mean_eps: 0.691525
 102970/300000: episode: 983, duration: 0.633s, episode steps: 100, steps per second: 158, episode reward: -80.646, mean reward: -0.806 [-100.000, 13.890], mean action: 1.670 [0.000, 3.000],  loss: 207.879204, mae: 459.412933, mean_q: 626.663351, mean_eps: 0.691241
 103077/300000: episode: 984, duration: 0.697s, episode steps: 107, steps per second: 154, episode reward: -262.709, mean reward: -2.455 [-100.000,  1.288], mean action: 1.673 [0.000, 3.000],  loss: 360.753160, mae: 463.575767, mean_q: 632.632836, mean_eps: 0.690931
 103169/300000: episode: 985, duration: 0.616s, episode steps:  92, steps per second: 149, episode reward: -74.769, mean reward: -0.813 [-100.000, 28.879], mean action: 1.815 [0.000, 3.000],  loss: 216.270885, mae: 465.492391, mean_q: 635.421368, mean_eps: 0.690633
 103337/300000: episode: 986, duration: 1.082s, episode steps: 168, steps per second: 155, episode reward: -82.106, mean reward: -0.489 [-100.000, 10.316], mean action: 1.571 [0.000, 3.000],  loss: 369.954854, mae: 468.249560, mean_q: 638.272121, mean_eps: 0.690242
 103416/300000: episode: 987, duration: 0.527s, episode steps:  79, steps per second: 150, episode reward: -307.918, mean reward: -3.898 [-100.000,  5.852], mean action: 1.570 [0.000, 3.000],  loss: 259.576931, mae: 465.758208, mean_q: 635.911931, mean_eps: 0.689872
 103557/300000: episode: 988, duration: 0.915s, episode steps: 141, steps per second: 154, episode reward:  1.236, mean reward:  0.009 [-100.000, 13.356], mean action: 1.617 [0.000, 3.000],  loss: 260.228263, mae: 465.172414, mean_q: 634.593179, mean_eps: 0.689542
 103654/300000: episode: 989, duration: 0.608s, episode steps:  97, steps per second: 160, episode reward: -13.860, mean reward: -0.143 [-100.000, 15.632], mean action: 1.670 [0.000, 3.000],  loss: 292.293857, mae: 461.007890, mean_q: 628.697976, mean_eps: 0.689185
 103758/300000: episode: 990, duration: 0.684s, episode steps: 104, steps per second: 152, episode reward: -110.388, mean reward: -1.061 [-100.000,  6.146], mean action: 1.490 [0.000, 3.000],  loss: 273.322283, mae: 461.621864, mean_q: 629.967681, mean_eps: 0.688883
 103871/300000: episode: 991, duration: 0.741s, episode steps: 113, steps per second: 152, episode reward: -153.126, mean reward: -1.355 [-100.000,  2.976], mean action: 1.584 [0.000, 3.000],  loss: 301.084641, mae: 464.665506, mean_q: 632.218840, mean_eps: 0.688558
 103995/300000: episode: 992, duration: 0.776s, episode steps: 124, steps per second: 160, episode reward: -82.840, mean reward: -0.668 [-100.000, 21.061], mean action: 1.661 [0.000, 3.000],  loss: 329.665027, mae: 465.437606, mean_q: 633.646333, mean_eps: 0.688202
 104106/300000: episode: 993, duration: 0.753s, episode steps: 111, steps per second: 147, episode reward: -108.722, mean reward: -0.979 [-100.000,  7.557], mean action: 1.468 [0.000, 3.000],  loss: 300.220816, mae: 472.254254, mean_q: 643.727369, mean_eps: 0.687850
 104207/300000: episode: 994, duration: 0.645s, episode steps: 101, steps per second: 157, episode reward: -230.150, mean reward: -2.279 [-100.000,  0.961], mean action: 1.287 [0.000, 3.000],  loss: 353.440448, mae: 470.658862, mean_q: 639.299606, mean_eps: 0.687532
 104346/300000: episode: 995, duration: 0.883s, episode steps: 139, steps per second: 157, episode reward: -232.756, mean reward: -1.675 [-100.000, 12.232], mean action: 1.691 [0.000, 3.000],  loss: 213.415577, mae: 460.906035, mean_q: 625.658109, mean_eps: 0.687172
 104512/300000: episode: 996, duration: 1.093s, episode steps: 166, steps per second: 152, episode reward: -96.697, mean reward: -0.583 [-100.000, 10.534], mean action: 1.687 [0.000, 3.000],  loss: 243.761437, mae: 461.462707, mean_q: 626.967633, mean_eps: 0.686715
 104624/300000: episode: 997, duration: 0.705s, episode steps: 112, steps per second: 159, episode reward: -183.373, mean reward: -1.637 [-100.000,  2.617], mean action: 1.330 [0.000, 3.000],  loss: 234.526226, mae: 457.574381, mean_q: 621.149591, mean_eps: 0.686298
 104751/300000: episode: 998, duration: 0.820s, episode steps: 127, steps per second: 155, episode reward: -35.138, mean reward: -0.277 [-100.000, 21.198], mean action: 1.559 [0.000, 3.000],  loss: 229.924713, mae: 458.632926, mean_q: 620.963739, mean_eps: 0.685939
 104868/300000: episode: 999, duration: 0.772s, episode steps: 117, steps per second: 151, episode reward: -117.179, mean reward: -1.002 [-100.000,  6.402], mean action: 1.564 [0.000, 3.000],  loss: 312.952180, mae: 457.497146, mean_q: 619.619212, mean_eps: 0.685573
 105063/300000: episode: 1000, duration: 1.253s, episode steps: 195, steps per second: 156, episode reward: -128.488, mean reward: -0.659 [-100.000, 10.309], mean action: 1.621 [0.000, 3.000],  loss: 223.602462, mae: 453.747573, mean_q: 614.767751, mean_eps: 0.685105
 105179/300000: episode: 1001, duration: 0.775s, episode steps: 116, steps per second: 150, episode reward: -66.537, mean reward: -0.574 [-100.000,  8.113], mean action: 1.629 [0.000, 3.000],  loss: 232.258410, mae: 451.802077, mean_q: 612.074518, mean_eps: 0.684638
 105257/300000: episode: 1002, duration: 0.513s, episode steps:  78, steps per second: 152, episode reward: -61.560, mean reward: -0.789 [-100.000, 11.512], mean action: 1.654 [0.000, 3.000],  loss: 211.406786, mae: 453.782027, mean_q: 615.304449, mean_eps: 0.684347
 105464/300000: episode: 1003, duration: 1.362s, episode steps: 207, steps per second: 152, episode reward: -244.539, mean reward: -1.181 [-100.000, 22.966], mean action: 1.802 [0.000, 3.000],  loss: 231.323619, mae: 457.775087, mean_q: 621.346197, mean_eps: 0.683920
 105541/300000: episode: 1004, duration: 0.499s, episode steps:  77, steps per second: 154, episode reward: -26.184, mean reward: -0.340 [-100.000, 13.633], mean action: 1.636 [0.000, 3.000],  loss: 170.897802, mae: 463.745961, mean_q: 630.404505, mean_eps: 0.683494
 105612/300000: episode: 1005, duration: 0.461s, episode steps:  71, steps per second: 154, episode reward: -51.877, mean reward: -0.731 [-100.000, 22.100], mean action: 1.746 [0.000, 3.000],  loss: 259.004030, mae: 462.401678, mean_q: 628.951212, mean_eps: 0.683272
 105691/300000: episode: 1006, duration: 0.505s, episode steps:  79, steps per second: 157, episode reward: -83.989, mean reward: -1.063 [-100.000,  5.863], mean action: 1.734 [0.000, 3.000],  loss: 191.851238, mae: 467.110531, mean_q: 637.143325, mean_eps: 0.683047
 105779/300000: episode: 1007, duration: 0.593s, episode steps:  88, steps per second: 148, episode reward: -39.710, mean reward: -0.451 [-100.000,  7.754], mean action: 1.705 [0.000, 3.000],  loss: 337.228845, mae: 458.968640, mean_q: 625.900437, mean_eps: 0.682797
 105896/300000: episode: 1008, duration: 0.904s, episode steps: 117, steps per second: 129, episode reward: -176.533, mean reward: -1.509 [-100.000,  2.333], mean action: 1.564 [0.000, 3.000],  loss: 279.382835, mae: 468.060611, mean_q: 637.446005, mean_eps: 0.682489
 105983/300000: episode: 1009, duration: 0.667s, episode steps:  87, steps per second: 130, episode reward: -0.913, mean reward: -0.010 [-100.000, 12.672], mean action: 1.632 [0.000, 3.000],  loss: 336.451091, mae: 467.679671, mean_q: 635.709887, mean_eps: 0.682183
 106117/300000: episode: 1010, duration: 1.106s, episode steps: 134, steps per second: 121, episode reward: -161.108, mean reward: -1.202 [-100.000,  3.829], mean action: 1.731 [0.000, 3.000],  loss: 335.947337, mae: 472.087281, mean_q: 643.743213, mean_eps: 0.681851
 106219/300000: episode: 1011, duration: 0.735s, episode steps: 102, steps per second: 139, episode reward: -59.609, mean reward: -0.584 [-100.000, 12.218], mean action: 1.706 [0.000, 3.000],  loss: 292.797927, mae: 475.243849, mean_q: 647.982557, mean_eps: 0.681497
 106333/300000: episode: 1012, duration: 0.913s, episode steps: 114, steps per second: 125, episode reward: -311.476, mean reward: -2.732 [-100.000,  1.087], mean action: 1.623 [0.000, 3.000],  loss: 336.398007, mae: 471.721188, mean_q: 643.122607, mean_eps: 0.681173
 106418/300000: episode: 1013, duration: 0.634s, episode steps:  85, steps per second: 134, episode reward: -25.891, mean reward: -0.305 [-100.000, 12.660], mean action: 1.624 [0.000, 3.000],  loss: 259.119793, mae: 480.482342, mean_q: 654.393462, mean_eps: 0.680875
 106534/300000: episode: 1014, duration: 0.802s, episode steps: 116, steps per second: 145, episode reward: -58.166, mean reward: -0.501 [-100.000, 10.477], mean action: 1.569 [0.000, 3.000],  loss: 259.448627, mae: 472.003689, mean_q: 642.516613, mean_eps: 0.680573
 106623/300000: episode: 1015, duration: 0.606s, episode steps:  89, steps per second: 147, episode reward: -204.620, mean reward: -2.299 [-100.000,  1.718], mean action: 1.753 [0.000, 3.000],  loss: 338.976701, mae: 482.981610, mean_q: 657.625481, mean_eps: 0.680266
 106696/300000: episode: 1016, duration: 0.483s, episode steps:  73, steps per second: 151, episode reward: -69.574, mean reward: -0.953 [-100.000,  7.918], mean action: 1.411 [0.000, 3.000],  loss: 418.753092, mae: 469.395533, mean_q: 637.673454, mean_eps: 0.680023
 106846/300000: episode: 1017, duration: 0.963s, episode steps: 150, steps per second: 156, episode reward: -221.661, mean reward: -1.478 [-100.000,  4.041], mean action: 1.613 [0.000, 3.000],  loss: 356.026845, mae: 484.192943, mean_q: 659.012046, mean_eps: 0.679688
 106966/300000: episode: 1018, duration: 0.813s, episode steps: 120, steps per second: 148, episode reward: -8.474, mean reward: -0.071 [-100.000, 18.089], mean action: 1.708 [0.000, 3.000],  loss: 381.121675, mae: 482.775796, mean_q: 656.245370, mean_eps: 0.679284
 107074/300000: episode: 1019, duration: 0.704s, episode steps: 108, steps per second: 153, episode reward: -16.288, mean reward: -0.151 [-100.000, 40.903], mean action: 1.667 [0.000, 3.000],  loss: 223.479846, mae: 488.464911, mean_q: 665.801155, mean_eps: 0.678941
 107142/300000: episode: 1020, duration: 0.440s, episode steps:  68, steps per second: 155, episode reward: -74.194, mean reward: -1.091 [-100.000, 10.341], mean action: 1.471 [0.000, 3.000],  loss: 297.752736, mae: 487.897280, mean_q: 665.009265, mean_eps: 0.678678
 107273/300000: episode: 1021, duration: 0.849s, episode steps: 131, steps per second: 154, episode reward: -51.933, mean reward: -0.396 [-100.000,  7.613], mean action: 1.870 [0.000, 3.000],  loss: 301.552003, mae: 490.240192, mean_q: 668.554973, mean_eps: 0.678379
 107359/300000: episode: 1022, duration: 0.583s, episode steps:  86, steps per second: 147, episode reward: -118.775, mean reward: -1.381 [-100.000, 15.637], mean action: 1.791 [0.000, 3.000],  loss: 339.589196, mae: 490.820818, mean_q: 668.558379, mean_eps: 0.678053
 107499/300000: episode: 1023, duration: 0.917s, episode steps: 140, steps per second: 153, episode reward: -93.797, mean reward: -0.670 [-100.000, 11.743], mean action: 1.507 [0.000, 3.000],  loss: 234.674441, mae: 492.465201, mean_q: 671.402706, mean_eps: 0.677714
 108046/300000: episode: 1024, duration: 3.882s, episode steps: 547, steps per second: 141, episode reward: -255.689, mean reward: -0.467 [-100.000, 32.885], mean action: 1.700 [0.000, 3.000],  loss: 328.819322, mae: 496.616144, mean_q: 675.891442, mean_eps: 0.676684
 108160/300000: episode: 1025, duration: 0.717s, episode steps: 114, steps per second: 159, episode reward: -116.093, mean reward: -1.018 [-100.000,  7.977], mean action: 1.754 [0.000, 3.000],  loss: 324.038265, mae: 496.671148, mean_q: 677.389088, mean_eps: 0.675693
 108270/300000: episode: 1026, duration: 0.746s, episode steps: 110, steps per second: 147, episode reward: -201.821, mean reward: -1.835 [-100.000,  1.435], mean action: 1.682 [0.000, 3.000],  loss: 279.519915, mae: 494.325065, mean_q: 673.571741, mean_eps: 0.675357
 108458/300000: episode: 1027, duration: 1.239s, episode steps: 188, steps per second: 152, episode reward: -314.458, mean reward: -1.673 [-100.000,  4.634], mean action: 1.793 [0.000, 3.000],  loss: 333.437901, mae: 506.718527, mean_q: 691.353026, mean_eps: 0.674910
 108588/300000: episode: 1028, duration: 0.857s, episode steps: 130, steps per second: 152, episode reward: -213.839, mean reward: -1.645 [-100.000,  4.818], mean action: 1.669 [0.000, 3.000],  loss: 533.312407, mae: 502.707259, mean_q: 685.010982, mean_eps: 0.674432
 108707/300000: episode: 1029, duration: 0.784s, episode steps: 119, steps per second: 152, episode reward: -250.478, mean reward: -2.105 [-100.000, 18.511], mean action: 1.622 [0.000, 3.000],  loss: 366.123691, mae: 504.901268, mean_q: 688.925564, mean_eps: 0.674059
 108824/300000: episode: 1030, duration: 0.760s, episode steps: 117, steps per second: 154, episode reward: -519.412, mean reward: -4.439 [-100.000,  2.654], mean action: 1.564 [0.000, 3.000],  loss: 307.105875, mae: 494.125364, mean_q: 673.293579, mean_eps: 0.673705
 108906/300000: episode: 1031, duration: 0.574s, episode steps:  82, steps per second: 143, episode reward: -133.034, mean reward: -1.622 [-100.000,  6.151], mean action: 1.683 [0.000, 3.000],  loss: 297.506326, mae: 490.153538, mean_q: 667.749534, mean_eps: 0.673407
 109198/300000: episode: 1032, duration: 1.931s, episode steps: 292, steps per second: 151, episode reward: -72.251, mean reward: -0.247 [-100.000, 14.249], mean action: 1.712 [0.000, 3.000],  loss: 418.532877, mae: 494.998373, mean_q: 675.321240, mean_eps: 0.672845
 109284/300000: episode: 1033, duration: 0.567s, episode steps:  86, steps per second: 152, episode reward: -80.523, mean reward: -0.936 [-100.000, 12.887], mean action: 1.535 [0.000, 3.000],  loss: 318.938333, mae: 483.403606, mean_q: 658.861043, mean_eps: 0.672278
 109421/300000: episode: 1034, duration: 0.869s, episode steps: 137, steps per second: 158, episode reward: -240.204, mean reward: -1.753 [-100.000,  1.709], mean action: 1.679 [0.000, 3.000],  loss: 275.388378, mae: 484.985105, mean_q: 661.399897, mean_eps: 0.671944
 109578/300000: episode: 1035, duration: 1.038s, episode steps: 157, steps per second: 151, episode reward: -38.088, mean reward: -0.243 [-100.000, 16.426], mean action: 1.567 [0.000, 3.000],  loss: 256.445956, mae: 500.009548, mean_q: 682.605633, mean_eps: 0.671503
 109714/300000: episode: 1036, duration: 0.863s, episode steps: 136, steps per second: 158, episode reward: -132.873, mean reward: -0.977 [-100.000, 16.409], mean action: 1.750 [0.000, 3.000],  loss: 562.041655, mae: 496.937521, mean_q: 676.418588, mean_eps: 0.671063
 109814/300000: episode: 1037, duration: 0.639s, episode steps: 100, steps per second: 157, episode reward: -371.952, mean reward: -3.720 [-100.000, 49.334], mean action: 1.570 [0.000, 3.000],  loss: 219.407876, mae: 497.586277, mean_q: 677.445464, mean_eps: 0.670710
 109913/300000: episode: 1038, duration: 0.844s, episode steps:  99, steps per second: 117, episode reward: -3.300, mean reward: -0.033 [-100.000, 12.958], mean action: 1.667 [0.000, 3.000],  loss: 573.003321, mae: 504.234813, mean_q: 685.831176, mean_eps: 0.670411
 110003/300000: episode: 1039, duration: 0.684s, episode steps:  90, steps per second: 132, episode reward: -9.004, mean reward: -0.100 [-100.000, 32.274], mean action: 1.667 [0.000, 3.000],  loss: 261.423453, mae: 501.991897, mean_q: 683.877913, mean_eps: 0.670128
 110089/300000: episode: 1040, duration: 0.570s, episode steps:  86, steps per second: 151, episode reward: -40.761, mean reward: -0.474 [-100.000, 13.358], mean action: 1.581 [0.000, 3.000],  loss: 203.985335, mae: 508.677064, mean_q: 693.002703, mean_eps: 0.669863
 110180/300000: episode: 1041, duration: 0.631s, episode steps:  91, steps per second: 144, episode reward: -199.481, mean reward: -2.192 [-100.000,  1.791], mean action: 1.780 [0.000, 3.000],  loss: 332.593812, mae: 499.218450, mean_q: 678.577279, mean_eps: 0.669598
 110343/300000: episode: 1042, duration: 1.229s, episode steps: 163, steps per second: 133, episode reward: -14.057, mean reward: -0.086 [-100.000, 12.865], mean action: 1.638 [0.000, 3.000],  loss: 652.279711, mae: 507.594386, mean_q: 689.998692, mean_eps: 0.669217
 110448/300000: episode: 1043, duration: 0.765s, episode steps: 105, steps per second: 137, episode reward: -73.908, mean reward: -0.704 [-100.000, 11.244], mean action: 1.467 [0.000, 3.000],  loss: 519.724275, mae: 515.048156, mean_q: 700.330307, mean_eps: 0.668815
 110586/300000: episode: 1044, duration: 0.924s, episode steps: 138, steps per second: 149, episode reward: -14.470, mean reward: -0.105 [-100.000, 16.568], mean action: 1.609 [0.000, 3.000],  loss: 421.060950, mae: 511.770714, mean_q: 697.494990, mean_eps: 0.668451
 110664/300000: episode: 1045, duration: 0.525s, episode steps:  78, steps per second: 149, episode reward: -16.117, mean reward: -0.207 [-100.000, 10.575], mean action: 1.615 [0.000, 3.000],  loss: 536.958717, mae: 527.089818, mean_q: 720.411212, mean_eps: 0.668126
 110824/300000: episode: 1046, duration: 1.083s, episode steps: 160, steps per second: 148, episode reward: -183.243, mean reward: -1.145 [-100.000, 10.542], mean action: 1.725 [0.000, 3.000],  loss: 364.328684, mae: 519.748650, mean_q: 709.234850, mean_eps: 0.667770
 110988/300000: episode: 1047, duration: 1.090s, episode steps: 164, steps per second: 150, episode reward: -212.472, mean reward: -1.296 [-100.000,  4.094], mean action: 1.689 [0.000, 3.000],  loss: 365.155268, mae: 526.560634, mean_q: 718.309159, mean_eps: 0.667284
 111065/300000: episode: 1048, duration: 0.494s, episode steps:  77, steps per second: 156, episode reward: -52.651, mean reward: -0.684 [-100.000, 19.877], mean action: 1.753 [0.000, 3.000],  loss: 306.417288, mae: 538.696816, mean_q: 737.189074, mean_eps: 0.666922
 111360/300000: episode: 1049, duration: 1.963s, episode steps: 295, steps per second: 150, episode reward: -86.704, mean reward: -0.294 [-100.000, 10.412], mean action: 1.658 [0.000, 3.000],  loss: 319.920771, mae: 533.797372, mean_q: 728.910832, mean_eps: 0.666364
 111454/300000: episode: 1050, duration: 0.647s, episode steps:  94, steps per second: 145, episode reward: -35.015, mean reward: -0.372 [-100.000, 16.633], mean action: 1.553 [0.000, 3.000],  loss: 867.635167, mae: 536.039055, mean_q: 731.888857, mean_eps: 0.665780
 111553/300000: episode: 1051, duration: 0.644s, episode steps:  99, steps per second: 154, episode reward: -100.249, mean reward: -1.013 [-100.000,  7.903], mean action: 1.535 [0.000, 3.000],  loss: 720.360563, mae: 536.005152, mean_q: 730.915527, mean_eps: 0.665491
 111667/300000: episode: 1052, duration: 0.732s, episode steps: 114, steps per second: 156, episode reward: -120.435, mean reward: -1.056 [-100.000,  7.325], mean action: 1.605 [0.000, 3.000],  loss: 397.277748, mae: 530.241086, mean_q: 723.566983, mean_eps: 0.665171
 111806/300000: episode: 1053, duration: 1.056s, episode steps: 139, steps per second: 132, episode reward: -66.227, mean reward: -0.476 [-100.000,  6.626], mean action: 1.755 [0.000, 3.000],  loss: 365.280478, mae: 534.084279, mean_q: 728.014264, mean_eps: 0.664792
 111949/300000: episode: 1054, duration: 1.004s, episode steps: 143, steps per second: 142, episode reward: -33.666, mean reward: -0.235 [-100.000, 10.356], mean action: 1.713 [0.000, 3.000],  loss: 326.363874, mae: 540.960745, mean_q: 737.561871, mean_eps: 0.664369
 112074/300000: episode: 1055, duration: 0.915s, episode steps: 125, steps per second: 137, episode reward: -142.738, mean reward: -1.142 [-100.000,  9.804], mean action: 1.632 [0.000, 3.000],  loss: 330.882050, mae: 538.393776, mean_q: 733.864517, mean_eps: 0.663967
 112145/300000: episode: 1056, duration: 0.495s, episode steps:  71, steps per second: 143, episode reward: -57.679, mean reward: -0.812 [-100.000,  9.233], mean action: 1.634 [0.000, 3.000],  loss: 593.936979, mae: 534.975313, mean_q: 728.145835, mean_eps: 0.663673
 112253/300000: episode: 1057, duration: 0.754s, episode steps: 108, steps per second: 143, episode reward: -44.809, mean reward: -0.415 [-100.000, 11.679], mean action: 1.620 [0.000, 3.000],  loss: 417.158796, mae: 528.867880, mean_q: 720.238173, mean_eps: 0.663405
 112355/300000: episode: 1058, duration: 0.724s, episode steps: 102, steps per second: 141, episode reward: 17.968, mean reward:  0.176 [-100.000, 15.217], mean action: 1.569 [0.000, 3.000],  loss: 344.496309, mae: 527.691148, mean_q: 719.316500, mean_eps: 0.663089
 112448/300000: episode: 1059, duration: 0.618s, episode steps:  93, steps per second: 150, episode reward: -141.244, mean reward: -1.519 [-100.000,  5.085], mean action: 1.742 [0.000, 3.000],  loss: 592.834181, mae: 531.922223, mean_q: 725.157901, mean_eps: 0.662797
 112536/300000: episode: 1060, duration: 0.565s, episode steps:  88, steps per second: 156, episode reward: -3.870, mean reward: -0.044 [-100.000, 17.265], mean action: 1.557 [0.000, 3.000],  loss: 373.575300, mae: 540.570793, mean_q: 737.316834, mean_eps: 0.662525
 112604/300000: episode: 1061, duration: 0.426s, episode steps:  68, steps per second: 160, episode reward: -81.947, mean reward: -1.205 [-100.000,  7.698], mean action: 1.353 [0.000, 3.000],  loss: 492.719525, mae: 539.029780, mean_q: 734.667525, mean_eps: 0.662291
 112803/300000: episode: 1062, duration: 1.334s, episode steps: 199, steps per second: 149, episode reward: -186.034, mean reward: -0.935 [-100.000,  6.039], mean action: 1.678 [0.000, 3.000],  loss: 466.066005, mae: 545.921568, mean_q: 743.871336, mean_eps: 0.661891
 112934/300000: episode: 1063, duration: 0.855s, episode steps: 131, steps per second: 153, episode reward: -65.076, mean reward: -0.497 [-100.000,  9.662], mean action: 1.573 [0.000, 3.000],  loss: 504.132755, mae: 553.188783, mean_q: 753.302637, mean_eps: 0.661396
 113057/300000: episode: 1064, duration: 0.832s, episode steps: 123, steps per second: 148, episode reward: -184.435, mean reward: -1.499 [-100.000,  5.415], mean action: 1.634 [0.000, 3.000],  loss: 253.680966, mae: 546.130345, mean_q: 745.245341, mean_eps: 0.661015
 113150/300000: episode: 1065, duration: 0.596s, episode steps:  93, steps per second: 156, episode reward: -59.051, mean reward: -0.635 [-100.000, 14.872], mean action: 1.516 [0.000, 3.000],  loss: 638.888575, mae: 553.181503, mean_q: 753.235520, mean_eps: 0.660691
 113408/300000: episode: 1066, duration: 1.721s, episode steps: 258, steps per second: 150, episode reward: -137.316, mean reward: -0.532 [-100.000,  7.157], mean action: 1.733 [0.000, 3.000],  loss: 439.179884, mae: 557.051593, mean_q: 759.435537, mean_eps: 0.660165
 113539/300000: episode: 1067, duration: 0.826s, episode steps: 131, steps per second: 159, episode reward: -136.962, mean reward: -1.046 [-100.000,  7.458], mean action: 1.695 [0.000, 3.000],  loss: 440.837304, mae: 565.665518, mean_q: 770.441114, mean_eps: 0.659581
 113653/300000: episode: 1068, duration: 0.785s, episode steps: 114, steps per second: 145, episode reward: -141.348, mean reward: -1.240 [-100.000,  7.983], mean action: 1.596 [0.000, 3.000],  loss: 478.507903, mae: 554.406796, mean_q: 755.746970, mean_eps: 0.659213
 113760/300000: episode: 1069, duration: 0.722s, episode steps: 107, steps per second: 148, episode reward: -91.497, mean reward: -0.855 [-100.000, 16.183], mean action: 1.626 [0.000, 3.000],  loss: 349.650156, mae: 564.981117, mean_q: 770.368928, mean_eps: 0.658882
 113949/300000: episode: 1070, duration: 1.208s, episode steps: 189, steps per second: 156, episode reward: -88.663, mean reward: -0.469 [-100.000, 10.819], mean action: 1.624 [0.000, 3.000],  loss: 368.307681, mae: 562.695043, mean_q: 767.813529, mean_eps: 0.658438
 114066/300000: episode: 1071, duration: 0.799s, episode steps: 117, steps per second: 147, episode reward: -162.638, mean reward: -1.390 [-100.000,  2.380], mean action: 1.761 [0.000, 3.000],  loss: 482.341879, mae: 567.052109, mean_q: 773.109256, mean_eps: 0.657979
 114186/300000: episode: 1072, duration: 0.778s, episode steps: 120, steps per second: 154, episode reward: -279.297, mean reward: -2.327 [-100.000,  3.258], mean action: 1.608 [0.000, 3.000],  loss: 472.735784, mae: 560.746730, mean_q: 764.807021, mean_eps: 0.657624
 114292/300000: episode: 1073, duration: 0.690s, episode steps: 106, steps per second: 154, episode reward: -178.237, mean reward: -1.681 [-100.000,  1.195], mean action: 1.755 [0.000, 3.000],  loss: 300.795237, mae: 565.114256, mean_q: 771.186736, mean_eps: 0.657284
 114407/300000: episode: 1074, duration: 0.773s, episode steps: 115, steps per second: 149, episode reward: 29.802, mean reward:  0.259 [-100.000, 21.109], mean action: 1.617 [0.000, 3.000],  loss: 321.298311, mae: 568.138222, mean_q: 776.180552, mean_eps: 0.656953
 114535/300000: episode: 1075, duration: 0.828s, episode steps: 128, steps per second: 155, episode reward: -201.298, mean reward: -1.573 [-100.000, 44.431], mean action: 1.750 [0.000, 3.000],  loss: 449.096969, mae: 564.476355, mean_q: 769.469349, mean_eps: 0.656589
 114811/300000: episode: 1076, duration: 1.933s, episode steps: 276, steps per second: 143, episode reward: -235.925, mean reward: -0.855 [-100.000, 69.694], mean action: 1.707 [0.000, 3.000],  loss: 360.442352, mae: 571.646023, mean_q: 780.107577, mean_eps: 0.655982
 114942/300000: episode: 1077, duration: 0.877s, episode steps: 131, steps per second: 149, episode reward: -193.614, mean reward: -1.478 [-100.000,  2.930], mean action: 1.687 [0.000, 3.000],  loss: 392.171474, mae: 585.239102, mean_q: 797.333287, mean_eps: 0.655372
 115118/300000: episode: 1078, duration: 1.152s, episode steps: 176, steps per second: 153, episode reward: -42.434, mean reward: -0.241 [-100.000,  7.779], mean action: 1.665 [0.000, 3.000],  loss: 379.771009, mae: 586.526161, mean_q: 800.253791, mean_eps: 0.654911
 115244/300000: episode: 1079, duration: 0.813s, episode steps: 126, steps per second: 155, episode reward: -199.572, mean reward: -1.584 [-100.000, 19.046], mean action: 1.492 [0.000, 3.000],  loss: 394.037618, mae: 587.252174, mean_q: 801.783589, mean_eps: 0.654458
 115331/300000: episode: 1080, duration: 0.607s, episode steps:  87, steps per second: 143, episode reward: -85.063, mean reward: -0.978 [-100.000, 10.784], mean action: 1.736 [0.000, 3.000],  loss: 431.732877, mae: 581.821278, mean_q: 793.115974, mean_eps: 0.654139
 115413/300000: episode: 1081, duration: 0.554s, episode steps:  82, steps per second: 148, episode reward: -33.761, mean reward: -0.412 [-100.000, 13.643], mean action: 1.634 [0.000, 3.000],  loss: 480.985799, mae: 573.906438, mean_q: 782.079926, mean_eps: 0.653886
 115586/300000: episode: 1082, duration: 1.409s, episode steps: 173, steps per second: 123, episode reward:  8.789, mean reward:  0.051 [-100.000, 13.714], mean action: 1.757 [0.000, 3.000],  loss: 487.107972, mae: 597.418027, mean_q: 813.992754, mean_eps: 0.653503
 115652/300000: episode: 1083, duration: 0.512s, episode steps:  66, steps per second: 129, episode reward: -187.592, mean reward: -2.842 [-100.000,  6.333], mean action: 1.636 [0.000, 3.000],  loss: 389.522105, mae: 601.761494, mean_q: 821.286758, mean_eps: 0.653145
 115730/300000: episode: 1084, duration: 0.631s, episode steps:  78, steps per second: 124, episode reward: -43.126, mean reward: -0.553 [-100.000,  9.524], mean action: 1.474 [0.000, 3.000],  loss: 312.958796, mae: 597.324513, mean_q: 815.945096, mean_eps: 0.652929
 115895/300000: episode: 1085, duration: 1.358s, episode steps: 165, steps per second: 122, episode reward: -14.956, mean reward: -0.091 [-100.000, 16.568], mean action: 1.770 [0.000, 3.000],  loss: 398.204169, mae: 598.067061, mean_q: 813.979082, mean_eps: 0.652564
 116017/300000: episode: 1086, duration: 0.857s, episode steps: 122, steps per second: 142, episode reward: -50.619, mean reward: -0.415 [-100.000, 20.619], mean action: 1.590 [0.000, 3.000],  loss: 519.787138, mae: 602.707789, mean_q: 822.463812, mean_eps: 0.652134
 116108/300000: episode: 1087, duration: 0.644s, episode steps:  91, steps per second: 141, episode reward: -5.954, mean reward: -0.065 [-100.000, 100.147], mean action: 1.648 [0.000, 3.000],  loss: 372.412489, mae: 595.879500, mean_q: 812.774006, mean_eps: 0.651814
 116188/300000: episode: 1088, duration: 0.561s, episode steps:  80, steps per second: 143, episode reward: -98.584, mean reward: -1.232 [-100.000, 21.771], mean action: 1.650 [0.000, 3.000],  loss: 461.145705, mae: 604.654188, mean_q: 824.175930, mean_eps: 0.651558
 116355/300000: episode: 1089, duration: 1.106s, episode steps: 167, steps per second: 151, episode reward: -50.620, mean reward: -0.303 [-100.000, 10.287], mean action: 1.683 [0.000, 3.000],  loss: 363.729785, mae: 605.103530, mean_q: 824.702932, mean_eps: 0.651187
 116516/300000: episode: 1090, duration: 1.071s, episode steps: 161, steps per second: 150, episode reward: -138.802, mean reward: -0.862 [-100.000,  7.827], mean action: 1.702 [0.000, 3.000],  loss: 397.574843, mae: 608.951210, mean_q: 830.716466, mean_eps: 0.650695
 116607/300000: episode: 1091, duration: 0.593s, episode steps:  91, steps per second: 154, episode reward: -99.611, mean reward: -1.095 [-100.000,  8.043], mean action: 1.429 [0.000, 3.000],  loss: 571.949852, mae: 594.578271, mean_q: 809.590820, mean_eps: 0.650317
 116729/300000: episode: 1092, duration: 0.791s, episode steps: 122, steps per second: 154, episode reward: -174.508, mean reward: -1.430 [-100.000,  3.457], mean action: 1.762 [0.000, 3.000],  loss: 485.233639, mae: 604.269415, mean_q: 822.792743, mean_eps: 0.649997
 116877/300000: episode: 1093, duration: 0.997s, episode steps: 148, steps per second: 148, episode reward: -101.518, mean reward: -0.686 [-100.000,  9.325], mean action: 1.750 [0.000, 3.000],  loss: 421.961130, mae: 605.913352, mean_q: 824.588863, mean_eps: 0.649593
 117032/300000: episode: 1094, duration: 0.991s, episode steps: 155, steps per second: 156, episode reward: -168.037, mean reward: -1.084 [-100.000,  2.812], mean action: 1.703 [0.000, 3.000],  loss: 455.272523, mae: 609.945483, mean_q: 831.565868, mean_eps: 0.649138
 117166/300000: episode: 1095, duration: 0.906s, episode steps: 134, steps per second: 148, episode reward: -178.589, mean reward: -1.333 [-100.000,  2.053], mean action: 1.769 [0.000, 3.000],  loss: 404.051769, mae: 617.343174, mean_q: 840.588183, mean_eps: 0.648704
 117342/300000: episode: 1096, duration: 1.157s, episode steps: 176, steps per second: 152, episode reward: -206.061, mean reward: -1.171 [-100.000, 12.960], mean action: 1.773 [0.000, 3.000],  loss: 397.022441, mae: 616.513385, mean_q: 840.043708, mean_eps: 0.648239
 117484/300000: episode: 1097, duration: 0.959s, episode steps: 142, steps per second: 148, episode reward: -52.519, mean reward: -0.370 [-100.000,  6.827], mean action: 1.754 [0.000, 3.000],  loss: 637.925025, mae: 624.220738, mean_q: 850.484237, mean_eps: 0.647762
 117617/300000: episode: 1098, duration: 0.867s, episode steps: 133, steps per second: 153, episode reward: -16.477, mean reward: -0.124 [-100.000, 17.093], mean action: 1.511 [0.000, 3.000],  loss: 351.031685, mae: 625.422875, mean_q: 853.466099, mean_eps: 0.647350
 117712/300000: episode: 1099, duration: 0.621s, episode steps:  95, steps per second: 153, episode reward: -71.699, mean reward: -0.755 [-100.000,  6.946], mean action: 1.684 [0.000, 3.000],  loss: 373.992852, mae: 630.566875, mean_q: 859.746605, mean_eps: 0.647008
 117842/300000: episode: 1100, duration: 0.894s, episode steps: 130, steps per second: 145, episode reward: -49.584, mean reward: -0.381 [-100.000, 11.638], mean action: 1.762 [0.000, 3.000],  loss: 306.277073, mae: 625.116456, mean_q: 851.899792, mean_eps: 0.646670
 117970/300000: episode: 1101, duration: 0.827s, episode steps: 128, steps per second: 155, episode reward: -67.178, mean reward: -0.525 [-100.000, 10.943], mean action: 1.734 [0.000, 3.000],  loss: 355.767595, mae: 622.604327, mean_q: 848.357751, mean_eps: 0.646284
 118066/300000: episode: 1102, duration: 0.640s, episode steps:  96, steps per second: 150, episode reward: -87.946, mean reward: -0.916 [-100.000,  8.690], mean action: 1.802 [0.000, 3.000],  loss: 452.857553, mae: 620.298136, mean_q: 845.195153, mean_eps: 0.645948
 118325/300000: episode: 1103, duration: 1.764s, episode steps: 259, steps per second: 147, episode reward: -110.673, mean reward: -0.427 [-100.000, 12.850], mean action: 1.695 [0.000, 3.000],  loss: 442.454768, mae: 628.659188, mean_q: 857.538984, mean_eps: 0.645415
 118441/300000: episode: 1104, duration: 0.785s, episode steps: 116, steps per second: 148, episode reward: -109.328, mean reward: -0.942 [-100.000, 15.946], mean action: 1.759 [0.000, 3.000],  loss: 530.497822, mae: 629.641204, mean_q: 859.417868, mean_eps: 0.644852
 118596/300000: episode: 1105, duration: 1.020s, episode steps: 155, steps per second: 152, episode reward: -203.262, mean reward: -1.311 [-100.000,  2.600], mean action: 1.671 [0.000, 3.000],  loss: 372.144300, mae: 633.411575, mean_q: 863.858491, mean_eps: 0.644446
 118696/300000: episode: 1106, duration: 0.632s, episode steps: 100, steps per second: 158, episode reward: -178.762, mean reward: -1.788 [-100.000,  2.224], mean action: 1.860 [0.000, 3.000],  loss: 292.961140, mae: 631.028513, mean_q: 860.059692, mean_eps: 0.644064
 118778/300000: episode: 1107, duration: 0.582s, episode steps:  82, steps per second: 141, episode reward: -87.445, mean reward: -1.066 [-100.000, 10.033], mean action: 1.902 [0.000, 3.000],  loss: 516.678587, mae: 639.839108, mean_q: 870.361933, mean_eps: 0.643791
 118910/300000: episode: 1108, duration: 0.897s, episode steps: 132, steps per second: 147, episode reward: -135.828, mean reward: -1.029 [-100.000,  2.219], mean action: 1.795 [0.000, 3.000],  loss: 423.522828, mae: 636.142375, mean_q: 866.649276, mean_eps: 0.643470
 119040/300000: episode: 1109, duration: 0.922s, episode steps: 130, steps per second: 141, episode reward: -174.798, mean reward: -1.345 [-100.000,  2.284], mean action: 1.808 [0.000, 3.000],  loss: 368.971498, mae: 639.428748, mean_q: 871.328809, mean_eps: 0.643076
 119161/300000: episode: 1110, duration: 0.797s, episode steps: 121, steps per second: 152, episode reward: -71.566, mean reward: -0.591 [-100.000, 13.238], mean action: 1.678 [0.000, 3.000],  loss: 451.511736, mae: 636.898427, mean_q: 867.010170, mean_eps: 0.642700
 119253/300000: episode: 1111, duration: 0.583s, episode steps:  92, steps per second: 158, episode reward: -92.542, mean reward: -1.006 [-100.000,  9.305], mean action: 1.576 [0.000, 3.000],  loss: 468.800253, mae: 625.913913, mean_q: 852.194404, mean_eps: 0.642380
 119321/300000: episode: 1112, duration: 0.434s, episode steps:  68, steps per second: 157, episode reward: -62.621, mean reward: -0.921 [-100.000,  5.530], mean action: 1.765 [0.000, 3.000],  loss: 352.144379, mae: 628.270535, mean_q: 854.407640, mean_eps: 0.642141
 119507/300000: episode: 1113, duration: 1.260s, episode steps: 186, steps per second: 148, episode reward: -74.065, mean reward: -0.398 [-100.000,  9.166], mean action: 1.710 [0.000, 3.000],  loss: 503.272022, mae: 630.519455, mean_q: 858.171358, mean_eps: 0.641760
 119595/300000: episode: 1114, duration: 0.569s, episode steps:  88, steps per second: 155, episode reward: -49.943, mean reward: -0.568 [-100.000, 10.340], mean action: 1.670 [0.000, 3.000],  loss: 554.468514, mae: 647.646008, mean_q: 880.088939, mean_eps: 0.641348
 119725/300000: episode: 1115, duration: 0.880s, episode steps: 130, steps per second: 148, episode reward: -175.339, mean reward: -1.349 [-100.000,  2.996], mean action: 1.677 [0.000, 3.000],  loss: 431.871343, mae: 638.234260, mean_q: 867.418894, mean_eps: 0.641022
 119846/300000: episode: 1116, duration: 0.818s, episode steps: 121, steps per second: 148, episode reward: -57.017, mean reward: -0.471 [-100.000,  5.770], mean action: 1.736 [0.000, 3.000],  loss: 402.357652, mae: 627.446144, mean_q: 852.311516, mean_eps: 0.640645
 120237/300000: episode: 1117, duration: 2.652s, episode steps: 391, steps per second: 147, episode reward: -264.892, mean reward: -0.677 [-100.000, 17.747], mean action: 1.744 [0.000, 3.000],  loss: 473.481029, mae: 633.937915, mean_q: 862.377673, mean_eps: 0.639877
 120399/300000: episode: 1118, duration: 1.100s, episode steps: 162, steps per second: 147, episode reward: -39.142, mean reward: -0.242 [-100.000,  7.554], mean action: 1.833 [0.000, 3.000],  loss: 518.527248, mae: 637.263117, mean_q: 865.130826, mean_eps: 0.639048
 120503/300000: episode: 1119, duration: 0.693s, episode steps: 104, steps per second: 150, episode reward: -30.351, mean reward: -0.292 [-100.000,  8.782], mean action: 1.587 [0.000, 3.000],  loss: 592.297737, mae: 640.228735, mean_q: 869.749193, mean_eps: 0.638648
 120772/300000: episode: 1120, duration: 1.800s, episode steps: 269, steps per second: 149, episode reward: -5.869, mean reward: -0.022 [-100.000, 16.874], mean action: 1.658 [0.000, 3.000],  loss: 519.078539, mae: 632.660530, mean_q: 858.979444, mean_eps: 0.638089
 120890/300000: episode: 1121, duration: 0.760s, episode steps: 118, steps per second: 155, episode reward: -39.618, mean reward: -0.336 [-100.000,  8.625], mean action: 1.703 [0.000, 3.000],  loss: 536.253994, mae: 634.770327, mean_q: 862.622487, mean_eps: 0.637509
 121020/300000: episode: 1122, duration: 0.877s, episode steps: 130, steps per second: 148, episode reward: -234.259, mean reward: -1.802 [-100.000, 64.574], mean action: 1.592 [0.000, 3.000],  loss: 567.495847, mae: 633.053646, mean_q: 861.366523, mean_eps: 0.637136
 121215/300000: episode: 1123, duration: 1.261s, episode steps: 195, steps per second: 155, episode reward: -117.240, mean reward: -0.601 [-100.000,  9.159], mean action: 1.672 [0.000, 3.000],  loss: 569.174016, mae: 639.288684, mean_q: 870.067227, mean_eps: 0.636649
 121324/300000: episode: 1124, duration: 0.725s, episode steps: 109, steps per second: 150, episode reward: -156.738, mean reward: -1.438 [-100.000, 14.595], mean action: 1.596 [0.000, 3.000],  loss: 488.077209, mae: 632.612163, mean_q: 861.250418, mean_eps: 0.636193
 121415/300000: episode: 1125, duration: 0.612s, episode steps:  91, steps per second: 149, episode reward: -88.383, mean reward: -0.971 [-100.000,  8.040], mean action: 1.714 [0.000, 3.000],  loss: 369.918407, mae: 641.152479, mean_q: 872.352638, mean_eps: 0.635893
 121531/300000: episode: 1126, duration: 0.814s, episode steps: 116, steps per second: 142, episode reward:  7.428, mean reward:  0.064 [-100.000, 14.341], mean action: 1.776 [0.000, 3.000],  loss: 569.151239, mae: 638.460289, mean_q: 867.332067, mean_eps: 0.635583
 121666/300000: episode: 1127, duration: 1.015s, episode steps: 135, steps per second: 133, episode reward: -25.746, mean reward: -0.191 [-100.000, 17.659], mean action: 1.548 [0.000, 3.000],  loss: 508.266626, mae: 633.100825, mean_q: 860.511353, mean_eps: 0.635206
 121767/300000: episode: 1128, duration: 0.716s, episode steps: 101, steps per second: 141, episode reward: -71.171, mean reward: -0.705 [-100.000,  7.286], mean action: 1.574 [0.000, 3.000],  loss: 677.543089, mae: 638.114108, mean_q: 866.827219, mean_eps: 0.634852
 121926/300000: episode: 1129, duration: 1.178s, episode steps: 159, steps per second: 135, episode reward: -181.757, mean reward: -1.143 [-100.000,  3.652], mean action: 1.717 [0.000, 3.000],  loss: 561.454673, mae: 633.691396, mean_q: 860.327459, mean_eps: 0.634462
 121999/300000: episode: 1130, duration: 0.531s, episode steps:  73, steps per second: 138, episode reward: -86.122, mean reward: -1.180 [-100.000,  7.653], mean action: 1.603 [0.000, 3.000],  loss: 695.266699, mae: 639.371932, mean_q: 865.637202, mean_eps: 0.634114
 122133/300000: episode: 1131, duration: 0.929s, episode steps: 134, steps per second: 144, episode reward: -67.817, mean reward: -0.506 [-100.000,  7.599], mean action: 1.627 [0.000, 3.000],  loss: 489.131782, mae: 642.551076, mean_q: 870.803144, mean_eps: 0.633803
 122239/300000: episode: 1132, duration: 0.732s, episode steps: 106, steps per second: 145, episode reward: -59.670, mean reward: -0.563 [-100.000, 10.100], mean action: 1.679 [0.000, 3.000],  loss: 517.914059, mae: 642.330402, mean_q: 871.246205, mean_eps: 0.633443
 122342/300000: episode: 1133, duration: 0.684s, episode steps: 103, steps per second: 151, episode reward: -15.971, mean reward: -0.155 [-100.000, 18.045], mean action: 1.699 [0.000, 3.000],  loss: 435.716307, mae: 645.007989, mean_q: 875.607302, mean_eps: 0.633130
 122517/300000: episode: 1134, duration: 1.120s, episode steps: 175, steps per second: 156, episode reward: -79.110, mean reward: -0.452 [-100.000,  7.860], mean action: 1.691 [0.000, 3.000],  loss: 590.366101, mae: 632.382998, mean_q: 858.671842, mean_eps: 0.632713
 122781/300000: episode: 1135, duration: 1.823s, episode steps: 264, steps per second: 145, episode reward: -187.453, mean reward: -0.710 [-100.000,  7.633], mean action: 1.633 [0.000, 3.000],  loss: 570.546481, mae: 636.411514, mean_q: 863.123183, mean_eps: 0.632055
 123010/300000: episode: 1136, duration: 1.567s, episode steps: 229, steps per second: 146, episode reward: -78.296, mean reward: -0.342 [-100.000, 18.148], mean action: 1.760 [0.000, 3.000],  loss: 689.560143, mae: 637.831237, mean_q: 864.468511, mean_eps: 0.631315
 123148/300000: episode: 1137, duration: 0.915s, episode steps: 138, steps per second: 151, episode reward: -150.255, mean reward: -1.089 [-100.000, 19.892], mean action: 1.609 [0.000, 3.000],  loss: 666.205044, mae: 630.509268, mean_q: 855.516740, mean_eps: 0.630764
 123264/300000: episode: 1138, duration: 0.958s, episode steps: 116, steps per second: 121, episode reward: -60.545, mean reward: -0.522 [-100.000, 13.791], mean action: 1.638 [0.000, 3.000],  loss: 603.689289, mae: 619.725483, mean_q: 838.946149, mean_eps: 0.630383
 123394/300000: episode: 1139, duration: 0.861s, episode steps: 130, steps per second: 151, episode reward: -162.521, mean reward: -1.250 [-100.000, 12.328], mean action: 1.669 [0.000, 3.000],  loss: 584.183923, mae: 620.349248, mean_q: 843.144942, mean_eps: 0.630014
 123522/300000: episode: 1140, duration: 0.870s, episode steps: 128, steps per second: 147, episode reward: -98.199, mean reward: -0.767 [-100.000, 11.276], mean action: 1.727 [0.000, 3.000],  loss: 860.600852, mae: 619.085870, mean_q: 839.720646, mean_eps: 0.629628
 123677/300000: episode: 1141, duration: 1.007s, episode steps: 155, steps per second: 154, episode reward: -99.438, mean reward: -0.642 [-100.000,  7.198], mean action: 1.813 [0.000, 3.000],  loss: 618.416044, mae: 626.889569, mean_q: 850.506081, mean_eps: 0.629203
 123752/300000: episode: 1142, duration: 0.486s, episode steps:  75, steps per second: 154, episode reward: -31.799, mean reward: -0.424 [-100.000, 11.991], mean action: 1.747 [0.000, 3.000],  loss: 430.384345, mae: 617.681836, mean_q: 838.103524, mean_eps: 0.628858
 123871/300000: episode: 1143, duration: 0.816s, episode steps: 119, steps per second: 146, episode reward: -3.035, mean reward: -0.026 [-100.000, 12.826], mean action: 1.639 [0.000, 3.000],  loss: 583.144703, mae: 615.461020, mean_q: 835.780073, mean_eps: 0.628567
 124091/300000: episode: 1144, duration: 1.465s, episode steps: 220, steps per second: 150, episode reward: -45.648, mean reward: -0.207 [-100.000, 25.949], mean action: 1.664 [0.000, 3.000],  loss: 569.475049, mae: 622.151078, mean_q: 842.825165, mean_eps: 0.628058
 124188/300000: episode: 1145, duration: 0.671s, episode steps:  97, steps per second: 145, episode reward: -53.870, mean reward: -0.555 [-100.000,  8.040], mean action: 1.515 [0.000, 3.000],  loss: 708.126519, mae: 624.169856, mean_q: 846.925924, mean_eps: 0.627583
 124315/300000: episode: 1146, duration: 0.819s, episode steps: 127, steps per second: 155, episode reward: -35.249, mean reward: -0.278 [-100.000, 19.786], mean action: 1.567 [0.000, 3.000],  loss: 846.828177, mae: 629.320654, mean_q: 853.748663, mean_eps: 0.627247
 124606/300000: episode: 1147, duration: 1.952s, episode steps: 291, steps per second: 149, episode reward: -211.798, mean reward: -0.728 [-100.000,  7.736], mean action: 1.498 [0.000, 3.000],  loss: 681.901631, mae: 625.001216, mean_q: 847.844491, mean_eps: 0.626620
 124723/300000: episode: 1148, duration: 0.753s, episode steps: 117, steps per second: 155, episode reward: -66.553, mean reward: -0.569 [-100.000,  7.014], mean action: 1.778 [0.000, 3.000],  loss: 466.733871, mae: 632.065306, mean_q: 857.925797, mean_eps: 0.626008
 124836/300000: episode: 1149, duration: 0.803s, episode steps: 113, steps per second: 141, episode reward: -42.817, mean reward: -0.379 [-100.000,  6.529], mean action: 1.743 [0.000, 3.000],  loss: 636.387556, mae: 628.724277, mean_q: 853.602562, mean_eps: 0.625663
 124988/300000: episode: 1150, duration: 1.000s, episode steps: 152, steps per second: 152, episode reward: -60.784, mean reward: -0.400 [-100.000, 18.942], mean action: 1.724 [0.000, 3.000],  loss: 706.323116, mae: 633.363454, mean_q: 860.231494, mean_eps: 0.625266
 125066/300000: episode: 1151, duration: 0.531s, episode steps:  78, steps per second: 147, episode reward: -31.229, mean reward: -0.400 [-100.000, 26.857], mean action: 1.692 [0.000, 3.000],  loss: 491.527138, mae: 634.242651, mean_q: 861.797882, mean_eps: 0.624920
 125165/300000: episode: 1152, duration: 0.670s, episode steps:  99, steps per second: 148, episode reward: -19.161, mean reward: -0.194 [-100.000,  9.380], mean action: 1.778 [0.000, 3.000],  loss: 689.847048, mae: 640.026457, mean_q: 869.947234, mean_eps: 0.624655
 125259/300000: episode: 1153, duration: 0.708s, episode steps:  94, steps per second: 133, episode reward: 26.085, mean reward:  0.278 [-100.000, 21.184], mean action: 1.809 [0.000, 3.000],  loss: 630.971214, mae: 634.413620, mean_q: 862.522489, mean_eps: 0.624366
 125367/300000: episode: 1154, duration: 0.818s, episode steps: 108, steps per second: 132, episode reward: -33.487, mean reward: -0.310 [-100.000, 14.071], mean action: 1.694 [0.000, 3.000],  loss: 1186.909350, mae: 628.118076, mean_q: 852.838582, mean_eps: 0.624063
 125522/300000: episode: 1155, duration: 1.187s, episode steps: 155, steps per second: 131, episode reward: -13.573, mean reward: -0.088 [-100.000, 13.017], mean action: 1.690 [0.000, 3.000],  loss: 679.157895, mae: 637.123031, mean_q: 866.174795, mean_eps: 0.623668
 126522/300000: episode: 1156, duration: 7.948s, episode steps: 1000, steps per second: 126, episode reward: -79.584, mean reward: -0.080 [-24.561, 43.727], mean action: 1.659 [0.000, 3.000],  loss: 767.271238, mae: 665.677257, mean_q: 904.363827, mean_eps: 0.621936
 126645/300000: episode: 1157, duration: 0.953s, episode steps: 123, steps per second: 129, episode reward: -47.212, mean reward: -0.384 [-100.000, 18.467], mean action: 1.618 [0.000, 3.000],  loss: 1297.845473, mae: 695.137035, mean_q: 942.744239, mean_eps: 0.620251
 126719/300000: episode: 1158, duration: 0.556s, episode steps:  74, steps per second: 133, episode reward: -44.381, mean reward: -0.600 [-100.000,  7.492], mean action: 1.662 [0.000, 3.000],  loss: 1084.842891, mae: 697.287750, mean_q: 945.496283, mean_eps: 0.619955
 126843/300000: episode: 1159, duration: 0.869s, episode steps: 124, steps per second: 143, episode reward: -40.373, mean reward: -0.326 [-100.000, 12.044], mean action: 1.702 [0.000, 3.000],  loss: 805.397179, mae: 687.573795, mean_q: 934.041463, mean_eps: 0.619659
 126997/300000: episode: 1160, duration: 0.990s, episode steps: 154, steps per second: 156, episode reward: -117.030, mean reward: -0.760 [-100.000,  7.805], mean action: 1.416 [0.000, 3.000],  loss: 1076.392001, mae: 695.929149, mean_q: 943.740886, mean_eps: 0.619242
 127095/300000: episode: 1161, duration: 0.709s, episode steps:  98, steps per second: 138, episode reward: -8.810, mean reward: -0.090 [-100.000, 10.211], mean action: 1.694 [0.000, 3.000],  loss: 787.556171, mae: 700.934016, mean_q: 950.302492, mean_eps: 0.618864
 127199/300000: episode: 1162, duration: 0.712s, episode steps: 104, steps per second: 146, episode reward: -13.017, mean reward: -0.125 [-100.000, 19.834], mean action: 1.635 [0.000, 3.000],  loss: 869.268548, mae: 702.833201, mean_q: 954.281596, mean_eps: 0.618560
 127328/300000: episode: 1163, duration: 0.849s, episode steps: 129, steps per second: 152, episode reward: -41.318, mean reward: -0.320 [-100.000, 11.784], mean action: 1.721 [0.000, 3.000],  loss: 912.287640, mae: 710.699341, mean_q: 965.923035, mean_eps: 0.618211
 127409/300000: episode: 1164, duration: 0.553s, episode steps:  81, steps per second: 147, episode reward: -48.774, mean reward: -0.602 [-100.000, 18.832], mean action: 1.580 [0.000, 3.000],  loss: 984.805617, mae: 714.290700, mean_q: 969.544656, mean_eps: 0.617896
 127512/300000: episode: 1165, duration: 0.688s, episode steps: 103, steps per second: 150, episode reward: -43.888, mean reward: -0.426 [-100.000,  8.553], mean action: 1.641 [0.000, 3.000],  loss: 887.042956, mae: 709.754904, mean_q: 961.868352, mean_eps: 0.617620
 127701/300000: episode: 1166, duration: 1.201s, episode steps: 189, steps per second: 157, episode reward: -286.739, mean reward: -1.517 [-100.000,  5.424], mean action: 1.767 [0.000, 3.000],  loss: 793.101197, mae: 704.486272, mean_q: 957.078489, mean_eps: 0.617182
 127814/300000: episode: 1167, duration: 0.777s, episode steps: 113, steps per second: 145, episode reward: -42.408, mean reward: -0.375 [-100.000, 16.734], mean action: 1.549 [0.000, 3.000],  loss: 1349.677435, mae: 683.857231, mean_q: 929.362722, mean_eps: 0.616729
 127944/300000: episode: 1168, duration: 0.853s, episode steps: 130, steps per second: 152, episode reward: -13.240, mean reward: -0.102 [-100.000, 12.326], mean action: 1.408 [0.000, 3.000],  loss: 546.134329, mae: 695.324741, mean_q: 945.370953, mean_eps: 0.616364
 128030/300000: episode: 1169, duration: 0.544s, episode steps:  86, steps per second: 158, episode reward: -23.354, mean reward: -0.272 [-100.000, 10.441], mean action: 1.616 [0.000, 3.000],  loss: 785.618986, mae: 704.239405, mean_q: 956.995520, mean_eps: 0.616040
 128172/300000: episode: 1170, duration: 0.971s, episode steps: 142, steps per second: 146, episode reward: -104.156, mean reward: -0.733 [-100.000,  9.071], mean action: 1.655 [0.000, 3.000],  loss: 830.066101, mae: 699.529128, mean_q: 951.865004, mean_eps: 0.615699
 128268/300000: episode: 1171, duration: 0.630s, episode steps:  96, steps per second: 152, episode reward: -88.377, mean reward: -0.921 [-100.000, 12.828], mean action: 1.615 [0.000, 3.000],  loss: 900.417335, mae: 686.490435, mean_q: 934.028247, mean_eps: 0.615341
 128426/300000: episode: 1172, duration: 1.031s, episode steps: 158, steps per second: 153, episode reward: -49.887, mean reward: -0.316 [-100.000, 12.376], mean action: 1.646 [0.000, 3.000],  loss: 1024.084508, mae: 702.319817, mean_q: 955.202007, mean_eps: 0.614961
 128548/300000: episode: 1173, duration: 0.795s, episode steps: 122, steps per second: 153, episode reward: 20.852, mean reward:  0.171 [-100.000, 21.443], mean action: 1.631 [0.000, 3.000],  loss: 573.421939, mae: 702.459311, mean_q: 955.635001, mean_eps: 0.614540
 128628/300000: episode: 1174, duration: 0.504s, episode steps:  80, steps per second: 159, episode reward: -69.949, mean reward: -0.874 [-100.000, 12.399], mean action: 1.587 [0.000, 3.000],  loss: 917.764137, mae: 704.198145, mean_q: 958.115541, mean_eps: 0.614237
 128750/300000: episode: 1175, duration: 0.818s, episode steps: 122, steps per second: 149, episode reward: -51.258, mean reward: -0.420 [-100.000,  8.874], mean action: 1.615 [0.000, 3.000],  loss: 506.703653, mae: 712.366465, mean_q: 967.707258, mean_eps: 0.613934
 128836/300000: episode: 1176, duration: 0.585s, episode steps:  86, steps per second: 147, episode reward: -41.418, mean reward: -0.482 [-100.000,  8.305], mean action: 1.616 [0.000, 3.000],  loss: 813.525281, mae: 709.455955, mean_q: 964.830476, mean_eps: 0.613622
 128987/300000: episode: 1177, duration: 0.979s, episode steps: 151, steps per second: 154, episode reward:  3.120, mean reward:  0.021 [-100.000, 18.129], mean action: 1.662 [0.000, 3.000],  loss: 867.320282, mae: 705.282722, mean_q: 960.298522, mean_eps: 0.613267
 129117/300000: episode: 1178, duration: 0.879s, episode steps: 130, steps per second: 148, episode reward: -39.306, mean reward: -0.302 [-100.000, 15.429], mean action: 1.623 [0.000, 3.000],  loss: 736.201142, mae: 701.779718, mean_q: 954.203213, mean_eps: 0.612846
 129224/300000: episode: 1179, duration: 0.690s, episode steps: 107, steps per second: 155, episode reward: -14.601, mean reward: -0.136 [-100.000, 13.792], mean action: 1.710 [0.000, 3.000],  loss: 620.956565, mae: 705.894000, mean_q: 960.989553, mean_eps: 0.612490
 129351/300000: episode: 1180, duration: 0.815s, episode steps: 127, steps per second: 156, episode reward: -11.056, mean reward: -0.087 [-100.000, 10.148], mean action: 1.717 [0.000, 3.000],  loss: 811.626495, mae: 714.775846, mean_q: 973.442200, mean_eps: 0.612139
 129676/300000: episode: 1181, duration: 2.187s, episode steps: 325, steps per second: 149, episode reward: -350.741, mean reward: -1.079 [-100.000,  6.764], mean action: 1.471 [0.000, 3.000],  loss: 655.505740, mae: 725.930174, mean_q: 987.637583, mean_eps: 0.611461
 129789/300000: episode: 1182, duration: 0.785s, episode steps: 113, steps per second: 144, episode reward: -67.340, mean reward: -0.596 [-100.000, 11.617], mean action: 1.540 [0.000, 3.000],  loss: 851.983102, mae: 730.206273, mean_q: 992.008034, mean_eps: 0.610804
 129905/300000: episode: 1183, duration: 0.742s, episode steps: 116, steps per second: 156, episode reward: -90.694, mean reward: -0.782 [-100.000,  6.014], mean action: 1.690 [0.000, 3.000],  loss: 609.040369, mae: 726.155296, mean_q: 987.057576, mean_eps: 0.610460
 130011/300000: episode: 1184, duration: 0.665s, episode steps: 106, steps per second: 159, episode reward: -40.004, mean reward: -0.377 [-100.000, 13.183], mean action: 1.613 [0.000, 3.000],  loss: 475.349174, mae: 733.490760, mean_q: 998.225964, mean_eps: 0.610127
 130144/300000: episode: 1185, duration: 0.895s, episode steps: 133, steps per second: 149, episode reward: -56.465, mean reward: -0.425 [-100.000, 16.820], mean action: 1.617 [0.000, 3.000],  loss: 790.152174, mae: 742.376731, mean_q: 1008.799381, mean_eps: 0.609769
 130268/300000: episode: 1186, duration: 0.790s, episode steps: 124, steps per second: 157, episode reward: -94.754, mean reward: -0.764 [-100.000, 35.156], mean action: 1.540 [0.000, 3.000],  loss: 565.288201, mae: 731.429292, mean_q: 994.059643, mean_eps: 0.609384
 130350/300000: episode: 1187, duration: 0.525s, episode steps:  82, steps per second: 156, episode reward: -16.246, mean reward: -0.198 [-100.000, 27.327], mean action: 1.720 [0.000, 3.000],  loss: 674.391768, mae: 733.587768, mean_q: 996.910402, mean_eps: 0.609075
 130464/300000: episode: 1188, duration: 0.802s, episode steps: 114, steps per second: 142, episode reward: -11.709, mean reward: -0.103 [-100.000,  9.250], mean action: 1.561 [0.000, 3.000],  loss: 697.659648, mae: 731.203071, mean_q: 994.662283, mean_eps: 0.608780
 130549/300000: episode: 1189, duration: 0.557s, episode steps:  85, steps per second: 153, episode reward: -17.039, mean reward: -0.200 [-100.000, 22.561], mean action: 1.741 [0.000, 3.000],  loss: 598.416663, mae: 738.505844, mean_q: 1005.562732, mean_eps: 0.608482
 130673/300000: episode: 1190, duration: 0.789s, episode steps: 124, steps per second: 157, episode reward: 13.319, mean reward:  0.107 [-100.000, 22.222], mean action: 1.532 [0.000, 3.000],  loss: 525.692717, mae: 727.876399, mean_q: 991.054317, mean_eps: 0.608169
 130762/300000: episode: 1191, duration: 0.600s, episode steps:  89, steps per second: 148, episode reward: -14.895, mean reward: -0.167 [-100.000, 13.796], mean action: 1.674 [0.000, 3.000],  loss: 678.778618, mae: 740.252602, mean_q: 1008.924399, mean_eps: 0.607849
 130830/300000: episode: 1192, duration: 0.442s, episode steps:  68, steps per second: 154, episode reward: -25.709, mean reward: -0.378 [-100.000,  7.284], mean action: 1.632 [0.000, 3.000],  loss: 616.968072, mae: 731.674743, mean_q: 996.297197, mean_eps: 0.607613
 130908/300000: episode: 1193, duration: 0.497s, episode steps:  78, steps per second: 157, episode reward: -108.707, mean reward: -1.394 [-100.000,  5.821], mean action: 1.667 [0.000, 3.000],  loss: 515.281454, mae: 739.381184, mean_q: 1008.594505, mean_eps: 0.607394
 130996/300000: episode: 1194, duration: 0.565s, episode steps:  88, steps per second: 156, episode reward: -63.869, mean reward: -0.726 [-100.000,  9.823], mean action: 1.625 [0.000, 3.000],  loss: 410.177283, mae: 740.501221, mean_q: 1007.879730, mean_eps: 0.607146
 131099/300000: episode: 1195, duration: 0.790s, episode steps: 103, steps per second: 130, episode reward: -76.817, mean reward: -0.746 [-100.000, 11.515], mean action: 1.583 [0.000, 3.000],  loss: 624.663388, mae: 747.871304, mean_q: 1018.201069, mean_eps: 0.606859
 131196/300000: episode: 1196, duration: 0.707s, episode steps:  97, steps per second: 137, episode reward: -36.963, mean reward: -0.381 [-100.000,  8.423], mean action: 1.536 [0.000, 3.000],  loss: 460.941852, mae: 739.641335, mean_q: 1006.620001, mean_eps: 0.606559
 131274/300000: episode: 1197, duration: 0.543s, episode steps:  78, steps per second: 144, episode reward: -78.626, mean reward: -1.008 [-100.000, 14.902], mean action: 1.692 [0.000, 3.000],  loss: 502.782683, mae: 727.571254, mean_q: 990.621305, mean_eps: 0.606296
 131382/300000: episode: 1198, duration: 0.813s, episode steps: 108, steps per second: 133, episode reward: -120.801, mean reward: -1.119 [-100.000,  7.407], mean action: 1.611 [0.000, 3.000],  loss: 519.155616, mae: 748.627070, mean_q: 1018.367737, mean_eps: 0.606018
 131526/300000: episode: 1199, duration: 1.001s, episode steps: 144, steps per second: 144, episode reward: -9.028, mean reward: -0.063 [-100.000, 12.931], mean action: 1.826 [0.000, 3.000],  loss: 649.595736, mae: 735.735039, mean_q: 1001.946799, mean_eps: 0.605640
 131633/300000: episode: 1200, duration: 0.715s, episode steps: 107, steps per second: 150, episode reward: -77.277, mean reward: -0.722 [-100.000,  6.423], mean action: 1.486 [0.000, 3.000],  loss: 458.013001, mae: 734.586010, mean_q: 999.155586, mean_eps: 0.605263
 131725/300000: episode: 1201, duration: 0.654s, episode steps:  92, steps per second: 141, episode reward: -60.057, mean reward: -0.653 [-100.000,  7.570], mean action: 1.674 [0.000, 3.000],  loss: 983.701248, mae: 726.986285, mean_q: 988.492034, mean_eps: 0.604964
 131836/300000: episode: 1202, duration: 0.762s, episode steps: 111, steps per second: 146, episode reward: -60.662, mean reward: -0.547 [-100.000, 14.186], mean action: 1.649 [0.000, 3.000],  loss: 608.953208, mae: 728.155945, mean_q: 989.779742, mean_eps: 0.604660
 131909/300000: episode: 1203, duration: 0.475s, episode steps:  73, steps per second: 154, episode reward: -96.586, mean reward: -1.323 [-100.000,  5.571], mean action: 1.904 [0.000, 3.000],  loss: 484.063586, mae: 726.326289, mean_q: 988.328517, mean_eps: 0.604384
 131989/300000: episode: 1204, duration: 0.537s, episode steps:  80, steps per second: 149, episode reward: -50.789, mean reward: -0.635 [-100.000, 11.852], mean action: 1.725 [0.000, 3.000],  loss: 672.589919, mae: 736.416193, mean_q: 1001.504720, mean_eps: 0.604154
 132079/300000: episode: 1205, duration: 0.593s, episode steps:  90, steps per second: 152, episode reward: -18.991, mean reward: -0.211 [-100.000, 22.044], mean action: 1.856 [0.000, 3.000],  loss: 485.169305, mae: 732.251576, mean_q: 996.271610, mean_eps: 0.603900
 132183/300000: episode: 1206, duration: 0.729s, episode steps: 104, steps per second: 143, episode reward: -53.609, mean reward: -0.515 [-100.000, 11.492], mean action: 1.692 [0.000, 3.000],  loss: 723.100042, mae: 728.653009, mean_q: 990.560869, mean_eps: 0.603608
 132275/300000: episode: 1207, duration: 0.784s, episode steps:  92, steps per second: 117, episode reward: -84.810, mean reward: -0.922 [-100.000,  8.528], mean action: 1.587 [0.000, 3.000],  loss: 656.276437, mae: 723.511506, mean_q: 985.243804, mean_eps: 0.603314
 132380/300000: episode: 1208, duration: 0.722s, episode steps: 105, steps per second: 145, episode reward: -3.120, mean reward: -0.030 [-100.000, 11.593], mean action: 1.610 [0.000, 3.000],  loss: 485.556564, mae: 720.520862, mean_q: 980.229861, mean_eps: 0.603019
 132504/300000: episode: 1209, duration: 0.800s, episode steps: 124, steps per second: 155, episode reward: -50.838, mean reward: -0.410 [-100.000,  7.743], mean action: 1.597 [0.000, 3.000],  loss: 421.939594, mae: 732.883041, mean_q: 996.702441, mean_eps: 0.602675
 132586/300000: episode: 1210, duration: 0.571s, episode steps:  82, steps per second: 144, episode reward: -37.224, mean reward: -0.454 [-100.000, 10.839], mean action: 1.598 [0.000, 3.000],  loss: 709.454343, mae: 728.423786, mean_q: 988.941100, mean_eps: 0.602367
 132708/300000: episode: 1211, duration: 0.812s, episode steps: 122, steps per second: 150, episode reward: -41.196, mean reward: -0.338 [-100.000, 11.061], mean action: 1.680 [0.000, 3.000],  loss: 456.480261, mae: 736.049328, mean_q: 1001.457233, mean_eps: 0.602061
 132822/300000: episode: 1212, duration: 0.734s, episode steps: 114, steps per second: 155, episode reward: -67.093, mean reward: -0.589 [-100.000,  5.790], mean action: 1.544 [0.000, 3.000],  loss: 433.052326, mae: 739.170690, mean_q: 1006.777210, mean_eps: 0.601706
 133822/300000: episode: 1213, duration: 7.583s, episode steps: 1000, steps per second: 132, episode reward: -5.770, mean reward: -0.006 [-21.130, 29.244], mean action: 1.630 [0.000, 3.000],  loss: 705.684148, mae: 765.768781, mean_q: 1041.589007, mean_eps: 0.600035
 133908/300000: episode: 1214, duration: 0.565s, episode steps:  86, steps per second: 152, episode reward: -35.553, mean reward: -0.413 [-100.000, 10.365], mean action: 1.581 [0.000, 3.000],  loss: 870.106175, mae: 795.804761, mean_q: 1080.010362, mean_eps: 0.598406
 134025/300000: episode: 1215, duration: 0.761s, episode steps: 117, steps per second: 154, episode reward: -50.746, mean reward: -0.434 [-100.000, 12.315], mean action: 1.573 [0.000, 3.000],  loss: 638.202746, mae: 788.888244, mean_q: 1070.900349, mean_eps: 0.598102
 134363/300000: episode: 1216, duration: 2.290s, episode steps: 338, steps per second: 148, episode reward: -289.587, mean reward: -0.857 [-100.000, 18.584], mean action: 1.675 [0.000, 3.000],  loss: 620.869917, mae: 789.746603, mean_q: 1073.305746, mean_eps: 0.597419
 134485/300000: episode: 1217, duration: 0.831s, episode steps: 122, steps per second: 147, episode reward: -10.372, mean reward: -0.085 [-100.000, 13.430], mean action: 1.672 [0.000, 3.000],  loss: 731.044425, mae: 789.975967, mean_q: 1073.352092, mean_eps: 0.596730
 134609/300000: episode: 1218, duration: 0.816s, episode steps: 124, steps per second: 152, episode reward: -20.410, mean reward: -0.165 [-100.000, 11.891], mean action: 1.589 [0.000, 3.000],  loss: 479.081223, mae: 790.759042, mean_q: 1073.582079, mean_eps: 0.596360
 134779/300000: episode: 1219, duration: 1.375s, episode steps: 170, steps per second: 124, episode reward: -80.455, mean reward: -0.473 [-100.000,  5.801], mean action: 1.824 [0.000, 3.000],  loss: 772.117844, mae: 792.356926, mean_q: 1077.257315, mean_eps: 0.595919
 134897/300000: episode: 1220, duration: 0.849s, episode steps: 118, steps per second: 139, episode reward: -48.109, mean reward: -0.408 [-100.000, 12.707], mean action: 1.737 [0.000, 3.000],  loss: 1170.638928, mae: 792.718381, mean_q: 1078.821449, mean_eps: 0.595488
 135006/300000: episode: 1221, duration: 0.820s, episode steps: 109, steps per second: 133, episode reward: -55.666, mean reward: -0.511 [-100.000, 16.340], mean action: 1.615 [0.000, 3.000],  loss: 1025.073659, mae: 795.035949, mean_q: 1081.221885, mean_eps: 0.595147
 135165/300000: episode: 1222, duration: 1.126s, episode steps: 159, steps per second: 141, episode reward: -16.414, mean reward: -0.103 [-100.000, 10.267], mean action: 1.717 [0.000, 3.000],  loss: 650.382905, mae: 806.047689, mean_q: 1096.566429, mean_eps: 0.594745
 135276/300000: episode: 1223, duration: 0.792s, episode steps: 111, steps per second: 140, episode reward: 14.301, mean reward:  0.129 [-100.000, 18.823], mean action: 1.793 [0.000, 3.000],  loss: 726.465794, mae: 812.293817, mean_q: 1103.711810, mean_eps: 0.594340
 135403/300000: episode: 1224, duration: 0.895s, episode steps: 127, steps per second: 142, episode reward: -155.551, mean reward: -1.225 [-100.000,  8.719], mean action: 1.724 [0.000, 3.000],  loss: 525.139344, mae: 816.741334, mean_q: 1112.168677, mean_eps: 0.593983
 135515/300000: episode: 1225, duration: 0.722s, episode steps: 112, steps per second: 155, episode reward: -10.027, mean reward: -0.090 [-100.000, 17.223], mean action: 1.830 [0.000, 3.000],  loss: 919.947847, mae: 806.899337, mean_q: 1099.191910, mean_eps: 0.593624
 135612/300000: episode: 1226, duration: 0.650s, episode steps:  97, steps per second: 149, episode reward: -71.363, mean reward: -0.736 [-100.000, 11.640], mean action: 1.680 [0.000, 3.000],  loss: 509.319064, mae: 811.183937, mean_q: 1105.072953, mean_eps: 0.593311
 135751/300000: episode: 1227, duration: 0.929s, episode steps: 139, steps per second: 150, episode reward: -32.400, mean reward: -0.233 [-100.000, 24.515], mean action: 1.712 [0.000, 3.000],  loss: 866.821630, mae: 821.309689, mean_q: 1118.472422, mean_eps: 0.592957
 135853/300000: episode: 1228, duration: 0.649s, episode steps: 102, steps per second: 157, episode reward: -110.408, mean reward: -1.082 [-100.000,  9.683], mean action: 1.686 [0.000, 3.000],  loss: 629.020956, mae: 813.316897, mean_q: 1106.527937, mean_eps: 0.592595
 135981/300000: episode: 1229, duration: 0.857s, episode steps: 128, steps per second: 149, episode reward: -39.688, mean reward: -0.310 [-100.000, 10.449], mean action: 1.562 [0.000, 3.000],  loss: 781.051191, mae: 821.480362, mean_q: 1118.026119, mean_eps: 0.592251
 136063/300000: episode: 1230, duration: 0.540s, episode steps:  82, steps per second: 152, episode reward: -32.026, mean reward: -0.391 [-100.000,  8.044], mean action: 1.854 [0.000, 3.000],  loss: 600.829353, mae: 803.618291, mean_q: 1094.579321, mean_eps: 0.591935
 136168/300000: episode: 1231, duration: 0.727s, episode steps: 105, steps per second: 144, episode reward: -24.929, mean reward: -0.237 [-100.000, 11.905], mean action: 1.686 [0.000, 3.000],  loss: 763.785818, mae: 817.487070, mean_q: 1112.469922, mean_eps: 0.591655
 136277/300000: episode: 1232, duration: 0.804s, episode steps: 109, steps per second: 136, episode reward: -60.946, mean reward: -0.559 [-100.000, 11.779], mean action: 1.642 [0.000, 3.000],  loss: 1246.095950, mae: 815.582537, mean_q: 1108.204742, mean_eps: 0.591334
 137277/300000: episode: 1233, duration: 7.531s, episode steps: 1000, steps per second: 133, episode reward: 47.402, mean reward:  0.047 [-22.979, 22.793], mean action: 1.783 [0.000, 3.000],  loss: 900.813750, mae: 836.047725, mean_q: 1137.843090, mean_eps: 0.589670
 137360/300000: episode: 1234, duration: 0.527s, episode steps:  83, steps per second: 158, episode reward: -24.391, mean reward: -0.294 [-100.000,  9.324], mean action: 1.759 [0.000, 3.000],  loss: 986.302030, mae: 856.848613, mean_q: 1164.797345, mean_eps: 0.588046
 137476/300000: episode: 1235, duration: 0.816s, episode steps: 116, steps per second: 142, episode reward: -50.260, mean reward: -0.433 [-100.000, 13.718], mean action: 1.440 [0.000, 3.000],  loss: 1187.453381, mae: 860.174340, mean_q: 1170.652864, mean_eps: 0.587747
 137581/300000: episode: 1236, duration: 0.706s, episode steps: 105, steps per second: 149, episode reward:  4.470, mean reward:  0.043 [-100.000, 58.634], mean action: 1.886 [0.000, 3.000],  loss: 1052.650767, mae: 861.653184, mean_q: 1171.776965, mean_eps: 0.587416
 137665/300000: episode: 1237, duration: 0.544s, episode steps:  84, steps per second: 155, episode reward: -23.680, mean reward: -0.282 [-100.000,  9.141], mean action: 1.726 [0.000, 3.000],  loss: 1026.478056, mae: 854.490681, mean_q: 1163.274788, mean_eps: 0.587132
 137753/300000: episode: 1238, duration: 0.605s, episode steps:  88, steps per second: 145, episode reward: -50.494, mean reward: -0.574 [-100.000, 11.115], mean action: 1.784 [0.000, 3.000],  loss: 895.997903, mae: 856.989403, mean_q: 1166.750415, mean_eps: 0.586874
 137851/300000: episode: 1239, duration: 0.651s, episode steps:  98, steps per second: 151, episode reward: -77.426, mean reward: -0.790 [-100.000,  8.263], mean action: 1.602 [0.000, 3.000],  loss: 828.135878, mae: 858.709626, mean_q: 1169.604705, mean_eps: 0.586596
 137961/300000: episode: 1240, duration: 0.708s, episode steps: 110, steps per second: 155, episode reward: -11.386, mean reward: -0.104 [-100.000, 15.272], mean action: 1.873 [0.000, 3.000],  loss: 845.476635, mae: 862.363152, mean_q: 1174.187097, mean_eps: 0.586283
 138048/300000: episode: 1241, duration: 0.581s, episode steps:  87, steps per second: 150, episode reward: -38.711, mean reward: -0.445 [-100.000, 11.115], mean action: 1.506 [0.000, 3.000],  loss: 1133.281159, mae: 871.128754, mean_q: 1187.002095, mean_eps: 0.585988
 138122/300000: episode: 1242, duration: 0.496s, episode steps:  74, steps per second: 149, episode reward: -45.381, mean reward: -0.613 [-100.000, 11.722], mean action: 1.662 [0.000, 3.000],  loss: 864.154948, mae: 864.135656, mean_q: 1178.509804, mean_eps: 0.585746
 138232/300000: episode: 1243, duration: 0.736s, episode steps: 110, steps per second: 149, episode reward: -15.554, mean reward: -0.141 [-100.000, 17.035], mean action: 1.573 [0.000, 3.000],  loss: 681.716674, mae: 872.388665, mean_q: 1187.380280, mean_eps: 0.585470
 138328/300000: episode: 1244, duration: 0.629s, episode steps:  96, steps per second: 153, episode reward: -67.121, mean reward: -0.699 [-100.000,  9.739], mean action: 1.677 [0.000, 3.000],  loss: 1351.572633, mae: 861.099068, mean_q: 1171.944136, mean_eps: 0.585162
 138419/300000: episode: 1245, duration: 0.606s, episode steps:  91, steps per second: 150, episode reward: -70.485, mean reward: -0.775 [-100.000, 15.735], mean action: 1.637 [0.000, 3.000],  loss: 936.078275, mae: 860.974760, mean_q: 1172.387968, mean_eps: 0.584881
 138523/300000: episode: 1246, duration: 0.683s, episode steps: 104, steps per second: 152, episode reward: -41.780, mean reward: -0.402 [-100.000, 11.873], mean action: 1.788 [0.000, 3.000],  loss: 639.603202, mae: 860.173652, mean_q: 1171.909167, mean_eps: 0.584588
 138652/300000: episode: 1247, duration: 0.837s, episode steps: 129, steps per second: 154, episode reward: -45.115, mean reward: -0.350 [-100.000, 18.231], mean action: 1.566 [0.000, 3.000],  loss: 1161.980969, mae: 866.722784, mean_q: 1180.143708, mean_eps: 0.584239
 138798/300000: episode: 1248, duration: 0.992s, episode steps: 146, steps per second: 147, episode reward: -45.617, mean reward: -0.312 [-100.000, 10.038], mean action: 1.808 [0.000, 3.000],  loss: 914.977457, mae: 857.525657, mean_q: 1168.163207, mean_eps: 0.583826
 138915/300000: episode: 1249, duration: 0.755s, episode steps: 117, steps per second: 155, episode reward: -61.493, mean reward: -0.526 [-100.000, 12.654], mean action: 1.641 [0.000, 3.000],  loss: 830.122924, mae: 867.963122, mean_q: 1183.855899, mean_eps: 0.583432
 139042/300000: episode: 1250, duration: 0.842s, episode steps: 127, steps per second: 151, episode reward:  4.233, mean reward:  0.033 [-100.000, 17.117], mean action: 1.669 [0.000, 3.000],  loss: 747.819457, mae: 871.391182, mean_q: 1186.826323, mean_eps: 0.583066
 139128/300000: episode: 1251, duration: 0.578s, episode steps:  86, steps per second: 149, episode reward: -46.520, mean reward: -0.541 [-100.000, 13.560], mean action: 1.674 [0.000, 3.000],  loss: 810.365815, mae: 885.564273, mean_q: 1207.421665, mean_eps: 0.582747
 139219/300000: episode: 1252, duration: 0.595s, episode steps:  91, steps per second: 153, episode reward: 14.565, mean reward:  0.160 [-100.000, 13.864], mean action: 1.648 [0.000, 3.000],  loss: 710.360268, mae: 873.363874, mean_q: 1190.095721, mean_eps: 0.582481
 139282/300000: episode: 1253, duration: 0.395s, episode steps:  63, steps per second: 159, episode reward: -45.752, mean reward: -0.726 [-100.000, 12.981], mean action: 1.698 [0.000, 3.000],  loss: 693.959239, mae: 882.672871, mean_q: 1201.481806, mean_eps: 0.582250
 139362/300000: episode: 1254, duration: 0.525s, episode steps:  80, steps per second: 152, episode reward: -42.689, mean reward: -0.534 [-100.000,  7.003], mean action: 1.688 [0.000, 3.000],  loss: 1057.384175, mae: 879.966219, mean_q: 1198.514642, mean_eps: 0.582035
 139434/300000: episode: 1255, duration: 0.497s, episode steps:  72, steps per second: 145, episode reward: -62.797, mean reward: -0.872 [-100.000,  6.517], mean action: 1.556 [0.000, 3.000],  loss: 866.927102, mae: 868.878316, mean_q: 1181.548414, mean_eps: 0.581808
 139579/300000: episode: 1256, duration: 0.929s, episode steps: 145, steps per second: 156, episode reward: 16.172, mean reward:  0.112 [-100.000, 14.962], mean action: 1.745 [0.000, 3.000],  loss: 721.335457, mae: 873.256222, mean_q: 1189.934353, mean_eps: 0.581482
 139691/300000: episode: 1257, duration: 0.735s, episode steps: 112, steps per second: 152, episode reward: -48.701, mean reward: -0.435 [-100.000,  7.759], mean action: 1.759 [0.000, 3.000],  loss: 560.392050, mae: 871.005372, mean_q: 1186.669781, mean_eps: 0.581097
 139780/300000: episode: 1258, duration: 0.607s, episode steps:  89, steps per second: 147, episode reward: -11.802, mean reward: -0.133 [-100.000, 12.559], mean action: 1.528 [0.000, 3.000],  loss: 883.200571, mae: 877.358061, mean_q: 1197.631198, mean_eps: 0.580795
 139855/300000: episode: 1259, duration: 0.527s, episode steps:  75, steps per second: 142, episode reward: -26.834, mean reward: -0.358 [-100.000, 13.763], mean action: 1.467 [0.000, 3.000],  loss: 776.231010, mae: 874.049802, mean_q: 1193.193171, mean_eps: 0.580549
 139929/300000: episode: 1260, duration: 0.485s, episode steps:  74, steps per second: 153, episode reward: -33.616, mean reward: -0.454 [-100.000,  8.516], mean action: 1.581 [0.000, 3.000],  loss: 654.813477, mae: 888.060007, mean_q: 1209.672927, mean_eps: 0.580325
 140057/300000: episode: 1261, duration: 0.856s, episode steps: 128, steps per second: 150, episode reward: -99.740, mean reward: -0.779 [-100.000,  9.412], mean action: 1.641 [0.000, 3.000],  loss: 786.542300, mae: 878.408764, mean_q: 1196.001762, mean_eps: 0.580022
 140168/300000: episode: 1262, duration: 0.724s, episode steps: 111, steps per second: 153, episode reward: -64.260, mean reward: -0.579 [-100.000, 16.545], mean action: 1.613 [0.000, 3.000],  loss: 871.656318, mae: 872.531703, mean_q: 1188.699008, mean_eps: 0.579664
 140281/300000: episode: 1263, duration: 0.730s, episode steps: 113, steps per second: 155, episode reward: -212.955, mean reward: -1.885 [-100.000, 23.576], mean action: 1.575 [0.000, 3.000],  loss: 953.869547, mae: 870.903676, mean_q: 1188.458405, mean_eps: 0.579328
 140381/300000: episode: 1264, duration: 0.701s, episode steps: 100, steps per second: 143, episode reward: 24.197, mean reward:  0.242 [-100.000, 16.579], mean action: 1.490 [0.000, 3.000],  loss: 650.227755, mae: 885.621855, mean_q: 1207.620937, mean_eps: 0.579008
 140464/300000: episode: 1265, duration: 0.585s, episode steps:  83, steps per second: 142, episode reward: -40.568, mean reward: -0.489 [-100.000, 13.238], mean action: 1.639 [0.000, 3.000],  loss: 776.375921, mae: 881.153242, mean_q: 1203.036749, mean_eps: 0.578734
 140581/300000: episode: 1266, duration: 0.852s, episode steps: 117, steps per second: 137, episode reward: -40.780, mean reward: -0.349 [-100.000,  6.741], mean action: 1.752 [0.000, 3.000],  loss: 782.798090, mae: 884.018007, mean_q: 1207.244471, mean_eps: 0.578434
 140696/300000: episode: 1267, duration: 0.893s, episode steps: 115, steps per second: 129, episode reward: -144.417, mean reward: -1.256 [-100.000, 14.468], mean action: 1.783 [0.000, 3.000],  loss: 723.126425, mae: 880.955399, mean_q: 1202.669973, mean_eps: 0.578086
 140804/300000: episode: 1268, duration: 0.861s, episode steps: 108, steps per second: 125, episode reward: -77.465, mean reward: -0.717 [-100.000,  6.420], mean action: 1.444 [0.000, 3.000],  loss: 560.471705, mae: 885.846657, mean_q: 1210.842211, mean_eps: 0.577751
 140908/300000: episode: 1269, duration: 0.739s, episode steps: 104, steps per second: 141, episode reward: -9.245, mean reward: -0.089 [-100.000, 19.080], mean action: 1.673 [0.000, 3.000],  loss: 942.558509, mae: 873.216052, mean_q: 1192.114476, mean_eps: 0.577433
 141011/300000: episode: 1270, duration: 0.766s, episode steps: 103, steps per second: 134, episode reward: -68.077, mean reward: -0.661 [-100.000, 11.213], mean action: 1.709 [0.000, 3.000],  loss: 935.055163, mae: 870.488107, mean_q: 1186.653924, mean_eps: 0.577123
 141102/300000: episode: 1271, duration: 0.642s, episode steps:  91, steps per second: 142, episode reward: -10.581, mean reward: -0.116 [-100.000, 11.661], mean action: 1.791 [0.000, 3.000],  loss: 661.566818, mae: 876.499834, mean_q: 1196.431780, mean_eps: 0.576832
 141205/300000: episode: 1272, duration: 0.758s, episode steps: 103, steps per second: 136, episode reward: -5.076, mean reward: -0.049 [-100.000, 18.803], mean action: 1.495 [0.000, 3.000],  loss: 714.807193, mae: 880.739335, mean_q: 1201.294981, mean_eps: 0.576541
 141297/300000: episode: 1273, duration: 0.652s, episode steps:  92, steps per second: 141, episode reward: -49.408, mean reward: -0.537 [-100.000, 12.036], mean action: 1.609 [0.000, 3.000],  loss: 700.530916, mae: 886.708098, mean_q: 1210.189732, mean_eps: 0.576249
 141366/300000: episode: 1274, duration: 0.460s, episode steps:  69, steps per second: 150, episode reward: -92.067, mean reward: -1.334 [-100.000,  9.632], mean action: 1.594 [0.000, 3.000],  loss: 1364.577274, mae: 891.154929, mean_q: 1215.126859, mean_eps: 0.576007
 141452/300000: episode: 1275, duration: 0.551s, episode steps:  86, steps per second: 156, episode reward: 12.473, mean reward:  0.145 [-100.000, 12.694], mean action: 1.686 [0.000, 3.000],  loss: 1424.956844, mae: 872.604492, mean_q: 1192.644201, mean_eps: 0.575775
 141539/300000: episode: 1276, duration: 0.571s, episode steps:  87, steps per second: 152, episode reward: -83.379, mean reward: -0.958 [-100.000,  9.438], mean action: 1.655 [0.000, 3.000],  loss: 1038.123911, mae: 885.919333, mean_q: 1210.523776, mean_eps: 0.575515
 141672/300000: episode: 1277, duration: 0.896s, episode steps: 133, steps per second: 148, episode reward: 18.658, mean reward:  0.140 [-100.000, 19.028], mean action: 1.812 [0.000, 3.000],  loss: 1126.907178, mae: 895.623761, mean_q: 1223.267799, mean_eps: 0.575185
 141778/300000: episode: 1278, duration: 0.666s, episode steps: 106, steps per second: 159, episode reward: -68.474, mean reward: -0.646 [-100.000,  7.869], mean action: 1.632 [0.000, 3.000],  loss: 550.475450, mae: 895.998627, mean_q: 1224.271065, mean_eps: 0.574827
 141857/300000: episode: 1279, duration: 0.515s, episode steps:  79, steps per second: 153, episode reward: -91.917, mean reward: -1.164 [-100.000, 12.258], mean action: 1.646 [0.000, 3.000],  loss: 1028.940505, mae: 889.831956, mean_q: 1214.707360, mean_eps: 0.574549
 142066/300000: episode: 1280, duration: 1.435s, episode steps: 209, steps per second: 146, episode reward: -127.401, mean reward: -0.610 [-100.000, 20.125], mean action: 1.722 [0.000, 3.000],  loss: 862.541863, mae: 899.862474, mean_q: 1228.287775, mean_eps: 0.574117
 142158/300000: episode: 1281, duration: 0.587s, episode steps:  92, steps per second: 157, episode reward: -5.662, mean reward: -0.062 [-100.000, 14.647], mean action: 1.652 [0.000, 3.000],  loss: 560.349352, mae: 899.845564, mean_q: 1228.170527, mean_eps: 0.573665
 142233/300000: episode: 1282, duration: 0.503s, episode steps:  75, steps per second: 149, episode reward: -13.430, mean reward: -0.179 [-100.000, 20.229], mean action: 1.600 [0.000, 3.000],  loss: 954.889010, mae: 904.362262, mean_q: 1233.877544, mean_eps: 0.573415
 142386/300000: episode: 1283, duration: 1.015s, episode steps: 153, steps per second: 151, episode reward: 35.092, mean reward:  0.229 [-100.000, 28.207], mean action: 1.719 [0.000, 3.000],  loss: 1078.110626, mae: 898.756283, mean_q: 1228.264871, mean_eps: 0.573073
 142492/300000: episode: 1284, duration: 0.675s, episode steps: 106, steps per second: 157, episode reward: -66.596, mean reward: -0.628 [-100.000, 24.601], mean action: 1.642 [0.000, 3.000],  loss: 1139.579853, mae: 909.472626, mean_q: 1242.687680, mean_eps: 0.572685
 142602/300000: episode: 1285, duration: 0.738s, episode steps: 110, steps per second: 149, episode reward:  9.449, mean reward:  0.086 [-100.000, 17.175], mean action: 1.664 [0.000, 3.000],  loss: 1190.465835, mae: 905.296153, mean_q: 1236.534116, mean_eps: 0.572361
 142722/300000: episode: 1286, duration: 0.799s, episode steps: 120, steps per second: 150, episode reward: 25.352, mean reward:  0.211 [-100.000, 24.762], mean action: 1.767 [0.000, 3.000],  loss: 1435.186937, mae: 911.876789, mean_q: 1246.004674, mean_eps: 0.572016
 142808/300000: episode: 1287, duration: 0.570s, episode steps:  86, steps per second: 151, episode reward: -77.039, mean reward: -0.896 [-100.000,  6.864], mean action: 1.651 [0.000, 3.000],  loss: 931.748370, mae: 915.429199, mean_q: 1250.317645, mean_eps: 0.571706
 142906/300000: episode: 1288, duration: 0.700s, episode steps:  98, steps per second: 140, episode reward: -38.827, mean reward: -0.396 [-100.000, 14.622], mean action: 1.622 [0.000, 3.000],  loss: 1492.181392, mae: 918.877754, mean_q: 1254.764191, mean_eps: 0.571431
 143442/300000: episode: 1289, duration: 3.791s, episode steps: 536, steps per second: 141, episode reward: -356.482, mean reward: -0.665 [-100.000, 20.145], mean action: 1.642 [0.000, 3.000],  loss: 1138.452080, mae: 914.989217, mean_q: 1250.649244, mean_eps: 0.570480
 143566/300000: episode: 1290, duration: 0.865s, episode steps: 124, steps per second: 143, episode reward: -50.679, mean reward: -0.409 [-100.000,  7.264], mean action: 1.726 [0.000, 3.000],  loss: 1209.116795, mae: 925.702971, mean_q: 1265.194576, mean_eps: 0.569490
 143659/300000: episode: 1291, duration: 0.624s, episode steps:  93, steps per second: 149, episode reward: -8.539, mean reward: -0.092 [-100.000, 14.472], mean action: 1.677 [0.000, 3.000],  loss: 995.634549, mae: 935.933438, mean_q: 1278.407534, mean_eps: 0.569164
 143768/300000: episode: 1292, duration: 0.694s, episode steps: 109, steps per second: 157, episode reward: -17.402, mean reward: -0.160 [-100.000, 10.316], mean action: 1.706 [0.000, 3.000],  loss: 693.520280, mae: 938.176739, mean_q: 1282.659708, mean_eps: 0.568861
 143864/300000: episode: 1293, duration: 0.665s, episode steps:  96, steps per second: 144, episode reward: -81.780, mean reward: -0.852 [-100.000, 12.942], mean action: 1.573 [0.000, 3.000],  loss: 1137.760590, mae: 942.777761, mean_q: 1286.430373, mean_eps: 0.568554
 143978/300000: episode: 1294, duration: 0.726s, episode steps: 114, steps per second: 157, episode reward: -6.156, mean reward: -0.054 [-100.000, 12.693], mean action: 1.518 [0.000, 3.000],  loss: 979.838851, mae: 929.533409, mean_q: 1270.593770, mean_eps: 0.568238
 144364/300000: episode: 1295, duration: 2.973s, episode steps: 386, steps per second: 130, episode reward: -240.098, mean reward: -0.622 [-100.000, 22.946], mean action: 1.777 [0.000, 3.000],  loss: 1084.396714, mae: 945.018354, mean_q: 1289.888229, mean_eps: 0.567489
 144479/300000: episode: 1296, duration: 0.851s, episode steps: 115, steps per second: 135, episode reward: -13.767, mean reward: -0.120 [-100.000, 23.185], mean action: 1.696 [0.000, 3.000],  loss: 1517.521786, mae: 950.432717, mean_q: 1298.504235, mean_eps: 0.566737
 144587/300000: episode: 1297, duration: 0.765s, episode steps: 108, steps per second: 141, episode reward:  3.826, mean reward:  0.035 [-100.000, 15.174], mean action: 1.750 [0.000, 3.000],  loss: 1191.559092, mae: 943.752526, mean_q: 1289.580458, mean_eps: 0.566403
 144713/300000: episode: 1298, duration: 0.960s, episode steps: 126, steps per second: 131, episode reward:  1.360, mean reward:  0.011 [-100.000, 16.274], mean action: 1.484 [0.000, 3.000],  loss: 1458.152330, mae: 937.444507, mean_q: 1278.784527, mean_eps: 0.566051
 144807/300000: episode: 1299, duration: 0.656s, episode steps:  94, steps per second: 143, episode reward: -51.321, mean reward: -0.546 [-100.000, 12.669], mean action: 1.564 [0.000, 3.000],  loss: 787.316852, mae: 928.409853, mean_q: 1268.228652, mean_eps: 0.565721
 144900/300000: episode: 1300, duration: 0.633s, episode steps:  93, steps per second: 147, episode reward: -88.987, mean reward: -0.957 [-100.000, 19.304], mean action: 1.527 [0.000, 3.000],  loss: 751.761546, mae: 950.563612, mean_q: 1296.454646, mean_eps: 0.565441
 145015/300000: episode: 1301, duration: 0.767s, episode steps: 115, steps per second: 150, episode reward: -29.703, mean reward: -0.258 [-100.000, 10.712], mean action: 1.626 [0.000, 3.000],  loss: 1142.270983, mae: 938.372555, mean_q: 1279.457801, mean_eps: 0.565129
 145119/300000: episode: 1302, duration: 0.683s, episode steps: 104, steps per second: 152, episode reward: -43.933, mean reward: -0.422 [-100.000, 16.410], mean action: 1.740 [0.000, 3.000],  loss: 849.783210, mae: 947.453380, mean_q: 1291.214580, mean_eps: 0.564801
 145232/300000: episode: 1303, duration: 0.774s, episode steps: 113, steps per second: 146, episode reward: -70.099, mean reward: -0.620 [-100.000, 28.707], mean action: 1.708 [0.000, 3.000],  loss: 996.229614, mae: 943.390471, mean_q: 1286.642643, mean_eps: 0.564475
 145352/300000: episode: 1304, duration: 0.849s, episode steps: 120, steps per second: 141, episode reward: -15.354, mean reward: -0.128 [-100.000, 11.760], mean action: 1.775 [0.000, 3.000],  loss: 2419.435022, mae: 943.766212, mean_q: 1285.807058, mean_eps: 0.564126
 145435/300000: episode: 1305, duration: 0.543s, episode steps:  83, steps per second: 153, episode reward: -33.067, mean reward: -0.398 [-100.000, 10.141], mean action: 1.771 [0.000, 3.000],  loss: 1577.843044, mae: 932.792981, mean_q: 1271.304883, mean_eps: 0.563821
 145514/300000: episode: 1306, duration: 0.505s, episode steps:  79, steps per second: 156, episode reward: -48.836, mean reward: -0.618 [-100.000,  9.235], mean action: 1.557 [0.000, 3.000],  loss: 1106.131706, mae: 936.056668, mean_q: 1275.672410, mean_eps: 0.563578
 145600/300000: episode: 1307, duration: 0.575s, episode steps:  86, steps per second: 150, episode reward: 27.311, mean reward:  0.318 [-100.000, 17.504], mean action: 1.767 [0.000, 3.000],  loss: 1179.019651, mae: 925.627664, mean_q: 1261.515781, mean_eps: 0.563331
 145699/300000: episode: 1308, duration: 0.696s, episode steps:  99, steps per second: 142, episode reward: -103.121, mean reward: -1.042 [-100.000,  5.877], mean action: 1.646 [0.000, 3.000],  loss: 1324.420875, mae: 912.008149, mean_q: 1244.004261, mean_eps: 0.563053
 145783/300000: episode: 1309, duration: 0.597s, episode steps:  84, steps per second: 141, episode reward: -38.956, mean reward: -0.464 [-100.000, 10.135], mean action: 1.595 [0.000, 3.000],  loss: 912.324828, mae: 914.508713, mean_q: 1249.290019, mean_eps: 0.562779
 145933/300000: episode: 1310, duration: 0.988s, episode steps: 150, steps per second: 152, episode reward: -266.707, mean reward: -1.778 [-100.000,  8.055], mean action: 1.733 [0.000, 3.000],  loss: 1211.197480, mae: 916.431781, mean_q: 1251.066295, mean_eps: 0.562427
 146020/300000: episode: 1311, duration: 0.600s, episode steps:  87, steps per second: 145, episode reward: -22.819, mean reward: -0.262 [-100.000,  7.478], mean action: 1.655 [0.000, 3.000],  loss: 1072.360804, mae: 900.119408, mean_q: 1228.393348, mean_eps: 0.562072
 146094/300000: episode: 1312, duration: 0.479s, episode steps:  74, steps per second: 155, episode reward: -72.103, mean reward: -0.974 [-100.000,  8.213], mean action: 1.649 [0.000, 3.000],  loss: 1055.465929, mae: 913.848464, mean_q: 1247.230208, mean_eps: 0.561830
 146211/300000: episode: 1313, duration: 0.750s, episode steps: 117, steps per second: 156, episode reward: -31.794, mean reward: -0.272 [-100.000, 12.249], mean action: 1.427 [0.000, 3.000],  loss: 1074.600245, mae: 906.906615, mean_q: 1239.281642, mean_eps: 0.561544
 146310/300000: episode: 1314, duration: 0.695s, episode steps:  99, steps per second: 142, episode reward: 22.625, mean reward:  0.229 [-100.000, 12.970], mean action: 1.828 [0.000, 3.000],  loss: 1154.951875, mae: 910.053318, mean_q: 1243.001459, mean_eps: 0.561220
 146396/300000: episode: 1315, duration: 0.567s, episode steps:  86, steps per second: 152, episode reward: -33.055, mean reward: -0.384 [-100.000, 17.113], mean action: 1.500 [0.000, 3.000],  loss: 854.361302, mae: 902.814796, mean_q: 1235.698909, mean_eps: 0.560942
 146514/300000: episode: 1316, duration: 0.749s, episode steps: 118, steps per second: 158, episode reward: -6.338, mean reward: -0.054 [-100.000,  9.969], mean action: 1.483 [0.000, 3.000],  loss: 1757.352425, mae: 902.315781, mean_q: 1231.725730, mean_eps: 0.560636
 146624/300000: episode: 1317, duration: 0.729s, episode steps: 110, steps per second: 151, episode reward: -178.688, mean reward: -1.624 [-100.000, 35.021], mean action: 1.500 [0.000, 3.000],  loss: 1757.849271, mae: 902.085445, mean_q: 1233.983132, mean_eps: 0.560294
 146702/300000: episode: 1318, duration: 0.512s, episode steps:  78, steps per second: 152, episode reward: -37.093, mean reward: -0.476 [-100.000, 10.390], mean action: 1.679 [0.000, 3.000],  loss: 1103.320236, mae: 908.742107, mean_q: 1241.753318, mean_eps: 0.560012
 146806/300000: episode: 1319, duration: 0.664s, episode steps: 104, steps per second: 157, episode reward: -77.155, mean reward: -0.742 [-100.000,  9.689], mean action: 1.644 [0.000, 3.000],  loss: 1160.658989, mae: 908.779374, mean_q: 1240.824490, mean_eps: 0.559739
 146918/300000: episode: 1320, duration: 0.720s, episode steps: 112, steps per second: 156, episode reward: -6.860, mean reward: -0.061 [-100.000, 13.337], mean action: 1.705 [0.000, 3.000],  loss: 1238.621821, mae: 907.228687, mean_q: 1237.944312, mean_eps: 0.559415
 147078/300000: episode: 1321, duration: 1.088s, episode steps: 160, steps per second: 147, episode reward: 21.865, mean reward:  0.137 [-100.000, 14.770], mean action: 1.725 [0.000, 3.000],  loss: 1034.000514, mae: 907.053294, mean_q: 1239.599824, mean_eps: 0.559007
 147171/300000: episode: 1322, duration: 0.613s, episode steps:  93, steps per second: 152, episode reward: -31.736, mean reward: -0.341 [-100.000, 13.893], mean action: 1.667 [0.000, 3.000],  loss: 1511.385552, mae: 907.334009, mean_q: 1239.557390, mean_eps: 0.558628
 147295/300000: episode: 1323, duration: 0.846s, episode steps: 124, steps per second: 147, episode reward: -23.233, mean reward: -0.187 [-100.000,  9.379], mean action: 1.661 [0.000, 3.000],  loss: 1009.449476, mae: 900.608572, mean_q: 1231.380297, mean_eps: 0.558302
 147365/300000: episode: 1324, duration: 0.455s, episode steps:  70, steps per second: 154, episode reward: -164.902, mean reward: -2.356 [-100.000,  4.901], mean action: 1.314 [0.000, 3.000],  loss: 2033.300706, mae: 906.087655, mean_q: 1238.607756, mean_eps: 0.558011
 147485/300000: episode: 1325, duration: 0.768s, episode steps: 120, steps per second: 156, episode reward: -35.250, mean reward: -0.294 [-100.000, 15.035], mean action: 1.683 [0.000, 3.000],  loss: 958.895169, mae: 892.704838, mean_q: 1220.843515, mean_eps: 0.557726
 147558/300000: episode: 1326, duration: 0.465s, episode steps:  73, steps per second: 157, episode reward: -70.394, mean reward: -0.964 [-100.000,  5.781], mean action: 1.973 [0.000, 3.000],  loss: 1351.317618, mae: 904.456636, mean_q: 1235.686067, mean_eps: 0.557437
 147682/300000: episode: 1327, duration: 0.849s, episode steps: 124, steps per second: 146, episode reward: -17.041, mean reward: -0.137 [-100.000, 12.321], mean action: 1.476 [0.000, 3.000],  loss: 969.067657, mae: 895.137918, mean_q: 1223.665989, mean_eps: 0.557141
 147805/300000: episode: 1328, duration: 0.803s, episode steps: 123, steps per second: 153, episode reward: -22.913, mean reward: -0.186 [-100.000, 17.435], mean action: 1.626 [0.000, 3.000],  loss: 1242.088689, mae: 893.455544, mean_q: 1221.098788, mean_eps: 0.556771
 147923/300000: episode: 1329, duration: 0.788s, episode steps: 118, steps per second: 150, episode reward: -14.353, mean reward: -0.122 [-100.000,  8.298], mean action: 1.661 [0.000, 3.000],  loss: 1116.588011, mae: 898.000452, mean_q: 1227.778403, mean_eps: 0.556410
 148060/300000: episode: 1330, duration: 0.907s, episode steps: 137, steps per second: 151, episode reward: -17.638, mean reward: -0.129 [-100.000,  8.671], mean action: 1.606 [0.000, 3.000],  loss: 1444.921291, mae: 900.278910, mean_q: 1229.835086, mean_eps: 0.556027
 148178/300000: episode: 1331, duration: 0.752s, episode steps: 118, steps per second: 157, episode reward: -40.798, mean reward: -0.346 [-100.000,  8.922], mean action: 1.780 [0.000, 3.000],  loss: 1510.266981, mae: 896.192058, mean_q: 1224.239869, mean_eps: 0.555644
 148380/300000: episode: 1332, duration: 1.329s, episode steps: 202, steps per second: 152, episode reward: -327.925, mean reward: -1.623 [-100.000, 31.750], mean action: 1.748 [0.000, 3.000],  loss: 911.840574, mae: 888.451318, mean_q: 1215.459936, mean_eps: 0.555164
 148478/300000: episode: 1333, duration: 0.625s, episode steps:  98, steps per second: 157, episode reward: -49.252, mean reward: -0.503 [-100.000,  6.656], mean action: 1.714 [0.000, 3.000],  loss: 1293.510623, mae: 889.865264, mean_q: 1217.532771, mean_eps: 0.554714
 148584/300000: episode: 1334, duration: 0.721s, episode steps: 106, steps per second: 147, episode reward: -77.580, mean reward: -0.732 [-100.000, 13.232], mean action: 1.481 [0.000, 3.000],  loss: 1628.824214, mae: 882.599501, mean_q: 1205.356363, mean_eps: 0.554408
 148707/300000: episode: 1335, duration: 0.838s, episode steps: 123, steps per second: 147, episode reward: -1.674, mean reward: -0.014 [-100.000,  8.954], mean action: 1.480 [0.000, 3.000],  loss: 1382.091199, mae: 884.258659, mean_q: 1207.681987, mean_eps: 0.554065
 148778/300000: episode: 1336, duration: 0.458s, episode steps:  71, steps per second: 155, episode reward: -53.675, mean reward: -0.756 [-100.000,  7.287], mean action: 1.746 [0.000, 3.000],  loss: 1318.728468, mae: 873.655106, mean_q: 1191.558222, mean_eps: 0.553774
 148854/300000: episode: 1337, duration: 0.481s, episode steps:  76, steps per second: 158, episode reward: -1.689, mean reward: -0.022 [-100.000, 19.900], mean action: 1.684 [0.000, 3.000],  loss: 1446.505513, mae: 857.603161, mean_q: 1172.452402, mean_eps: 0.553553
 148931/300000: episode: 1338, duration: 0.521s, episode steps:  77, steps per second: 148, episode reward: -144.014, mean reward: -1.870 [-100.000, 10.857], mean action: 1.701 [0.000, 3.000],  loss: 1191.336246, mae: 861.680725, mean_q: 1179.111575, mean_eps: 0.553324
 149051/300000: episode: 1339, duration: 0.785s, episode steps: 120, steps per second: 153, episode reward: -154.168, mean reward: -1.285 [-100.000, 35.514], mean action: 1.825 [0.000, 3.000],  loss: 1296.409732, mae: 865.992620, mean_q: 1183.048274, mean_eps: 0.553028
 149196/300000: episode: 1340, duration: 1.049s, episode steps: 145, steps per second: 138, episode reward: -108.411, mean reward: -0.748 [-100.000, 17.437], mean action: 1.621 [0.000, 3.000],  loss: 1231.950010, mae: 871.747205, mean_q: 1193.227539, mean_eps: 0.552631
 149289/300000: episode: 1341, duration: 0.636s, episode steps:  93, steps per second: 146, episode reward: -33.790, mean reward: -0.363 [-100.000, 12.716], mean action: 1.645 [0.000, 3.000],  loss: 1232.792531, mae: 878.061447, mean_q: 1201.639960, mean_eps: 0.552274
 149394/300000: episode: 1342, duration: 0.687s, episode steps: 105, steps per second: 153, episode reward: -26.862, mean reward: -0.256 [-100.000, 11.806], mean action: 1.562 [0.000, 3.000],  loss: 1903.413367, mae: 877.338802, mean_q: 1201.823425, mean_eps: 0.551977
 149515/300000: episode: 1343, duration: 0.857s, episode steps: 121, steps per second: 141, episode reward: -56.373, mean reward: -0.466 [-100.000,  7.552], mean action: 1.636 [0.000, 3.000],  loss: 1471.169484, mae: 882.468892, mean_q: 1209.489929, mean_eps: 0.551638
 149627/300000: episode: 1344, duration: 0.763s, episode steps: 112, steps per second: 147, episode reward:  8.669, mean reward:  0.077 [-100.000, 19.068], mean action: 1.643 [0.000, 3.000],  loss: 1506.384757, mae: 887.365647, mean_q: 1214.213481, mean_eps: 0.551288
 150627/300000: episode: 1345, duration: 8.614s, episode steps: 1000, steps per second: 116, episode reward: 41.377, mean reward:  0.041 [-23.663, 22.936], mean action: 1.592 [0.000, 3.000],  loss: 1435.377335, mae: 905.087394, mean_q: 1237.477823, mean_eps: 0.549620
 150729/300000: episode: 1346, duration: 0.657s, episode steps: 102, steps per second: 155, episode reward: -110.942, mean reward: -1.088 [-100.000, 10.226], mean action: 1.549 [0.000, 3.000],  loss: 2245.496611, mae: 920.695852, mean_q: 1256.506899, mean_eps: 0.547968
 150827/300000: episode: 1347, duration: 0.650s, episode steps:  98, steps per second: 151, episode reward: -72.004, mean reward: -0.735 [-100.000, 10.391], mean action: 1.633 [0.000, 3.000],  loss: 1566.949314, mae: 915.012024, mean_q: 1249.272978, mean_eps: 0.547668
 150931/300000: episode: 1348, duration: 0.705s, episode steps: 104, steps per second: 148, episode reward: -12.235, mean reward: -0.118 [-100.000, 18.460], mean action: 1.625 [0.000, 3.000],  loss: 1277.148116, mae: 927.173031, mean_q: 1263.616765, mean_eps: 0.547365
 151029/300000: episode: 1349, duration: 0.636s, episode steps:  98, steps per second: 154, episode reward: -17.145, mean reward: -0.175 [-100.000, 15.639], mean action: 1.561 [0.000, 3.000],  loss: 1544.424219, mae: 922.948968, mean_q: 1259.318123, mean_eps: 0.547062
 151125/300000: episode: 1350, duration: 0.605s, episode steps:  96, steps per second: 159, episode reward: 13.996, mean reward:  0.146 [-100.000,  6.647], mean action: 1.667 [0.000, 3.000],  loss: 1880.647063, mae: 919.599874, mean_q: 1255.695563, mean_eps: 0.546770
 151203/300000: episode: 1351, duration: 0.546s, episode steps:  78, steps per second: 143, episode reward: -13.337, mean reward: -0.171 [-100.000,  9.710], mean action: 1.474 [0.000, 3.000],  loss: 1514.249542, mae: 923.685828, mean_q: 1262.445818, mean_eps: 0.546509
 151307/300000: episode: 1352, duration: 0.695s, episode steps: 104, steps per second: 150, episode reward: -255.353, mean reward: -2.455 [-100.000,  6.697], mean action: 1.885 [0.000, 3.000],  loss: 1301.850592, mae: 916.993008, mean_q: 1251.650762, mean_eps: 0.546236
 151418/300000: episode: 1353, duration: 0.704s, episode steps: 111, steps per second: 158, episode reward: -53.046, mean reward: -0.478 [-100.000,  7.849], mean action: 1.550 [0.000, 3.000],  loss: 1354.681696, mae: 905.207273, mean_q: 1234.161020, mean_eps: 0.545914
 151506/300000: episode: 1354, duration: 0.582s, episode steps:  88, steps per second: 151, episode reward: -109.788, mean reward: -1.248 [-100.000, 21.324], mean action: 1.602 [0.000, 3.000],  loss: 1636.105764, mae: 919.360458, mean_q: 1253.797828, mean_eps: 0.545616
 151648/300000: episode: 1355, duration: 0.969s, episode steps: 142, steps per second: 147, episode reward: 15.855, mean reward:  0.112 [-100.000, 11.461], mean action: 1.599 [0.000, 3.000],  loss: 1711.278866, mae: 920.785746, mean_q: 1255.534487, mean_eps: 0.545271
 151750/300000: episode: 1356, duration: 0.657s, episode steps: 102, steps per second: 155, episode reward: -10.529, mean reward: -0.103 [-100.000, 19.388], mean action: 1.373 [0.000, 3.000],  loss: 1313.885532, mae: 930.084665, mean_q: 1268.190271, mean_eps: 0.544904
 151844/300000: episode: 1357, duration: 0.606s, episode steps:  94, steps per second: 155, episode reward: -98.483, mean reward: -1.048 [-100.000, 10.151], mean action: 1.723 [0.000, 3.000],  loss: 1098.157986, mae: 923.181587, mean_q: 1258.285654, mean_eps: 0.544610
 151951/300000: episode: 1358, duration: 0.716s, episode steps: 107, steps per second: 149, episode reward: -87.505, mean reward: -0.818 [-100.000, 10.677], mean action: 1.673 [0.000, 3.000],  loss: 832.716029, mae: 923.436894, mean_q: 1258.905745, mean_eps: 0.544309
 152147/300000: episode: 1359, duration: 1.268s, episode steps: 196, steps per second: 155, episode reward: -186.332, mean reward: -0.951 [-100.000,  9.370], mean action: 1.663 [0.000, 3.000],  loss: 1550.911798, mae: 919.932831, mean_q: 1252.788882, mean_eps: 0.543855
 152240/300000: episode: 1360, duration: 0.645s, episode steps:  93, steps per second: 144, episode reward: -25.718, mean reward: -0.277 [-100.000,  7.361], mean action: 1.774 [0.000, 3.000],  loss: 1355.032462, mae: 918.006431, mean_q: 1249.284047, mean_eps: 0.543421
 152342/300000: episode: 1361, duration: 0.656s, episode steps: 102, steps per second: 155, episode reward: -53.858, mean reward: -0.528 [-100.000,  6.596], mean action: 1.578 [0.000, 3.000],  loss: 1748.470237, mae: 912.749468, mean_q: 1243.014331, mean_eps: 0.543128
 152426/300000: episode: 1362, duration: 0.549s, episode steps:  84, steps per second: 153, episode reward: -31.465, mean reward: -0.375 [-100.000, 21.723], mean action: 1.750 [0.000, 3.000],  loss: 1589.067691, mae: 913.722690, mean_q: 1246.013197, mean_eps: 0.542849
 152583/300000: episode: 1363, duration: 1.048s, episode steps: 157, steps per second: 150, episode reward: -30.236, mean reward: -0.193 [-100.000, 21.541], mean action: 1.739 [0.000, 3.000],  loss: 1860.453591, mae: 915.072715, mean_q: 1247.446785, mean_eps: 0.542488
 152688/300000: episode: 1364, duration: 0.665s, episode steps: 105, steps per second: 158, episode reward: -48.030, mean reward: -0.457 [-100.000, 16.795], mean action: 1.562 [0.000, 3.000],  loss: 1143.717696, mae: 927.526559, mean_q: 1263.703947, mean_eps: 0.542095
 152789/300000: episode: 1365, duration: 0.636s, episode steps: 101, steps per second: 159, episode reward: -23.189, mean reward: -0.230 [-100.000,  9.037], mean action: 1.713 [0.000, 3.000],  loss: 1498.934506, mae: 925.625597, mean_q: 1261.947968, mean_eps: 0.541786
 153033/300000: episode: 1366, duration: 1.663s, episode steps: 244, steps per second: 147, episode reward: -135.397, mean reward: -0.555 [-100.000, 17.166], mean action: 1.779 [0.000, 3.000],  loss: 1595.026695, mae: 923.132273, mean_q: 1257.841361, mean_eps: 0.541269
 153134/300000: episode: 1367, duration: 0.644s, episode steps: 101, steps per second: 157, episode reward: -280.222, mean reward: -2.774 [-100.000,  4.509], mean action: 1.970 [0.000, 3.000],  loss: 1297.617013, mae: 924.478720, mean_q: 1260.579210, mean_eps: 0.540751
 153237/300000: episode: 1368, duration: 0.739s, episode steps: 103, steps per second: 139, episode reward: -40.400, mean reward: -0.392 [-100.000, 12.644], mean action: 1.476 [0.000, 3.000],  loss: 1523.374570, mae: 922.509068, mean_q: 1258.228747, mean_eps: 0.540445
 154237/300000: episode: 1369, duration: 8.546s, episode steps: 1000, steps per second: 117, episode reward: -29.159, mean reward: -0.029 [-24.038, 25.537], mean action: 1.679 [0.000, 3.000],  loss: 1294.848892, mae: 917.255416, mean_q: 1250.242580, mean_eps: 0.538791
 154330/300000: episode: 1370, duration: 0.613s, episode steps:  93, steps per second: 152, episode reward: -92.577, mean reward: -0.995 [-100.000, 23.764], mean action: 1.720 [0.000, 3.000],  loss: 1203.429139, mae: 932.131147, mean_q: 1270.151505, mean_eps: 0.537151
 154424/300000: episode: 1371, duration: 0.600s, episode steps:  94, steps per second: 157, episode reward: -61.679, mean reward: -0.656 [-100.000, 38.150], mean action: 1.649 [0.000, 3.000],  loss: 1407.345069, mae: 925.447184, mean_q: 1262.584709, mean_eps: 0.536871
 154549/300000: episode: 1372, duration: 0.842s, episode steps: 125, steps per second: 148, episode reward: -110.727, mean reward: -0.886 [-100.000,  8.265], mean action: 1.528 [0.000, 3.000],  loss: 1821.475549, mae: 920.700051, mean_q: 1254.934223, mean_eps: 0.536542
 154785/300000: episode: 1373, duration: 1.563s, episode steps: 236, steps per second: 151, episode reward: -9.384, mean reward: -0.040 [-100.000, 18.490], mean action: 1.559 [0.000, 3.000],  loss: 1546.361324, mae: 920.534317, mean_q: 1254.081669, mean_eps: 0.536000
 154915/300000: episode: 1374, duration: 0.886s, episode steps: 130, steps per second: 147, episode reward: -70.525, mean reward: -0.543 [-100.000, 10.767], mean action: 1.692 [0.000, 3.000],  loss: 1672.927917, mae: 921.196556, mean_q: 1253.879447, mean_eps: 0.535452
 155010/300000: episode: 1375, duration: 0.609s, episode steps:  95, steps per second: 156, episode reward:  6.777, mean reward:  0.071 [-100.000, 13.102], mean action: 1.716 [0.000, 3.000],  loss: 1311.386622, mae: 912.711744, mean_q: 1244.230345, mean_eps: 0.535114
 155100/300000: episode: 1376, duration: 0.575s, episode steps:  90, steps per second: 157, episode reward: -43.961, mean reward: -0.488 [-100.000, 11.085], mean action: 1.856 [0.000, 3.000],  loss: 2207.667656, mae: 905.500767, mean_q: 1230.478956, mean_eps: 0.534837
 155214/300000: episode: 1377, duration: 0.770s, episode steps: 114, steps per second: 148, episode reward: 26.080, mean reward:  0.229 [-100.000, 15.923], mean action: 1.798 [0.000, 3.000],  loss: 1334.369917, mae: 914.490427, mean_q: 1245.278936, mean_eps: 0.534531
 155335/300000: episode: 1378, duration: 0.791s, episode steps: 121, steps per second: 153, episode reward: -165.544, mean reward: -1.368 [-100.000, 20.295], mean action: 1.298 [0.000, 3.000],  loss: 1583.240170, mae: 912.879504, mean_q: 1242.860767, mean_eps: 0.534178
 155468/300000: episode: 1379, duration: 0.889s, episode steps: 133, steps per second: 150, episode reward: -80.216, mean reward: -0.603 [-100.000,  6.603], mean action: 1.722 [0.000, 3.000],  loss: 1555.189946, mae: 909.287646, mean_q: 1237.879982, mean_eps: 0.533797
 155616/300000: episode: 1380, duration: 0.999s, episode steps: 148, steps per second: 148, episode reward: -0.276, mean reward: -0.002 [-100.000, 18.392], mean action: 1.682 [0.000, 3.000],  loss: 1484.956372, mae: 908.013065, mean_q: 1234.955139, mean_eps: 0.533376
 155711/300000: episode: 1381, duration: 0.604s, episode steps:  95, steps per second: 157, episode reward: -183.865, mean reward: -1.935 [-100.000,  5.812], mean action: 1.642 [0.000, 3.000],  loss: 1628.299279, mae: 912.456232, mean_q: 1242.371991, mean_eps: 0.533011
 155809/300000: episode: 1382, duration: 0.648s, episode steps:  98, steps per second: 151, episode reward: -81.185, mean reward: -0.828 [-100.000, 11.223], mean action: 1.673 [0.000, 3.000],  loss: 1544.570471, mae: 914.541773, mean_q: 1244.128974, mean_eps: 0.532721
 155908/300000: episode: 1383, duration: 0.668s, episode steps:  99, steps per second: 148, episode reward: 22.460, mean reward:  0.227 [-100.000, 11.784], mean action: 1.737 [0.000, 3.000],  loss: 1513.228485, mae: 913.662754, mean_q: 1244.500994, mean_eps: 0.532426
 156058/300000: episode: 1384, duration: 0.948s, episode steps: 150, steps per second: 158, episode reward: -82.430, mean reward: -0.550 [-100.000, 19.740], mean action: 1.780 [0.000, 3.000],  loss: 1684.532446, mae: 921.823109, mean_q: 1255.329405, mean_eps: 0.532052
 156162/300000: episode: 1385, duration: 0.695s, episode steps: 104, steps per second: 150, episode reward: -148.147, mean reward: -1.424 [-100.000, 39.170], mean action: 1.615 [0.000, 3.000],  loss: 2134.741517, mae: 911.507908, mean_q: 1240.675184, mean_eps: 0.531671
 156253/300000: episode: 1386, duration: 0.631s, episode steps:  91, steps per second: 144, episode reward: -31.103, mean reward: -0.342 [-100.000, 10.596], mean action: 1.725 [0.000, 3.000],  loss: 2079.504897, mae: 905.559960, mean_q: 1230.570363, mean_eps: 0.531379
 156353/300000: episode: 1387, duration: 0.658s, episode steps: 100, steps per second: 152, episode reward: -98.850, mean reward: -0.988 [-100.000,  8.163], mean action: 1.680 [0.000, 3.000],  loss: 2055.068359, mae: 910.587812, mean_q: 1239.703761, mean_eps: 0.531092
 156457/300000: episode: 1388, duration: 0.682s, episode steps: 104, steps per second: 153, episode reward: -75.829, mean reward: -0.729 [-100.000, 19.072], mean action: 1.644 [0.000, 3.000],  loss: 1801.714139, mae: 902.071518, mean_q: 1226.310637, mean_eps: 0.530787
 156549/300000: episode: 1389, duration: 0.607s, episode steps:  92, steps per second: 151, episode reward: -51.338, mean reward: -0.558 [-100.000,  9.576], mean action: 1.859 [0.000, 3.000],  loss: 1479.377125, mae: 892.322096, mean_q: 1215.240890, mean_eps: 0.530492
 156654/300000: episode: 1390, duration: 0.681s, episode steps: 105, steps per second: 154, episode reward: -106.105, mean reward: -1.011 [-100.000, 16.388], mean action: 1.657 [0.000, 3.000],  loss: 1218.461433, mae: 892.591813, mean_q: 1215.182622, mean_eps: 0.530197
 156779/300000: episode: 1391, duration: 0.796s, episode steps: 125, steps per second: 157, episode reward: -88.799, mean reward: -0.710 [-100.000, 10.937], mean action: 1.728 [0.000, 3.000],  loss: 1728.506947, mae: 890.309357, mean_q: 1212.664808, mean_eps: 0.529852
 156890/300000: episode: 1392, duration: 0.753s, episode steps: 111, steps per second: 147, episode reward: -94.551, mean reward: -0.852 [-100.000, 11.755], mean action: 1.613 [0.000, 3.000],  loss: 1520.525203, mae: 887.498382, mean_q: 1209.468194, mean_eps: 0.529498
 157050/300000: episode: 1393, duration: 1.040s, episode steps: 160, steps per second: 154, episode reward: -61.997, mean reward: -0.387 [-100.000,  8.583], mean action: 1.669 [0.000, 3.000],  loss: 1164.042381, mae: 886.222363, mean_q: 1206.914349, mean_eps: 0.529091
 157226/300000: episode: 1394, duration: 1.216s, episode steps: 176, steps per second: 145, episode reward: -72.195, mean reward: -0.410 [-100.000, 27.681], mean action: 1.869 [0.000, 3.000],  loss: 1593.540246, mae: 883.790346, mean_q: 1203.233870, mean_eps: 0.528587
 157328/300000: episode: 1395, duration: 0.645s, episode steps: 102, steps per second: 158, episode reward: -12.773, mean reward: -0.125 [-100.000, 22.110], mean action: 1.676 [0.000, 3.000],  loss: 1364.811916, mae: 877.977817, mean_q: 1194.707610, mean_eps: 0.528170
 157460/300000: episode: 1396, duration: 0.864s, episode steps: 132, steps per second: 153, episode reward: -36.444, mean reward: -0.276 [-100.000, 16.079], mean action: 1.788 [0.000, 3.000],  loss: 1047.605645, mae: 869.410734, mean_q: 1184.939707, mean_eps: 0.527819
 157565/300000: episode: 1397, duration: 0.698s, episode steps: 105, steps per second: 150, episode reward: -56.531, mean reward: -0.538 [-100.000,  7.651], mean action: 1.629 [0.000, 3.000],  loss: 1507.510521, mae: 874.068526, mean_q: 1190.480866, mean_eps: 0.527464
 157665/300000: episode: 1398, duration: 0.642s, episode steps: 100, steps per second: 156, episode reward: -37.136, mean reward: -0.371 [-100.000,  8.690], mean action: 1.730 [0.000, 3.000],  loss: 847.225579, mae: 862.429888, mean_q: 1173.247366, mean_eps: 0.527157
 157753/300000: episode: 1399, duration: 0.566s, episode steps:  88, steps per second: 155, episode reward: -20.422, mean reward: -0.232 [-100.000, 16.673], mean action: 1.864 [0.000, 3.000],  loss: 1510.034857, mae: 861.919496, mean_q: 1172.110949, mean_eps: 0.526875
 157854/300000: episode: 1400, duration: 0.698s, episode steps: 101, steps per second: 145, episode reward: -85.591, mean reward: -0.847 [-100.000,  7.323], mean action: 1.396 [0.000, 3.000],  loss: 1630.768627, mae: 852.158282, mean_q: 1159.927375, mean_eps: 0.526591
 157944/300000: episode: 1401, duration: 0.610s, episode steps:  90, steps per second: 148, episode reward: -58.449, mean reward: -0.649 [-100.000, 14.148], mean action: 1.711 [0.000, 3.000],  loss: 1455.679349, mae: 854.371132, mean_q: 1161.262035, mean_eps: 0.526304
 158094/300000: episode: 1402, duration: 1.041s, episode steps: 150, steps per second: 144, episode reward: -87.536, mean reward: -0.584 [-100.000,  7.976], mean action: 1.707 [0.000, 3.000],  loss: 1063.272461, mae: 853.470496, mean_q: 1161.043654, mean_eps: 0.525945
 158183/300000: episode: 1403, duration: 0.594s, episode steps:  89, steps per second: 150, episode reward: -26.781, mean reward: -0.301 [-100.000,  7.432], mean action: 1.854 [0.000, 3.000],  loss: 1496.807519, mae: 854.353917, mean_q: 1160.342426, mean_eps: 0.525586
 158304/300000: episode: 1404, duration: 0.772s, episode steps: 121, steps per second: 157, episode reward: -71.135, mean reward: -0.588 [-100.000,  7.825], mean action: 1.612 [0.000, 3.000],  loss: 1665.591341, mae: 847.609434, mean_q: 1150.949835, mean_eps: 0.525271
 158429/300000: episode: 1405, duration: 0.809s, episode steps: 125, steps per second: 155, episode reward: -21.847, mean reward: -0.175 [-100.000, 16.149], mean action: 1.688 [0.000, 3.000],  loss: 1642.322470, mae: 849.075973, mean_q: 1154.104993, mean_eps: 0.524902
 158535/300000: episode: 1406, duration: 0.717s, episode steps: 106, steps per second: 148, episode reward: -364.468, mean reward: -3.438 [-100.000,  3.893], mean action: 1.717 [0.000, 3.000],  loss: 1490.838548, mae: 849.113969, mean_q: 1154.785084, mean_eps: 0.524555
 158668/300000: episode: 1407, duration: 0.912s, episode steps: 133, steps per second: 146, episode reward: -87.754, mean reward: -0.660 [-100.000, 11.097], mean action: 1.579 [0.000, 3.000],  loss: 1238.137844, mae: 847.730956, mean_q: 1153.201143, mean_eps: 0.524197
 158802/300000: episode: 1408, duration: 0.987s, episode steps: 134, steps per second: 136, episode reward: -134.563, mean reward: -1.004 [-100.000,  7.490], mean action: 1.575 [0.000, 3.000],  loss: 1268.985983, mae: 843.693743, mean_q: 1146.631393, mean_eps: 0.523797
 158896/300000: episode: 1409, duration: 0.700s, episode steps:  94, steps per second: 134, episode reward: -47.236, mean reward: -0.503 [-100.000, 17.736], mean action: 1.574 [0.000, 3.000],  loss: 1154.373878, mae: 838.608174, mean_q: 1140.520942, mean_eps: 0.523455
 159000/300000: episode: 1410, duration: 0.724s, episode steps: 104, steps per second: 144, episode reward: -49.557, mean reward: -0.477 [-100.000, 48.407], mean action: 1.837 [0.000, 3.000],  loss: 951.837661, mae: 834.492057, mean_q: 1136.057752, mean_eps: 0.523157
 159090/300000: episode: 1411, duration: 0.668s, episode steps:  90, steps per second: 135, episode reward: -64.252, mean reward: -0.714 [-100.000, 10.368], mean action: 1.589 [0.000, 3.000],  loss: 1131.376214, mae: 823.202030, mean_q: 1118.678348, mean_eps: 0.522867
 159179/300000: episode: 1412, duration: 0.665s, episode steps:  89, steps per second: 134, episode reward: -55.639, mean reward: -0.625 [-100.000, 13.483], mean action: 1.685 [0.000, 3.000],  loss: 1242.248593, mae: 819.062855, mean_q: 1115.436849, mean_eps: 0.522598
 159317/300000: episode: 1413, duration: 1.044s, episode steps: 138, steps per second: 132, episode reward: -41.333, mean reward: -0.300 [-100.000,  9.668], mean action: 1.725 [0.000, 3.000],  loss: 2267.887625, mae: 818.008242, mean_q: 1112.582277, mean_eps: 0.522258
 159453/300000: episode: 1414, duration: 1.084s, episode steps: 136, steps per second: 126, episode reward: -66.562, mean reward: -0.489 [-100.000,  9.738], mean action: 1.559 [0.000, 3.000],  loss: 1014.908627, mae: 816.819034, mean_q: 1111.432470, mean_eps: 0.521846
 159560/300000: episode: 1415, duration: 1.056s, episode steps: 107, steps per second: 101, episode reward: -106.017, mean reward: -0.991 [-100.000,  6.036], mean action: 1.738 [0.000, 3.000],  loss: 1415.699909, mae: 811.500306, mean_q: 1103.534783, mean_eps: 0.521482
 159673/300000: episode: 1416, duration: 1.326s, episode steps: 113, steps per second:  85, episode reward: -42.974, mean reward: -0.380 [-100.000, 11.916], mean action: 1.832 [0.000, 3.000],  loss: 775.809893, mae: 807.105742, mean_q: 1098.012159, mean_eps: 0.521152
 160061/300000: episode: 1417, duration: 4.219s, episode steps: 388, steps per second:  92, episode reward: -390.780, mean reward: -1.007 [-100.000, 21.164], mean action: 1.750 [0.000, 3.000],  loss: 1272.357108, mae: 814.368544, mean_q: 1108.009415, mean_eps: 0.520400
 160150/300000: episode: 1418, duration: 1.554s, episode steps:  89, steps per second:  57, episode reward:  3.594, mean reward:  0.040 [-100.000, 15.040], mean action: 1.539 [0.000, 3.000],  loss: 1434.697925, mae: 808.961233, mean_q: 1100.869976, mean_eps: 0.519685
 160262/300000: episode: 1419, duration: 1.563s, episode steps: 112, steps per second:  72, episode reward: -55.158, mean reward: -0.492 [-100.000, 10.998], mean action: 1.509 [0.000, 3.000],  loss: 1095.708873, mae: 802.067696, mean_q: 1091.734249, mean_eps: 0.519383
 160377/300000: episode: 1420, duration: 0.982s, episode steps: 115, steps per second: 117, episode reward: -58.480, mean reward: -0.509 [-100.000,  7.221], mean action: 1.600 [0.000, 3.000],  loss: 1145.625361, mae: 799.215268, mean_q: 1090.493259, mean_eps: 0.519043
 160480/300000: episode: 1421, duration: 0.851s, episode steps: 103, steps per second: 121, episode reward: -66.794, mean reward: -0.648 [-100.000,  7.455], mean action: 1.718 [0.000, 3.000],  loss: 1384.370828, mae: 807.276215, mean_q: 1099.562918, mean_eps: 0.518716
 160578/300000: episode: 1422, duration: 1.169s, episode steps:  98, steps per second:  84, episode reward: -174.582, mean reward: -1.781 [-100.000,  5.556], mean action: 1.622 [0.000, 3.000],  loss: 1108.150662, mae: 803.681041, mean_q: 1094.660262, mean_eps: 0.518415
 160719/300000: episode: 1423, duration: 1.431s, episode steps: 141, steps per second:  99, episode reward: -53.027, mean reward: -0.376 [-100.000,  8.837], mean action: 1.773 [0.000, 3.000],  loss: 1174.232131, mae: 790.732824, mean_q: 1075.861225, mean_eps: 0.518056
 160832/300000: episode: 1424, duration: 1.462s, episode steps: 113, steps per second:  77, episode reward: -58.366, mean reward: -0.517 [-100.000, 13.604], mean action: 1.743 [0.000, 3.000],  loss: 1225.061724, mae: 787.576450, mean_q: 1071.746917, mean_eps: 0.517675
 160935/300000: episode: 1425, duration: 1.701s, episode steps: 103, steps per second:  61, episode reward: -58.198, mean reward: -0.565 [-100.000, 15.751], mean action: 1.680 [0.000, 3.000],  loss: 1186.102282, mae: 793.284708, mean_q: 1079.370813, mean_eps: 0.517351
 161041/300000: episode: 1426, duration: 1.353s, episode steps: 106, steps per second:  78, episode reward: -245.663, mean reward: -2.318 [-100.000, 66.184], mean action: 1.745 [0.000, 3.000],  loss: 1244.376554, mae: 782.797149, mean_q: 1064.840192, mean_eps: 0.517037
 161169/300000: episode: 1427, duration: 1.162s, episode steps: 128, steps per second: 110, episode reward: -75.632, mean reward: -0.591 [-100.000, 16.564], mean action: 1.633 [0.000, 3.000],  loss: 878.895299, mae: 787.301510, mean_q: 1070.476996, mean_eps: 0.516687
 161293/300000: episode: 1428, duration: 0.967s, episode steps: 124, steps per second: 128, episode reward: -114.642, mean reward: -0.925 [-100.000,  9.071], mean action: 1.613 [0.000, 3.000],  loss: 920.936433, mae: 778.352310, mean_q: 1059.769967, mean_eps: 0.516308
 161425/300000: episode: 1429, duration: 1.194s, episode steps: 132, steps per second: 111, episode reward:  0.939, mean reward:  0.007 [-100.000, 17.037], mean action: 1.667 [0.000, 3.000],  loss: 1258.803461, mae: 781.395581, mean_q: 1062.681158, mean_eps: 0.515925
 161576/300000: episode: 1430, duration: 1.045s, episode steps: 151, steps per second: 144, episode reward: 32.156, mean reward:  0.213 [-100.000, 18.855], mean action: 1.795 [0.000, 3.000],  loss: 1132.780570, mae: 784.519463, mean_q: 1067.665959, mean_eps: 0.515500
 161725/300000: episode: 1431, duration: 1.242s, episode steps: 149, steps per second: 120, episode reward: -219.196, mean reward: -1.471 [-100.000, 16.605], mean action: 1.604 [0.000, 3.000],  loss: 1101.575198, mae: 767.191042, mean_q: 1043.913383, mean_eps: 0.515050
 162612/300000: episode: 1432, duration: 7.775s, episode steps: 887, steps per second: 114, episode reward: -307.375, mean reward: -0.347 [-100.000, 17.205], mean action: 1.682 [0.000, 3.000],  loss: 1008.407341, mae: 769.589850, mean_q: 1047.262100, mean_eps: 0.513496
 162724/300000: episode: 1433, duration: 0.773s, episode steps: 112, steps per second: 145, episode reward: -90.754, mean reward: -0.810 [-100.000,  9.293], mean action: 1.643 [0.000, 3.000],  loss: 1043.521648, mae: 775.827000, mean_q: 1054.890045, mean_eps: 0.511997
 162804/300000: episode: 1434, duration: 0.563s, episode steps:  80, steps per second: 142, episode reward: -47.183, mean reward: -0.590 [-100.000, 12.414], mean action: 1.575 [0.000, 3.000],  loss: 1506.997440, mae: 768.633794, mean_q: 1044.577446, mean_eps: 0.511710
 162912/300000: episode: 1435, duration: 0.771s, episode steps: 108, steps per second: 140, episode reward: -31.762, mean reward: -0.294 [-100.000,  9.543], mean action: 1.602 [0.000, 3.000],  loss: 1131.173013, mae: 770.447064, mean_q: 1048.591916, mean_eps: 0.511428
 163069/300000: episode: 1436, duration: 1.023s, episode steps: 157, steps per second: 153, episode reward: -332.894, mean reward: -2.120 [-100.000, 52.876], mean action: 1.713 [0.000, 3.000],  loss: 676.937053, mae: 772.165147, mean_q: 1052.526667, mean_eps: 0.511030
 163217/300000: episode: 1437, duration: 1.076s, episode steps: 148, steps per second: 138, episode reward: 34.671, mean reward:  0.234 [-100.000, 17.640], mean action: 1.696 [0.000, 3.000],  loss: 1209.049413, mae: 770.671162, mean_q: 1048.859781, mean_eps: 0.510572
 163323/300000: episode: 1438, duration: 0.774s, episode steps: 106, steps per second: 137, episode reward: -77.303, mean reward: -0.729 [-100.000,  9.206], mean action: 1.689 [0.000, 3.000],  loss: 979.272271, mae: 772.993296, mean_q: 1051.731746, mean_eps: 0.510191
 163451/300000: episode: 1439, duration: 0.862s, episode steps: 128, steps per second: 148, episode reward: -85.576, mean reward: -0.669 [-100.000, 20.038], mean action: 1.609 [0.000, 3.000],  loss: 773.800436, mae: 767.888230, mean_q: 1046.073793, mean_eps: 0.509841
 163555/300000: episode: 1440, duration: 0.762s, episode steps: 104, steps per second: 136, episode reward: -58.473, mean reward: -0.562 [-100.000, 12.611], mean action: 1.798 [0.000, 3.000],  loss: 970.751183, mae: 768.738527, mean_q: 1045.298106, mean_eps: 0.509492
 163633/300000: episode: 1441, duration: 0.575s, episode steps:  78, steps per second: 136, episode reward: -55.265, mean reward: -0.709 [-100.000,  7.658], mean action: 1.603 [0.000, 3.000],  loss: 883.352224, mae: 772.654237, mean_q: 1051.744155, mean_eps: 0.509219
 163740/300000: episode: 1442, duration: 0.720s, episode steps: 107, steps per second: 149, episode reward: -97.688, mean reward: -0.913 [-100.000,  9.799], mean action: 1.692 [0.000, 3.000],  loss: 1091.235666, mae: 774.183418, mean_q: 1052.069383, mean_eps: 0.508942
 163863/300000: episode: 1443, duration: 0.983s, episode steps: 123, steps per second: 125, episode reward: -38.567, mean reward: -0.314 [-100.000, 12.370], mean action: 1.650 [0.000, 3.000],  loss: 896.081434, mae: 772.970457, mean_q: 1051.914406, mean_eps: 0.508597
 163949/300000: episode: 1444, duration: 0.594s, episode steps:  86, steps per second: 145, episode reward: -92.771, mean reward: -1.079 [-100.000, 18.668], mean action: 1.721 [0.000, 3.000],  loss: 945.816051, mae: 776.439021, mean_q: 1055.986203, mean_eps: 0.508283
 164082/300000: episode: 1445, duration: 0.863s, episode steps: 133, steps per second: 154, episode reward: -43.994, mean reward: -0.331 [-100.000,  9.428], mean action: 1.647 [0.000, 3.000],  loss: 954.055132, mae: 773.099855, mean_q: 1051.176393, mean_eps: 0.507955
 164189/300000: episode: 1446, duration: 0.721s, episode steps: 107, steps per second: 148, episode reward: -51.217, mean reward: -0.479 [-100.000, 22.755], mean action: 1.766 [0.000, 3.000],  loss: 979.726795, mae: 777.449977, mean_q: 1056.261466, mean_eps: 0.507595
 164325/300000: episode: 1447, duration: 0.880s, episode steps: 136, steps per second: 155, episode reward: -145.183, mean reward: -1.068 [-100.000, 11.282], mean action: 1.662 [0.000, 3.000],  loss: 876.917068, mae: 764.891893, mean_q: 1039.318888, mean_eps: 0.507230
 164426/300000: episode: 1448, duration: 0.660s, episode steps: 101, steps per second: 153, episode reward: -35.133, mean reward: -0.348 [-100.000, 16.691], mean action: 1.772 [0.000, 3.000],  loss: 1128.219298, mae: 755.691100, mean_q: 1027.601868, mean_eps: 0.506875
 164527/300000: episode: 1449, duration: 0.730s, episode steps: 101, steps per second: 138, episode reward: -213.459, mean reward: -2.113 [-100.000, 15.412], mean action: 1.792 [0.000, 3.000],  loss: 1007.978804, mae: 751.875707, mean_q: 1021.657312, mean_eps: 0.506572
 164654/300000: episode: 1450, duration: 0.812s, episode steps: 127, steps per second: 156, episode reward: -24.026, mean reward: -0.189 [-100.000, 17.347], mean action: 1.496 [0.000, 3.000],  loss: 913.537522, mae: 743.840747, mean_q: 1011.687819, mean_eps: 0.506230
 164768/300000: episode: 1451, duration: 0.716s, episode steps: 114, steps per second: 159, episode reward: -18.876, mean reward: -0.166 [-100.000, 10.280], mean action: 1.763 [0.000, 3.000],  loss: 871.782749, mae: 741.519913, mean_q: 1007.697951, mean_eps: 0.505868
 164872/300000: episode: 1452, duration: 0.780s, episode steps: 104, steps per second: 133, episode reward: -99.484, mean reward: -0.957 [-100.000, 11.735], mean action: 1.721 [0.000, 3.000],  loss: 870.586569, mae: 725.947471, mean_q: 986.439011, mean_eps: 0.505541
 164976/300000: episode: 1453, duration: 0.731s, episode steps: 104, steps per second: 142, episode reward: -111.620, mean reward: -1.073 [-100.000, 12.047], mean action: 1.596 [0.000, 3.000],  loss: 815.244726, mae: 722.224041, mean_q: 982.407666, mean_eps: 0.505229
 165083/300000: episode: 1454, duration: 0.707s, episode steps: 107, steps per second: 151, episode reward: -88.176, mean reward: -0.824 [-100.000, 11.699], mean action: 1.692 [0.000, 3.000],  loss: 798.452374, mae: 724.937150, mean_q: 984.486516, mean_eps: 0.504913
 165190/300000: episode: 1455, duration: 0.770s, episode steps: 107, steps per second: 139, episode reward: -8.231, mean reward: -0.077 [-100.000, 18.667], mean action: 1.617 [0.000, 3.000],  loss: 927.968259, mae: 722.984338, mean_q: 981.424828, mean_eps: 0.504592
 165279/300000: episode: 1456, duration: 0.621s, episode steps:  89, steps per second: 143, episode reward: -54.376, mean reward: -0.611 [-100.000, 10.490], mean action: 1.775 [0.000, 3.000],  loss: 793.779658, mae: 725.414357, mean_q: 985.510609, mean_eps: 0.504298
 165388/300000: episode: 1457, duration: 0.744s, episode steps: 109, steps per second: 146, episode reward: -37.729, mean reward: -0.346 [-100.000,  7.730], mean action: 1.780 [0.000, 3.000],  loss: 924.538177, mae: 720.214862, mean_q: 977.850215, mean_eps: 0.504001
 165479/300000: episode: 1458, duration: 0.677s, episode steps:  91, steps per second: 134, episode reward: -70.941, mean reward: -0.780 [-100.000, 36.778], mean action: 1.813 [0.000, 3.000],  loss: 1241.165986, mae: 715.617762, mean_q: 971.184368, mean_eps: 0.503701
 165615/300000: episode: 1459, duration: 0.971s, episode steps: 136, steps per second: 140, episode reward: -67.834, mean reward: -0.499 [-100.000, 17.184], mean action: 1.669 [0.000, 3.000],  loss: 889.063867, mae: 713.785611, mean_q: 969.977414, mean_eps: 0.503361
 165726/300000: episode: 1460, duration: 0.741s, episode steps: 111, steps per second: 150, episode reward: -0.688, mean reward: -0.006 [-100.000, 12.865], mean action: 1.883 [0.000, 3.000],  loss: 859.408543, mae: 708.120801, mean_q: 962.482636, mean_eps: 0.502990
 165819/300000: episode: 1461, duration: 0.630s, episode steps:  93, steps per second: 148, episode reward: -55.647, mean reward: -0.598 [-100.000, 10.795], mean action: 1.634 [0.000, 3.000],  loss: 891.816932, mae: 709.704135, mean_q: 963.182903, mean_eps: 0.502684
 165939/300000: episode: 1462, duration: 0.750s, episode steps: 120, steps per second: 160, episode reward: -62.463, mean reward: -0.521 [-100.000, 14.752], mean action: 1.583 [0.000, 3.000],  loss: 1006.666713, mae: 699.133698, mean_q: 951.450632, mean_eps: 0.502364
 166043/300000: episode: 1463, duration: 0.671s, episode steps: 104, steps per second: 155, episode reward: -17.298, mean reward: -0.166 [-100.000,  8.203], mean action: 1.625 [0.000, 3.000],  loss: 995.517312, mae: 704.471205, mean_q: 959.085342, mean_eps: 0.502028
 166134/300000: episode: 1464, duration: 0.632s, episode steps:  91, steps per second: 144, episode reward: -67.634, mean reward: -0.743 [-100.000, 10.380], mean action: 1.659 [0.000, 3.000],  loss: 657.820220, mae: 701.309074, mean_q: 955.497639, mean_eps: 0.501736
 166233/300000: episode: 1465, duration: 0.663s, episode steps:  99, steps per second: 149, episode reward: -45.863, mean reward: -0.463 [-100.000,  9.836], mean action: 1.879 [0.000, 3.000],  loss: 708.966750, mae: 697.508189, mean_q: 949.591410, mean_eps: 0.501451
 166368/300000: episode: 1466, duration: 1.128s, episode steps: 135, steps per second: 120, episode reward: -35.547, mean reward: -0.263 [-100.000, 14.765], mean action: 1.667 [0.000, 3.000],  loss: 773.195726, mae: 705.430563, mean_q: 960.151088, mean_eps: 0.501100
 166470/300000: episode: 1467, duration: 0.792s, episode steps: 102, steps per second: 129, episode reward: 11.398, mean reward:  0.112 [-100.000, 20.236], mean action: 1.735 [0.000, 3.000],  loss: 836.274558, mae: 699.509067, mean_q: 952.565189, mean_eps: 0.500745
 166587/300000: episode: 1468, duration: 0.803s, episode steps: 117, steps per second: 146, episode reward: -30.145, mean reward: -0.258 [-100.000,  8.545], mean action: 1.692 [0.000, 3.000],  loss: 780.054614, mae: 689.023261, mean_q: 939.278064, mean_eps: 0.500416
 166681/300000: episode: 1469, duration: 0.698s, episode steps:  94, steps per second: 135, episode reward: -111.168, mean reward: -1.183 [-100.000, 10.941], mean action: 1.649 [0.000, 3.000],  loss: 637.381346, mae: 691.574692, mean_q: 940.974070, mean_eps: 0.500099
 166799/300000: episode: 1470, duration: 0.812s, episode steps: 118, steps per second: 145, episode reward: -158.380, mean reward: -1.342 [-100.000, 37.237], mean action: 1.856 [0.000, 3.000],  loss: 850.639948, mae: 694.920168, mean_q: 947.314570, mean_eps: 0.499781
 167010/300000: episode: 1471, duration: 1.479s, episode steps: 211, steps per second: 143, episode reward: -37.225, mean reward: -0.176 [-100.000, 17.152], mean action: 1.810 [0.000, 3.000],  loss: 708.946716, mae: 693.444511, mean_q: 945.879146, mean_eps: 0.499288
 167097/300000: episode: 1472, duration: 0.620s, episode steps:  87, steps per second: 140, episode reward: -35.581, mean reward: -0.409 [-100.000, 10.817], mean action: 1.529 [0.000, 3.000],  loss: 979.612106, mae: 691.740878, mean_q: 942.483323, mean_eps: 0.498841
 167197/300000: episode: 1473, duration: 0.652s, episode steps: 100, steps per second: 153, episode reward: -41.345, mean reward: -0.413 [-100.000, 11.533], mean action: 1.750 [0.000, 3.000],  loss: 687.869629, mae: 698.276640, mean_q: 949.601169, mean_eps: 0.498561
 167313/300000: episode: 1474, duration: 0.822s, episode steps: 116, steps per second: 141, episode reward: -22.428, mean reward: -0.193 [-100.000, 16.027], mean action: 1.621 [0.000, 3.000],  loss: 818.335736, mae: 694.988432, mean_q: 945.253918, mean_eps: 0.498236
 168313/300000: episode: 1475, duration: 8.023s, episode steps: 1000, steps per second: 125, episode reward: 96.558, mean reward:  0.097 [-23.253, 23.196], mean action: 1.500 [0.000, 3.000],  loss: 690.531333, mae: 694.642809, mean_q: 944.756593, mean_eps: 0.496563
 168417/300000: episode: 1476, duration: 0.715s, episode steps: 104, steps per second: 145, episode reward: -77.562, mean reward: -0.746 [-100.000, 16.367], mean action: 1.692 [0.000, 3.000],  loss: 711.456602, mae: 680.518115, mean_q: 924.300025, mean_eps: 0.494906
 169417/300000: episode: 1477, duration: 7.498s, episode steps: 1000, steps per second: 133, episode reward: -50.833, mean reward: -0.051 [-23.052, 23.861], mean action: 1.699 [0.000, 3.000],  loss: 620.677149, mae: 674.328279, mean_q: 915.814972, mean_eps: 0.493250
 169550/300000: episode: 1478, duration: 0.900s, episode steps: 133, steps per second: 148, episode reward: -20.607, mean reward: -0.155 [-100.000, 12.530], mean action: 1.865 [0.000, 3.000],  loss: 552.331989, mae: 676.392730, mean_q: 918.920957, mean_eps: 0.491551
 169697/300000: episode: 1479, duration: 1.040s, episode steps: 147, steps per second: 141, episode reward: -46.250, mean reward: -0.315 [-100.000, 22.043], mean action: 1.646 [0.000, 3.000],  loss: 683.184287, mae: 672.240121, mean_q: 911.330704, mean_eps: 0.491131
 169847/300000: episode: 1480, duration: 1.060s, episode steps: 150, steps per second: 141, episode reward: -188.212, mean reward: -1.255 [-100.000, 38.245], mean action: 1.580 [0.000, 3.000],  loss: 558.306968, mae: 668.107020, mean_q: 905.450080, mean_eps: 0.490685
 169990/300000: episode: 1481, duration: 0.968s, episode steps: 143, steps per second: 148, episode reward: -45.635, mean reward: -0.319 [-100.000, 10.345], mean action: 1.566 [0.000, 3.000],  loss: 576.338391, mae: 663.175471, mean_q: 900.178028, mean_eps: 0.490246
 170084/300000: episode: 1482, duration: 0.610s, episode steps:  94, steps per second: 154, episode reward: -44.176, mean reward: -0.470 [-100.000, 16.977], mean action: 1.660 [0.000, 3.000],  loss: 437.612288, mae: 664.997322, mean_q: 902.706797, mean_eps: 0.489890
 170207/300000: episode: 1483, duration: 0.822s, episode steps: 123, steps per second: 150, episode reward:  2.910, mean reward:  0.024 [-100.000, 17.718], mean action: 1.691 [0.000, 3.000],  loss: 546.654107, mae: 658.657127, mean_q: 893.317742, mean_eps: 0.489565
 170345/300000: episode: 1484, duration: 1.022s, episode steps: 138, steps per second: 135, episode reward: -29.359, mean reward: -0.213 [-100.000,  9.111], mean action: 1.717 [0.000, 3.000],  loss: 520.164329, mae: 657.584244, mean_q: 892.287375, mean_eps: 0.489174
 170471/300000: episode: 1485, duration: 0.935s, episode steps: 126, steps per second: 135, episode reward: -28.132, mean reward: -0.223 [-100.000, 26.916], mean action: 1.540 [0.000, 3.000],  loss: 551.738009, mae: 660.937158, mean_q: 897.930108, mean_eps: 0.488778
 170557/300000: episode: 1486, duration: 0.602s, episode steps:  86, steps per second: 143, episode reward: -55.749, mean reward: -0.648 [-100.000,  7.693], mean action: 1.419 [0.000, 3.000],  loss: 550.759099, mae: 658.142852, mean_q: 892.759735, mean_eps: 0.488459
 170650/300000: episode: 1487, duration: 0.636s, episode steps:  93, steps per second: 146, episode reward: -30.753, mean reward: -0.331 [-100.000, 11.248], mean action: 1.634 [0.000, 3.000],  loss: 496.752627, mae: 657.398570, mean_q: 893.701083, mean_eps: 0.488191
 170800/300000: episode: 1488, duration: 1.013s, episode steps: 150, steps per second: 148, episode reward: -80.669, mean reward: -0.538 [-100.000, 48.302], mean action: 1.553 [0.000, 3.000],  loss: 596.704385, mae: 654.647299, mean_q: 887.889702, mean_eps: 0.487826
 170917/300000: episode: 1489, duration: 0.909s, episode steps: 117, steps per second: 129, episode reward:  0.624, mean reward:  0.005 [-100.000, 12.748], mean action: 1.684 [0.000, 3.000],  loss: 480.255868, mae: 643.402271, mean_q: 871.296468, mean_eps: 0.487426
 171012/300000: episode: 1490, duration: 0.737s, episode steps:  95, steps per second: 129, episode reward: -55.013, mean reward: -0.579 [-100.000,  7.532], mean action: 1.600 [0.000, 3.000],  loss: 544.905701, mae: 636.420054, mean_q: 864.302760, mean_eps: 0.487108
 171831/300000: episode: 1491, duration: 6.493s, episode steps: 819, steps per second: 126, episode reward: -139.737, mean reward: -0.171 [-100.000, 29.306], mean action: 1.672 [0.000, 3.000],  loss: 533.182678, mae: 635.802522, mean_q: 862.615174, mean_eps: 0.485737
 171943/300000: episode: 1492, duration: 0.753s, episode steps: 112, steps per second: 149, episode reward:  8.928, mean reward:  0.080 [-100.000, 16.076], mean action: 1.750 [0.000, 3.000],  loss: 634.805164, mae: 637.832487, mean_q: 865.563576, mean_eps: 0.484341
 172019/300000: episode: 1493, duration: 0.480s, episode steps:  76, steps per second: 158, episode reward: -70.255, mean reward: -0.924 [-100.000,  9.653], mean action: 1.724 [0.000, 3.000],  loss: 375.695212, mae: 630.478643, mean_q: 855.864618, mean_eps: 0.484059
 173019/300000: episode: 1494, duration: 7.658s, episode steps: 1000, steps per second: 131, episode reward: 52.323, mean reward:  0.052 [-23.844, 27.306], mean action: 1.486 [0.000, 3.000],  loss: 532.600257, mae: 622.430553, mean_q: 845.743960, mean_eps: 0.482444
 173131/300000: episode: 1495, duration: 0.800s, episode steps: 112, steps per second: 140, episode reward: 17.641, mean reward:  0.158 [-100.000, 19.281], mean action: 1.714 [0.000, 3.000],  loss: 563.101737, mae: 602.676733, mean_q: 819.147048, mean_eps: 0.480777
 173500/300000: episode: 1496, duration: 2.819s, episode steps: 369, steps per second: 131, episode reward: -221.119, mean reward: -0.599 [-100.000, 20.270], mean action: 1.656 [0.000, 3.000],  loss: 512.389258, mae: 600.207642, mean_q: 815.277171, mean_eps: 0.480055
 173620/300000: episode: 1497, duration: 0.965s, episode steps: 120, steps per second: 124, episode reward: -11.102, mean reward: -0.093 [-100.000, 20.026], mean action: 1.800 [0.000, 3.000],  loss: 371.599447, mae: 601.150785, mean_q: 817.246016, mean_eps: 0.479322
 173966/300000: episode: 1498, duration: 2.821s, episode steps: 346, steps per second: 123, episode reward: -252.749, mean reward: -0.730 [-100.000, 30.900], mean action: 1.723 [0.000, 3.000],  loss: 408.896348, mae: 593.748175, mean_q: 806.908196, mean_eps: 0.478623
 174107/300000: episode: 1499, duration: 1.084s, episode steps: 141, steps per second: 130, episode reward: -26.765, mean reward: -0.190 [-100.000, 18.955], mean action: 1.468 [0.000, 3.000],  loss: 587.275523, mae: 594.529894, mean_q: 806.766044, mean_eps: 0.477892
 174202/300000: episode: 1500, duration: 0.774s, episode steps:  95, steps per second: 123, episode reward: -75.485, mean reward: -0.795 [-100.000, 20.565], mean action: 1.832 [0.000, 3.000],  loss: 435.977921, mae: 581.832232, mean_q: 789.945670, mean_eps: 0.477538
 175202/300000: episode: 1501, duration: 11.334s, episode steps: 1000, steps per second:  88, episode reward: 18.149, mean reward:  0.018 [-24.557, 25.090], mean action: 1.602 [0.000, 3.000],  loss: 383.267335, mae: 585.784373, mean_q: 795.121688, mean_eps: 0.475896
 176202/300000: episode: 1502, duration: 8.539s, episode steps: 1000, steps per second: 117, episode reward: 30.366, mean reward:  0.030 [-23.755, 23.139], mean action: 1.518 [0.000, 3.000],  loss: 357.344935, mae: 567.470000, mean_q: 768.656955, mean_eps: 0.472896
 177202/300000: episode: 1503, duration: 10.019s, episode steps: 1000, steps per second: 100, episode reward: 37.500, mean reward:  0.037 [-24.803, 26.519], mean action: 1.712 [0.000, 3.000],  loss: 354.951667, mae: 547.520014, mean_q: 741.598214, mean_eps: 0.469896
 177341/300000: episode: 1504, duration: 1.100s, episode steps: 139, steps per second: 126, episode reward: -3.790, mean reward: -0.027 [-100.000, 11.352], mean action: 1.719 [0.000, 3.000],  loss: 314.945890, mae: 540.538697, mean_q: 732.925793, mean_eps: 0.468187
 177468/300000: episode: 1505, duration: 0.854s, episode steps: 127, steps per second: 149, episode reward:  2.573, mean reward:  0.020 [-100.000, 15.558], mean action: 1.583 [0.000, 3.000],  loss: 295.552290, mae: 539.480072, mean_q: 730.390329, mean_eps: 0.467788
 177572/300000: episode: 1506, duration: 0.740s, episode steps: 104, steps per second: 140, episode reward: -27.747, mean reward: -0.267 [-100.000, 16.989], mean action: 1.587 [0.000, 3.000],  loss: 277.616502, mae: 536.695003, mean_q: 727.296903, mean_eps: 0.467441
 177707/300000: episode: 1507, duration: 0.986s, episode steps: 135, steps per second: 137, episode reward: -29.213, mean reward: -0.216 [-100.000, 10.264], mean action: 1.733 [0.000, 3.000],  loss: 271.824717, mae: 533.968682, mean_q: 723.962268, mean_eps: 0.467083
 177828/300000: episode: 1508, duration: 1.102s, episode steps: 121, steps per second: 110, episode reward: -84.917, mean reward: -0.702 [-100.000,  7.340], mean action: 1.810 [0.000, 3.000],  loss: 294.630011, mae: 526.766763, mean_q: 714.539235, mean_eps: 0.466699
 178828/300000: episode: 1509, duration: 9.085s, episode steps: 1000, steps per second: 110, episode reward: 76.616, mean reward:  0.077 [-24.752, 24.281], mean action: 1.523 [0.000, 3.000],  loss: 324.590910, mae: 519.871544, mean_q: 703.483610, mean_eps: 0.465018
 178926/300000: episode: 1510, duration: 0.711s, episode steps:  98, steps per second: 138, episode reward: -57.270, mean reward: -0.584 [-100.000, 16.532], mean action: 1.694 [0.000, 3.000],  loss: 327.859196, mae: 514.482383, mean_q: 696.439132, mean_eps: 0.463371
 179052/300000: episode: 1511, duration: 0.893s, episode steps: 126, steps per second: 141, episode reward: -39.531, mean reward: -0.314 [-100.000, 12.580], mean action: 1.595 [0.000, 3.000],  loss: 338.498666, mae: 514.548201, mean_q: 695.853491, mean_eps: 0.463035
 179165/300000: episode: 1512, duration: 0.851s, episode steps: 113, steps per second: 133, episode reward: -32.775, mean reward: -0.290 [-100.000, 12.298], mean action: 1.558 [0.000, 3.000],  loss: 337.997901, mae: 508.642022, mean_q: 689.103336, mean_eps: 0.462676
 179427/300000: episode: 1513, duration: 2.176s, episode steps: 262, steps per second: 120, episode reward: -285.524, mean reward: -1.090 [-100.000, 17.672], mean action: 1.786 [0.000, 3.000],  loss: 328.607051, mae: 508.013800, mean_q: 688.139692, mean_eps: 0.462114
 179522/300000: episode: 1514, duration: 0.754s, episode steps:  95, steps per second: 126, episode reward: -34.122, mean reward: -0.359 [-100.000, 15.012], mean action: 1.611 [0.000, 3.000],  loss: 344.497921, mae: 504.928286, mean_q: 684.552306, mean_eps: 0.461578
 179611/300000: episode: 1515, duration: 0.649s, episode steps:  89, steps per second: 137, episode reward:  0.835, mean reward:  0.009 [-100.000, 19.298], mean action: 1.517 [0.000, 3.000],  loss: 243.337288, mae: 502.482502, mean_q: 680.055466, mean_eps: 0.461302
 179695/300000: episode: 1516, duration: 0.598s, episode steps:  84, steps per second: 140, episode reward: -58.972, mean reward: -0.702 [-100.000,  8.298], mean action: 1.714 [0.000, 3.000],  loss: 287.200934, mae: 494.200332, mean_q: 669.764117, mean_eps: 0.461043
 179834/300000: episode: 1517, duration: 0.935s, episode steps: 139, steps per second: 149, episode reward: -67.156, mean reward: -0.483 [-100.000, 28.095], mean action: 1.647 [0.000, 3.000],  loss: 325.798332, mae: 496.710401, mean_q: 673.553811, mean_eps: 0.460708
 179956/300000: episode: 1518, duration: 0.865s, episode steps: 122, steps per second: 141, episode reward: -54.280, mean reward: -0.445 [-100.000, 11.963], mean action: 1.639 [0.000, 3.000],  loss: 248.000015, mae: 499.601948, mean_q: 677.003503, mean_eps: 0.460317
 180073/300000: episode: 1519, duration: 0.792s, episode steps: 117, steps per second: 148, episode reward: -19.385, mean reward: -0.166 [-100.000, 13.888], mean action: 1.795 [0.000, 3.000],  loss: 311.929850, mae: 498.292579, mean_q: 675.256922, mean_eps: 0.459958
 180226/300000: episode: 1520, duration: 0.972s, episode steps: 153, steps per second: 157, episode reward: 39.986, mean reward:  0.261 [-100.000, 17.317], mean action: 1.699 [0.000, 3.000],  loss: 349.505851, mae: 502.031101, mean_q: 680.631320, mean_eps: 0.459553
 181226/300000: episode: 1521, duration: 8.010s, episode steps: 1000, steps per second: 125, episode reward: 59.860, mean reward:  0.060 [-24.046, 25.132], mean action: 1.566 [0.000, 3.000],  loss: 307.626087, mae: 492.578290, mean_q: 666.761299, mean_eps: 0.457824
 181332/300000: episode: 1522, duration: 0.860s, episode steps: 106, steps per second: 123, episode reward: -0.658, mean reward: -0.006 [-100.000, 19.430], mean action: 1.792 [0.000, 3.000],  loss: 352.086123, mae: 483.758229, mean_q: 655.049859, mean_eps: 0.456164
 181434/300000: episode: 1523, duration: 0.844s, episode steps: 102, steps per second: 121, episode reward: -16.472, mean reward: -0.161 [-100.000,  8.235], mean action: 1.598 [0.000, 3.000],  loss: 355.189637, mae: 483.703363, mean_q: 654.338861, mean_eps: 0.455852
 181549/300000: episode: 1524, duration: 0.759s, episode steps: 115, steps per second: 152, episode reward: -103.735, mean reward: -0.902 [-100.000,  7.846], mean action: 1.678 [0.000, 3.000],  loss: 246.490999, mae: 480.891487, mean_q: 650.967227, mean_eps: 0.455527
 181667/300000: episode: 1525, duration: 0.843s, episode steps: 118, steps per second: 140, episode reward: -155.977, mean reward: -1.322 [-100.000, 38.765], mean action: 1.754 [0.000, 3.000],  loss: 317.927924, mae: 478.852274, mean_q: 648.326804, mean_eps: 0.455177
 181762/300000: episode: 1526, duration: 0.628s, episode steps:  95, steps per second: 151, episode reward: -100.764, mean reward: -1.061 [-100.000,  9.565], mean action: 1.600 [0.000, 3.000],  loss: 311.790768, mae: 479.896044, mean_q: 649.468620, mean_eps: 0.454858
 181864/300000: episode: 1527, duration: 0.684s, episode steps: 102, steps per second: 149, episode reward: -57.256, mean reward: -0.561 [-100.000, 15.329], mean action: 1.804 [0.000, 3.000],  loss: 336.239605, mae: 481.372057, mean_q: 651.710709, mean_eps: 0.454562
 181971/300000: episode: 1528, duration: 0.864s, episode steps: 107, steps per second: 124, episode reward: -45.970, mean reward: -0.430 [-100.000, 17.697], mean action: 1.589 [0.000, 3.000],  loss: 345.215472, mae: 476.210731, mean_q: 643.515113, mean_eps: 0.454249
 182082/300000: episode: 1529, duration: 1.065s, episode steps: 111, steps per second: 104, episode reward:  6.670, mean reward:  0.060 [-100.000,  9.368], mean action: 1.505 [0.000, 3.000],  loss: 219.310469, mae: 474.908556, mean_q: 642.655635, mean_eps: 0.453922
 182192/300000: episode: 1530, duration: 1.194s, episode steps: 110, steps per second:  92, episode reward:  6.833, mean reward:  0.062 [-100.000, 17.005], mean action: 1.718 [0.000, 3.000],  loss: 297.080350, mae: 470.771487, mean_q: 636.895733, mean_eps: 0.453590
 182277/300000: episode: 1531, duration: 0.748s, episode steps:  85, steps per second: 114, episode reward:  9.735, mean reward:  0.115 [-100.000, 18.984], mean action: 1.729 [0.000, 3.000],  loss: 265.401855, mae: 479.932569, mean_q: 648.329849, mean_eps: 0.453298
 182504/300000: episode: 1532, duration: 1.775s, episode steps: 227, steps per second: 128, episode reward: -134.864, mean reward: -0.594 [-100.000, 30.425], mean action: 1.683 [0.000, 3.000],  loss: 271.955617, mae: 472.043666, mean_q: 639.449896, mean_eps: 0.452830
 182615/300000: episode: 1533, duration: 0.937s, episode steps: 111, steps per second: 118, episode reward: 13.044, mean reward:  0.118 [-100.000, 16.115], mean action: 1.748 [0.000, 3.000],  loss: 324.569462, mae: 473.216513, mean_q: 639.667276, mean_eps: 0.452323
 182727/300000: episode: 1534, duration: 1.037s, episode steps: 112, steps per second: 108, episode reward: 20.072, mean reward:  0.179 [-100.000, 14.905], mean action: 1.732 [0.000, 3.000],  loss: 330.001092, mae: 467.685971, mean_q: 633.005108, mean_eps: 0.451989
 182819/300000: episode: 1535, duration: 0.672s, episode steps:  92, steps per second: 137, episode reward: 25.679, mean reward:  0.279 [-100.000, 12.021], mean action: 1.707 [0.000, 3.000],  loss: 272.883487, mae: 467.682001, mean_q: 633.125648, mean_eps: 0.451682
 182934/300000: episode: 1536, duration: 0.913s, episode steps: 115, steps per second: 126, episode reward: -544.871, mean reward: -4.738 [-100.000,  1.634], mean action: 1.443 [0.000, 3.000],  loss: 238.417326, mae: 466.454391, mean_q: 631.243452, mean_eps: 0.451372
 183049/300000: episode: 1537, duration: 0.837s, episode steps: 115, steps per second: 137, episode reward: -14.570, mean reward: -0.127 [-100.000, 13.829], mean action: 1.530 [0.000, 3.000],  loss: 222.617151, mae: 463.596113, mean_q: 627.801365, mean_eps: 0.451027
 183155/300000: episode: 1538, duration: 0.752s, episode steps: 106, steps per second: 141, episode reward: -25.656, mean reward: -0.242 [-100.000, 42.574], mean action: 1.755 [0.000, 3.000],  loss: 260.053543, mae: 461.566643, mean_q: 624.423476, mean_eps: 0.450696
 183269/300000: episode: 1539, duration: 0.833s, episode steps: 114, steps per second: 137, episode reward:  0.795, mean reward:  0.007 [-100.000, 11.987], mean action: 1.798 [0.000, 3.000],  loss: 212.189965, mae: 456.043432, mean_q: 617.623721, mean_eps: 0.450366
 183356/300000: episode: 1540, duration: 0.627s, episode steps:  87, steps per second: 139, episode reward: -15.658, mean reward: -0.180 [-100.000, 16.835], mean action: 1.425 [0.000, 3.000],  loss: 285.778054, mae: 451.388069, mean_q: 611.001846, mean_eps: 0.450064
 183465/300000: episode: 1541, duration: 0.750s, episode steps: 109, steps per second: 145, episode reward: -20.805, mean reward: -0.191 [-100.000, 13.647], mean action: 1.532 [0.000, 3.000],  loss: 277.244235, mae: 450.767810, mean_q: 610.395268, mean_eps: 0.449770
 183556/300000: episode: 1542, duration: 0.687s, episode steps:  91, steps per second: 132, episode reward: -61.796, mean reward: -0.679 [-100.000,  9.804], mean action: 1.791 [0.000, 3.000],  loss: 405.761256, mae: 450.655967, mean_q: 609.716203, mean_eps: 0.449470
 183632/300000: episode: 1543, duration: 0.564s, episode steps:  76, steps per second: 135, episode reward: -28.252, mean reward: -0.372 [-100.000,  6.694], mean action: 1.816 [0.000, 3.000],  loss: 408.413331, mae: 451.787119, mean_q: 611.130721, mean_eps: 0.449219
 183756/300000: episode: 1544, duration: 0.862s, episode steps: 124, steps per second: 144, episode reward: 16.358, mean reward:  0.132 [-100.000, 18.471], mean action: 1.629 [0.000, 3.000],  loss: 370.885858, mae: 447.765888, mean_q: 605.418680, mean_eps: 0.448919
 183865/300000: episode: 1545, duration: 0.924s, episode steps: 109, steps per second: 118, episode reward:  4.787, mean reward:  0.044 [-100.000, 25.827], mean action: 1.624 [0.000, 3.000],  loss: 323.977884, mae: 440.652431, mean_q: 596.561648, mean_eps: 0.448570
 183957/300000: episode: 1546, duration: 0.740s, episode steps:  92, steps per second: 124, episode reward: -48.448, mean reward: -0.527 [-100.000, 18.214], mean action: 1.620 [0.000, 3.000],  loss: 400.274904, mae: 442.583530, mean_q: 598.112512, mean_eps: 0.448269
 184957/300000: episode: 1547, duration: 9.141s, episode steps: 1000, steps per second: 109, episode reward: 86.348, mean reward:  0.086 [-23.243, 40.057], mean action: 1.443 [0.000, 3.000],  loss: 288.133786, mae: 439.166696, mean_q: 594.535309, mean_eps: 0.446630
 185031/300000: episode: 1548, duration: 0.510s, episode steps:  74, steps per second: 145, episode reward: -26.669, mean reward: -0.360 [-100.000, 13.576], mean action: 1.581 [0.000, 3.000],  loss: 259.015439, mae: 431.702403, mean_q: 583.333560, mean_eps: 0.445020
 185133/300000: episode: 1549, duration: 0.758s, episode steps: 102, steps per second: 135, episode reward: -150.617, mean reward: -1.477 [-100.000,  4.053], mean action: 1.716 [0.000, 3.000],  loss: 349.949496, mae: 431.800701, mean_q: 584.656613, mean_eps: 0.444755
 185242/300000: episode: 1550, duration: 0.796s, episode steps: 109, steps per second: 137, episode reward: -262.947, mean reward: -2.412 [-100.000,  9.258], mean action: 1.642 [0.000, 3.000],  loss: 221.741516, mae: 434.543299, mean_q: 587.881128, mean_eps: 0.444439
 185354/300000: episode: 1551, duration: 0.972s, episode steps: 112, steps per second: 115, episode reward: -293.101, mean reward: -2.617 [-100.000,  1.330], mean action: 1.580 [0.000, 3.000],  loss: 290.865182, mae: 435.535304, mean_q: 590.381353, mean_eps: 0.444107
 185451/300000: episode: 1552, duration: 0.788s, episode steps:  97, steps per second: 123, episode reward: -66.614, mean reward: -0.687 [-100.000,  9.409], mean action: 1.804 [0.000, 3.000],  loss: 286.022368, mae: 432.263945, mean_q: 586.159104, mean_eps: 0.443794
 185563/300000: episode: 1553, duration: 0.778s, episode steps: 112, steps per second: 144, episode reward: -6.025, mean reward: -0.054 [-100.000, 11.964], mean action: 1.598 [0.000, 3.000],  loss: 246.809236, mae: 429.745013, mean_q: 582.493770, mean_eps: 0.443481
 185647/300000: episode: 1554, duration: 0.762s, episode steps:  84, steps per second: 110, episode reward: -79.651, mean reward: -0.948 [-100.000, 12.948], mean action: 1.429 [0.000, 3.000],  loss: 441.023762, mae: 426.620954, mean_q: 577.048216, mean_eps: 0.443186
 185812/300000: episode: 1555, duration: 1.297s, episode steps: 165, steps per second: 127, episode reward: -222.612, mean reward: -1.349 [-100.000, 22.705], mean action: 1.727 [0.000, 3.000],  loss: 347.876306, mae: 425.448384, mean_q: 576.032798, mean_eps: 0.442813
 185903/300000: episode: 1556, duration: 0.643s, episode steps:  91, steps per second: 142, episode reward: -22.820, mean reward: -0.251 [-100.000, 18.144], mean action: 1.780 [0.000, 3.000],  loss: 328.109104, mae: 425.597162, mean_q: 575.737020, mean_eps: 0.442429
 186030/300000: episode: 1557, duration: 1.002s, episode steps: 127, steps per second: 127, episode reward: -166.613, mean reward: -1.312 [-100.000, 10.248], mean action: 1.567 [0.000, 3.000],  loss: 232.173962, mae: 430.818980, mean_q: 584.085819, mean_eps: 0.442102
 186128/300000: episode: 1558, duration: 1.375s, episode steps:  98, steps per second:  71, episode reward: -49.281, mean reward: -0.503 [-100.000,  7.403], mean action: 1.816 [0.000, 3.000],  loss: 243.586639, mae: 426.117411, mean_q: 576.611425, mean_eps: 0.441765
 186244/300000: episode: 1559, duration: 1.032s, episode steps: 116, steps per second: 112, episode reward: -1.680, mean reward: -0.014 [-100.000, 14.574], mean action: 1.638 [0.000, 3.000],  loss: 273.139307, mae: 423.598436, mean_q: 573.364554, mean_eps: 0.441444
 186349/300000: episode: 1560, duration: 0.781s, episode steps: 105, steps per second: 134, episode reward: -23.030, mean reward: -0.219 [-100.000, 10.586], mean action: 1.771 [0.000, 3.000],  loss: 268.667520, mae: 418.816305, mean_q: 566.284750, mean_eps: 0.441112
 186464/300000: episode: 1561, duration: 0.977s, episode steps: 115, steps per second: 118, episode reward: -113.368, mean reward: -0.986 [-100.000,  5.528], mean action: 1.748 [0.000, 3.000],  loss: 271.473308, mae: 416.841076, mean_q: 565.567238, mean_eps: 0.440782
 186592/300000: episode: 1562, duration: 1.244s, episode steps: 128, steps per second: 103, episode reward: -18.115, mean reward: -0.142 [-100.000, 15.358], mean action: 1.781 [0.000, 3.000],  loss: 276.672795, mae: 414.535319, mean_q: 561.393967, mean_eps: 0.440418
 187592/300000: episode: 1563, duration: 8.198s, episode steps: 1000, steps per second: 122, episode reward: 24.793, mean reward:  0.025 [-23.151, 46.034], mean action: 2.080 [0.000, 3.000],  loss: 331.872531, mae: 412.660905, mean_q: 558.352193, mean_eps: 0.438725
 187692/300000: episode: 1564, duration: 1.112s, episode steps: 100, steps per second:  90, episode reward: -28.565, mean reward: -0.286 [-100.000, 19.535], mean action: 1.550 [0.000, 3.000],  loss: 450.809309, mae: 409.099375, mean_q: 553.447758, mean_eps: 0.437075
 187801/300000: episode: 1565, duration: 0.977s, episode steps: 109, steps per second: 112, episode reward: -21.085, mean reward: -0.193 [-100.000, 13.944], mean action: 1.615 [0.000, 3.000],  loss: 283.413836, mae: 410.789710, mean_q: 555.572524, mean_eps: 0.436762
 187975/300000: episode: 1566, duration: 1.200s, episode steps: 174, steps per second: 145, episode reward: -146.352, mean reward: -0.841 [-100.000, 11.527], mean action: 1.782 [0.000, 3.000],  loss: 335.731090, mae: 410.511423, mean_q: 555.825647, mean_eps: 0.436338
 188079/300000: episode: 1567, duration: 0.744s, episode steps: 104, steps per second: 140, episode reward: -66.181, mean reward: -0.636 [-100.000, 11.941], mean action: 1.500 [0.000, 3.000],  loss: 290.932853, mae: 410.893651, mean_q: 555.488295, mean_eps: 0.435920
 188199/300000: episode: 1568, duration: 0.789s, episode steps: 120, steps per second: 152, episode reward: -188.134, mean reward: -1.568 [-100.000,  5.937], mean action: 1.658 [0.000, 3.000],  loss: 292.442880, mae: 411.659595, mean_q: 557.364759, mean_eps: 0.435584
 189199/300000: episode: 1569, duration: 8.744s, episode steps: 1000, steps per second: 114, episode reward: 46.603, mean reward:  0.047 [-23.046, 23.840], mean action: 1.573 [0.000, 3.000],  loss: 305.058298, mae: 400.679316, mean_q: 542.584367, mean_eps: 0.433904
 189296/300000: episode: 1570, duration: 0.681s, episode steps:  97, steps per second: 142, episode reward: -30.976, mean reward: -0.319 [-100.000, 11.547], mean action: 1.856 [0.000, 3.000],  loss: 193.200729, mae: 390.552966, mean_q: 529.543356, mean_eps: 0.432259
 189468/300000: episode: 1571, duration: 1.202s, episode steps: 172, steps per second: 143, episode reward: -460.872, mean reward: -2.679 [-100.000,  5.817], mean action: 1.535 [0.000, 3.000],  loss: 256.751790, mae: 390.175368, mean_q: 528.383769, mean_eps: 0.431855
 189576/300000: episode: 1572, duration: 0.726s, episode steps: 108, steps per second: 149, episode reward: -20.303, mean reward: -0.188 [-100.000, 20.764], mean action: 1.648 [0.000, 3.000],  loss: 318.729214, mae: 386.170761, mean_q: 522.637065, mean_eps: 0.431435
 189656/300000: episode: 1573, duration: 0.543s, episode steps:  80, steps per second: 147, episode reward:  3.876, mean reward:  0.048 [-100.000, 22.888], mean action: 1.525 [0.000, 3.000],  loss: 311.800123, mae: 388.442298, mean_q: 525.397080, mean_eps: 0.431154
 190656/300000: episode: 1574, duration: 7.386s, episode steps: 1000, steps per second: 135, episode reward: 74.039, mean reward:  0.074 [-23.679, 67.667], mean action: 1.508 [0.000, 3.000],  loss: 264.130150, mae: 382.625357, mean_q: 517.993024, mean_eps: 0.429534
 190750/300000: episode: 1575, duration: 0.641s, episode steps:  94, steps per second: 147, episode reward: 24.860, mean reward:  0.264 [-100.000, 18.364], mean action: 1.468 [0.000, 3.000],  loss: 487.004385, mae: 374.201772, mean_q: 506.383439, mean_eps: 0.427893
 190844/300000: episode: 1576, duration: 0.612s, episode steps:  94, steps per second: 154, episode reward: 36.974, mean reward:  0.393 [-100.000, 13.080], mean action: 1.681 [0.000, 3.000],  loss: 336.047897, mae: 373.189710, mean_q: 504.936483, mean_eps: 0.427611
 190986/300000: episode: 1577, duration: 1.003s, episode steps: 142, steps per second: 142, episode reward:  4.953, mean reward:  0.035 [-100.000, 19.370], mean action: 1.641 [0.000, 3.000],  loss: 264.997533, mae: 372.937917, mean_q: 504.642534, mean_eps: 0.427256
 191212/300000: episode: 1578, duration: 1.683s, episode steps: 226, steps per second: 134, episode reward:  2.056, mean reward:  0.009 [-100.000, 23.847], mean action: 1.845 [0.000, 3.000],  loss: 293.655365, mae: 375.485228, mean_q: 508.329610, mean_eps: 0.426704
 191297/300000: episode: 1579, duration: 0.548s, episode steps:  85, steps per second: 155, episode reward:  4.338, mean reward:  0.051 [-100.000, 12.800], mean action: 1.576 [0.000, 3.000],  loss: 265.301551, mae: 370.372466, mean_q: 501.257158, mean_eps: 0.426238
 191368/300000: episode: 1580, duration: 0.494s, episode steps:  71, steps per second: 144, episode reward: -67.196, mean reward: -0.946 [-100.000,  9.723], mean action: 1.606 [0.000, 3.000],  loss: 437.069127, mae: 375.689081, mean_q: 509.622525, mean_eps: 0.426004
 191463/300000: episode: 1581, duration: 0.630s, episode steps:  95, steps per second: 151, episode reward: 15.840, mean reward:  0.167 [-100.000, 34.392], mean action: 1.558 [0.000, 3.000],  loss: 387.042538, mae: 375.319401, mean_q: 507.753752, mean_eps: 0.425755
 191585/300000: episode: 1582, duration: 0.787s, episode steps: 122, steps per second: 155, episode reward: -32.288, mean reward: -0.265 [-100.000, 17.673], mean action: 1.787 [0.000, 3.000],  loss: 288.563691, mae: 375.448794, mean_q: 507.997769, mean_eps: 0.425430
 191762/300000: episode: 1583, duration: 1.183s, episode steps: 177, steps per second: 150, episode reward: -232.273, mean reward: -1.312 [-100.000,  5.475], mean action: 1.876 [0.000, 3.000],  loss: 319.580755, mae: 370.377713, mean_q: 501.302015, mean_eps: 0.424981
 191862/300000: episode: 1584, duration: 0.651s, episode steps: 100, steps per second: 153, episode reward: -163.394, mean reward: -1.634 [-100.000, 61.183], mean action: 1.650 [0.000, 3.000],  loss: 280.913003, mae: 369.929442, mean_q: 501.306292, mean_eps: 0.424565
 191956/300000: episode: 1585, duration: 0.634s, episode steps:  94, steps per second: 148, episode reward: -250.420, mean reward: -2.664 [-100.000,  0.851], mean action: 1.840 [0.000, 3.000],  loss: 219.389369, mae: 373.118198, mean_q: 505.507946, mean_eps: 0.424274
 192063/300000: episode: 1586, duration: 0.781s, episode steps: 107, steps per second: 137, episode reward: -16.162, mean reward: -0.151 [-100.000, 10.287], mean action: 1.561 [0.000, 3.000],  loss: 268.391281, mae: 374.175833, mean_q: 506.594693, mean_eps: 0.423973
 192134/300000: episode: 1587, duration: 0.510s, episode steps:  71, steps per second: 139, episode reward: -311.736, mean reward: -4.391 [-100.000,  4.760], mean action: 1.873 [0.000, 3.000],  loss: 354.468848, mae: 372.150576, mean_q: 503.925365, mean_eps: 0.423706
 193134/300000: episode: 1588, duration: 8.255s, episode steps: 1000, steps per second: 121, episode reward: 49.030, mean reward:  0.049 [-24.707, 22.857], mean action: 1.543 [0.000, 3.000],  loss: 278.223694, mae: 367.549001, mean_q: 497.304316, mean_eps: 0.422099
 193275/300000: episode: 1589, duration: 0.895s, episode steps: 141, steps per second: 158, episode reward: -219.597, mean reward: -1.557 [-100.000,  9.305], mean action: 1.674 [0.000, 3.000],  loss: 235.783240, mae: 350.343168, mean_q: 474.008846, mean_eps: 0.420388
 193476/300000: episode: 1590, duration: 1.359s, episode steps: 201, steps per second: 148, episode reward: -202.155, mean reward: -1.006 [-100.000, 13.907], mean action: 1.950 [0.000, 3.000],  loss: 260.559657, mae: 351.356200, mean_q: 475.515020, mean_eps: 0.419875
 193581/300000: episode: 1591, duration: 0.676s, episode steps: 105, steps per second: 155, episode reward: 58.059, mean reward:  0.553 [-100.000, 31.132], mean action: 1.905 [0.000, 3.000],  loss: 263.419699, mae: 352.068733, mean_q: 475.822176, mean_eps: 0.419416
 194581/300000: episode: 1592, duration: 7.590s, episode steps: 1000, steps per second: 132, episode reward: 80.045, mean reward:  0.080 [-23.509, 23.123], mean action: 1.584 [0.000, 3.000],  loss: 238.804504, mae: 341.727555, mean_q: 462.380344, mean_eps: 0.417759
 194705/300000: episode: 1593, duration: 0.973s, episode steps: 124, steps per second: 127, episode reward: 21.369, mean reward:  0.172 [-100.000, 18.403], mean action: 1.605 [0.000, 3.000],  loss: 197.493512, mae: 333.062264, mean_q: 450.213019, mean_eps: 0.416073
 194839/300000: episode: 1594, duration: 0.946s, episode steps: 134, steps per second: 142, episode reward: -37.016, mean reward: -0.276 [-100.000, 17.576], mean action: 1.694 [0.000, 3.000],  loss: 267.402411, mae: 332.290192, mean_q: 448.350644, mean_eps: 0.415686
 194935/300000: episode: 1595, duration: 0.676s, episode steps:  96, steps per second: 142, episode reward: 18.579, mean reward:  0.194 [-100.000, 18.405], mean action: 1.656 [0.000, 3.000],  loss: 256.662519, mae: 331.400738, mean_q: 448.781375, mean_eps: 0.415340
 195015/300000: episode: 1596, duration: 0.553s, episode steps:  80, steps per second: 145, episode reward: -48.476, mean reward: -0.606 [-100.000, 11.261], mean action: 1.587 [0.000, 3.000],  loss: 241.705459, mae: 328.343115, mean_q: 443.925090, mean_eps: 0.415076
 195131/300000: episode: 1597, duration: 0.836s, episode steps: 116, steps per second: 139, episode reward: -68.376, mean reward: -0.589 [-100.000, 11.354], mean action: 1.802 [0.000, 3.000],  loss: 198.672441, mae: 324.899601, mean_q: 439.278496, mean_eps: 0.414783
 195324/300000: episode: 1598, duration: 1.475s, episode steps: 193, steps per second: 131, episode reward: -225.623, mean reward: -1.169 [-100.000, 12.525], mean action: 1.658 [0.000, 3.000],  loss: 204.737788, mae: 328.038063, mean_q: 443.508234, mean_eps: 0.414319
 195639/300000: episode: 1599, duration: 2.517s, episode steps: 315, steps per second: 125, episode reward: -95.578, mean reward: -0.303 [-100.000, 27.976], mean action: 1.714 [0.000, 3.000],  loss: 206.320828, mae: 329.299233, mean_q: 444.832095, mean_eps: 0.413557
 195829/300000: episode: 1600, duration: 1.497s, episode steps: 190, steps per second: 127, episode reward: -58.748, mean reward: -0.309 [-100.000, 14.823], mean action: 1.737 [0.000, 3.000],  loss: 271.470319, mae: 333.264762, mean_q: 449.793168, mean_eps: 0.412800
 196010/300000: episode: 1601, duration: 1.229s, episode steps: 181, steps per second: 147, episode reward: -250.106, mean reward: -1.382 [-100.000, 16.757], mean action: 1.779 [0.000, 3.000],  loss: 185.203213, mae: 328.672111, mean_q: 443.846659, mean_eps: 0.412243
 196211/300000: episode: 1602, duration: 1.475s, episode steps: 201, steps per second: 136, episode reward: -186.438, mean reward: -0.928 [-100.000, 12.358], mean action: 1.637 [0.000, 3.000],  loss: 233.616438, mae: 329.904739, mean_q: 445.044021, mean_eps: 0.411670
 196343/300000: episode: 1603, duration: 0.997s, episode steps: 132, steps per second: 132, episode reward: -37.734, mean reward: -0.286 [-100.000, 15.434], mean action: 1.659 [0.000, 3.000],  loss: 259.849502, mae: 325.454908, mean_q: 440.003723, mean_eps: 0.411170
 196424/300000: episode: 1604, duration: 0.668s, episode steps:  81, steps per second: 121, episode reward: -53.348, mean reward: -0.659 [-100.000, 10.346], mean action: 1.531 [0.000, 3.000],  loss: 254.294801, mae: 322.646620, mean_q: 436.083942, mean_eps: 0.410851
 196503/300000: episode: 1605, duration: 0.612s, episode steps:  79, steps per second: 129, episode reward: -24.291, mean reward: -0.307 [-100.000, 16.049], mean action: 1.759 [0.000, 3.000],  loss: 157.804923, mae: 323.101797, mean_q: 435.876724, mean_eps: 0.410611
 196637/300000: episode: 1606, duration: 0.933s, episode steps: 134, steps per second: 144, episode reward: 16.580, mean reward:  0.124 [-100.000, 21.495], mean action: 1.731 [0.000, 3.000],  loss: 174.315126, mae: 322.481790, mean_q: 435.587597, mean_eps: 0.410292
 196738/300000: episode: 1607, duration: 0.653s, episode steps: 101, steps per second: 155, episode reward: -36.418, mean reward: -0.361 [-100.000, 17.492], mean action: 1.703 [0.000, 3.000],  loss: 202.710744, mae: 318.861053, mean_q: 430.737693, mean_eps: 0.409939
 196887/300000: episode: 1608, duration: 0.985s, episode steps: 149, steps per second: 151, episode reward: -27.986, mean reward: -0.188 [-100.000,  9.008], mean action: 1.711 [0.000, 3.000],  loss: 194.747956, mae: 322.551632, mean_q: 435.618371, mean_eps: 0.409564
 196983/300000: episode: 1609, duration: 0.638s, episode steps:  96, steps per second: 151, episode reward: -43.787, mean reward: -0.456 [-100.000,  7.978], mean action: 1.573 [0.000, 3.000],  loss: 188.751248, mae: 320.457634, mean_q: 432.620522, mean_eps: 0.409196
 197366/300000: episode: 1610, duration: 2.684s, episode steps: 383, steps per second: 143, episode reward: -123.290, mean reward: -0.322 [-100.000, 20.466], mean action: 1.802 [0.000, 3.000],  loss: 211.152391, mae: 321.149932, mean_q: 433.830505, mean_eps: 0.408478
 197515/300000: episode: 1611, duration: 0.982s, episode steps: 149, steps per second: 152, episode reward: -166.166, mean reward: -1.115 [-100.000, 12.757], mean action: 1.718 [0.000, 3.000],  loss: 229.292983, mae: 317.052727, mean_q: 427.647090, mean_eps: 0.407680
 197628/300000: episode: 1612, duration: 0.764s, episode steps: 113, steps per second: 148, episode reward: -37.060, mean reward: -0.328 [-100.000,  9.873], mean action: 1.823 [0.000, 3.000],  loss: 227.735161, mae: 313.471656, mean_q: 423.380336, mean_eps: 0.407287
 197979/300000: episode: 1613, duration: 2.499s, episode steps: 351, steps per second: 140, episode reward: -139.487, mean reward: -0.397 [-100.000, 20.564], mean action: 1.875 [0.000, 3.000],  loss: 187.860094, mae: 309.351306, mean_q: 417.314722, mean_eps: 0.406591
 198082/300000: episode: 1614, duration: 0.697s, episode steps: 103, steps per second: 148, episode reward: -136.672, mean reward: -1.327 [-100.000, 21.157], mean action: 1.728 [0.000, 3.000],  loss: 266.922881, mae: 307.731563, mean_q: 414.533634, mean_eps: 0.405910
 198232/300000: episode: 1615, duration: 1.015s, episode steps: 150, steps per second: 148, episode reward: 30.172, mean reward:  0.201 [-100.000, 17.208], mean action: 1.820 [0.000, 3.000],  loss: 183.330562, mae: 306.506987, mean_q: 414.868621, mean_eps: 0.405531
 198378/300000: episode: 1616, duration: 0.944s, episode steps: 146, steps per second: 155, episode reward: -39.696, mean reward: -0.272 [-100.000, 12.647], mean action: 1.863 [0.000, 3.000],  loss: 219.236706, mae: 307.854746, mean_q: 415.675231, mean_eps: 0.405087
 198751/300000: episode: 1617, duration: 2.573s, episode steps: 373, steps per second: 145, episode reward: -595.985, mean reward: -1.598 [-100.000,  3.347], mean action: 1.678 [0.000, 3.000],  loss: 236.331508, mae: 306.666912, mean_q: 413.629130, mean_eps: 0.404308
 198848/300000: episode: 1618, duration: 0.669s, episode steps:  97, steps per second: 145, episode reward: -74.282, mean reward: -0.766 [-100.000,  5.950], mean action: 1.938 [0.000, 3.000],  loss: 249.877905, mae: 307.205264, mean_q: 415.014221, mean_eps: 0.403603
 198938/300000: episode: 1619, duration: 0.585s, episode steps:  90, steps per second: 154, episode reward: -50.012, mean reward: -0.556 [-100.000,  7.646], mean action: 1.689 [0.000, 3.000],  loss: 226.098372, mae: 306.170026, mean_q: 413.715044, mean_eps: 0.403322
 199030/300000: episode: 1620, duration: 0.595s, episode steps:  92, steps per second: 155, episode reward: -85.609, mean reward: -0.931 [-100.000, 17.678], mean action: 1.707 [0.000, 3.000],  loss: 269.293315, mae: 300.434250, mean_q: 406.049774, mean_eps: 0.403049
 199134/300000: episode: 1621, duration: 0.735s, episode steps: 104, steps per second: 142, episode reward: -40.013, mean reward: -0.385 [-100.000, 10.757], mean action: 1.587 [0.000, 3.000],  loss: 256.309597, mae: 301.199388, mean_q: 406.662461, mean_eps: 0.402755
 199317/300000: episode: 1622, duration: 1.190s, episode steps: 183, steps per second: 154, episode reward: -38.281, mean reward: -0.209 [-100.000, 11.517], mean action: 1.710 [0.000, 3.000],  loss: 179.070586, mae: 298.605208, mean_q: 404.065070, mean_eps: 0.402325
 199438/300000: episode: 1623, duration: 0.809s, episode steps: 121, steps per second: 150, episode reward: 14.273, mean reward:  0.118 [-100.000, 16.999], mean action: 1.645 [0.000, 3.000],  loss: 171.191627, mae: 297.671027, mean_q: 402.455967, mean_eps: 0.401869
 199555/300000: episode: 1624, duration: 0.756s, episode steps: 117, steps per second: 155, episode reward: -75.781, mean reward: -0.648 [-100.000, 11.679], mean action: 1.709 [0.000, 3.000],  loss: 221.190109, mae: 300.128383, mean_q: 406.166876, mean_eps: 0.401512
 199687/300000: episode: 1625, duration: 0.830s, episode steps: 132, steps per second: 159, episode reward: -130.648, mean reward: -0.990 [-100.000, 13.684], mean action: 1.644 [0.000, 3.000],  loss: 174.306445, mae: 300.697842, mean_q: 407.403109, mean_eps: 0.401139
 199804/300000: episode: 1626, duration: 0.801s, episode steps: 117, steps per second: 146, episode reward:  9.425, mean reward:  0.081 [-100.000, 12.485], mean action: 1.701 [0.000, 3.000],  loss: 197.263686, mae: 295.979352, mean_q: 400.935643, mean_eps: 0.400765
 199918/300000: episode: 1627, duration: 0.744s, episode steps: 114, steps per second: 153, episode reward: -41.659, mean reward: -0.365 [-100.000, 11.105], mean action: 1.825 [0.000, 3.000],  loss: 205.306627, mae: 294.564426, mean_q: 398.211605, mean_eps: 0.400419
 200054/300000: episode: 1628, duration: 0.854s, episode steps: 136, steps per second: 159, episode reward: -55.876, mean reward: -0.411 [-100.000,  8.228], mean action: 1.728 [0.000, 3.000],  loss: 194.265675, mae: 296.739783, mean_q: 402.231954, mean_eps: 0.400044
 201054/300000: episode: 1629, duration: 7.771s, episode steps: 1000, steps per second: 129, episode reward: 87.712, mean reward:  0.088 [-24.999, 22.929], mean action: 1.663 [0.000, 3.000],  loss: 182.458589, mae: 291.346375, mean_q: 394.468609, mean_eps: 0.398340
 201220/300000: episode: 1630, duration: 1.308s, episode steps: 166, steps per second: 127, episode reward: -14.439, mean reward: -0.087 [-100.000, 19.327], mean action: 1.639 [0.000, 3.000],  loss: 151.794032, mae: 291.252261, mean_q: 393.915015, mean_eps: 0.396591
 201531/300000: episode: 1631, duration: 2.487s, episode steps: 311, steps per second: 125, episode reward: -295.484, mean reward: -0.950 [-100.000, 25.829], mean action: 1.669 [0.000, 3.000],  loss: 177.729329, mae: 287.725830, mean_q: 389.039076, mean_eps: 0.395875
 201635/300000: episode: 1632, duration: 0.864s, episode steps: 104, steps per second: 120, episode reward: -19.254, mean reward: -0.185 [-100.000, 15.369], mean action: 1.712 [0.000, 3.000],  loss: 167.987982, mae: 283.954904, mean_q: 384.287600, mean_eps: 0.395253
 201788/300000: episode: 1633, duration: 1.155s, episode steps: 153, steps per second: 133, episode reward: -35.795, mean reward: -0.234 [-100.000, 16.806], mean action: 1.693 [0.000, 3.000],  loss: 192.405245, mae: 283.558529, mean_q: 383.266794, mean_eps: 0.394867
 202052/300000: episode: 1634, duration: 1.797s, episode steps: 264, steps per second: 147, episode reward: 31.999, mean reward:  0.121 [-100.000, 26.866], mean action: 1.731 [0.000, 3.000],  loss: 152.090025, mae: 281.720284, mean_q: 379.842098, mean_eps: 0.394242
 202183/300000: episode: 1635, duration: 0.882s, episode steps: 131, steps per second: 149, episode reward: -98.329, mean reward: -0.751 [-100.000,  8.427], mean action: 1.740 [0.000, 3.000],  loss: 169.314385, mae: 274.615367, mean_q: 370.214033, mean_eps: 0.393649
 202610/300000: episode: 1636, duration: 3.006s, episode steps: 427, steps per second: 142, episode reward: -200.675, mean reward: -0.470 [-100.000, 19.277], mean action: 1.511 [0.000, 3.000],  loss: 178.154225, mae: 275.563935, mean_q: 371.469205, mean_eps: 0.392812
 202712/300000: episode: 1637, duration: 0.697s, episode steps: 102, steps per second: 146, episode reward: 27.215, mean reward:  0.267 [-100.000, 11.129], mean action: 1.853 [0.000, 3.000],  loss: 147.889484, mae: 273.464141, mean_q: 368.586146, mean_eps: 0.392018
 203712/300000: episode: 1638, duration: 8.619s, episode steps: 1000, steps per second: 116, episode reward: 56.346, mean reward:  0.056 [-23.459, 20.096], mean action: 1.548 [0.000, 3.000],  loss: 173.621884, mae: 270.638361, mean_q: 364.301172, mean_eps: 0.390365
 203866/300000: episode: 1639, duration: 1.031s, episode steps: 154, steps per second: 149, episode reward: -38.013, mean reward: -0.247 [-100.000, 13.316], mean action: 1.890 [0.000, 3.000],  loss: 157.000951, mae: 265.869283, mean_q: 358.202794, mean_eps: 0.388634
 203965/300000: episode: 1640, duration: 0.739s, episode steps:  99, steps per second: 134, episode reward: -48.671, mean reward: -0.492 [-100.000, 13.927], mean action: 1.687 [0.000, 3.000],  loss: 169.507248, mae: 264.010059, mean_q: 355.529666, mean_eps: 0.388255
 204101/300000: episode: 1641, duration: 0.974s, episode steps: 136, steps per second: 140, episode reward: -28.342, mean reward: -0.208 [-100.000, 17.597], mean action: 1.699 [0.000, 3.000],  loss: 152.952691, mae: 261.903574, mean_q: 352.469833, mean_eps: 0.387902
 204240/300000: episode: 1642, duration: 1.055s, episode steps: 139, steps per second: 132, episode reward: -189.343, mean reward: -1.362 [-100.000, 23.672], mean action: 1.719 [0.000, 3.000],  loss: 189.713107, mae: 268.585289, mean_q: 362.174253, mean_eps: 0.387490
 204335/300000: episode: 1643, duration: 0.762s, episode steps:  95, steps per second: 125, episode reward: -17.613, mean reward: -0.185 [-100.000, 13.387], mean action: 1.653 [0.000, 3.000],  loss: 156.995445, mae: 273.567700, mean_q: 368.060707, mean_eps: 0.387139
 204473/300000: episode: 1644, duration: 1.013s, episode steps: 138, steps per second: 136, episode reward: -39.406, mean reward: -0.286 [-100.000,  9.869], mean action: 1.754 [0.000, 3.000],  loss: 204.909958, mae: 271.836891, mean_q: 365.917947, mean_eps: 0.386790
 204651/300000: episode: 1645, duration: 1.266s, episode steps: 178, steps per second: 141, episode reward: -258.554, mean reward: -1.453 [-100.000, 39.846], mean action: 1.607 [0.000, 3.000],  loss: 158.662968, mae: 266.990142, mean_q: 359.646821, mean_eps: 0.386315
 204802/300000: episode: 1646, duration: 1.062s, episode steps: 151, steps per second: 142, episode reward: -40.962, mean reward: -0.271 [-100.000,  8.299], mean action: 1.795 [0.000, 3.000],  loss: 177.497743, mae: 264.149662, mean_q: 355.171454, mean_eps: 0.385822
 204949/300000: episode: 1647, duration: 0.985s, episode steps: 147, steps per second: 149, episode reward: -4.785, mean reward: -0.033 [-100.000, 15.119], mean action: 1.871 [0.000, 3.000],  loss: 191.820055, mae: 263.460814, mean_q: 354.238561, mean_eps: 0.385375
 205038/300000: episode: 1648, duration: 0.583s, episode steps:  89, steps per second: 153, episode reward: -440.466, mean reward: -4.949 [-100.000,  3.722], mean action: 1.775 [0.000, 3.000],  loss: 173.007447, mae: 266.044547, mean_q: 357.729916, mean_eps: 0.385021
 205121/300000: episode: 1649, duration: 0.564s, episode steps:  83, steps per second: 147, episode reward: -91.703, mean reward: -1.105 [-100.000,  7.013], mean action: 1.952 [0.000, 3.000],  loss: 196.778346, mae: 261.247211, mean_q: 351.255361, mean_eps: 0.384763
 205294/300000: episode: 1650, duration: 1.224s, episode steps: 173, steps per second: 141, episode reward: -278.021, mean reward: -1.607 [-100.000,  6.965], mean action: 1.659 [0.000, 3.000],  loss: 182.293141, mae: 262.456573, mean_q: 352.874507, mean_eps: 0.384379
 205575/300000: episode: 1651, duration: 1.908s, episode steps: 281, steps per second: 147, episode reward: -152.528, mean reward: -0.543 [-100.000, 15.970], mean action: 1.851 [0.000, 3.000],  loss: 138.236291, mae: 261.127081, mean_q: 351.473367, mean_eps: 0.383698
 205685/300000: episode: 1652, duration: 0.712s, episode steps: 110, steps per second: 154, episode reward: -69.394, mean reward: -0.631 [-100.000,  9.644], mean action: 1.864 [0.000, 3.000],  loss: 156.378408, mae: 255.808036, mean_q: 344.350261, mean_eps: 0.383111
 205782/300000: episode: 1653, duration: 0.614s, episode steps:  97, steps per second: 158, episode reward: 50.887, mean reward:  0.525 [-100.000, 18.273], mean action: 1.887 [0.000, 3.000],  loss: 173.098802, mae: 256.802583, mean_q: 345.864770, mean_eps: 0.382801
 205880/300000: episode: 1654, duration: 0.670s, episode steps:  98, steps per second: 146, episode reward:  1.528, mean reward:  0.016 [-100.000, 14.617], mean action: 1.776 [0.000, 3.000],  loss: 142.243655, mae: 254.618837, mean_q: 341.590602, mean_eps: 0.382508
 206880/300000: episode: 1655, duration: 7.629s, episode steps: 1000, steps per second: 131, episode reward: 36.890, mean reward:  0.037 [-24.550, 25.255], mean action: 1.553 [0.000, 3.000],  loss: 176.041891, mae: 258.842846, mean_q: 348.514214, mean_eps: 0.380861
 207032/300000: episode: 1656, duration: 0.997s, episode steps: 152, steps per second: 152, episode reward: -43.537, mean reward: -0.286 [-100.000, 11.578], mean action: 1.770 [0.000, 3.000],  loss: 162.550511, mae: 253.612673, mean_q: 341.304049, mean_eps: 0.379134
 207177/300000: episode: 1657, duration: 0.963s, episode steps: 145, steps per second: 151, episode reward: -29.681, mean reward: -0.205 [-100.000, 17.096], mean action: 1.862 [0.000, 3.000],  loss: 154.050138, mae: 251.541907, mean_q: 338.503855, mean_eps: 0.378688
 207260/300000: episode: 1658, duration: 0.543s, episode steps:  83, steps per second: 153, episode reward: -34.578, mean reward: -0.417 [-100.000,  9.508], mean action: 1.867 [0.000, 3.000],  loss: 152.677902, mae: 252.106321, mean_q: 338.303433, mean_eps: 0.378346
 207603/300000: episode: 1659, duration: 2.384s, episode steps: 343, steps per second: 144, episode reward: -190.530, mean reward: -0.555 [-100.000, 20.125], mean action: 1.863 [0.000, 3.000],  loss: 176.468129, mae: 247.222472, mean_q: 331.927149, mean_eps: 0.377707
 207772/300000: episode: 1660, duration: 1.152s, episode steps: 169, steps per second: 147, episode reward: -26.347, mean reward: -0.156 [-100.000, 14.209], mean action: 1.917 [0.000, 3.000],  loss: 218.130476, mae: 251.473301, mean_q: 337.049054, mean_eps: 0.376939
 207891/300000: episode: 1661, duration: 0.753s, episode steps: 119, steps per second: 158, episode reward: -72.403, mean reward: -0.608 [-100.000, 10.727], mean action: 1.798 [0.000, 3.000],  loss: 186.228204, mae: 248.718441, mean_q: 332.930455, mean_eps: 0.376507
 208891/300000: episode: 1662, duration: 8.369s, episode steps: 1000, steps per second: 119, episode reward: 46.345, mean reward:  0.046 [-23.282, 24.725], mean action: 1.507 [0.000, 3.000],  loss: 154.372422, mae: 245.364541, mean_q: 330.086110, mean_eps: 0.374829
 209010/300000: episode: 1663, duration: 0.965s, episode steps: 119, steps per second: 123, episode reward: -4.242, mean reward: -0.036 [-100.000, 15.379], mean action: 1.849 [0.000, 3.000],  loss: 173.150357, mae: 237.001510, mean_q: 319.202391, mean_eps: 0.373150
 209123/300000: episode: 1664, duration: 0.783s, episode steps: 113, steps per second: 144, episode reward: -3.833, mean reward: -0.034 [-100.000, 17.164], mean action: 1.876 [0.000, 3.000],  loss: 167.879555, mae: 241.034871, mean_q: 323.715372, mean_eps: 0.372802
 209318/300000: episode: 1665, duration: 1.438s, episode steps: 195, steps per second: 136, episode reward: -600.966, mean reward: -3.082 [-100.000,  3.270], mean action: 1.636 [0.000, 3.000],  loss: 164.478139, mae: 241.213671, mean_q: 324.625111, mean_eps: 0.372340
 209404/300000: episode: 1666, duration: 0.591s, episode steps:  86, steps per second: 146, episode reward: -89.781, mean reward: -1.044 [-100.000,  7.769], mean action: 1.767 [0.000, 3.000],  loss: 142.756635, mae: 239.796784, mean_q: 323.531942, mean_eps: 0.371918
 209589/300000: episode: 1667, duration: 1.226s, episode steps: 185, steps per second: 151, episode reward: -68.746, mean reward: -0.372 [-100.000,  9.560], mean action: 1.681 [0.000, 3.000],  loss: 178.358817, mae: 238.700151, mean_q: 321.545543, mean_eps: 0.371512
 209901/300000: episode: 1668, duration: 2.337s, episode steps: 312, steps per second: 134, episode reward: -273.415, mean reward: -0.876 [-100.000, 12.553], mean action: 1.750 [0.000, 3.000],  loss: 157.524507, mae: 241.692754, mean_q: 326.021863, mean_eps: 0.370766
 209991/300000: episode: 1669, duration: 0.657s, episode steps:  90, steps per second: 137, episode reward: -12.627, mean reward: -0.140 [-100.000, 12.589], mean action: 1.611 [0.000, 3.000],  loss: 181.361245, mae: 246.832141, mean_q: 332.296712, mean_eps: 0.370163
 210118/300000: episode: 1670, duration: 0.937s, episode steps: 127, steps per second: 136, episode reward: -98.369, mean reward: -0.775 [-100.000, 17.299], mean action: 1.748 [0.000, 3.000],  loss: 131.647634, mae: 243.825182, mean_q: 328.781730, mean_eps: 0.369838
 210360/300000: episode: 1671, duration: 1.757s, episode steps: 242, steps per second: 138, episode reward: -81.091, mean reward: -0.335 [-100.000, 33.008], mean action: 1.764 [0.000, 3.000],  loss: 185.595048, mae: 246.318751, mean_q: 331.798236, mean_eps: 0.369285
 210447/300000: episode: 1672, duration: 0.577s, episode steps:  87, steps per second: 151, episode reward: -66.123, mean reward: -0.760 [-100.000, 12.899], mean action: 1.793 [0.000, 3.000],  loss: 194.559198, mae: 244.197610, mean_q: 329.150066, mean_eps: 0.368791
 210537/300000: episode: 1673, duration: 0.596s, episode steps:  90, steps per second: 151, episode reward: -80.640, mean reward: -0.896 [-100.000, 20.261], mean action: 1.856 [0.000, 3.000],  loss: 141.403930, mae: 243.069142, mean_q: 327.425395, mean_eps: 0.368526
 210862/300000: episode: 1674, duration: 2.524s, episode steps: 325, steps per second: 129, episode reward: -87.303, mean reward: -0.269 [-100.000, 38.012], mean action: 1.708 [0.000, 3.000],  loss: 154.288918, mae: 243.567767, mean_q: 328.565107, mean_eps: 0.367903
 211022/300000: episode: 1675, duration: 1.028s, episode steps: 160, steps per second: 156, episode reward: -35.941, mean reward: -0.225 [-100.000, 11.609], mean action: 1.806 [0.000, 3.000],  loss: 189.481410, mae: 238.786868, mean_q: 322.286963, mean_eps: 0.367175
 211233/300000: episode: 1676, duration: 1.399s, episode steps: 211, steps per second: 151, episode reward: -374.762, mean reward: -1.776 [-100.000, 15.718], mean action: 1.706 [0.000, 3.000],  loss: 144.932585, mae: 234.519994, mean_q: 316.657792, mean_eps: 0.366619
 211316/300000: episode: 1677, duration: 0.539s, episode steps:  83, steps per second: 154, episode reward: -53.809, mean reward: -0.648 [-100.000,  9.738], mean action: 1.976 [0.000, 3.000],  loss: 136.211114, mae: 228.851063, mean_q: 308.375900, mean_eps: 0.366178
 211400/300000: episode: 1678, duration: 0.545s, episode steps:  84, steps per second: 154, episode reward: -38.852, mean reward: -0.463 [-100.000, 26.966], mean action: 2.036 [0.000, 3.000],  loss: 146.807757, mae: 231.369281, mean_q: 312.406781, mean_eps: 0.365927
 211577/300000: episode: 1679, duration: 1.197s, episode steps: 177, steps per second: 148, episode reward: -66.677, mean reward: -0.377 [-100.000, 10.833], mean action: 1.864 [0.000, 3.000],  loss: 171.563673, mae: 227.756629, mean_q: 306.498214, mean_eps: 0.365536
 211690/300000: episode: 1680, duration: 0.728s, episode steps: 113, steps per second: 155, episode reward: -76.240, mean reward: -0.675 [-100.000,  8.907], mean action: 1.752 [0.000, 3.000],  loss: 195.614706, mae: 226.701427, mean_q: 304.951952, mean_eps: 0.365101
 212690/300000: episode: 1681, duration: 7.707s, episode steps: 1000, steps per second: 130, episode reward: 85.405, mean reward:  0.085 [-24.537, 24.468], mean action: 1.801 [0.000, 3.000],  loss: 150.357892, mae: 226.355036, mean_q: 305.344093, mean_eps: 0.363432
 212994/300000: episode: 1682, duration: 2.658s, episode steps: 304, steps per second: 114, episode reward: -251.771, mean reward: -0.828 [-100.000, 11.389], mean action: 1.638 [0.000, 3.000],  loss: 168.184463, mae: 224.286069, mean_q: 302.110519, mean_eps: 0.361476
 213407/300000: episode: 1683, duration: 3.799s, episode steps: 413, steps per second: 109, episode reward: -169.338, mean reward: -0.410 [-100.000, 13.327], mean action: 1.574 [0.000, 3.000],  loss: 140.443716, mae: 221.959060, mean_q: 299.265664, mean_eps: 0.360400
 213597/300000: episode: 1684, duration: 1.939s, episode steps: 190, steps per second:  98, episode reward: -25.551, mean reward: -0.134 [-100.000, 16.654], mean action: 1.774 [0.000, 3.000],  loss: 155.595260, mae: 220.214494, mean_q: 296.969941, mean_eps: 0.359495
 213752/300000: episode: 1685, duration: 1.522s, episode steps: 155, steps per second: 102, episode reward: -300.000, mean reward: -1.935 [-100.000,  6.046], mean action: 1.800 [0.000, 3.000],  loss: 135.552584, mae: 217.963391, mean_q: 293.887538, mean_eps: 0.358978
 214081/300000: episode: 1686, duration: 2.549s, episode steps: 329, steps per second: 129, episode reward: -175.592, mean reward: -0.534 [-100.000, 17.632], mean action: 1.693 [0.000, 3.000],  loss: 175.422339, mae: 220.375513, mean_q: 296.855861, mean_eps: 0.358252
 214195/300000: episode: 1687, duration: 0.808s, episode steps: 114, steps per second: 141, episode reward: -219.358, mean reward: -1.924 [-100.000,  1.393], mean action: 1.430 [0.000, 3.000],  loss: 137.086667, mae: 220.647884, mean_q: 296.584713, mean_eps: 0.357588
 214286/300000: episode: 1688, duration: 0.874s, episode steps:  91, steps per second: 104, episode reward: -50.341, mean reward: -0.553 [-100.000, 10.714], mean action: 1.593 [0.000, 3.000],  loss: 185.058591, mae: 220.200211, mean_q: 295.771778, mean_eps: 0.357280
 214440/300000: episode: 1689, duration: 1.406s, episode steps: 154, steps per second: 110, episode reward: -54.596, mean reward: -0.355 [-100.000, 14.752], mean action: 1.539 [0.000, 3.000],  loss: 196.069933, mae: 215.632059, mean_q: 289.377631, mean_eps: 0.356913
 214877/300000: episode: 1690, duration: 3.248s, episode steps: 437, steps per second: 135, episode reward: -918.387, mean reward: -2.102 [-100.000,  3.023], mean action: 1.778 [0.000, 3.000],  loss: 143.177983, mae: 220.520986, mean_q: 297.268390, mean_eps: 0.356026
 215096/300000: episode: 1691, duration: 1.547s, episode steps: 219, steps per second: 142, episode reward: -303.080, mean reward: -1.384 [-100.000,  6.461], mean action: 1.397 [0.000, 3.000],  loss: 168.384277, mae: 224.418015, mean_q: 302.348977, mean_eps: 0.355042
 215214/300000: episode: 1692, duration: 0.803s, episode steps: 118, steps per second: 147, episode reward: -111.087, mean reward: -0.941 [-100.000, 10.254], mean action: 1.627 [0.000, 3.000],  loss: 163.362305, mae: 224.162908, mean_q: 300.787759, mean_eps: 0.354537
 215342/300000: episode: 1693, duration: 0.837s, episode steps: 128, steps per second: 153, episode reward: 14.650, mean reward:  0.114 [-100.000,  9.885], mean action: 1.406 [0.000, 3.000],  loss: 215.474766, mae: 227.614908, mean_q: 305.939242, mean_eps: 0.354167
 215460/300000: episode: 1694, duration: 0.761s, episode steps: 118, steps per second: 155, episode reward: -193.308, mean reward: -1.638 [-100.000, 55.017], mean action: 1.864 [0.000, 3.000],  loss: 194.850587, mae: 226.181697, mean_q: 304.322416, mean_eps: 0.353798
 215633/300000: episode: 1695, duration: 1.428s, episode steps: 173, steps per second: 121, episode reward: -223.212, mean reward: -1.290 [-100.000,  2.206], mean action: 1.370 [0.000, 3.000],  loss: 169.792352, mae: 228.203213, mean_q: 307.133441, mean_eps: 0.353362
 216225/300000: episode: 1696, duration: 4.450s, episode steps: 592, steps per second: 133, episode reward: -1255.170, mean reward: -2.120 [-100.000, 93.768], mean action: 1.639 [0.000, 3.000],  loss: 227.089916, mae: 235.527202, mean_q: 316.728355, mean_eps: 0.352214
 216353/300000: episode: 1697, duration: 1.123s, episode steps: 128, steps per second: 114, episode reward: -231.781, mean reward: -1.811 [-100.000,  2.279], mean action: 1.570 [0.000, 3.000],  loss: 328.667809, mae: 241.480855, mean_q: 325.704563, mean_eps: 0.351135
 216525/300000: episode: 1698, duration: 1.198s, episode steps: 172, steps per second: 144, episode reward:  2.526, mean reward:  0.015 [-100.000, 19.210], mean action: 1.802 [0.000, 3.000],  loss: 401.059704, mae: 241.086351, mean_q: 325.006587, mean_eps: 0.350684
 216805/300000: episode: 1699, duration: 1.905s, episode steps: 280, steps per second: 147, episode reward: -429.700, mean reward: -1.535 [-100.000, 14.686], mean action: 1.804 [0.000, 3.000],  loss: 201.126885, mae: 244.122521, mean_q: 329.707857, mean_eps: 0.350006
 216988/300000: episode: 1700, duration: 1.175s, episode steps: 183, steps per second: 156, episode reward: -7.210, mean reward: -0.039 [-100.000, 17.147], mean action: 1.607 [0.000, 3.000],  loss: 209.996070, mae: 245.439756, mean_q: 331.155510, mean_eps: 0.349312
 217069/300000: episode: 1701, duration: 0.569s, episode steps:  81, steps per second: 142, episode reward: -37.254, mean reward: -0.460 [-100.000,  9.243], mean action: 1.951 [0.000, 3.000],  loss: 206.684632, mae: 247.173938, mean_q: 333.461095, mean_eps: 0.348916
 217285/300000: episode: 1702, duration: 1.393s, episode steps: 216, steps per second: 155, episode reward:  5.514, mean reward:  0.026 [-100.000, 19.493], mean action: 1.708 [0.000, 3.000],  loss: 176.140824, mae: 243.650860, mean_q: 328.758006, mean_eps: 0.348470
 217482/300000: episode: 1703, duration: 1.318s, episode steps: 197, steps per second: 150, episode reward: -419.754, mean reward: -2.131 [-100.000,  2.201], mean action: 1.670 [0.000, 3.000],  loss: 184.269441, mae: 243.363599, mean_q: 328.609438, mean_eps: 0.347851
 217646/300000: episode: 1704, duration: 1.047s, episode steps: 164, steps per second: 157, episode reward: -319.024, mean reward: -1.945 [-100.000, 35.312], mean action: 1.354 [0.000, 3.000],  loss: 159.224196, mae: 243.213345, mean_q: 328.536999, mean_eps: 0.347309
 217753/300000: episode: 1705, duration: 0.742s, episode steps: 107, steps per second: 144, episode reward: -85.436, mean reward: -0.798 [-100.000, 12.545], mean action: 1.981 [0.000, 3.000],  loss: 160.329594, mae: 241.482904, mean_q: 326.418178, mean_eps: 0.346903
 218036/300000: episode: 1706, duration: 1.898s, episode steps: 283, steps per second: 149, episode reward: -352.176, mean reward: -1.244 [-100.000, 14.296], mean action: 1.696 [0.000, 3.000],  loss: 195.840057, mae: 246.680293, mean_q: 332.545102, mean_eps: 0.346318
 218190/300000: episode: 1707, duration: 1.053s, episode steps: 154, steps per second: 146, episode reward: -205.130, mean reward: -1.332 [-100.000,  2.993], mean action: 1.818 [0.000, 3.000],  loss: 190.337189, mae: 252.819941, mean_q: 340.317705, mean_eps: 0.345662
 218285/300000: episode: 1708, duration: 0.672s, episode steps:  95, steps per second: 141, episode reward: -45.481, mean reward: -0.479 [-100.000, 12.699], mean action: 1.747 [0.000, 3.000],  loss: 161.599393, mae: 249.005871, mean_q: 335.699902, mean_eps: 0.345289
 218414/300000: episode: 1709, duration: 0.949s, episode steps: 129, steps per second: 136, episode reward: -202.423, mean reward: -1.569 [-100.000,  3.009], mean action: 1.729 [0.000, 3.000],  loss: 161.197272, mae: 248.201849, mean_q: 334.204891, mean_eps: 0.344953
 218515/300000: episode: 1710, duration: 0.682s, episode steps: 101, steps per second: 148, episode reward: -145.497, mean reward: -1.441 [-100.000,  2.328], mean action: 1.713 [0.000, 3.000],  loss: 209.160062, mae: 247.575008, mean_q: 333.602857, mean_eps: 0.344608
 218602/300000: episode: 1711, duration: 0.631s, episode steps:  87, steps per second: 138, episode reward: 47.449, mean reward:  0.545 [-100.000, 17.902], mean action: 1.563 [0.000, 3.000],  loss: 192.594367, mae: 243.933861, mean_q: 329.783349, mean_eps: 0.344326
 218938/300000: episode: 1712, duration: 2.724s, episode steps: 336, steps per second: 123, episode reward: -1189.968, mean reward: -3.542 [-100.000,  2.036], mean action: 1.812 [0.000, 3.000],  loss: 169.015217, mae: 251.145685, mean_q: 339.531435, mean_eps: 0.343691
 219519/300000: episode: 1713, duration: 4.402s, episode steps: 581, steps per second: 132, episode reward: -657.306, mean reward: -1.131 [-100.000, 22.749], mean action: 1.773 [0.000, 3.000],  loss: 287.907892, mae: 264.001372, mean_q: 356.778004, mean_eps: 0.342316
 219902/300000: episode: 1714, duration: 2.912s, episode steps: 383, steps per second: 132, episode reward: -687.881, mean reward: -1.796 [-100.000,  3.341], mean action: 1.392 [0.000, 3.000],  loss: 297.123266, mae: 283.647312, mean_q: 383.826616, mean_eps: 0.340870
 220096/300000: episode: 1715, duration: 1.410s, episode steps: 194, steps per second: 138, episode reward: -214.326, mean reward: -1.105 [-100.000,  3.926], mean action: 1.701 [0.000, 3.000],  loss: 340.127984, mae: 293.117999, mean_q: 395.206409, mean_eps: 0.340004
 220243/300000: episode: 1716, duration: 1.117s, episode steps: 147, steps per second: 132, episode reward: -266.201, mean reward: -1.811 [-100.000,  1.799], mean action: 1.830 [0.000, 3.000],  loss: 306.524960, mae: 293.443915, mean_q: 396.542950, mean_eps: 0.339493
 220560/300000: episode: 1717, duration: 2.335s, episode steps: 317, steps per second: 136, episode reward: -258.056, mean reward: -0.814 [-100.000,  4.050], mean action: 1.785 [0.000, 3.000],  loss: 232.389308, mae: 298.311386, mean_q: 403.043963, mean_eps: 0.338797
 220670/300000: episode: 1718, duration: 0.955s, episode steps: 110, steps per second: 115, episode reward: -111.733, mean reward: -1.016 [-100.000,  9.725], mean action: 1.836 [0.000, 3.000],  loss: 358.794659, mae: 300.061114, mean_q: 404.143412, mean_eps: 0.338157
 220834/300000: episode: 1719, duration: 1.078s, episode steps: 164, steps per second: 152, episode reward: -45.258, mean reward: -0.276 [-100.000,  9.644], mean action: 1.750 [0.000, 3.000],  loss: 280.870259, mae: 301.367642, mean_q: 406.951303, mean_eps: 0.337745
 220933/300000: episode: 1720, duration: 0.665s, episode steps:  99, steps per second: 149, episode reward: -14.601, mean reward: -0.147 [-100.000, 15.231], mean action: 1.677 [0.000, 3.000],  loss: 308.055611, mae: 300.202792, mean_q: 405.765943, mean_eps: 0.337351
 221171/300000: episode: 1721, duration: 1.533s, episode steps: 238, steps per second: 155, episode reward: -339.867, mean reward: -1.428 [-100.000,  9.524], mean action: 1.550 [0.000, 3.000],  loss: 246.851076, mae: 295.286839, mean_q: 399.251927, mean_eps: 0.336846
 221313/300000: episode: 1722, duration: 0.953s, episode steps: 142, steps per second: 149, episode reward: -132.246, mean reward: -0.931 [-100.000,  5.350], mean action: 1.655 [0.000, 3.000],  loss: 250.199601, mae: 294.445890, mean_q: 397.446483, mean_eps: 0.336276
 221562/300000: episode: 1723, duration: 1.821s, episode steps: 249, steps per second: 137, episode reward: -437.707, mean reward: -1.758 [-100.000,  6.670], mean action: 1.703 [0.000, 3.000],  loss: 216.709995, mae: 299.385605, mean_q: 403.962728, mean_eps: 0.335689
 221644/300000: episode: 1724, duration: 0.573s, episode steps:  82, steps per second: 143, episode reward: 16.219, mean reward:  0.198 [-100.000, 19.637], mean action: 1.585 [0.000, 3.000],  loss: 226.809539, mae: 302.391327, mean_q: 408.510324, mean_eps: 0.335192
 222355/300000: episode: 1725, duration: 5.663s, episode steps: 711, steps per second: 126, episode reward: -208.136, mean reward: -0.293 [-100.000, 16.890], mean action: 1.747 [0.000, 3.000],  loss: 271.617724, mae: 303.511884, mean_q: 409.154203, mean_eps: 0.334003
 222811/300000: episode: 1726, duration: 3.399s, episode steps: 456, steps per second: 134, episode reward: -181.274, mean reward: -0.398 [-100.000, 11.687], mean action: 1.711 [0.000, 3.000],  loss: 255.578084, mae: 296.653092, mean_q: 399.978268, mean_eps: 0.332253
 222905/300000: episode: 1727, duration: 0.604s, episode steps:  94, steps per second: 156, episode reward: 71.795, mean reward:  0.764 [-100.000, 17.583], mean action: 1.500 [0.000, 3.000],  loss: 205.480906, mae: 295.519950, mean_q: 398.749251, mean_eps: 0.331427
 223494/300000: episode: 1728, duration: 4.217s, episode steps: 589, steps per second: 140, episode reward: -237.483, mean reward: -0.403 [-100.000, 33.517], mean action: 1.649 [0.000, 3.000],  loss: 243.171752, mae: 296.303181, mean_q: 400.152825, mean_eps: 0.330403
 223602/300000: episode: 1729, duration: 0.756s, episode steps: 108, steps per second: 143, episode reward: 58.626, mean reward:  0.543 [-100.000, 27.415], mean action: 1.556 [0.000, 3.000],  loss: 175.854117, mae: 292.318176, mean_q: 395.215174, mean_eps: 0.329358
 223863/300000: episode: 1730, duration: 1.725s, episode steps: 261, steps per second: 151, episode reward: -725.297, mean reward: -2.779 [-100.000,  2.297], mean action: 1.839 [0.000, 3.000],  loss: 275.780487, mae: 295.574007, mean_q: 398.737879, mean_eps: 0.328804
 224095/300000: episode: 1731, duration: 1.622s, episode steps: 232, steps per second: 143, episode reward: -259.624, mean reward: -1.119 [-100.000, 13.216], mean action: 1.759 [0.000, 3.000],  loss: 273.975133, mae: 300.754877, mean_q: 406.581369, mean_eps: 0.328064
 224283/300000: episode: 1732, duration: 1.260s, episode steps: 188, steps per second: 149, episode reward: -395.891, mean reward: -2.106 [-100.000,  3.368], mean action: 1.574 [0.000, 3.000],  loss: 249.213653, mae: 305.042665, mean_q: 413.244265, mean_eps: 0.327434
 224372/300000: episode: 1733, duration: 0.589s, episode steps:  89, steps per second: 151, episode reward: -19.035, mean reward: -0.214 [-100.000, 20.655], mean action: 1.730 [0.000, 3.000],  loss: 250.491902, mae: 305.608641, mean_q: 413.300595, mean_eps: 0.327019
 224845/300000: episode: 1734, duration: 3.168s, episode steps: 473, steps per second: 149, episode reward: -707.465, mean reward: -1.496 [-100.000,  4.257], mean action: 1.784 [0.000, 3.000],  loss: 262.433438, mae: 306.972991, mean_q: 415.755844, mean_eps: 0.326176
 225048/300000: episode: 1735, duration: 1.453s, episode steps: 203, steps per second: 140, episode reward: -369.108, mean reward: -1.818 [-100.000,  4.229], mean action: 1.700 [0.000, 3.000],  loss: 255.200786, mae: 307.601579, mean_q: 416.406412, mean_eps: 0.325162
 225198/300000: episode: 1736, duration: 1.063s, episode steps: 150, steps per second: 141, episode reward: -251.107, mean reward: -1.674 [-100.000, 11.073], mean action: 1.747 [0.000, 3.000],  loss: 242.850476, mae: 306.141179, mean_q: 414.928933, mean_eps: 0.324632
 225371/300000: episode: 1737, duration: 1.123s, episode steps: 173, steps per second: 154, episode reward: -161.638, mean reward: -0.934 [-100.000,  8.070], mean action: 1.746 [0.000, 3.000],  loss: 231.170051, mae: 303.791389, mean_q: 411.518333, mean_eps: 0.324148
 225455/300000: episode: 1738, duration: 0.537s, episode steps:  84, steps per second: 156, episode reward: -4.448, mean reward: -0.053 [-100.000, 17.297], mean action: 1.690 [0.000, 3.000],  loss: 208.652045, mae: 309.467012, mean_q: 419.350175, mean_eps: 0.323763
 225663/300000: episode: 1739, duration: 1.391s, episode steps: 208, steps per second: 150, episode reward: -289.512, mean reward: -1.392 [-100.000,  5.840], mean action: 1.683 [0.000, 3.000],  loss: 267.025665, mae: 305.773150, mean_q: 414.290729, mean_eps: 0.323325
 225802/300000: episode: 1740, duration: 0.885s, episode steps: 139, steps per second: 157, episode reward: -227.791, mean reward: -1.639 [-100.000,  7.680], mean action: 1.705 [0.000, 3.000],  loss: 226.184065, mae: 303.329140, mean_q: 411.790304, mean_eps: 0.322804
 225883/300000: episode: 1741, duration: 0.603s, episode steps:  81, steps per second: 134, episode reward: -12.313, mean reward: -0.152 [-100.000, 19.038], mean action: 1.630 [0.000, 3.000],  loss: 331.003513, mae: 309.158387, mean_q: 418.402133, mean_eps: 0.322474
 226116/300000: episode: 1742, duration: 1.700s, episode steps: 233, steps per second: 137, episode reward: -392.215, mean reward: -1.683 [-100.000, 142.165], mean action: 1.755 [0.000, 3.000],  loss: 214.617887, mae: 308.809914, mean_q: 418.330399, mean_eps: 0.322003
 226199/300000: episode: 1743, duration: 0.598s, episode steps:  83, steps per second: 139, episode reward: -227.529, mean reward: -2.741 [-100.000, 57.356], mean action: 2.012 [0.000, 3.000],  loss: 227.296695, mae: 307.460471, mean_q: 416.877718, mean_eps: 0.321529
 226459/300000: episode: 1744, duration: 1.766s, episode steps: 260, steps per second: 147, episode reward: -256.663, mean reward: -0.987 [-100.000,  4.706], mean action: 1.319 [0.000, 3.000],  loss: 244.855387, mae: 304.659843, mean_q: 412.975733, mean_eps: 0.321014
 226995/300000: episode: 1745, duration: 3.920s, episode steps: 536, steps per second: 137, episode reward: -332.585, mean reward: -0.620 [-100.000,  5.649], mean action: 1.741 [0.000, 3.000],  loss: 297.126514, mae: 303.252759, mean_q: 410.315041, mean_eps: 0.319821
 227181/300000: episode: 1746, duration: 1.301s, episode steps: 186, steps per second: 143, episode reward:  2.449, mean reward:  0.013 [-100.000, 13.945], mean action: 1.688 [0.000, 3.000],  loss: 201.742997, mae: 299.629574, mean_q: 405.364725, mean_eps: 0.318738
 227270/300000: episode: 1747, duration: 0.580s, episode steps:  89, steps per second: 153, episode reward: 38.175, mean reward:  0.429 [-100.000, 17.087], mean action: 1.640 [0.000, 3.000],  loss: 252.320631, mae: 300.224801, mean_q: 405.792531, mean_eps: 0.318325
 227913/300000: episode: 1748, duration: 5.313s, episode steps: 643, steps per second: 121, episode reward: -307.523, mean reward: -0.478 [-100.000, 17.195], mean action: 1.742 [0.000, 3.000],  loss: 234.632853, mae: 302.294547, mean_q: 408.703192, mean_eps: 0.317227
 228110/300000: episode: 1749, duration: 1.463s, episode steps: 197, steps per second: 135, episode reward: -754.280, mean reward: -3.829 [-100.000,  2.239], mean action: 1.827 [0.000, 3.000],  loss: 195.334381, mae: 301.030008, mean_q: 406.465972, mean_eps: 0.315967
 228319/300000: episode: 1750, duration: 1.748s, episode steps: 209, steps per second: 120, episode reward: -487.362, mean reward: -2.332 [-100.000,  2.687], mean action: 1.632 [0.000, 3.000],  loss: 220.156678, mae: 298.778080, mean_q: 402.841761, mean_eps: 0.315358
 228413/300000: episode: 1751, duration: 0.655s, episode steps:  94, steps per second: 144, episode reward: -280.985, mean reward: -2.989 [-100.000,  8.337], mean action: 1.691 [0.000, 3.000],  loss: 179.411137, mae: 298.013458, mean_q: 401.721102, mean_eps: 0.314903
 228620/300000: episode: 1752, duration: 1.377s, episode steps: 207, steps per second: 150, episode reward: -257.294, mean reward: -1.243 [-100.000, 10.020], mean action: 1.667 [0.000, 3.000],  loss: 257.384214, mae: 296.721371, mean_q: 399.356824, mean_eps: 0.314452
 228715/300000: episode: 1753, duration: 0.601s, episode steps:  95, steps per second: 158, episode reward: -248.591, mean reward: -2.617 [-100.000,  8.179], mean action: 1.747 [0.000, 3.000],  loss: 303.058440, mae: 287.275578, mean_q: 386.914239, mean_eps: 0.313999
 229041/300000: episode: 1754, duration: 2.356s, episode steps: 326, steps per second: 138, episode reward: -302.801, mean reward: -0.929 [-100.000,  5.055], mean action: 1.834 [0.000, 3.000],  loss: 186.863314, mae: 295.490154, mean_q: 399.097996, mean_eps: 0.313367
 229425/300000: episode: 1755, duration: 2.935s, episode steps: 384, steps per second: 131, episode reward: -896.103, mean reward: -2.334 [-100.000,  5.092], mean action: 1.646 [0.000, 3.000],  loss: 212.344464, mae: 297.327312, mean_q: 401.481244, mean_eps: 0.312302
 229668/300000: episode: 1756, duration: 1.609s, episode steps: 243, steps per second: 151, episode reward: -456.591, mean reward: -1.879 [-100.000, 54.583], mean action: 1.547 [0.000, 3.000],  loss: 310.417432, mae: 296.429653, mean_q: 399.886033, mean_eps: 0.311362
 229779/300000: episode: 1757, duration: 0.748s, episode steps: 111, steps per second: 148, episode reward: -8.845, mean reward: -0.080 [-100.000, 10.334], mean action: 1.766 [0.000, 3.000],  loss: 210.015883, mae: 288.179087, mean_q: 388.046485, mean_eps: 0.310831
 230114/300000: episode: 1758, duration: 2.264s, episode steps: 335, steps per second: 148, episode reward: -992.005, mean reward: -2.961 [-100.000,  2.922], mean action: 1.743 [0.000, 3.000],  loss: 237.333573, mae: 289.674531, mean_q: 390.081356, mean_eps: 0.310162
 230320/300000: episode: 1759, duration: 1.677s, episode steps: 206, steps per second: 123, episode reward: -584.090, mean reward: -2.835 [-100.000,  3.612], mean action: 1.699 [0.000, 3.000],  loss: 253.102337, mae: 296.115401, mean_q: 398.659410, mean_eps: 0.309351
 230674/300000: episode: 1760, duration: 2.788s, episode steps: 354, steps per second: 127, episode reward: -740.913, mean reward: -2.093 [-100.000,  2.900], mean action: 1.630 [0.000, 3.000],  loss: 234.487451, mae: 296.000678, mean_q: 398.939488, mean_eps: 0.308511
 230908/300000: episode: 1761, duration: 1.751s, episode steps: 234, steps per second: 134, episode reward: -390.134, mean reward: -1.667 [-100.000,  2.709], mean action: 1.675 [0.000, 3.000],  loss: 250.857104, mae: 302.467762, mean_q: 407.110283, mean_eps: 0.307628
 231157/300000: episode: 1762, duration: 1.746s, episode steps: 249, steps per second: 143, episode reward: -404.760, mean reward: -1.626 [-100.000, 11.430], mean action: 1.486 [0.000, 3.000],  loss: 226.679033, mae: 305.765539, mean_q: 411.847504, mean_eps: 0.306904
 231270/300000: episode: 1763, duration: 0.859s, episode steps: 113, steps per second: 131, episode reward: 21.300, mean reward:  0.188 [-100.000, 21.278], mean action: 1.478 [0.000, 3.000],  loss: 290.025800, mae: 308.068553, mean_q: 415.213371, mean_eps: 0.306361
 231487/300000: episode: 1764, duration: 1.603s, episode steps: 217, steps per second: 135, episode reward: -681.158, mean reward: -3.139 [-100.000,  3.097], mean action: 1.650 [0.000, 3.000],  loss: 262.629742, mae: 306.221107, mean_q: 412.608793, mean_eps: 0.305866
 231758/300000: episode: 1765, duration: 2.001s, episode steps: 271, steps per second: 135, episode reward: -312.761, mean reward: -1.154 [-100.000,  4.638], mean action: 1.524 [0.000, 3.000],  loss: 220.158558, mae: 307.855568, mean_q: 414.742816, mean_eps: 0.305134
 231917/300000: episode: 1766, duration: 1.043s, episode steps: 159, steps per second: 152, episode reward: -23.329, mean reward: -0.147 [-100.000, 13.617], mean action: 1.799 [0.000, 3.000],  loss: 219.824918, mae: 308.425054, mean_q: 415.460872, mean_eps: 0.304489
 232044/300000: episode: 1767, duration: 0.818s, episode steps: 127, steps per second: 155, episode reward:  7.302, mean reward:  0.057 [-100.000, 14.801], mean action: 1.811 [0.000, 3.000],  loss: 246.802903, mae: 307.812150, mean_q: 415.466430, mean_eps: 0.304060
 232354/300000: episode: 1768, duration: 2.030s, episode steps: 310, steps per second: 153, episode reward: -378.045, mean reward: -1.219 [-100.000,  8.724], mean action: 1.771 [0.000, 3.000],  loss: 223.014124, mae: 310.880986, mean_q: 419.496184, mean_eps: 0.303405
 232546/300000: episode: 1769, duration: 1.296s, episode steps: 192, steps per second: 148, episode reward: -49.980, mean reward: -0.260 [-100.000, 22.721], mean action: 1.714 [0.000, 3.000],  loss: 375.672693, mae: 315.085593, mean_q: 424.805076, mean_eps: 0.302652
 232879/300000: episode: 1770, duration: 2.324s, episode steps: 333, steps per second: 143, episode reward: -808.874, mean reward: -2.429 [-100.000,  3.716], mean action: 1.748 [0.000, 3.000],  loss: 283.974442, mae: 312.842014, mean_q: 422.745677, mean_eps: 0.301864
 232974/300000: episode: 1771, duration: 0.617s, episode steps:  95, steps per second: 154, episode reward: -10.450, mean reward: -0.110 [-100.000, 20.805], mean action: 1.642 [0.000, 3.000],  loss: 227.364917, mae: 308.962540, mean_q: 418.428333, mean_eps: 0.301222
 233265/300000: episode: 1772, duration: 1.978s, episode steps: 291, steps per second: 147, episode reward: -302.543, mean reward: -1.040 [-100.000, 18.970], mean action: 1.677 [0.000, 3.000],  loss: 234.980987, mae: 306.732170, mean_q: 414.245575, mean_eps: 0.300643
 233789/300000: episode: 1773, duration: 3.695s, episode steps: 524, steps per second: 142, episode reward: -407.646, mean reward: -0.778 [-100.000, 13.539], mean action: 1.796 [0.000, 3.000],  loss: 245.286562, mae: 310.362870, mean_q: 419.526845, mean_eps: 0.299421
 234050/300000: episode: 1774, duration: 1.738s, episode steps: 261, steps per second: 150, episode reward: -212.398, mean reward: -0.814 [-100.000, 18.222], mean action: 1.709 [0.000, 3.000],  loss: 213.639206, mae: 313.775252, mean_q: 423.286844, mean_eps: 0.298243
 234292/300000: episode: 1775, duration: 1.581s, episode steps: 242, steps per second: 153, episode reward: -501.419, mean reward: -2.072 [-100.000,  2.779], mean action: 1.711 [0.000, 3.000],  loss: 199.224997, mae: 312.419191, mean_q: 420.198696, mean_eps: 0.297489
 234756/300000: episode: 1776, duration: 3.264s, episode steps: 464, steps per second: 142, episode reward: -746.090, mean reward: -1.608 [-100.000,  6.364], mean action: 1.806 [0.000, 3.000],  loss: 268.197893, mae: 309.416875, mean_q: 416.614970, mean_eps: 0.296430
 235338/300000: episode: 1777, duration: 4.403s, episode steps: 582, steps per second: 132, episode reward: -179.257, mean reward: -0.308 [-100.000, 11.293], mean action: 1.711 [0.000, 3.000],  loss: 223.814649, mae: 300.019168, mean_q: 404.336760, mean_eps: 0.294861
 235734/300000: episode: 1778, duration: 3.037s, episode steps: 396, steps per second: 130, episode reward: -334.363, mean reward: -0.844 [-100.000, 10.276], mean action: 1.674 [0.000, 3.000],  loss: 200.284989, mae: 299.066848, mean_q: 402.618291, mean_eps: 0.293393
 236336/300000: episode: 1779, duration: 4.505s, episode steps: 602, steps per second: 134, episode reward: -356.591, mean reward: -0.592 [-100.000, 187.256], mean action: 1.676 [0.000, 3.000],  loss: 179.321927, mae: 299.619928, mean_q: 402.924740, mean_eps: 0.291897
 236813/300000: episode: 1780, duration: 3.393s, episode steps: 477, steps per second: 141, episode reward: -195.216, mean reward: -0.409 [-100.000,  6.127], mean action: 1.822 [0.000, 3.000],  loss: 175.920380, mae: 302.630582, mean_q: 407.552143, mean_eps: 0.290278
 237369/300000: episode: 1781, duration: 4.208s, episode steps: 556, steps per second: 132, episode reward: -469.584, mean reward: -0.845 [-100.000, 22.908], mean action: 1.901 [0.000, 3.000],  loss: 147.725354, mae: 300.468418, mean_q: 405.058931, mean_eps: 0.288728
 237665/300000: episode: 1782, duration: 2.015s, episode steps: 296, steps per second: 147, episode reward: -405.656, mean reward: -1.370 [-100.000,  5.660], mean action: 1.895 [0.000, 3.000],  loss: 144.608341, mae: 303.670747, mean_q: 409.510120, mean_eps: 0.287451
 238075/300000: episode: 1783, duration: 2.811s, episode steps: 410, steps per second: 146, episode reward: -344.375, mean reward: -0.840 [-100.000, 18.907], mean action: 1.522 [0.000, 3.000],  loss: 173.719245, mae: 301.145621, mean_q: 405.863636, mean_eps: 0.286391
 238198/300000: episode: 1784, duration: 0.841s, episode steps: 123, steps per second: 146, episode reward: -2.557, mean reward: -0.021 [-100.000, 15.682], mean action: 1.569 [0.000, 3.000],  loss: 241.591139, mae: 297.356875, mean_q: 399.450550, mean_eps: 0.285592
 238593/300000: episode: 1785, duration: 2.716s, episode steps: 395, steps per second: 145, episode reward: -176.671, mean reward: -0.447 [-100.000,  5.055], mean action: 1.752 [0.000, 3.000],  loss: 163.239745, mae: 296.680518, mean_q: 398.517280, mean_eps: 0.284815
 238875/300000: episode: 1786, duration: 1.901s, episode steps: 282, steps per second: 148, episode reward: -221.370, mean reward: -0.785 [-100.000,  5.168], mean action: 1.780 [0.000, 3.000],  loss: 191.201466, mae: 296.665447, mean_q: 398.947323, mean_eps: 0.283799
 239110/300000: episode: 1787, duration: 1.852s, episode steps: 235, steps per second: 127, episode reward: -338.945, mean reward: -1.442 [-100.000, 13.299], mean action: 1.711 [0.000, 3.000],  loss: 163.420122, mae: 291.472133, mean_q: 391.733242, mean_eps: 0.283024
 239959/300000: episode: 1788, duration: 6.524s, episode steps: 849, steps per second: 130, episode reward: -118.020, mean reward: -0.139 [-100.000, 14.544], mean action: 1.713 [0.000, 3.000],  loss: 158.795058, mae: 281.661748, mean_q: 378.265809, mean_eps: 0.281398
 240948/300000: episode: 1789, duration: 8.581s, episode steps: 989, steps per second: 115, episode reward: -420.079, mean reward: -0.425 [-100.000, 12.458], mean action: 1.803 [0.000, 3.000],  loss: 137.340160, mae: 279.544439, mean_q: 375.637117, mean_eps: 0.278641
 241201/300000: episode: 1790, duration: 1.982s, episode steps: 253, steps per second: 128, episode reward: -95.801, mean reward: -0.379 [-100.000,  6.034], mean action: 1.850 [0.000, 3.000],  loss: 129.338831, mae: 271.823972, mean_q: 364.731323, mean_eps: 0.276778
 242201/300000: episode: 1791, duration: 7.533s, episode steps: 1000, steps per second: 133, episode reward:  2.475, mean reward:  0.002 [-24.498, 24.599], mean action: 1.714 [0.000, 3.000],  loss: 124.952084, mae: 265.490359, mean_q: 355.701137, mean_eps: 0.274898
 242553/300000: episode: 1792, duration: 2.737s, episode steps: 352, steps per second: 129, episode reward: -203.357, mean reward: -0.578 [-100.000, 10.447], mean action: 1.827 [0.000, 3.000],  loss: 102.408027, mae: 255.525750, mean_q: 342.122604, mean_eps: 0.272870
 243553/300000: episode: 1793, duration: 7.943s, episode steps: 1000, steps per second: 126, episode reward: -110.843, mean reward: -0.111 [-21.906, 21.445], mean action: 1.773 [0.000, 3.000],  loss: 124.653440, mae: 255.324100, mean_q: 342.624336, mean_eps: 0.270842
 243676/300000: episode: 1794, duration: 1.091s, episode steps: 123, steps per second: 113, episode reward: 23.829, mean reward:  0.194 [-100.000, 35.049], mean action: 1.724 [0.000, 3.000],  loss: 99.880175, mae: 257.233881, mean_q: 345.001634, mean_eps: 0.269158
 243963/300000: episode: 1795, duration: 2.027s, episode steps: 287, steps per second: 142, episode reward: -167.607, mean reward: -0.584 [-100.000, 10.738], mean action: 1.711 [0.000, 3.000],  loss: 112.338847, mae: 261.540749, mean_q: 351.512373, mean_eps: 0.268543
 244963/300000: episode: 1796, duration: 8.120s, episode steps: 1000, steps per second: 123, episode reward: 26.447, mean reward:  0.026 [-21.476, 22.201], mean action: 1.884 [0.000, 3.000],  loss: 124.319490, mae: 256.304176, mean_q: 343.496775, mean_eps: 0.266612
 245963/300000: episode: 1797, duration: 7.776s, episode steps: 1000, steps per second: 129, episode reward: 27.156, mean reward:  0.027 [-20.584, 27.496], mean action: 1.669 [0.000, 3.000],  loss: 127.198133, mae: 253.310568, mean_q: 338.826746, mean_eps: 0.263613
 246118/300000: episode: 1798, duration: 1.039s, episode steps: 155, steps per second: 149, episode reward: -246.688, mean reward: -1.592 [-100.000, 10.454], mean action: 1.639 [0.000, 3.000],  loss: 131.620900, mae: 254.451191, mean_q: 340.938570, mean_eps: 0.261880
 246226/300000: episode: 1799, duration: 0.807s, episode steps: 108, steps per second: 134, episode reward: -211.705, mean reward: -1.960 [-100.000,  4.569], mean action: 1.889 [0.000, 3.000],  loss: 114.969848, mae: 249.113113, mean_q: 333.507499, mean_eps: 0.261485
 246378/300000: episode: 1800, duration: 1.524s, episode steps: 152, steps per second: 100, episode reward: -160.269, mean reward: -1.054 [-100.000,  7.205], mean action: 1.750 [0.000, 3.000],  loss: 101.710648, mae: 252.387805, mean_q: 338.285847, mean_eps: 0.261095
 246617/300000: episode: 1801, duration: 2.354s, episode steps: 239, steps per second: 102, episode reward: -302.893, mean reward: -1.267 [-100.000, 28.808], mean action: 1.736 [0.000, 3.000],  loss: 123.981063, mae: 249.637951, mean_q: 333.993064, mean_eps: 0.260509
 247047/300000: episode: 1802, duration: 3.385s, episode steps: 430, steps per second: 127, episode reward: -101.296, mean reward: -0.236 [-100.000, 29.608], mean action: 1.749 [0.000, 3.000],  loss: 115.954153, mae: 249.805963, mean_q: 334.241790, mean_eps: 0.259506
 247452/300000: episode: 1803, duration: 2.773s, episode steps: 405, steps per second: 146, episode reward: -397.179, mean reward: -0.981 [-100.000, 21.572], mean action: 1.874 [0.000, 3.000],  loss: 124.854817, mae: 255.368802, mean_q: 341.970314, mean_eps: 0.258253
 247654/300000: episode: 1804, duration: 1.346s, episode steps: 202, steps per second: 150, episode reward: -210.571, mean reward: -1.042 [-100.000,  8.237], mean action: 1.614 [0.000, 3.000],  loss: 127.282394, mae: 261.993889, mean_q: 350.926902, mean_eps: 0.257342
 247836/300000: episode: 1805, duration: 1.154s, episode steps: 182, steps per second: 158, episode reward: -72.089, mean reward: -0.396 [-100.000, 10.174], mean action: 1.692 [0.000, 3.000],  loss: 135.765510, mae: 258.653596, mean_q: 346.314310, mean_eps: 0.256766
 248020/300000: episode: 1806, duration: 1.219s, episode steps: 184, steps per second: 151, episode reward: -69.976, mean reward: -0.380 [-100.000, 12.930], mean action: 1.674 [0.000, 3.000],  loss: 141.448331, mae: 259.519429, mean_q: 346.713244, mean_eps: 0.256217
 248146/300000: episode: 1807, duration: 0.811s, episode steps: 126, steps per second: 155, episode reward: -154.970, mean reward: -1.230 [-100.000,  3.787], mean action: 1.643 [0.000, 3.000],  loss: 154.369927, mae: 256.348409, mean_q: 342.476977, mean_eps: 0.255752
 248242/300000: episode: 1808, duration: 0.631s, episode steps:  96, steps per second: 152, episode reward: -144.987, mean reward: -1.510 [-100.000,  1.939], mean action: 1.719 [0.000, 3.000],  loss: 125.970170, mae: 254.884646, mean_q: 341.234221, mean_eps: 0.255419
 248430/300000: episode: 1809, duration: 1.424s, episode steps: 188, steps per second: 132, episode reward: -153.712, mean reward: -0.818 [-100.000,  4.922], mean action: 1.633 [0.000, 3.000],  loss: 164.231978, mae: 252.790025, mean_q: 338.270765, mean_eps: 0.254993
 248688/300000: episode: 1810, duration: 3.283s, episode steps: 258, steps per second:  79, episode reward: -245.854, mean reward: -0.953 [-100.000, 11.223], mean action: 1.752 [0.000, 3.000],  loss: 123.106442, mae: 248.647412, mean_q: 332.028682, mean_eps: 0.254324
 249395/300000: episode: 1811, duration: 7.555s, episode steps: 707, steps per second:  94, episode reward: -128.108, mean reward: -0.181 [-100.000, 20.433], mean action: 1.949 [0.000, 3.000],  loss: 126.556564, mae: 248.513751, mean_q: 332.509210, mean_eps: 0.252877
 250395/300000: episode: 1812, duration: 8.915s, episode steps: 1000, steps per second: 112, episode reward: 79.887, mean reward:  0.080 [-24.545, 25.805], mean action: 1.809 [0.000, 3.000],  loss: 102.747099, mae: 239.990421, mean_q: 321.491658, mean_eps: 0.250316
 250919/300000: episode: 1813, duration: 5.521s, episode steps: 524, steps per second:  95, episode reward: -712.846, mean reward: -1.360 [-100.000, 121.522], mean action: 1.851 [0.000, 3.000],  loss: 100.576574, mae: 227.850247, mean_q: 304.411238, mean_eps: 0.248031
 251118/300000: episode: 1814, duration: 3.666s, episode steps: 199, steps per second:  54, episode reward: -158.225, mean reward: -0.795 [-100.000,  5.755], mean action: 1.779 [0.000, 3.000],  loss: 102.618686, mae: 228.876749, mean_q: 306.071245, mean_eps: 0.246946
 251568/300000: episode: 1815, duration: 3.774s, episode steps: 450, steps per second: 119, episode reward: -274.022, mean reward: -0.609 [-100.000,  5.750], mean action: 1.829 [0.000, 3.000],  loss: 116.003460, mae: 233.702436, mean_q: 312.067174, mean_eps: 0.245972
 251801/300000: episode: 1816, duration: 1.681s, episode steps: 233, steps per second: 139, episode reward: -105.513, mean reward: -0.453 [-100.000, 28.929], mean action: 1.485 [0.000, 3.000],  loss: 128.424705, mae: 232.565812, mean_q: 309.892361, mean_eps: 0.244948
 252035/300000: episode: 1817, duration: 1.580s, episode steps: 234, steps per second: 148, episode reward: -301.696, mean reward: -1.289 [-100.000,  4.419], mean action: 1.885 [0.000, 3.000],  loss: 96.205977, mae: 229.529238, mean_q: 305.948529, mean_eps: 0.244247
 252201/300000: episode: 1818, duration: 1.157s, episode steps: 166, steps per second: 143, episode reward: -120.677, mean reward: -0.727 [-100.000,  3.125], mean action: 1.566 [0.000, 3.000],  loss: 93.775999, mae: 227.206155, mean_q: 301.316159, mean_eps: 0.243647
 252392/300000: episode: 1819, duration: 1.762s, episode steps: 191, steps per second: 108, episode reward: -259.571, mean reward: -1.359 [-100.000,  3.956], mean action: 1.916 [0.000, 3.000],  loss: 78.248171, mae: 225.613624, mean_q: 300.010272, mean_eps: 0.243112
 252530/300000: episode: 1820, duration: 1.115s, episode steps: 138, steps per second: 124, episode reward: -124.434, mean reward: -0.902 [-100.000,  3.552], mean action: 1.486 [0.000, 3.000],  loss: 96.090388, mae: 221.532316, mean_q: 293.372310, mean_eps: 0.242618
 252751/300000: episode: 1821, duration: 1.748s, episode steps: 221, steps per second: 126, episode reward: -230.357, mean reward: -1.042 [-100.000,  8.609], mean action: 1.765 [0.000, 3.000],  loss: 100.403813, mae: 219.452359, mean_q: 291.603722, mean_eps: 0.242080
 252867/300000: episode: 1822, duration: 0.806s, episode steps: 116, steps per second: 144, episode reward: -1.416, mean reward: -0.012 [-100.000, 13.864], mean action: 1.819 [0.000, 3.000],  loss: 97.920972, mae: 214.197298, mean_q: 283.813810, mean_eps: 0.241574
 252988/300000: episode: 1823, duration: 0.851s, episode steps: 121, steps per second: 142, episode reward: -107.677, mean reward: -0.890 [-100.000, 14.221], mean action: 1.835 [0.000, 3.000],  loss: 86.038005, mae: 214.278753, mean_q: 283.425039, mean_eps: 0.241219
 253214/300000: episode: 1824, duration: 2.559s, episode steps: 226, steps per second:  88, episode reward: -211.125, mean reward: -0.934 [-100.000,  4.200], mean action: 1.872 [0.000, 3.000],  loss: 84.493411, mae: 214.824272, mean_q: 283.909849, mean_eps: 0.240698
 253395/300000: episode: 1825, duration: 1.693s, episode steps: 181, steps per second: 107, episode reward: -116.746, mean reward: -0.645 [-100.000,  4.567], mean action: 1.680 [0.000, 3.000],  loss: 77.797550, mae: 215.084989, mean_q: 284.214818, mean_eps: 0.240088
 253600/300000: episode: 1826, duration: 1.719s, episode steps: 205, steps per second: 119, episode reward: -236.239, mean reward: -1.152 [-100.000,  3.868], mean action: 1.766 [0.000, 3.000],  loss: 135.871539, mae: 210.333198, mean_q: 277.899507, mean_eps: 0.239509
 253697/300000: episode: 1827, duration: 0.806s, episode steps:  97, steps per second: 120, episode reward: -140.094, mean reward: -1.444 [-100.000,  2.651], mean action: 1.753 [0.000, 3.000],  loss: 88.313144, mae: 203.422379, mean_q: 268.538378, mean_eps: 0.239056
 253925/300000: episode: 1828, duration: 2.334s, episode steps: 228, steps per second:  98, episode reward: -1229.203, mean reward: -5.391 [-100.000, 143.269], mean action: 2.219 [0.000, 3.000],  loss: 108.567218, mae: 203.568301, mean_q: 267.470293, mean_eps: 0.238568
 254121/300000: episode: 1829, duration: 2.343s, episode steps: 196, steps per second:  84, episode reward: -121.879, mean reward: -0.622 [-100.000,  5.102], mean action: 1.638 [0.000, 3.000],  loss: 301.691351, mae: 206.681708, mean_q: 271.907151, mean_eps: 0.237932
 254239/300000: episode: 1830, duration: 1.248s, episode steps: 118, steps per second:  95, episode reward: -197.158, mean reward: -1.671 [-100.000, 34.651], mean action: 1.754 [0.000, 3.000],  loss: 150.621745, mae: 209.578381, mean_q: 278.077585, mean_eps: 0.237461
 254413/300000: episode: 1831, duration: 1.197s, episode steps: 174, steps per second: 145, episode reward: -171.823, mean reward: -0.987 [-100.000,  4.298], mean action: 1.776 [0.000, 3.000],  loss: 158.143188, mae: 209.546480, mean_q: 279.019941, mean_eps: 0.237023
 254688/300000: episode: 1832, duration: 1.815s, episode steps: 275, steps per second: 152, episode reward: -864.572, mean reward: -3.144 [-100.000,  3.704], mean action: 2.036 [0.000, 3.000],  loss: 173.281057, mae: 208.973799, mean_q: 277.876706, mean_eps: 0.236350
 254807/300000: episode: 1833, duration: 0.767s, episode steps: 119, steps per second: 155, episode reward: -135.628, mean reward: -1.140 [-100.000,  2.487], mean action: 1.571 [0.000, 3.000],  loss: 118.277735, mae: 208.706173, mean_q: 277.338169, mean_eps: 0.235759
 254913/300000: episode: 1834, duration: 0.729s, episode steps: 106, steps per second: 145, episode reward: -251.966, mean reward: -2.377 [-100.000,  8.464], mean action: 0.953 [0.000, 3.000],  loss: 223.430059, mae: 209.102572, mean_q: 277.155123, mean_eps: 0.235421
 255047/300000: episode: 1835, duration: 1.001s, episode steps: 134, steps per second: 134, episode reward: -305.743, mean reward: -2.282 [-100.000,  8.544], mean action: 1.418 [0.000, 3.000],  loss: 195.010867, mae: 208.726131, mean_q: 277.688256, mean_eps: 0.235062
 255188/300000: episode: 1836, duration: 0.995s, episode steps: 141, steps per second: 142, episode reward: -332.862, mean reward: -2.361 [-100.000,  4.077], mean action: 1.872 [0.000, 3.000],  loss: 154.804253, mae: 206.293129, mean_q: 273.385410, mean_eps: 0.234649
 255325/300000: episode: 1837, duration: 1.235s, episode steps: 137, steps per second: 111, episode reward: -46.306, mean reward: -0.338 [-100.000, 12.547], mean action: 1.511 [0.000, 3.000],  loss: 137.626321, mae: 205.641397, mean_q: 272.644319, mean_eps: 0.234232
 255456/300000: episode: 1838, duration: 1.673s, episode steps: 131, steps per second:  78, episode reward: -35.736, mean reward: -0.273 [-100.000, 19.520], mean action: 1.992 [0.000, 3.000],  loss: 127.915843, mae: 202.980035, mean_q: 269.018851, mean_eps: 0.233830
 255631/300000: episode: 1839, duration: 1.457s, episode steps: 175, steps per second: 120, episode reward: -193.177, mean reward: -1.104 [-100.000,  4.002], mean action: 1.863 [0.000, 3.000],  loss: 70.030985, mae: 202.244353, mean_q: 267.365227, mean_eps: 0.233371
 255914/300000: episode: 1840, duration: 2.617s, episode steps: 283, steps per second: 108, episode reward: -293.127, mean reward: -1.036 [-100.000, 36.878], mean action: 1.901 [0.000, 3.000],  loss: 139.661820, mae: 202.376589, mean_q: 267.615406, mean_eps: 0.232684
 256050/300000: episode: 1841, duration: 1.332s, episode steps: 136, steps per second: 102, episode reward: -38.253, mean reward: -0.281 [-100.000, 13.308], mean action: 1.566 [0.000, 3.000],  loss: 141.669725, mae: 204.475248, mean_q: 270.578267, mean_eps: 0.232055
 256222/300000: episode: 1842, duration: 1.401s, episode steps: 172, steps per second: 123, episode reward: -38.593, mean reward: -0.224 [-100.000, 14.043], mean action: 1.849 [0.000, 3.000],  loss: 98.664878, mae: 200.668334, mean_q: 265.038861, mean_eps: 0.231593
 256502/300000: episode: 1843, duration: 2.459s, episode steps: 280, steps per second: 114, episode reward: -307.147, mean reward: -1.097 [-100.000, 23.472], mean action: 1.732 [0.000, 3.000],  loss: 86.568254, mae: 198.098888, mean_q: 261.297811, mean_eps: 0.230915
 256783/300000: episode: 1844, duration: 2.168s, episode steps: 281, steps per second: 130, episode reward: -354.600, mean reward: -1.262 [-100.000, 16.303], mean action: 1.644 [0.000, 3.000],  loss: 102.418911, mae: 195.132669, mean_q: 256.725056, mean_eps: 0.230074
 256971/300000: episode: 1845, duration: 1.282s, episode steps: 188, steps per second: 147, episode reward: -177.664, mean reward: -0.945 [-100.000,  8.679], mean action: 1.883 [0.000, 3.000],  loss: 103.210774, mae: 195.580681, mean_q: 257.199515, mean_eps: 0.229370
 257184/300000: episode: 1846, duration: 1.548s, episode steps: 213, steps per second: 138, episode reward: -160.761, mean reward: -0.755 [-100.000,  6.590], mean action: 1.765 [0.000, 3.000],  loss: 91.429998, mae: 193.753112, mean_q: 254.648019, mean_eps: 0.228769
 257394/300000: episode: 1847, duration: 1.406s, episode steps: 210, steps per second: 149, episode reward: 35.166, mean reward:  0.167 [-100.000, 12.923], mean action: 1.562 [0.000, 3.000],  loss: 101.001916, mae: 194.885308, mean_q: 257.515752, mean_eps: 0.228134
 257585/300000: episode: 1848, duration: 2.071s, episode steps: 191, steps per second:  92, episode reward: -190.875, mean reward: -0.999 [-100.000,  9.621], mean action: 1.586 [0.000, 3.000],  loss: 68.878995, mae: 194.342140, mean_q: 256.198834, mean_eps: 0.227533
 257921/300000: episode: 1849, duration: 2.458s, episode steps: 336, steps per second: 137, episode reward: -402.604, mean reward: -1.198 [-100.000, 23.188], mean action: 1.610 [0.000, 3.000],  loss: 86.487831, mae: 191.167663, mean_q: 251.608522, mean_eps: 0.226742
 258921/300000: episode: 1850, duration: 7.721s, episode steps: 1000, steps per second: 130, episode reward: 162.656, mean reward:  0.163 [-20.790, 23.093], mean action: 1.139 [0.000, 3.000],  loss: 96.142304, mae: 184.345085, mean_q: 242.635365, mean_eps: 0.224738
 259297/300000: episode: 1851, duration: 2.674s, episode steps: 376, steps per second: 141, episode reward: -403.143, mean reward: -1.072 [-100.000, 20.353], mean action: 1.630 [0.000, 3.000],  loss: 101.110476, mae: 178.981516, mean_q: 234.822252, mean_eps: 0.222674
 259552/300000: episode: 1852, duration: 1.990s, episode steps: 255, steps per second: 128, episode reward: -58.555, mean reward: -0.230 [-100.000,  9.985], mean action: 1.624 [0.000, 3.000],  loss: 118.584545, mae: 175.440413, mean_q: 228.909246, mean_eps: 0.221728
 260552/300000: episode: 1853, duration: 7.512s, episode steps: 1000, steps per second: 133, episode reward: 98.169, mean reward:  0.098 [-23.742, 23.089], mean action: 1.178 [0.000, 3.000],  loss: 93.762572, mae: 174.114172, mean_q: 226.941317, mean_eps: 0.219845
 261552/300000: episode: 1854, duration: 7.778s, episode steps: 1000, steps per second: 129, episode reward: 114.857, mean reward:  0.115 [-21.145, 22.582], mean action: 1.761 [0.000, 3.000],  loss: 107.644399, mae: 170.084187, mean_q: 221.677502, mean_eps: 0.216845
 261853/300000: episode: 1855, duration: 2.313s, episode steps: 301, steps per second: 130, episode reward:  8.741, mean reward:  0.029 [-100.000, 15.962], mean action: 1.635 [0.000, 3.000],  loss: 83.649101, mae: 167.592580, mean_q: 218.680679, mean_eps: 0.214894
 262853/300000: episode: 1856, duration: 7.833s, episode steps: 1000, steps per second: 128, episode reward: -126.363, mean reward: -0.126 [-19.124, 15.307], mean action: 1.653 [0.000, 3.000],  loss: 103.157685, mae: 163.057167, mean_q: 212.360949, mean_eps: 0.212943
 262975/300000: episode: 1857, duration: 0.793s, episode steps: 122, steps per second: 154, episode reward: -473.931, mean reward: -3.885 [-100.000,  4.980], mean action: 1.844 [0.000, 3.000],  loss: 326.050405, mae: 161.209207, mean_q: 209.419303, mean_eps: 0.211259
 263975/300000: episode: 1858, duration: 7.062s, episode steps: 1000, steps per second: 142, episode reward: 151.650, mean reward:  0.152 [-21.028, 22.237], mean action: 1.707 [0.000, 3.000],  loss: 97.504371, mae: 156.466834, mean_q: 203.315079, mean_eps: 0.209576
 264512/300000: episode: 1859, duration: 4.233s, episode steps: 537, steps per second: 127, episode reward: -144.907, mean reward: -0.270 [-100.000, 16.323], mean action: 1.654 [0.000, 3.000],  loss: 72.761744, mae: 153.138691, mean_q: 198.735598, mean_eps: 0.207271
 264930/300000: episode: 1860, duration: 3.606s, episode steps: 418, steps per second: 116, episode reward: -245.746, mean reward: -0.588 [-100.000, 26.910], mean action: 1.536 [0.000, 3.000],  loss: 75.284434, mae: 153.398975, mean_q: 200.630986, mean_eps: 0.205838
 265166/300000: episode: 1861, duration: 1.772s, episode steps: 236, steps per second: 133, episode reward: -200.553, mean reward: -0.850 [-100.000, 21.851], mean action: 1.771 [0.000, 3.000],  loss: 90.845034, mae: 155.136046, mean_q: 203.246783, mean_eps: 0.204857
 266166/300000: episode: 1862, duration: 7.525s, episode steps: 1000, steps per second: 133, episode reward: 63.094, mean reward:  0.063 [-19.178, 14.449], mean action: 1.630 [0.000, 3.000],  loss: 70.531095, mae: 154.099159, mean_q: 201.316293, mean_eps: 0.203003
 266313/300000: episode: 1863, duration: 1.017s, episode steps: 147, steps per second: 145, episode reward: -94.030, mean reward: -0.640 [-100.000, 16.623], mean action: 1.687 [0.000, 3.000],  loss: 124.884662, mae: 152.430524, mean_q: 199.034334, mean_eps: 0.201283
 266498/300000: episode: 1864, duration: 1.236s, episode steps: 185, steps per second: 150, episode reward: -223.721, mean reward: -1.209 [-100.000,  4.607], mean action: 1.611 [0.000, 3.000],  loss: 64.794256, mae: 150.924286, mean_q: 197.545434, mean_eps: 0.200785
 267498/300000: episode: 1865, duration: 8.683s, episode steps: 1000, steps per second: 115, episode reward: 95.903, mean reward:  0.096 [-21.469, 15.470], mean action: 1.422 [0.000, 3.000],  loss: 65.023988, mae: 147.205902, mean_q: 192.313681, mean_eps: 0.199008
 268397/300000: episode: 1866, duration: 7.756s, episode steps: 899, steps per second: 116, episode reward: -387.018, mean reward: -0.430 [-100.000, 17.691], mean action: 1.701 [0.000, 3.000],  loss: 63.083990, mae: 144.384376, mean_q: 189.197950, mean_eps: 0.196159
 268582/300000: episode: 1867, duration: 1.242s, episode steps: 185, steps per second: 149, episode reward: -113.130, mean reward: -0.612 [-100.000, 11.181], mean action: 1.708 [0.000, 3.000],  loss: 89.612974, mae: 142.987670, mean_q: 187.530551, mean_eps: 0.194533
 268904/300000: episode: 1868, duration: 2.386s, episode steps: 322, steps per second: 135, episode reward: -139.706, mean reward: -0.434 [-100.000, 12.479], mean action: 1.702 [0.000, 3.000],  loss: 105.939462, mae: 141.611023, mean_q: 185.004287, mean_eps: 0.193773
 269040/300000: episode: 1869, duration: 0.925s, episode steps: 136, steps per second: 147, episode reward: -180.942, mean reward: -1.330 [-100.000, 18.930], mean action: 1.882 [0.000, 3.000],  loss: 51.431582, mae: 143.686949, mean_q: 188.709636, mean_eps: 0.193085
 269856/300000: episode: 1870, duration: 6.717s, episode steps: 816, steps per second: 121, episode reward: -296.192, mean reward: -0.363 [-100.000, 10.736], mean action: 1.570 [0.000, 3.000],  loss: 78.619038, mae: 140.938775, mean_q: 184.450360, mean_eps: 0.191657
 270054/300000: episode: 1871, duration: 1.427s, episode steps: 198, steps per second: 139, episode reward: -183.034, mean reward: -0.924 [-100.000,  3.427], mean action: 1.591 [0.000, 3.000],  loss: 57.326371, mae: 137.175695, mean_q: 178.669354, mean_eps: 0.190137
 271054/300000: episode: 1872, duration: 7.688s, episode steps: 1000, steps per second: 130, episode reward: -35.246, mean reward: -0.035 [-5.379,  4.465], mean action: 1.782 [0.000, 3.000],  loss: 46.041954, mae: 132.818181, mean_q: 172.167185, mean_eps: 0.188339
 272054/300000: episode: 1873, duration: 9.524s, episode steps: 1000, steps per second: 105, episode reward: -91.135, mean reward: -0.091 [-12.823, 12.376], mean action: 1.670 [0.000, 3.000],  loss: 44.980784, mae: 125.314937, mean_q: 162.679756, mean_eps: 0.185339
 273000/300000: episode: 1874, duration: 8.992s, episode steps: 946, steps per second: 105, episode reward: -123.652, mean reward: -0.131 [-100.000, 23.972], mean action: 1.705 [0.000, 3.000],  loss: 63.881615, mae: 124.337418, mean_q: 162.038285, mean_eps: 0.182420
 273136/300000: episode: 1875, duration: 0.910s, episode steps: 136, steps per second: 149, episode reward: -287.840, mean reward: -2.116 [-100.000,  3.247], mean action: 1.640 [0.000, 3.000],  loss: 45.594978, mae: 126.632277, mean_q: 165.845938, mean_eps: 0.180797
 273696/300000: episode: 1876, duration: 3.977s, episode steps: 560, steps per second: 141, episode reward: -195.850, mean reward: -0.350 [-100.000, 22.457], mean action: 1.595 [0.000, 3.000],  loss: 40.188080, mae: 123.232626, mean_q: 160.756918, mean_eps: 0.179753
 273831/300000: episode: 1877, duration: 0.865s, episode steps: 135, steps per second: 156, episode reward: -339.194, mean reward: -2.513 [-100.000,  2.834], mean action: 1.674 [0.000, 3.000],  loss: 34.997667, mae: 121.059443, mean_q: 158.493442, mean_eps: 0.178711
 274831/300000: episode: 1878, duration: 8.468s, episode steps: 1000, steps per second: 118, episode reward: 38.811, mean reward:  0.039 [-21.834, 21.605], mean action: 1.637 [0.000, 3.000],  loss: 33.202200, mae: 117.258529, mean_q: 152.588367, mean_eps: 0.177008
 275831/300000: episode: 1879, duration: 10.109s, episode steps: 1000, steps per second:  99, episode reward: 48.831, mean reward:  0.049 [-22.665, 23.468], mean action: 1.843 [0.000, 3.000],  loss: 34.583504, mae: 114.165379, mean_q: 149.349656, mean_eps: 0.174008
 276187/300000: episode: 1880, duration: 4.005s, episode steps: 356, steps per second:  89, episode reward: -159.949, mean reward: -0.449 [-100.000, 10.642], mean action: 1.784 [0.000, 3.000],  loss: 35.418769, mae: 114.148575, mean_q: 150.383296, mean_eps: 0.171974
 277087/300000: episode: 1881, duration: 7.589s, episode steps: 900, steps per second: 119, episode reward: 49.051, mean reward:  0.055 [-21.047, 100.000], mean action: 1.179 [0.000, 3.000],  loss: 35.228296, mae: 116.242491, mean_q: 153.357947, mean_eps: 0.170090
 277863/300000: episode: 1882, duration: 6.021s, episode steps: 776, steps per second: 129, episode reward: 122.444, mean reward:  0.158 [-12.267, 100.000], mean action: 1.526 [0.000, 3.000],  loss: 29.651119, mae: 116.605857, mean_q: 155.014889, mean_eps: 0.167576
 277984/300000: episode: 1883, duration: 0.769s, episode steps: 121, steps per second: 157, episode reward: -30.010, mean reward: -0.248 [-100.000, 22.043], mean action: 1.719 [0.000, 3.000],  loss: 28.590888, mae: 117.944300, mean_q: 156.689510, mean_eps: 0.166231
 278984/300000: episode: 1884, duration: 7.195s, episode steps: 1000, steps per second: 139, episode reward: 19.179, mean reward:  0.019 [-22.708, 22.818], mean action: 1.489 [0.000, 3.000],  loss: 26.896767, mae: 115.400453, mean_q: 153.370537, mean_eps: 0.164549
 279984/300000: episode: 1885, duration: 7.317s, episode steps: 1000, steps per second: 137, episode reward:  4.791, mean reward:  0.005 [-20.326, 22.166], mean action: 1.503 [0.000, 3.000],  loss: 31.762387, mae: 113.119474, mean_q: 151.102977, mean_eps: 0.161549
 280984/300000: episode: 1886, duration: 8.650s, episode steps: 1000, steps per second: 116, episode reward: 77.549, mean reward:  0.078 [-21.316, 22.151], mean action: 1.649 [0.000, 3.000],  loss: 28.289318, mae: 110.174232, mean_q: 147.378135, mean_eps: 0.158549
 281984/300000: episode: 1887, duration: 7.731s, episode steps: 1000, steps per second: 129, episode reward: -56.788, mean reward: -0.057 [-3.947,  6.565], mean action: 1.730 [0.000, 3.000],  loss: 22.096139, mae: 105.065534, mean_q: 140.257678, mean_eps: 0.155549
 282491/300000: episode: 1888, duration: 3.963s, episode steps: 507, steps per second: 128, episode reward: -203.226, mean reward: -0.401 [-100.000, 15.539], mean action: 1.617 [0.000, 3.000],  loss: 22.656877, mae: 102.265005, mean_q: 136.384710, mean_eps: 0.153289
 283491/300000: episode: 1889, duration: 8.826s, episode steps: 1000, steps per second: 113, episode reward: 36.334, mean reward:  0.036 [-22.023, 22.981], mean action: 1.684 [0.000, 3.000],  loss: 19.942997, mae: 102.481325, mean_q: 136.845950, mean_eps: 0.151028
 284491/300000: episode: 1890, duration: 7.936s, episode steps: 1000, steps per second: 126, episode reward: 24.864, mean reward:  0.025 [-21.653, 21.914], mean action: 1.942 [0.000, 3.000],  loss: 21.556305, mae: 101.762918, mean_q: 136.098999, mean_eps: 0.148028
 285491/300000: episode: 1891, duration: 8.739s, episode steps: 1000, steps per second: 114, episode reward: 46.721, mean reward:  0.047 [-21.920, 24.940], mean action: 1.429 [0.000, 3.000],  loss: 18.658898, mae: 96.275969, mean_q: 128.937564, mean_eps: 0.145028
 286491/300000: episode: 1892, duration: 7.616s, episode steps: 1000, steps per second: 131, episode reward: 78.204, mean reward:  0.078 [-19.018, 22.555], mean action: 1.534 [0.000, 3.000],  loss: 17.082489, mae: 95.745728, mean_q: 128.194786, mean_eps: 0.142028
 287230/300000: episode: 1893, duration: 6.205s, episode steps: 739, steps per second: 119, episode reward: 205.378, mean reward:  0.278 [-23.412, 100.000], mean action: 1.438 [0.000, 3.000],  loss: 17.083438, mae: 94.491388, mean_q: 126.455836, mean_eps: 0.139420
 287418/300000: episode: 1894, duration: 1.311s, episode steps: 188, steps per second: 143, episode reward: -229.819, mean reward: -1.222 [-100.000, 24.652], mean action: 1.878 [0.000, 3.000],  loss: 12.843739, mae: 95.120645, mean_q: 127.389946, mean_eps: 0.138029
 288057/300000: episode: 1895, duration: 5.320s, episode steps: 639, steps per second: 120, episode reward: 201.969, mean reward:  0.316 [-18.334, 100.000], mean action: 1.541 [0.000, 3.000],  loss: 18.535272, mae: 94.352067, mean_q: 126.216618, mean_eps: 0.136789
 288458/300000: episode: 1896, duration: 3.130s, episode steps: 401, steps per second: 128, episode reward: -190.971, mean reward: -0.476 [-100.000, 35.350], mean action: 1.925 [0.000, 3.000],  loss: 17.383640, mae: 90.587389, mean_q: 121.164810, mean_eps: 0.135229
 289458/300000: episode: 1897, duration: 7.872s, episode steps: 1000, steps per second: 127, episode reward: 15.155, mean reward:  0.015 [-4.728,  5.013], mean action: 1.594 [0.000, 3.000],  loss: 19.529777, mae: 86.398224, mean_q: 115.383959, mean_eps: 0.133128
 289635/300000: episode: 1898, duration: 1.323s, episode steps: 177, steps per second: 134, episode reward: -146.364, mean reward: -0.827 [-100.000,  5.077], mean action: 1.746 [0.000, 3.000],  loss: 18.916047, mae: 82.370572, mean_q: 109.964279, mean_eps: 0.131362
 290635/300000: episode: 1899, duration: 9.075s, episode steps: 1000, steps per second: 110, episode reward: 92.190, mean reward:  0.092 [-20.405, 24.085], mean action: 1.720 [0.000, 3.000],  loss: 18.041961, mae: 82.449931, mean_q: 110.010564, mean_eps: 0.129597
 291635/300000: episode: 1900, duration: 9.047s, episode steps: 1000, steps per second: 111, episode reward: 62.689, mean reward:  0.063 [-21.502, 21.054], mean action: 1.667 [0.000, 3.000],  loss: 21.549644, mae: 78.943266, mean_q: 105.117366, mean_eps: 0.126596
 292519/300000: episode: 1901, duration: 6.773s, episode steps: 884, steps per second: 131, episode reward: 186.128, mean reward:  0.211 [-21.092, 100.000], mean action: 1.396 [0.000, 3.000],  loss: 17.341540, mae: 77.498116, mean_q: 103.183569, mean_eps: 0.123770
 293292/300000: episode: 1902, duration: 5.582s, episode steps: 773, steps per second: 138, episode reward: 237.055, mean reward:  0.307 [-18.613, 100.000], mean action: 1.439 [0.000, 3.000],  loss: 14.913498, mae: 77.683252, mean_q: 103.497704, mean_eps: 0.121285
 293512/300000: episode: 1903, duration: 1.825s, episode steps: 220, steps per second: 121, episode reward: -113.994, mean reward: -0.518 [-100.000,  4.932], mean action: 1.523 [0.000, 3.000],  loss: 16.308922, mae: 80.398797, mean_q: 107.554074, mean_eps: 0.119795
 293781/300000: episode: 1904, duration: 2.237s, episode steps: 269, steps per second: 120, episode reward: -308.322, mean reward: -1.146 [-100.000,  5.418], mean action: 1.662 [0.000, 3.000],  loss: 15.950291, mae: 82.149015, mean_q: 110.153970, mean_eps: 0.119062
 294168/300000: episode: 1905, duration: 2.949s, episode steps: 387, steps per second: 131, episode reward: 213.618, mean reward:  0.552 [-10.368, 100.000], mean action: 1.501 [0.000, 3.000],  loss: 13.869466, mae: 81.719518, mean_q: 109.822359, mean_eps: 0.118078
 294497/300000: episode: 1906, duration: 2.795s, episode steps: 329, steps per second: 118, episode reward: 206.615, mean reward:  0.628 [-9.388, 100.000], mean action: 1.277 [0.000, 3.000],  loss: 13.212186, mae: 83.051089, mean_q: 111.560957, mean_eps: 0.117004
 294602/300000: episode: 1907, duration: 1.090s, episode steps: 105, steps per second:  96, episode reward: -14.692, mean reward: -0.140 [-100.000,  8.861], mean action: 1.676 [0.000, 3.000],  loss: 24.475566, mae: 81.613072, mean_q: 109.271142, mean_eps: 0.116353
 294719/300000: episode: 1908, duration: 0.873s, episode steps: 117, steps per second: 134, episode reward: -113.482, mean reward: -0.970 [-100.000,  3.207], mean action: 1.598 [0.000, 3.000],  loss: 18.063608, mae: 82.815575, mean_q: 111.142076, mean_eps: 0.116020
 294851/300000: episode: 1909, duration: 1.148s, episode steps: 132, steps per second: 115, episode reward: -56.596, mean reward: -0.429 [-100.000, 33.764], mean action: 1.750 [0.000, 3.000],  loss: 17.265920, mae: 82.890264, mean_q: 111.211504, mean_eps: 0.115646
 294956/300000: episode: 1910, duration: 0.947s, episode steps: 105, steps per second: 111, episode reward: 26.927, mean reward:  0.256 [-100.000, 19.313], mean action: 1.629 [0.000, 3.000],  loss: 24.114108, mae: 83.017410, mean_q: 111.180030, mean_eps: 0.115291
 295812/300000: episode: 1911, duration: 6.817s, episode steps: 856, steps per second: 126, episode reward: 160.567, mean reward:  0.188 [-20.937, 100.000], mean action: 1.868 [0.000, 3.000],  loss: 18.562917, mae: 85.770701, mean_q: 114.897901, mean_eps: 0.113849
 296683/300000: episode: 1912, duration: 6.946s, episode steps: 871, steps per second: 125, episode reward: -127.304, mean reward: -0.146 [-100.000, 24.342], mean action: 1.642 [0.000, 3.000],  loss: 20.155082, mae: 86.024219, mean_q: 115.022357, mean_eps: 0.111259
 297271/300000: episode: 1913, duration: 4.819s, episode steps: 588, steps per second: 122, episode reward: -212.451, mean reward: -0.361 [-100.000,  5.250], mean action: 1.628 [0.000, 3.000],  loss: 20.473867, mae: 84.130217, mean_q: 112.102286, mean_eps: 0.109071
 297442/300000: episode: 1914, duration: 1.173s, episode steps: 171, steps per second: 146, episode reward: -30.576, mean reward: -0.179 [-100.000, 17.778], mean action: 1.474 [0.000, 3.000],  loss: 15.973761, mae: 82.045331, mean_q: 109.472111, mean_eps: 0.107932
 297561/300000: episode: 1915, duration: 0.768s, episode steps: 119, steps per second: 155, episode reward: -32.262, mean reward: -0.271 [-100.000, 57.390], mean action: 1.303 [0.000, 3.000],  loss: 20.573451, mae: 82.580140, mean_q: 110.101023, mean_eps: 0.107497
 297642/300000: episode: 1916, duration: 0.521s, episode steps:  81, steps per second: 156, episode reward: -78.047, mean reward: -0.964 [-100.000, 10.797], mean action: 0.951 [0.000, 3.000],  loss: 17.307681, mae: 83.695445, mean_q: 111.565519, mean_eps: 0.107197
 297723/300000: episode: 1917, duration: 0.542s, episode steps:  81, steps per second: 149, episode reward: -117.111, mean reward: -1.446 [-100.000,  9.300], mean action: 1.148 [0.000, 3.000],  loss: 17.397021, mae: 83.658181, mean_q: 111.404695, mean_eps: 0.106954
 297964/300000: episode: 1918, duration: 1.817s, episode steps: 241, steps per second: 133, episode reward: -59.039, mean reward: -0.245 [-100.000, 23.701], mean action: 1.643 [0.000, 3.000],  loss: 30.659684, mae: 84.402759, mean_q: 112.272707, mean_eps: 0.106471
 298964/300000: episode: 1919, duration: 8.473s, episode steps: 1000, steps per second: 118, episode reward: 71.085, mean reward:  0.071 [-21.373, 22.527], mean action: 1.803 [0.000, 3.000],  loss: 26.890249, mae: 85.594844, mean_q: 113.828524, mean_eps: 0.104609
 299115/300000: episode: 1920, duration: 1.288s, episode steps: 151, steps per second: 117, episode reward: -26.616, mean reward: -0.176 [-100.000, 17.882], mean action: 1.695 [0.000, 3.000],  loss: 15.803496, mae: 88.232943, mean_q: 117.483754, mean_eps: 0.102883
 299270/300000: episode: 1921, duration: 1.479s, episode steps: 155, steps per second: 105, episode reward: -400.460, mean reward: -2.584 [-100.000, 60.870], mean action: 1.465 [0.000, 3.000],  loss: 26.740726, mae: 89.405011, mean_q: 118.695935, mean_eps: 0.102424
 299448/300000: episode: 1922, duration: 1.475s, episode steps: 178, steps per second: 121, episode reward: -114.601, mean reward: -0.644 [-100.000,  6.699], mean action: 1.449 [0.000, 3.000],  loss: 26.462784, mae: 92.314102, mean_q: 122.610775, mean_eps: 0.101924
done, took 2199.474 seconds
Testing for 5 episodes ...
Episode 1: reward: 59.671, steps: 1000
Episode 2: reward: 175.547, steps: 780
Episode 3: reward: 30.339, steps: 293
Episode 4: reward: -44.507, steps: 208
Episode 5: reward: 6.976, steps: 1000